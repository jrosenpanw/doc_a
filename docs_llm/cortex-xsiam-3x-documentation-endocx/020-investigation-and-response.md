## Investigation and response

### Cases and issues

#### What are cases?

A case is a workbench for resolving security problems in your
environment. Each case groups related issues, highlights the impacted
assets, and provides essential data in one place. Cases help you stay
focused on threats and risks that have the most impact on the
organization security, help you to reduce noise in your environment, and
guide you to resolution using automation actions that reduce time and
effort.

Cases comprise the following objects:

- **Related issues:** Issues represent problems that were detected in
  your environment that exceed defined thresholds, or surpass your
  organization\'s accepted level of risk and threat tolerance.

- **Affected assets:** Cortex XSIAM identifies the assets impacted in a
  case, and how they fit into the story.

- **Artifacts:** Cortex XSIAM Artifacts are objects to which we can
  attribute behavior or influence, such as filenames, file signers,
  processes, domains, and IP addresses.

The following tabs describe the main features of cases and the problems
they can help you to solve:

##### Smart grouping

**Problems:** Understanding and remediating the full scope of a problem,
and struggling to identify the real issues due to alert fatigue

**Solution:** Smart grouping of issues based on context

To reduce the noise in your environment, Cortex XSIAM groups related
issues in a single case so that you can address the workload as a whole,
and see the full picture of the related risks and vulnerabilities.

In addition, to enable you to focus your efforts on the most critical
issues and identify the issues that need to be addressed first, issues
are ranked by severity.

![](media/rId1270.png){width="5.833333333333333in"
height="3.091666666666667in"}

##### SmartScore

**Problem:** What should I prioritize first

**Solution:** SmartScore for priority

Cortex XSIAM uses SmartScore and rule based scoring methods to assign a
score to each case that indicates the urgency of a case. On the
**Cases** page you easily identify the cases with high scores and
prioritize them accordingly. You can also star cases and set up starring
configurations to highlight your most important cases.

![](media/rId1274.png){width="5.833333333333333in"
height="3.120833333333333in"}

##### Remediation suggestions and automations

**Problem:** How to address and remediate the problem

**Solution:** Remediation suggestions and automations

Cortex XSIAM provides smart suggestions and guidance to help you to
investigate and remediate the issues in a case.In addition, Cortex XSIAM
provides OOTB playbooks that run automatically to remediate certain
issues. If no playbook is run, Cortex XSIAM offers playbook suggestions
or lists available playbooks. You can also create your own playbooks and
automation rules to automate the remediation of known issues,
automatically assign issues, or open tickets in your ticketing system
(for example, Jira).

![](media/rId1278.png){width="5.833333333333333in"
height="3.1135411198600176in"}

##### Tracking and SLAs

**Problem:** Tracking cases against defined KPIs

**Solution:** Tracking case progress and SLAs

Track your cases and linked issues through their full life cycle,
including tracking case progress, issue assignability and
accountability, and receiving notification for issue updates. In
addition, you can set up SLAs to help you to track KPIs, obtain
real-time insights into operational performance, and keep you inline
with company policies.

##### Additional case information

To see a list of all cases, go to Cases & Issues \> Cases.

A case can contain one or more related issues. Issues are linked to
cases by matching their content. If a new issue is triggered in the
system that doesn\'t match any of the existing cases, a new case is
created. When an issue is linked to a case, all associated assets and
artifacts are also linked to the case. Each case is individually
configured and requires its own independent investigation.

For the Security, IT, Health, and Custom domains, issues with
a Medium severity or higher automatically generate a case. While most
Low severity issues do not create cases, specific analytic rules can
trigger case creation for Low severity issues when action is deemed
necessary. Low severity issues created from correlation rules are not
grouped into cases.

For more information about working with cases, see [Investigate
cases](#UUID635a92a349ac52b8a5f774e748bccb51).

If a case is resolved with the status `Resolved - Auto Resolved`, Cortex
XSIAM can reopen the case for up-to six hours if a new issue is
triggered that matches the case. The six-hour period is defined by the
timestamp of the last issue that was grouped into the case. After the
six-hour period, any new issues are linked to a new case for a new
investigation.

While cases are configured to work OOTB, users with specific
requirements can customize and tailor their cases. For more information,
see [Customize your cases](#UUIDad57efe6e839808ea716418cb96b8e02).

##### Issues

Issues identify the problems that you need to solve in your environment.
Cortex XSIAM creates issues when problems occur in your environment that
cross defined thresholds, or surpass your organization\'s accepted level
of risk and threat tolerance.

Each issue comprises a defined framework of:

- **What happened:** A description of the problem

- **How is your environment impacted:** Affected assets or the impact of
  this issue in your environment

- **Contributing evidence:** Data that supports our analysis and
  observations

- **Recommended actions:** Automations, Playbooks, and manual
  suggestions

Issues are created from findings or from events that occur in your
environment. When an issue is created, Cortex XSIAM assess the content
of the issue and assign it to a new or existing case. In addition,
according to the content of the issue, it is assigned to a domain that
reflects the operational use case of the issue, such as **Security** or
**Posture**.

On the **Cases** page, you see the issues that are linked to a case in
the **Issues & Insights** tab. To start your investigation into an
issue, open an issue in the issue investigation pane to review issue
details, review the causality chain, run automations, and see the
suggested remediations.

Cortex XSIAM offers the flexibility to manually link and unlink issues
from cases. Issues can also be linked to multiple cases. In addition,
you can create your own custom issues from rules that you define. For
example, correlation rules, malware rules, and vulnerability rules. For
more information about setting up rules, see [What are detection
rules?](#UUID427485dcd0011e80a604173223507910)

##### Findings and events

Findings and events form the core of our knowledge data lake.

###### Findings

**Findings** are non-actionable, informational objects that provide
context about the *current state* of the assets in your environment.

To gather findings, Cortex XSIAM periodically scans the assets in your
environment and collects raw data about vulnerabilities, compliance,
exposures, malware, secrets, and other posture-related information about
the asset. This raw data is processed, saved to datasets, and recorded
as findings. Each time the assets are scanned, the finding are updated
to reflect the current state of the assets.

Each finding is categorized according to its context, for example
Configuration, Vulnerability, Compliance, or Identity, and is related
directly to the scanned asset. When you investigate an asset through the
**Asset Inventory**, you can see any findings that were collected for
the asset. 

Findings themselves are not issues, however findings that match a
specific logic can generate issues. You can also set up your own rules
to trigger issues when certain types of findings are recorded. For
example, you can set up Compliance rules that will create issues if
specific compliance fails are identified in compliance findings.

You can view all findings in the **Findings Table**. Access the
**Findings Table** from the **Issues** page or **Issues** tab in a case.
You can also search the `Findings` data set to see the findings
collected over time for an asset.

###### Events

**Events** are logged activities that occur in your environment.

Cortex XSIAM collects event logs that audit the activities that occur in
your environment. The logs are ingested from various sources, such as
Palo Alto Networks Next-Generation Firewall (NGFW), Prisma Access,
third-party sources, and EDRs. These logs provide a complete picture of
the events that occur in the environment and the activities surrounding
the events.

When certain malicious objects (such as malware) are discovered in the
event logs, an issue is created. During case investigation, you can
query your event logs to see information about the actors and processes
that triggered the issue.

#### Case and issue domains

Depending on the objects identified in a case or issue, each case and
issue is assigned to a domain that reflects the root cause and the
system areas of operation.

Domains are a contextual boundary that allow you to manage and
prioritize each use case and help you to differentiate between your
security use cases and non-security use cases. Domains help you to
organize and manage your work efforts, streamline the assignment of
cases, and enable you to create tailored experiences for each domain.

When an issue is created, Cortex XSIAM automatically assigns it to a
domain, and the same domain is assigned to the associated case. If you
create your own case, you can select the domain to which you want to
assign it.

You can see the assigned domain on the **Cases** and **Issues** pages.
Each case and issue is assigned to a single domain. You cannot change
the assigned domain, however cases can be linked to issues from
different domains.

##### Built-in domains

Cortex XSIAM provides the following built-in domains:

+-----------------------------------+-----------------------------------+
| Domain                            | Description                       |
+===================================+===================================+
| Security                          | For cases and issues that are     |
|                                   | associated with case response     |
|                                   | activities for detecting,         |
|                                   | preventing, and blocking threats  |
|                                   | as they occur in runtime.         |
|                                   |                                   |
|                                   | For example, identification of    |
|                                   | malware in a file, a compromised  |
|                                   | endpoint, or a phishing attempt.  |
|                                   | These cases can be assigned to a  |
|                                   | SOC analyst that specializes in   |
|                                   | blocking and remediating attacks. |
+-----------------------------------+-----------------------------------+
| Posture                           | For cases and issues that are     |
|                                   | associated with risk management   |
|                                   | activities to detect and mitigate |
|                                   | risks to assets in the            |
|                                   | environment before they occur in  |
|                                   | runtime, and improve resilience.  |
|                                   |                                   |
|                                   | For example, misconfigurations in |
|                                   | cloud instances, over-permissive  |
|                                   | users, or the detection of        |
|                                   | secrets or shadow data. These     |
|                                   | cases can be assigned to an       |
|                                   | analyst that specializes in       |
|                                   | strengthening the security        |
|                                   | posture.                          |
|                                   |                                   |
|                                   | The Posture domain has            |
|                                   | subcategories that define the     |
|                                   | posture issue (Configurations,    |
|                                   | Vulnerability, Identity, etc).    |
+-----------------------------------+-----------------------------------+
| Health                            | For cases and issues that are     |
|                                   | associated with health monitoring |
|                                   | activities to ensure optimal      |
|                                   | platform performance and gain     |
|                                   | insights into health drifts. For  |
|                                   | example, disruptions in data      |
|                                   | ingestion, collector connectivity |
|                                   | errors, correlation rule errors,  |
|                                   | and event forwarding errors.      |
+-----------------------------------+-----------------------------------+
| Hunting                           | For cases and issues that are     |
|                                   | associated with identifying and   |
|                                   | mitigating potential security     |
|                                   | threats before they cause any     |
|                                   | damage. For example, monitoring   |
|                                   | network traffic, analyzing logs,  |
|                                   | and conducting vulnerability      |
|                                   | assessments.                      |
+-----------------------------------+-----------------------------------+
| IT                                | For cases and issues that are     |
|                                   | associated with operational       |
|                                   | activities for ensuring           |
|                                   | availability and reliability in   |
|                                   | system performance. For example,  |
|                                   | server outages, network           |
|                                   | connectivity issues, application  |
|                                   | performance problems, or IT       |
|                                   | tasks.                            |
+-----------------------------------+-----------------------------------+

##### Manage your domains

You can see all domains under Configurations \> Object Setup \> Cases \>
Domains. From this tab you can edit the properties of the built in
domains, and create your own custom domains.

Consider the following information:

- You can\'t merge cases with different domains.

- SmartScore and smart grouping are not supported for custom domains.

- For SBAC, use the **Cases and Issues** scoping area to define cases
  and issues domains that enable you to control access to your domains.
  For more information, see [Manage user
  scope](#UUID071cdbb66c6a6afe3a671fa79991a0a8).

- Domains might affect custom content that is connected to cases and
  issues. Review you custom content to ensure it is associated with the
  intended domains, this includes:

  - Automation Rules

  - Starring Rules

  - Notifications

  - Issue Exclusions

  - Scoring Rules

  - XQL that accesses the cases or issues datasets in Scheduled Queries,
    and Widgets

#### Manage your cases

On the **Cases** page you can track, investigate, and take remedial
action on your cases. Go to Case and Issues \> Cases and locate the case
you want to investigate.

> **Note**
>
> If you do not have permissions to access an asset of a case (which is
> shown as grayed out and locked), check your scoping permissions in
> Manage Users or Manage User Groups.

##### Assign a case

You can assign or reassign a case by clicking on the **Assigned** field.

If the case contains unassigned issues, or the issues are not assigned
to case assignee, a dialog opens with options for assigning the issues.

##### Case thresholds

To keep cases fresh and relevant, Cortex XSIAM implements the following
thresholds. When the case reaches a threshold, it stops accepting issues
and groups subsequent related issues in a new case.

- 30 days after case creation.

- 14 days since the last issue in the case was detected.

- A case reaches the 1,000 issue limit.

You can track the threshold status in the `Issues Grouping Status` field
in the cases table.

##### Link or unlink issues from a case

You can link and unlink issues from cases. An issue can be assigned to
more than one case, and the case domain can be different from the issue
domain.

Link issues to a case

From the **Issues** page, select one or more issues that you want to
link, right-click and select . You can select one or more case to link
the issues.

Unlink an issue from a case

From the **Issues** page, select the issue that you want to unlink,
right-click and select . You can select one or more cases to unlink the
issue. You cannot bulk select issues to unlink.

##### Resolve a case

You can resolve a resolve a case in the following ways:

- On the **Cases** page,

- Run the `!setParentIncidentFields` command in the **War Room** or as a
  playbook task.

- Run the `Update Case` command in the API.

###### Resolution reasons for cases and issues

When you resolve a case or issue you must also specify a resolution
reason. The following table describes the resolution reasons available
for selection.

> **Note**
>
> The displayed resolution reasons are domain specific. You can see the
> resolution reasons that are defined for a domain under Configurations
> \> Object Setup \> Cases \> Domains.

+-----------------------------------+-----------------------------------+
| Resolution reason                 | Description                       |
+===================================+===================================+
| Resolved - True Positive          | The case or issue was correctly   |
|                                   | identified by Cortex XSIAM as a   |
|                                   | real threat, and the case was     |
|                                   | successfully handled and          |
|                                   | resolved.                         |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > Cases and issues resolved as    |
|                                   | > True Positive and False         |
|                                   | > Positive help Cortex XSIAM to   |
|                                   | > identify real threats in your   |
|                                   | > environment by comparing future |
|                                   | > cases and associated issues to  |
|                                   | > the resolved cases. Therefore,  |
|                                   | > the handling and scoring of     |
|                                   | > future cases is affected by     |
|                                   | > these resolutions.              |
+-----------------------------------+-----------------------------------+
| Resolved - False Positive         | The case or issue is not a real   |
|                                   | threat.                           |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > Cases and issues resolved as    |
|                                   | > True Positive and False         |
|                                   | > Positive help Cortex XSIAM to   |
|                                   | > identify real threats in your   |
|                                   | > environment by comparing future |
|                                   | > cases and associated issues to  |
|                                   | > the resolved cases. Therefore,  |
|                                   | > the handling and scoring of     |
|                                   | > future cases is affected by     |
|                                   | > these resolutions.              |
+-----------------------------------+-----------------------------------+
| Resolved - Security Testing       | The case or issue is related to   |
|                                   | security testing or simulation    |
|                                   | activity such as a BAS, pentest,  |
|                                   | or red team activity.             |
+-----------------------------------+-----------------------------------+
| Resolved - Known Issue            | The case or issue is related to   |
|                                   | an existing issue or an issue     |
|                                   | that is already being handled.    |
+-----------------------------------+-----------------------------------+
| Resolved - Duplicate Case         | The case or issue is a duplicate  |
|                                   | of another case.                  |
+-----------------------------------+-----------------------------------+
| Resolved - Risk Accepted          | The case or issue is related to a |
|                                   | known mitigation or impact.       |
+-----------------------------------+-----------------------------------+

If you created a custom resolution, it is also available for selection.

###### Create custom case statuses and resolution reasons

> **Note**
>
> Before you create a custom status, please review the built-in options.
> For more information, see [Resolution reasons for cases and
> issues](#UUID245034f82bc3db3f28264ec08c062aa2).
>
> We recommend using the built-in statuses and resolution reasons where
> possible. Custom statuses and resolution reasons might not be
> supported by all content, and status syncing can take time.
>
> In addition, custom statuses affect Cortex XSIAM's ability to learn,
> correctly identify, and score future cases.

You can create custom cases statuses and custom resolution reasons that
are tailored to your workflow. Custom case statuses and resolution
reasons apply to case and issue statuses, and can also be used in
playbooks.

Adding custom ,case statuses and resolution reasons requires a
**View/Edit** RBAC permission for **Case Properties** (under
Configurations \> Object Setup).

> **Note**
>
> After creation, custom statuses and resolution reasons cannot be
> deleted or modified.

**How to create custom case statuses**

1.  Go to Configurations \> Object Setup \> Cases \> Properties.

- The existing statuses and resolution types are listed.

2.  In the **Add another status** field, type a new status and click
    **Save**.

3.  Click **Edit** to rearrange the order of the statuses. This order is
    presented when you set a status or select a resolution type.

##### Create a case

> **Note**
>
> To create a case manually, you must have View/Edit permission for
> **Cases and Issues** selected under Settings \> Configurations \>
> Access Management \> Roles \> Components \> Cases & Issues.

You can create a case directly from the **Cases** page.

1.  On the **Cases** page click **New Case**.

2.  Under **Case Details**, specify the case domain, name, severity, and
    (Optional) assignee and description.

- The severity of a manually generated case cannot be low.

  > **Note**

  > You can assign a case to a single domain only and you cannot change
  > the assigned domain. For more information, see [Case and issue
  > domains](#UUID60c4e95d81e3f8730530e920dfd698e5).

3.  (Optional) Under **Case Fields**, select custom case fields.

- Cortex XSIAM validates the **Host IP**, **Local IP**, and
  **Remote IP** fields.

  If you select
  **Set fields as default for new \<domain\> domain cases**, the custom
  case fields that are configured are saved for all users. When a user
  next creates a case for the same domain, these fields are
  automatically configured instead of the default field set.

  To reset the custom fields to the system default, click
  **Restore Default Field Set**.

4.  Under **Issue Details**, select the issues to link to the case, or
    create a new issue.

- > **Tip**

  > The issues that you link to a case can be linked to multiple cases,
  > and the issue domains do not need to match the case domain.

5.  Under **Issue Fields**, define the following:

- > **Note**

  > This option is only relevant for certain domains.

  - MITRE ATT&CK tactics and techniques to assign to the case.

  - Custom issue fields.

6.  (Optional) Under **Playbook**, specify playbook run settings. By
    default, a playbook is run **Automatically by trigger**.

- > **Note**

  > This option is only relevant for certain domains.

7.  Click **Create new case**.

- Each case creation generates one issue. The name, the severity, and
  the description of the generated issue mirrors the name, the severity,
  and the description of the case.

  > **Note**

  > You can\'t attach files to manually created cases.

##### Issue syncing

You can set up integrations in Cortex XSIAM that mirror Cortex issues
with external applications, such as Atlassian Jira or ServiceNow. When
mirroring issues (also referred to as issue syncing), you can make
changes in an external application that will be reflected in Cortex
XSIAM, and vice versa. If an issue is mirrored with an external
application, you have the following options:

- **Link the ticket to the issue:** If an issue is linked to a ticket,
  the ticket number is displayed in the **Overview** section of the
  issue card. You see details about the status of the ticket by clicking
  on the ticket number.

- **Sync changes between the issue and the ticket:** If an issue is
  synced to a ticket, changes are synchronized in an outbound, inbound,
  or bi-directional flow.

> **Note**
>
> Multiple tickets can be linked to an issue with outbound syncing.
> Issues with inbound syncing can be linked to a single ticket only.

###### Set up an external integration to sync with issues

Before you can sync issues with external applications, you must set up
and configure your instance integration. Complete the following steps:

1.  Connect an instance integration:

    a.  Go to Settings \> Configurations \> Data Sources and click
        **Add Data Source**.

    b.  Search for the relevant data source, for example
        **Atlassian Jira**.

    c.  Complete the required fields and click **Connect**.

2.  Install the content pack:

    a.  Go to **Marketplace**.

    b.  Install the relevant content pack, for example
        **Atlassian Jira** or **ServiceNow**.

3.  Configure the content pack to connect to the instance integration:

    a.  Go to Settings \> Configurations \> Data Collection \>
        Automation & Feed Integrations.

    b.  Search for the relevant content pack and click **Add instance**.

    c.  Enter details of the data source instance that you connected in
        step 1.

###### Manually create a synced ticket

> **Prerequisite**
>
> You must set up an integration before you can sync issues. For more
> information, see [Set up an integration for mirroring
> issues](#Xfc531920297b40071e06656cb00cc7e4ab1d27e).

You can manually sync existing issues with external applications.

1.  From the **Issues** page, right-click an issue and select Run
    Automation \> Select Automation.

2.  Under **Quick Actions**, select the action you want to configure,
    such as **Create Jira Ticket** or **Create ServiceNow Ticket**.

3.  Define the required ticket parameters.

- > **Note**

  > Using issue fields as variables is not currently supported.

4.  Under **Using**, select the name of the instance to execute the
    command.

- > **Warning**

  > If you leave this field blank, all configured instances will be
  > used.

5.  Under **Sync Configuration**, the following options are displayed,
    depending on your selection:

    - **Link to issue:** select this option if you want the issue to be
      linked to the created ticket. You must check this option if you
      want to sync the issue with the ticket.

    - **Sync Direction:** select the syncing configuration:

      - **Inbound:** Sync changes from the external ticket with the
        Cortex XSIAM issue.

      - **Outbound:** Sync changes from the Cortex XSIAM issue with the
        external ticket.

      - **Bi-directional:** Sync changes in both directions.

      - **None:** Do not sync changes between the Cortex XSIAM issue
        with the external ticket. If you select this option, the tickets
        are still linked, but changes are not synced. You can update
        this option at any time to start syncing.

    - Define the inbound and/or outbound sync profiles.

    <!-- -->

    - Depending on the selected option, select sync profiles that define
      field mapping between the issue and the external ticket. You can
      use the default sync profiles or you can create custom profiles.
      For more information about sync profiles, see [Create a sync
      profile](#UUID83034312d293e350843a0101dbb41061).

      > **Note**

      > You can only define a single inbound profile. If you change the
      > inbound sync profile the current profile is overwritten.

      > You can define multiple outbound profiles; one issue can update
      > multiple tickets.

6.  Click **OK**.

- After ticket creation, the ticket number is shown in the Issue card.
  Click on the ticket number to see details about the created ticket and
  syncing configuration. In addition, the execution is recorded in the
  **War Room** tab. If there is a error in the requested action, you can
  see details in the audit.

7.  View or edit the syncing configuration. For more information, see
    [View, update, or resolve a
    ticket](#Xfbb7dcef78cc9087ca0922756cf31a34f6b6cb0).

The following example shows an automation run on an issue to create a
ServiceNow ticket that is synced in an outbound flow with the ticket.

![](media/rId1302.png){width="5.833333333333333in"
height="4.30937445319335in"}

###### Run a War Room command to create and sync a ticket

You can run the following command in the War Room to create an external
ticket and define the syncing configuration:

    !jira-create-issue-quick-action summary="<summary>" project_key="<key>" issue_type_name="<type>" 
    description="<description>" using="<instance>" mirroring_link_to_object="true" 
    mirroring_sync_direction="<syncDirection>" mirroring_outbound_profile_id="<profileID>"

> **Tip**
>
> You can find a sync profile ID under Settings \> Configurations \>
> Object Setup \> Issues \> Sync Profiles. By default the ID field is
> not displayed in the table. Click the three dot menu and add it to the
> table layout.

The following example creates a Jira Bug ticket for the Project Key
SCRUM, with an Outbound sync configuration:

    !jira-create-issue-quick-action summary="Restrict ingress on AWS Network ACLs for admin ports 22 and 3349" 
    project_key="SCRUM" issue_type_name="Bug" description="We identified that multiple AWS Network ACLS are 
    allowing inbound (ingress) traffic on admin ports" using="JiraV3" mirroring_link_to_object="true" 
    mirroring_sync_direction="OUTBOUND" mirroring_outbound_profile_id="h8e14996-8695-5396-9g87-f08suu907486"

###### Create an automation rule for syncing issues with external tickets

> **Prerequisite**
>
> You must set up an integration before you can sync issues. For more
> information, see [Set up an integration for mirroring
> issues](#Xfc531920297b40071e06656cb00cc7e4ab1d27e).

You can set up automation rules that create external tickets when
certain issues occur and define the syncing configuration for
transferring data between the issues and tickets.

1.  Go to Investigation & Response \> Automation \> Automation Rules.

2.  Click **Add Automation Rule**.

3.  Enter a name and description for the rule.

4.  Select whether to enable the rule after creation.

5.  Under Rule Conditions, define the WHEN, and IF conditions. For more
    information about rule conditions, see [Create an automation
    rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c).

6.  Under THEN select the desired automation, such as
    **Create Jira Ticket** and complete the following fields:

    a.  Define the required ticket parameters.

    - > **Note**

      > Using issue fields as variables is not currently supported.

    b.  Under **Using**, select the name of the instance to execute the
        command.

    - > **Warning**

      > If you leave this field blank, all configured instances will be
      > used.

    c.  Under **Sync Configuration**, the following options are
        displayed, depending on your selection:

        - **Link to issue:** select this option if you want the issue to
          be linked to the created ticket. You must check this option if
          you want to sync the issue with the ticket.

        - **Sync Direction:** select the syncing configuration:

          - **Inbound:** Sync changes from the external ticket with the
            Cortex XSIAM issue.

          - **Outbound:** Sync changes from the Cortex XSIAM issue with
            the external ticket.

          - **Bi-directional:** Sync changes in both directions.

          - **None:** Do not sync changes between the Cortex XSIAM issue
            with the external ticket. If you select this option, the
            tickets are still linked, but changes are not synced. You
            can update this option at any time to start syncing.

        - Define the inbound and/or outbound sync profiles.

        <!-- -->

        - Depending on the selected option, select sync profiles that
          define field mapping between the issue and the external
          ticket. You can use the default sync profiles or you can
          create custom profiles. For more information about sync
          profiles, see [Create a sync
          profile](#UUID83034312d293e350843a0101dbb41061).

          > **Note**

          > You can only define a single inbound profile. If you change
          > the inbound sync profile the current profile is overwritten.

          > You can define multiple outbound profiles; one issue can
          > update multiple tickets.

    d.  Click **OK**.

    - If a ticket is created, the ticket number is shown in the Issue
      card. You can click on the ticket number to see details about the
      created ticket and syncing configuration. In addition, the
      execution is recorded in the **War Room** tab. If there is a error
      in the requested action, you can see details in the audit.

7.  Click **Create**.

- The rule is added to the **Automation Rules** page. If required, drag
  to reorder the rules.

The following example shows an automation rule that creates a Jira
ticket with bi-directional syncing when a Critical Posture issue is
triggered.

![](media/rId1309.png){width="5.833333333333333in"
height="2.9895833333333335in"}

###### View, update, or resolve a ticket

Once you have set up ticket syncing, you can view, update and resolve
the issue and external ticket as required The changes are reflected
according to the defined syncing configuration.

1.  To open the ticket details, in the **Overview** section of the issue
    card, click on the external ticket number.

- A panel opens with details of the external ticket. You can see the
  external ticket number, the sync configuration, and details of the
  ticket.

2.  Open the linked ticket by clicking on the external ticket number in
    the panel.

3.  Update the fields as required.

- The updates are logged in the ticket history.

  > **Note**

  - > The inbound syncing flow runs every two minutes, and the outbound
    > syncing flow runs every five minutes.

  - > In a bi-directional set-up, if the same field is updated in both
    > tickets, the most recently updated value is used.

  - > In the external ticket, the logged history shows updates to the
    > ticket. The user name that is logged with the history reflects the
    > user token of the user who configured the data source.

4.  Resolve the ticket.

- > **Note**

  > After an issue is resolved, ticket syncing remains active for up-to
  > seven days. Therefore, you still update, change, or reopen the issue
  > or external ticket and the tickets will continue to sync.

###### Edit or disable ticket syncing

You can change the syncing configuration between a ticket and an issue
from the issue card.

1.  In the **Overview** section of the issue card, click on the external
    ticket number.

- A panel opens with details of the ticket.

2.  Click on the settings icon.

3.  Under **Sync Configuration**, change the syncing configuration as
    required.

- > **Note**

  > If you change the selected inbound sync profile, the original sync
  > profile is immediately overwritten.

4.  To disable ticket syncing, take one of the following actions:

    - To pause ticket syncing, set the **Sync Direction** value to
      **None**.

    <!-- -->

    - This temporarily stops the tickets from syncing, but the tickets
      are still linked. You can update the syncing configuration at any
      time to resume ticket syncing.

    <!-- -->

    - To unlink the tickets, uncheck **Link to issue**.

    <!-- -->

    - This action is not reversable.

5.  Click **Save**.

###### Add playbook tasks to create external tickets

> **Prerequisite**
>
> You must set up an integration before you can sync issues. For more
> information, see [Set up an integration for mirroring
> issues](#Xfc531920297b40071e06656cb00cc7e4ab1d27e).

You can add a playbook task that creates external tickets and defines
the syncing configuration.

1.  Open a new or existing playbook and add a new task.

2.  Select the **Task Type** and add a task name.

3.  Select one of the following scripts:

    - `jira-create-issue-quick-action (Jira V3)`

    - `servicenow-create-issue-quick-action (Jira V3)`

4.  Under **Inputs**, add fields for the ticket parameters.

- This example defines fields for a Jira ticket.

  - **Summary:** AWS Network ACLs allow ingress traffic on Admin ports

  - **Project Key:** SCRUM

  - **Issue Type:** Bug

  - **Description:** We identified that multiple AWS Network ACLS are
    allowing inbound (ingress) traffic on admin ports

5.  Under **Sync Configuration**, the following options are displayed,
    depending on your selection:

    - **Link to issue:** select this option if you want the issue to be
      linked to the created ticket.

    - **Sync Direction:** select the syncing configuration:

      - **Inbound:** Sync changes from the external ticket with the
        Cortex XSIAM issue.

      - **Outbound:** Sync changes from the Cortex XSIAM issue with the
        external ticket.

      - **Bi-directional:** Sync changes in both directions.

      - **None:** Do not sync changes between the Cortex XSIAM issue
        with the external ticket.

    - Define the inbound and outbound sync profiles.

    <!-- -->

    - Depending on the selected option, select sync profiles that define
      field mapping between the issue and the external ticket. You can
      use the default sync profiles or you can create custom profiles.
      For more information about sync profiles, see [Create a sync
      profile](#UUID83034312d293e350843a0101dbb41061).

      > **Note**

      > You can only define a single inbound profile. If you change the
      > inbound sync profile the current profile is overwritten.

      > You can define multiple outbound profiles; one issue can update
      > multiple tickets.

6.  Save the playbook.

###### Limitations of issue mirroring

Consider the following limitations of issue mirroring:

- Issue syncing requires the latest version of Atlassian Jira (V3) and
  ServiceNow (V2).

- Issue syncing is currently supported in Atlassian Jira (V3) and
  ServiceNow (V2) only.

- You can sync up to 50K objects.

- You can create a maximum of 200 sync profiles.

- Cortex XSIAM supports up-to 100 Inbound syncs across all synced
  tickets over a two-minute time period. Any additional changes beyond
  this limit will not be synced.

- If a connector instance is deleted or disabled, tickets are no longer
  synced and external ticket information is not available.

- Custom statuses are not supported.

- Currently, a specific set of fields is supported.

###### Create a sync profile

Sync profiles provide a blueprint for how information is exchanged
between Cortex XSIAM issues and external applications, by defining field
mapping. This ensures that relevant data, such as **Status** or
**Description**, is accurately transferred and maintains consistency,
even if the systems use different terminology.

When you link an issue with an external application (such as Jira), or
set up an automation, you can select the sync profile you want to use.
Cortex XSIAM provides default outbound and inbound sync profiles, or you
can create custom sync profiles as described in the following procedure.

**How to create a sync profile**

1.  Go to Settings \> Configurations \> Object Setup \> Issues \> Sync
    Profiles.

2.  Click **New Profile**.

3.  Type a profile name and description.

4.  Under **Integration**, select the external application with which
    you want to map fields, such as Jira V3 or ServiceNow V2.

5.  Under **Sync Direction**, select **Inbound** or **Outbound**. 

- If you select **Inbound**, you will define field mapping from the
  external application to Cortex XSIAM. If you select **Outbound**, you
  will define field mapping from Cortex XSIAM to the external
  application.

  > **Note**

  > If an issue is using bi-directional syncing, you need to provide
  > both an Inbound and an outbound sync profile.

6.  Under **Field Mapping**, select a field to map and select the
    corresponding field. For example, Jira: Priority, Cortex: Severity.

7.  Define one or more values for each field that you want to map.

- > **Note**

  - > Blank fields are skipped.

  - > You must define exact values.

  - > Custom status values are not currently supported.

  - > Support is currently limited to a specific set of fields.

8.  Click **Save**.

- In this example, the sync profile specifies Inbound mapping from Jira
  v3 fields to Cortex fields.

  ![](media/rId1319.png){width="5.833333333333333in"
  height="4.185416666666667in"}

#### Customize your cases

##### External integrations

You can integrate external threat intelligence services with Cortex
XSIAM that provide additional verification sources for each key artifact
in a case. Cortex XSIAM supports the following integrations:

###### Threat intelligence

+-----------------------------------+-------------------------------------------------+
| Integration                       | Description                                     |
+===================================+=================================================+
| WildFire                          | Cortex XSIAM automatically includes WildFire    |
|                                   | threat intelligence in the case and issue       |
|                                   | investigation.                                  |
|                                   |                                                 |
|                                   | WildFire detects known and unknown threats,     |
|                                   | such as malware. The WildFire verdict contains  |
|                                   | detailed insights into the behavior of          |
|                                   | identified threats. The WildFire verdict is     |
|                                   | displayed next to relevant **Key Artifacts** in |
|                                   | the **Cases** page. See [Review WildFire        |
|                                   | analysis                                        |
|                                   | details](#UUIDf60c77e435d0f54bb121c950627fbefc) |
|                                   | for more information.                           |
+-----------------------------------+-------------------------------------------------+
| VirusTotal                        | VirusTotal provides aggregated results from     |
|                                   | over 70 antivirus scanners, domain services     |
|                                   | included in the block list, and user            |
|                                   | contributions. The VirusTotal score is          |
|                                   | represented as a fraction. For example, a score |
|                                   | of 34/52 means out of 52 queried services, 34   |
|                                   | services determined the artifact to be          |
|                                   | malicious.                                      |
|                                   |                                                 |
|                                   | To view VirusTotal threat intelligence in       |
|                                   | cases, you must obtain the license key for the  |
|                                   | service and add it to the Cortex XSIAM          |
|                                   | **Configuration**. When you add the service,    |
|                                   | the relevant VirusTotal (VT) score is displayed |
|                                   | in the **Cases** page under **Key Artifacts**.  |
+-----------------------------------+-------------------------------------------------+

###### Case management

  -----------------------------------------------------------------------
  Integration                         Description
  ----------------------------------- -----------------------------------
  Third-party ticketing systems       To manage cases from the
                                      application of your choice, you can
                                      use the Cortex XSIAM API Reference
                                      to send issues and issue details to
                                      an external receiver. After you
                                      generate your API key and set up
                                      the API to query Cortex XSIAM,
                                      external apps can receive case
                                      updates, request additional data
                                      about cases, and make changes such
                                      as setting the status and changing
                                      the severity or assigning an owner.
                                      To get started, see the Cortex
                                      XSIAM API Reference guide.

  -----------------------------------------------------------------------

##### Prioritize cases with starring and scoring

Cortex XSIAM provides starring and scoring to help you to prioritize
your cases.

Starring enables you to highlight and filter the cases that you deem
most important. Scoring assigns a numerical value to each case to
reflect its severity. Using these functions, you can easily compare case
scores, filter starred cases, and prioritize your most urgent cases.

###### Case starring

To help you focus on the most important cases, you can star a case.
Starring enables you to narrow down the scope of cases on the **Cases**
page. Cortex XSIAM identifies starred cases with a purple star.

You can star cases manually, or create a starring configuration. A
starring configuration automatically categorizes and stars cases that
contain issues with specific attributes. In a starring configuration you
define attributes or assets for issues that you want to star. If an
issue matches the attributes in the starring configuration, the issue
and case linked to the issue are starred. You can manage all starring
configurations under Case & Issues \> Case Configuration \> Starred
Issues.

####### Scope-Based Access Control considerations

Case starring supports Scope-Based Access Control (SBAC). The following
parameters are considered when editing a starring configuration:

- If **Scope-Based Access Control (SBAC)** is enabled and the
  **Endpoint Scoping Mode** is set to restrictive mode, you can edit a
  configuration if you are scoped to all tags in the configuration.

- If **Scope-Based Access Control (SBAC)** is enabled and the
  **Endpoint Scoping Mode** is set to permissive mode, you can edit a
  configuration if you are scoped to at least one tag listed in the
  configuration.

- If a policy was added when set to restrictive mode, and then changed
  to permissive (or vice versa), you will only have view permissions.

####### Star a specific case

You can manually star a case during or after investigation:

1.  Select Cases & Issues \> Cases.

2.  In the list of cases, locate the case you want to star.

3.  Select the star icon.

####### Create a starring configuration

You can proactively star issues and the cases to which they are linked
by creating a starring configuration:

1.  Select Cases & Issues \> Case Configuration \> Starred Issues.

2.  Select **Add Starring Configuration**.

3.  Under **Configuration Name**, enter a name to identify your starring
    configuration.

4.  (Optional) Under **Comment**, enter a descriptive comment.

5.  In the issue table, use the filters to define the issue attributes
    you want to include in the match criteria.

- You can also right-click a specific value in the issue to add it as
  match criteria.

6.  Click **Create**.

###### Case scoring

A case score is a numeric value that indicates the urgency of a case.
Scoring can help you to streamline the process of prioritizing and
investigating your cases, and help you to identify the cases that
require immediate attention.

####### Types of scoring

Cortex XSIAM uses the following scoring methods:

- **Rule-based scoring:** The score is determined by user-defined
  scoring rules that match the issues linked to the case.

<!-- -->

- You create scoring rules that define scores for issues with specific
  attributes or assets. You can base scoring rules on:

  - Hostnames

  - IP addresses

  - Users

  - Active Directory, or Azure groups and organization units

  <!-- -->

  - (Requires the Cloud Identity Engine to be configured).

  When an issue is created, Cortex XSIAM searches for scoring rules that
  match the issue. An issue can match multiple rules or sub-rules. If a
  match is found, Cortex XSIAM assigns the scores of the matching rules
  to the issue. If multiple rules match the issue, the issue score is an
  aggregation of the rule scores. By default, a score is applied only to
  the first issue in the case that matches the defined rule and
  sub-rule.

  You can create a rule hierarchy by setting up sub-rules. If an issue
  matches one or more sub-rules, the sub-rule scores are also aggregated
  in the issue score. However, a sub-rule score is only applied to an
  issue if the top-level rule was a match.

  To determine the case score, Cortex XSIAM calculates the combined
  issue score total for all issues in the case. You can see a breakdown
  of the score by clicking on the score in the details pane.

<!-- -->

- **SmartScore:** The score is automatically calculated, based on
  machine learning.

<!-- -->

- SmartScore relies on machine learning, statistical analysis, case
  attributes, and cross-customer insights to identify high-risk cases.
  When an issue is created, Cortex XSIAM calculates the SmartScore
  according to the compiled data.

<!-- -->

- **Manual scoring:** The score is defined by the user.

####### How Cortex XSIAM assigns the score

For Cortex XSIAM to provide effective rule-based scores, you must define
accurate scoring rules that are suitable for your environment and
workflows. In addition, SmartScore requires sufficient data to calculate
and display the score. On first activation, this can take up to 48
hours. If sufficient data is not available, no score is assigned.

When a case is created, Cortex XSIAM searches for a match between your
scoring rules and the issues linked to a case. If a match is found, a
rule based score is assigned. If no match is found and there is
sufficient data available, Cortex XSIAM assigns a SmartScore. If Cortex
XSIAM doesn\'t have sufficient data to assign a score, you can manually
assign a score.

To enable Cortex XSIAM to automatically assign a score to a case, you
must enable SmartScore and define scoring rules. For more information,
see [Set up case scoring](#UUID817aa363d099c81dc4bb50a3ca959f9e).

You can see the assigned score on the **Cases** page.

####### Set up case scoring

To set up case scoring you need to enable SmartScore, and enable and
define scoring rules.

######## Enable SmartScore

1.  Select Settings \> Configurations \> Cortex XSIAM- Analytics and
    click **Enable**.

2.  Select Cases & Issues \> Case Configuration \> Case Scoring and
    enable **SmartScore**.

> **Note**
>
> On the first activation, it can take up to 48 hours for SmartScore to
> calculate and display the score.
>
> Enabling SmartScore subsequently impacts the User Score.

######## Enable and define scoring rules

1.  Select Cases & Issues \> Case Configuration \> Case Scoring \>
    Scoring Rules and enable **User Scoring Rules**.

- The **Scoring Rules** table displays the user-defined rules and
  sub-rules.

2.  Click **Add Scoring Rule**.

3.  In the **Create New Scoring Rule** dialog, define the rule criteria:

    1.  Under **Rule Name**, enter a unique name for your rule.

    2.  Under **Score**, define the score that Cortex XSIAM should apply
        to issues that matching the rule criteria.

    3.  Under **Base Rule**, select whether to create a top-level rule
        (labeled **Root**) or a sub-rule (labeled
        ***Rule Name (ID:#)***). By default, rules are defined at the
        root level.

    4.  Select or deselect **Apply score only to first issue of case**.

    - By selecting this option you choose to apply the score only to the
      first issue that matches the defined rule. Subsequent issues of
      the same case will not receive a score from this rule. By default,
      a score is applied only to the first issue that matches the
      defined rule and sub-rule.

    5.  In the issue table, use the filters to define the attributes you
        want to include in the rule match criteria.

- Example
  With this rule, Cortex XSIAM assigns a score of 30 to any XDR BIOC
  issues with a severity level of Critical:

  - Score = 30

  - Base Rule = Root

  - Filters:

  <!-- -->

  - `Issue Source=XDR BIOC AND Severity=Critical`

4.  Click **Create**.

- You are automatically redirected to the **Scoring Rules** table.

5.  In the **Scoring Rules** table, click **Save** to save your scoring
    rule.

- > **Note**

  > For scoped users, a small lock icon indicates that you don\'t have
  > permissions to edit a rule.

**What to do next**

After setting up your scoring rules, you can take the following actions:

See a breakdown of the score

You can see details about the scoring method and the assigned score.

1.  On the **Cases** page, click on the menu icon to switch to the
    detailed view.

2.  Click on an assigned score.

If you are not satisfied with the score, you can change the scoring
method, or overwrite the score by setting the score manually. If you see
a discrepancy with the assigned score, consider the following:

- For rule-based scores, revise your scoring rules.

- For SmartScores, help to improve the accuracy of SmartScore.
  **Give feedback** by hovering over the displayed score.

Change the scoring method or set the score manually

You can change the default scoring method. In addition, if Cortex XSIAM
was unable to assign a score, you can set the score manually.

1.  On the **Cases** page, click on the menu icon to switch to the
    detailed view.

2.  Click on the assigned score.

- If no score was assigned, in the case investigation pane click the
  more options icon and select **Manage Score**.

3.  Select a different scoring method, or click **Set score manually**
    and define a new score.

Revise existing scoring rules

In the Scoring Rules table, take the following actions to review your
rules and sub-rules:

- Use the arrows to rearrange rule priorities. Make sure to click
  **Save** after any changes.

- Select one or more rules and right-click to see the available actions.

Scope-Based Access Control considerations

Case Scoring supports Scope-Based Access Control (SBAC). If you\'re a
scoped user, a small lock icon indicates that you don\'t have
permissions to edit a rule. The following parameters are considered when
editing a scoring rule:

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to restrictive mode, you can edit a
  rule if you are scoped to all tags in the rule.

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to permissive mode, you can edit a
  rule if you are scoped to at least one tag listed in the rule.

- To change the order of a rule, you must have permissions to the other
  rules of which you want to change the order.

- If a rule was added when set to restrictive mode, and then changed to
  permissive (or vice versa), you will only have view permissions.

##### Customize issue fields and layouts

You can create custom issue fields and custom issue layouts. Custom
issue layouts can include both out-of-the-box and custom issue fields.
Issue layouts are applied to issues according to layout rules.

###### Issue fields

Cortex XSIAM includes out-of-the-box issue fields, issue fields from
installed content packs, and user defined custom issue fields. You can
use issue fields for mapping, correlation rules, and custom issue
layouts.

All system and custom issue fields are available in the **Issues**
table. New custom fields are hidden by default. To show custom issue
fields in the **Issues** table, click the three dot vertical ellipses
and select the column(s) from the list.

For Grid fields, HTML fields, and Markdown fields, if the field contains
data the **Issues** table shows **Data Available** instead of the
values. To view the data, open the issue and click **Investigate** to
see the full issue layout. For multi-select fields, the first value is
shown in the **Issues** table and the number of additional values is
stated, but the additional values are not shown. For example, if a
multi-select field holds the values x, y, and z, the **Issues** table
shows **x + 2 More**.

Cortex XSIAM stores both the original value of the field and the current
value of the field, if different. Any changes made between the original
value and the current value are not stored. For example, if the original
value of the field was x, the value was then changed to m, and then
changed to y, only the x and y values are stored. To view the original
value and the current value of changed fields, hover over the updated
issue fields icon ![](media/rId1347.png){width="0.1842946194225722in"
height="0.20833333333333334in"} on the right side of the row in the
**Issues** table. To revert all of the fields in an issue to their
original values, click **Restore all fields to their original values**
in the updated issue fields box. Restoring all fields to their original
values also restores the original values in the issue context data. Once
you restore fields to their original values, this action can not be
undone.

Custom issue fields can be exported and imported. To export a single
custom issue field, right-click on the field in the fields table, and
select **Export**. To export all custom issue fields in a single JSON
file, click the **Export All** button above the fields table. System
issue fields cannot be exported or imported.

After a custom issue field is created, it can be edited, deleted, or
exported by right-clicking on the row. The field name and field type
cannot be changed after the field is created. System fields cannot be
edited, deleted, or exported.

> **Warning**
>
> Deleting an issue field or uninstalling a content pack containing an
> issue field may affect detection and other capabilities based on the
> deleted field. For example, correlation, layouts, case scoring,
> starring rules, and playbook triggers.

####### Issue field types

You can create the following types of issue fields.

+-----------------------------------+------------------------------------------------+
| Field                             | Description                                    |
+===================================+================================================+
| Boolean                           | True or False                                  |
|                                   |                                                |
|                                   | - Incoming values `0`, `false`, and `False`    |
|                                   |   are treated as **False**.                    |
|                                   |                                                |
|                                   | - Incoming values `true`, `True`, or any       |
|                                   |   number besides 0 are treated as **True**.    |
|                                   |                                                |
|                                   | - Other values are treated as null.            |
+-----------------------------------+------------------------------------------------+
| Date picker                       | Adds the date to the field.                    |
|                                   |                                                |
|                                   | Supported time formats for validation are ISO  |
|                                   | 8601 and Epoch. Other values are treated as    |
|                                   | null.                                          |
|                                   |                                                |
|                                   | > **Note**                                     |
|                                   | >                                              |
|                                   | > You cannot set filters, starring rules,      |
|                                   | > playbook triggers, layout rules, or issue    |
|                                   | > exclusions based on the values in custom     |
|                                   | > timestamp fields.                            |
+-----------------------------------+------------------------------------------------+
| Grid (table)                      | Include an interactive, editable grid as a     |
|                                   | field. For details, see [Create a grid         |
|                                   | field](#UUID6402283c76ce5392bb8100d2245a1980). |
|                                   |                                                |
|                                   | > **Note**                                     |
|                                   | >                                              |
|                                   | > When grid field is shown in the **Issues**   |
|                                   | > table, if there are values in the field,     |
|                                   | > they do not display in the table. Instead,   |
|                                   | > the column shows **Data Available**.         |
+-----------------------------------+------------------------------------------------+
| HTML                              | Create and view HTML content.                  |
|                                   |                                                |
|                                   | > **Note**                                     |
|                                   | >                                              |
|                                   | > When an HTML field is shown in the Issues    |
|                                   | > table, if there is a value in the field, it  |
|                                   | > does not display in the Issues table.        |
|                                   | > Instead, the column shows                    |
|                                   | > **Data Available**.                          |
|                                   | >                                              |
|                                   | > The following HTML tags are not permitted:   |
|                                   | > `blockquote`, `del`, `dd`, `div`, `dl`,      |
|                                   | > `dt`, `fieldset`, `form`, `h1`, `h2`, `h3`,  |
|                                   | > `h4`, `h5`, `h6`, `hr`, `iframe`, `ins`,     |
|                                   | > `li`, `math`, `noscript`, `ol`, `pre`, `p`,  |
|                                   | > `script`, `style`, `table`, `ul`, `address`, |
|                                   | > `article`, `aside`, `canvas`, `details`,     |
|                                   | > `dialog`, `figcaption`, `figure`, `footer`,  |
|                                   | > `header`, `hgroup`, `main`, `nav`, `output`, |
|                                   | > `progress`, `section`, `video`.              |
|                                   | >                                              |
|                                   | > The following CSS tags are not permitted:    |
|                                   | > `background-color`, `text-align`,            |
|                                   | > `font-size`, `font-family`, `font-weight`,   |
|                                   | > `color`, `line-height`, `border-style`,      |
|                                   | > `border`, `page-break-inside`,               |
|                                   | > `tablelayout`, `padding`, `background-size`, |
|                                   | > `display`, `padding-top`, `padding-right`,   |
|                                   | > `padding-bottom`, `padding-left`,            |
|                                   | > `text-size-adjust`, `break-inside`,          |
|                                   | > `word-break`, `width`, `height`,             |
|                                   | > `-ms-text-size-adjust`,                      |
|                                   | > `-webkit-text-size-adjust`.                  |
+-----------------------------------+------------------------------------------------+
| Long text                         | - Long text is analyzed and tokenized, and     |
|                                   |   entries are indexed as individual words,     |
|                                   |   enabling you to perform advanced searches    |
|                                   |   and use wildcards.                           |
|                                   |                                                |
|                                   | - Long text fields cannot be sorted and cannot |
|                                   |   be used in graphical dashboard widgets.      |
|                                   |                                                |
|                                   | - While editing a long text field, pressing    |
|                                   |   enter will create a new line. Case is        |
|                                   |   insensitive.                                 |
+-----------------------------------+------------------------------------------------+
| Markdown                          | Add markdown-formatted text as a **Template**  |
|                                   | which is displayed to users in the field.      |
|                                   | Markdown lets you add basic formatting to text |
|                                   | to provide a better end-user experience.       |
|                                   |                                                |
|                                   | > **Note**                                     |
|                                   | >                                              |
|                                   | > When a Markdown field is shown in the        |
|                                   | > **Issues** table, if there is a value in the |
|                                   | > field, it does not display in the table.     |
|                                   | > Instead, the column shows                    |
|                                   | > **Data Available**.                          |
+-----------------------------------+------------------------------------------------+
| Multi select / Array              | Includes two options:                          |
|                                   |                                                |
|                                   | - Multi select from a pre-filled list.         |
|                                   |                                                |
|                                   | - An empty array field for the user to add one |
|                                   |   or more values as a comma-separated list.    |
|                                   |                                                |
|                                   | In the **Basic Settings** section, enter a     |
|                                   | comma-separated list of values.                |
+-----------------------------------+------------------------------------------------+
| Number                            | Can contain any number. Default is 0.          |
+-----------------------------------+------------------------------------------------+
| Short Text                        | - Short text is treated as a single unit of    |
|                                   |   text, and is not indexed by word. Advanced   |
|                                   |   search, including wildcards, is not          |
|                                   |   supported.                                   |
|                                   |                                                |
|                                   | - Short text fields are case insensitive.      |
|                                   |                                                |
|                                   | - While editing a short text field, pressing   |
|                                   |   enter will save and close.                   |
|                                   |                                                |
|                                   | - Recommended use is one word entries.         |
|                                   |   Examples: username, email address, etc.      |
+-----------------------------------+------------------------------------------------+
| Single select                     | Select one from a list of options. Add a list  |
|                                   | of comma-separated values. By default, the     |
|                                   | first value is used, unless the checkbox for   |
|                                   | **Use first as default** is cleared.           |
+-----------------------------------+------------------------------------------------+
| Timer                             | Timer fields enable you to view how much time  |
|                                   | has passed since the timer was started and how |
|                                   | much time remains until the timer times out.   |
|                                   | You can also configure a script to run when a  |
|                                   | timer times out.                               |
+-----------------------------------+------------------------------------------------+
| URL                               | Contains a URL.                                |
+-----------------------------------+------------------------------------------------+

####### Create custom issue fields

You can create custom issue fields to:

- Map raw JSON fields from incoming issues.

- Display custom fields data in the **Issues** table.

- Create correlation rules that generate issues from XQL queries and map
  the output of the queries to custom issue fields.

- Design custom issue layouts that include custom issue fields.

**How to create a custom issue field:**

1.  Select Settings \> Configurations \> Object Setup \> Issues \>
    Fields \> New Field.

2.  Choose a field type and enter a field name. For a description of
    available field types, see [Issue field
    types](#UUID7e00c66910eaecf1ec3beef6094dd7df). You can add an
    optional tooltip to provide users with information about the field.

- If adding a grid, see [Create a grid
  field](#UUID6402283c76ce5392bb8100d2245a1980).

3.  Click **Save**.

Custom issue fields can be exported and imported. To export a single
custom issue field, right-click on the field in the fields table, and
select **Export**. To export all custom issue fields in a single JSON
file, click the **Export All** button above the fields table.

After a custom issue field is created, it can be edited, deleted, or
exported by right-clicking on the row. The field name and field type
cannot be changed after the field is created.

You can also update the custom field values by running the Set command
in the CLI, a script, or a playbook. For more information, see [Update
issue fields](#UUIDaf219191200cbe7ea66a8d2683888253).

######## Create a grid field

The grid field enables you to view and edit a table. You can add a grid
field to a custom issue layout.

1.  Select Settings \> Configurations \> Object Setup \> Issues \>
    Fields \> New Field.

2.  In the **New Issue Field** window under **Field Type**, select
    **Grid (table)**.

3.  Complete the following parameters:

  -----------------------------------------------------------------------
  Parameter                           Description
  ----------------------------------- -----------------------------------
  Field Name                          Name for the grid field.

  Tooltip                             (*Optional*) A brief descriptive
                                      message that explains what the
                                      field is and how to use it.

  User can add rows                   (*Optional*) Enables users to
                                      add/remove rows in the grid.
  -----------------------------------------------------------------------

4.  In the **Grid** tab, add or remove rows and columns.

- How you design the grid determines how it appears to users. If you
  select **user can add rows**, the user can add rows but not columns.

5.  Configure each column by selecting the required field types, such as
    short text, Boolean, URL, etc. You can move the columns, rename, and
    add values.

- If you select the **Lock** check box, the value for that field is
  static (not editable). If you do not select the **Lock** check box
  (default), users can perform inline editing.

6.  Click **Save**.

######## Issue field triggered scripts

Issue fields can be assigned scripts that run when the field changes.
This enables you to automate workflows during an issue lifecycle. These
scripts can perform any action, such as dynamically changing the field
value or notifying the responder when an issue severity has been
changed. Field triggered scripts can include conditions that must be met
for the script to run, such as the field having a certain value.

Scripts can be created in Python, PowerShell, or JavaScript on the
**Scripts** page. To use a script with a field trigger, you need to add
the field-change-triggered tag to the script. You can then add the
script in the **Attributes** tab, when you edit or create an issue
field. If you did not add the tag when creating the script, it cannot be
selected, until you add the tag.

When a script is associated with an issue field, changes to that field
are saved only after the triggered script finishes running. This allows
you, for example, to perform verifications such as checking that a
specific field has been filled out, before allowing a user to resolve an
issue.

If you perform a bulk update and change the same field across multiple
issues at the same time, and that field has a field triggered script
assigned, the script runs in each issue.

An issue field triggered script can modify multiple issue fields. Note
that if field A changes and a script is triggered and changes field B,
and field B is also assigned a field triggered script, the script for
field B is not triggered.

Cortex XSIAM comes out-of-the-box with the **emailFieldTriggered**
script, which sends an email to the issue owner when the selected field
is triggered. You can also create your own custom scripts.

> **Caution**
>
> This feature assumes fair and intended usage of field triggered
> scripts. In cases of excessive or abusive usage, execution may be
> restricted or disabled. If script execution is restricted or disabled,
> fields are still updated, but without the results of the assigned
> script.

######### Issue field triggered script arguments

Issue field triggered scripts have the following triggered field
information available as arguments (args):

+-----------------------------------+-----------------------------------+
| Argument                          | Description                       |
+===================================+===================================+
| `associatedToAll`                 | Whether the field is associated   |
|                                   | with all or some issues.          |
|                                   |                                   |
|                                   | Value: `true` or `false`.         |
+-----------------------------------+-----------------------------------+
| `associatedTypes`                 | An array of the issue types, with |
|                                   | which the field is associated.    |
+-----------------------------------+-----------------------------------+
| `cliName`                         | The name of the field when called |
|                                   | from the command line.            |
+-----------------------------------+-----------------------------------+
| `description`                     | The description of the field.     |
+-----------------------------------+-----------------------------------+
| `isReadOnly`                      | Specifies whether the field is    |
|                                   | non-editable.                     |
|                                   |                                   |
|                                   | Value: `true` or `false`.         |
+-----------------------------------+-----------------------------------+
| `name`                            | The name of the field.            |
+-----------------------------------+-----------------------------------+
| `new`                             | The new value of the field.       |
+-----------------------------------+-----------------------------------+
| `old`                             | The old value of the field.       |
+-----------------------------------+-----------------------------------+
| `ownerOnly`                       | Specifies that only the creator   |
|                                   | of the field can edit.            |
|                                   |                                   |
|                                   | Value: `true` or `false`.         |
+-----------------------------------+-----------------------------------+
| `placeholder`                     | The placeholder text.             |
+-----------------------------------+-----------------------------------+
| `required`                        | Specifies whether this is a       |
|                                   | mandatory field.                  |
|                                   |                                   |
|                                   | Value: `true` or `false`.         |
+-----------------------------------+-----------------------------------+
| `selectValues`                    | If this is a multi-select type    |
|                                   | field, these are the values the   |
|                                   | field can take.                   |
+-----------------------------------+-----------------------------------+
| `system`                          | Whether it is a Cortex XSIAM      |
|                                   | defined field.                    |
+-----------------------------------+-----------------------------------+
| `type`                            | The field type.                   |
+-----------------------------------+-----------------------------------+
| `unmapped`                        | Whether it is not mapped to any   |
|                                   | issue.                            |
+-----------------------------------+-----------------------------------+
| `useAsKpi`                        | Whether it is being used for      |
|                                   | tracking KPI on an issue page.    |
+-----------------------------------+-----------------------------------+
| `validationRegex`                 | Whether there is a regex          |
|                                   | associated for validation the     |
|                                   | values the field can hold.        |
+-----------------------------------+-----------------------------------+

> **Note**
>
> Fields that can hold a list, such as multi-select custom fields,
> return the delta in an array as a new argument. For example, if a
> multi-select field value has changed from \[\"a\"\] to \[\"a\",
> \"b\"\], the new argument of the script gets a value of \[\"b\"\].

######### Add an issue field triggered script to an issue field

After creating an issue field triggered script in the **Scripts** page
in Python, PowerShell, or JavaScript, you can then associate it with an
issue field.

1.  Go to Settings \> Configurations \> Object Setup \> Issues \>
    Fields.

2.  Right click the issue field and select **Edit**.

3.  In the **Attributes** tab, under
    **Script to run when field changes**, select the desired issue field
    triggered script.

- > **Note**

  > Issue field triggered scripts must have the `field-change-triggered`
  > tag to appear in the list.

######### Field-change-triggered with single select or multi select types

1.  Create and save a single select or multi-select script in the
    **Scripts** page.

- > **Note**

  > When creating the script, add the **field-change-triggered** tag in
  > the script settings.

  This is an example of a single select script.

      # Mapping of user selection to email addresses
      owner_mapping = {
          'option1': 'alice@example.com',
          'option2': 'eled@example.com',
          'option3': 'carol@example.com',
          'option4': 'dave@example.com',
          'option5': 'eve@example.com',
      }

      # The value selected by the user when the script is triggered
      val = demisto.args().get('new')

      # Get the mapped email address
      owner_email = owner_mapping.get(val, val)

      # Set the owner of the incident
      demisto.executeCommand('setIssue', {
          'owner': owner_email
      })

2.  Go to Settings \> Configurations \> Object Setup \> Issues \>
    Fields.

3.  Click **New Field** and create a new issue field of one of the
    following types:

    - Single select

    - Multi-select

4.  Click **Basic Settings** and in the **Values** section set the
    values you want to see in the issue layout dropdown list for this
    field.

- For example, `option1,option2,option3,option4,option5`.

5.  Click **Attributes** and in **Script to run when field changes**,
    select the script you created in Step 1.

6.  Go to Settings \> Configurations \> Object Setup \> Issues \>
    Layouts and add the new issue field to an existing layout or create
    a new layout.

7.  In the issue layout edit page, click **Fields and Buttons** and drag
    the new issue field you created to the layout.

8.  Save the version.

9.  Select one of the values. The layout will update with the mapped
    value as set on the script related to the issue field.

######### Use scripts with a grid field

You can use scripts to manipulate and populate data in a grid field. In
this example, analysts add comments to issues they work on during their
shifts. The script automatically populates a column of the grid, logging
the timestamp of each comment.

1.  Create a script called `ShiftSummariesChange`. The script operates
    in the following phases:

    - The script gets all new rows and sets the Date Logged field to now
      (current day).

    - For each existing row, if the name matches, and the findings
      column is not updated, the Date Logged column is also updated.

    - After creating a grid field, it is saved with the new values using
      the `setIssue` command.

    <!-- -->

    - var newField = args.new ? JSON.parse(args.new)  : [];
          //if line(s) added, set "datelogged" to now.
          if (oldField.length < newField.length) {
              // for each new line change date.    
              for(var i=oldField.length; i < newField.length; i++) {
                  newField[i].datelogged = new Date ().toISOString();
              }
          }
          var columnName = "findings";
          // for each old line if the "columnName" has changed, change date to now.
          for(var i=0; i < oldField.length; i++) {
              if (newField[i] && oldField[i].fullname === newField[i].fullname &&
              oldField[i][columnName] !== newField[i][columnName]) {
                  newField[i].datelogged = new Date().toISOString();
              }
          }
          var newVal = {};
          newVal[args.cliName] = newField;
          executeCommand("setIssue", newVal);

2.  Add the `field-change-triggered` tag and save the script.

3.  Create a `Shift Summaries` grid field with the following columns:

    - Full name

    - Findings

    - Status

    - Date Logged

    <!-- -->

    - Select **Date picker** with the **Lock** checkbox, so the script
      can populate the values for that column. If a column is unlocked
      (default), the column values can be entered manually (by users),
      or by a script.

- > **Note**

  > Verify that **User can add rows** is selected.

**Add a row to a grid**

During playbook execution, if a malicious finding is discovered, you can
add that finding to a grid, using a script in a playbook task.

This Python script requires two arguments:

- `fieldCliName`: The machine name for the field for which you want to
  add a new row.

- `Row`: The new row to add the grid. This is a JSON object in lowercase
  characters, with no white space.

<!-- -->

    fieldCliName = demisto.args().get('field')
    currentValue = demisto.incidents()[0]["CustomFields"][fieldCliName];

    if currentValue is None:
        currentValue = [json.loads(demisto.args().get('row'))]
    else:
        currentValue.append(json.loads(demisto.args().get('row')))

    val = json.dumps({ fieldCliName: currentValue })
    demisto.results(demisto.executeCommand("setIssue", { 'customFields': val }))

######## Issue timer fields

By default, timer fields are disabled in Cortex XSIAM. To enable timer
fields, go to Settings \> Configurations \> General \> Server Settings
\> Issues and **Enable Timer Field**.

Timer issue fields provide you with the ability to track reaction time
and help you measure issue-level metrics. Timers can measure multiple
aspects of an issue. You can, for example, have a timer track how long
since the first playbook ran, and have another timer track how long
you\'ve been waiting for a user\'s response. Timers display in the
issues table and in issue layouts.

Timer fields can be started, stopped, or paused in a playbook, script,
or manually in the CLI.

Timer fields count up from when a specific action or task began and also
(optionally) count down from a target. The Risk Threshold tells you when
a timer is considered at risk and you can customize the time period for
the Risk Threshold.

Timer fields always show the total duration while they are still
running. If they are at risk, they show the at risk status. After a
timer field has timed out (passed the target), the timer shows both the
total duration and how long past the target.

Timer fields do not automatically trigger actions when timers time out.
You can configure a script to run when a timer times out.

**Scripts**

You can run scripts to act on timeouts, such as sending an email when a
timeout occurs. You can also make specific changes to an issue field or
a parent case issue, such as changing the case owner. Cortex XSIAM
includes out-of-the-box scripts or you can create your own scripts.
Scripts must have the `SLA` tag to be used for timer fields. For more
information, see [Automate changes to issue fields using timer
scripts](#UUID5ab5c3e7b83002be1991ff3347138056).

**Using the CLI**

If you want to set or change timers for an issue you can use the
`setIssue` command in the CLI. You can also use commands such as
`startTimer`, `stopTimer`, and `pauseTimer`. For more information, see
[Use issue timer field commands manually in the
CLI](#UUID5d42fd6371dece263caedde77536becc).

######### Configure issue timer fields

You can create timer fields that display in the issues table and issue
layouts. When you create an issue timer field, you have the option of
providing a target for completion and also the option of triggering a
script when the timer field has timed out (the target has passed).

If you set a target for a timer field, the **Risk Threshold** is
automatically activated and displays when the timer is considered at
risk. You can customize the timeframe for the **Risk Threshold**. If you
do not provide a target, the timer only counts up from when it was
triggered.

You can start, stop, or pause a timer from the CLI, from scripts, and
from playbooks.

**How to create a timer issue field**

1.  Go to Settings \> Configurations \> Object Setup \> Issues \> Fields
    \> New Field.

2.  Select **Timer** as the **Field Type**.

3.  Type a field name.

4.  (Optional) Under **Basic Settings**, **Timer** you have the option
    of setting a target for the timer field. By default, the timer field
    shows hours and minutes. You can change this to days and hours, by
    clicking **Hours**. If you do not enter the number of hours and
    minutes, the timer only counts up from when it is triggered.

- If you set a target in the timer field, by default the
  **Risk Threshold** field is activated. You can edit the
  **Risk Threshold** value.

5.  (Optional) Under **Run script on timeout**, select the script to run
    when the target has timed out. For example, you could write a script
    that sends an email when the target has timed out. For more
    information, see [Automate changes to issue fields using timer
    scripts](#UUID5ab5c3e7b83002be1991ff3347138056).

- > **Note**

  > Only scripts to which you have added the `SLA` tag appear in the
  > list of scripts you can select. To add a tag to a script, create a
  > new script or edit an existing script and enter the tag name in the
  > script settings.

  > When you hover over the machine name (below the Field Name) note the
  > name which is used in the command line or script.

6.  Save the field.

7.  (Optional) Add the field to one or more issue layouts. By default,
    the timer field is available to view in the issues table.

######### Configure a playbook to run timers

Within a playbook, you can set a timer to start, pause, or stop at a
specific section header or task. For example, you can create a timer
called **Pending user response** and have it start in a playbook when an
email is sent to a user. If the user does not respond within the target
timeframe, then you can automatically send an additional reminder to the
user or run a different task.

To select a timer in a task or section header, in the **Timers** tab
select the action that you want the timer to perform for the task. You
can add multiple timers to a task or section header, so in the same task
you can stop one timer and start another.

> **Note**
>
> When a task or section has a timer configured, it displays the
> hourglass icon.

The following table describes the timer options:

+-----------------------------------+-----------------------------------+
| Option                            | Description                       |
+===================================+===================================+
| `Timer.start`                     | Starts the timer.                 |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > Timers are not started          |
|                                   | > automatically when a case is    |
|                                   | > created.                        |
+-----------------------------------+-----------------------------------+
| `Timer.pause`                     | Pauses the timer. A paused timer  |
|                                   | can be started again without      |
|                                   | being reset.                      |
+-----------------------------------+-----------------------------------+
| `Timer.stop`                      | Stops the timer. Information      |
|                                   | about the timer is still          |
|                                   | displayed in the issue layout     |
|                                   | and/or issues table, but the      |
|                                   | status displays as **Ended**.     |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > If you stop a timer before the  |
|                                   | > issue is closed, you must reset |
|                                   | > the timer using the             |
|                                   | > `resetTimer` command before you |
|                                   | > can start the timer again. When |
|                                   | > you reset the timer, all fields |
|                                   | > are cleared.                    |
+-----------------------------------+-----------------------------------+

Some playbooks, such as **Phishing - Generic v3**, come out-of-the-box
with timer tasks included. If you need the same timers across use cases,
create a sub-playbook based on your use case or conditions such as issue
severity.

If you want to stop or pause a timer in a playbook, you can use an
existing task or create a new section header/task. When you select
**Timer.stop**, the run is considered finished and cannot be restarted
without setting it to zero. If you plan to restart the timer, select
**Timer.pause** so you do not lose the accumulated time. By default, all
timers stop when the case closes.

######### Automate changes to issue fields using timer scripts

Scripts in Cortex XSIAM enable you to automate processes. You can create
scripts that perform specific actions when a timer field times out.
Scripts used with timers must have the SLA tag.

You can use an out-of-the-box or custom script and attach it to an timer
issue field.

A common use of scripts for timer fields is to send an email when a
timer is breached. You can create a custom script that sends an email to
specific users when the script is triggered. You can add this to any
timer issue field as needed.

######### Use issue timer field commands manually in the CLI

You can manage the timers for a specific issue by running commands
manually in the CLI. By running CLI command you can to manage timers on
a more granular level within specific issues when the need arises. For
example, for a high severity issue you might need to decrease the
response time.

Set timer fields

Use the `setIssue` command to set a specific issue due date, or to set a
specific timer field in an issue. If you add the `sla` parameter to the
command, it sets the time for the issue\'s due date. If you also add the
`slaField` you set the timer for the issue field.

To change the **Time to Assignment** field target to 30 minutes in the
current issue, run the following command:

    !setIssue sla=30 slaField=timetoassignment

To change the timer to February 1, 2024, at 11.12 am, run the following
command:

    !setIssue sla=2024-02-01T11:12

> **Note**
>
> When defining the values for the `slaField` use the machine name for
> the field, which is lowercase and without spaces. You can check the
> machine name by editing the issue field.

Start or stop timer fields

Run the following commands in the CLI:

+-----------------------------------+----------------------------------------------+
| Command                           | Description                                  |
+===================================+==============================================+
| `startTimer`                      | Starts the timer.                            |
|                                   |                                              |
|                                   | This command can also be used to restart a   |
|                                   | paused timer.                                |
|                                   |                                              |
|                                   |     !startTimer timerField=timetoassignnment |
|                                   |                                              |
|                                   | > **Note**                                   |
|                                   | >                                            |
|                                   | > Timer fields are not started automatically |
|                                   | > when an issue is created unless run in a   |
|                                   | > playbook.                                  |
+-----------------------------------+----------------------------------------------+
| `pauseTimer`                      | Pauses the timer.                            |
|                                   |                                              |
|                                   | Use this command when a timer field has      |
|                                   | already started.                             |
|                                   |                                              |
|                                   |     !pauseTimer timerField=timetoassignment  |
+-----------------------------------+----------------------------------------------+
| `stopTimer`                       | Stops the timer.                             |
|                                   |                                              |
|                                   |     !stopTimer timerField=timetoassignment   |
|                                   |                                              |
|                                   | > **Note**                                   |
|                                   | >                                            |
|                                   | > After a timer field is stopped, before you |
|                                   | > can start the timer again you must reset   |
|                                   | > the timer using the `resetTimer` command.  |
|                                   | >                                            |
|                                   | > Timers are automatically stopped when an   |
|                                   | > issue is closed.                           |
+-----------------------------------+----------------------------------------------+
| `resetTimer`                      | Clears all fields for the timer.             |
|                                   |                                              |
|                                   | This command must be used before restarting  |
|                                   | a timer that was stopped.                    |
|                                   |                                              |
|                                   |     !resetTimer timerField=timetoassignment  |
+-----------------------------------+----------------------------------------------+

> **Note**
>
> When running commands in the CLI, you can specify the `alertID` to
> change the timer for a different issue.

###### Issue layouts

Cortex XSIAM includes default issue layouts. You can add additional
issue layouts by installing content packs, duplicating system issue
layouts, or creating new custom issue layouts. Issue layouts are applied
to incoming issues based on issue layout rules.

Issue layouts control the information displayed in the **Investigate**
panel. To see the issue layout that has been applied, in the Issue
investigation panel click the **Layout Info** button
![](media/rId1374.png){width="0.22435804899387576in"
height="0.20833333333333334in"} in the upper right corner. Empty layout
fields are hidden by default, but are shown if you select
**Show empty fields**.

The default issue layouts and any layouts that are added from content
packs, are locked by default and cannot be deleted, edited, or exported.
To view a system layout, right-click the layout row and select **View**.
If you want to edit a system layout, you can detach or duplicate the
layout by right-clicking the layout row in the issue layout table and
selecting **Detach** or **Duplicate**. If you detach a layout, the
layout does not receive content updates until it is reattached. To
reattach a system layout, right-click the layout row and select
**Attach**. If you detach a layout and make changes, those changes may
be overwritten if you later reattach the layout. If a layout is
detached, you can edit or duplicate it, but you cannot delete or export
it. If you instead duplicate the issue layout, the new duplicated layout
can be edited, deleted, or exported, the same as a custom issue layout.

When viewing an issue, most issue fields can be edited inline, by users
with editing permissions. After editing a field inline, click the check
mark to save your change. Some system fields, such as
**Source Instance**, cannot be edited.

To modify an existing custom layout, go to Settings \> Configurations \>
Object Setup \> Issues \> Layouts, right-click the layout in the layouts
table, and select **Edit**, **Duplicate**, **Delete**, or **Export**.

###### Create custom issue layouts

Custom issue layouts let you choose the specific fields and buttons that
are displayed for different types of issues. You can create custom issue
layouts that include both custom and out-of-the-box issue fields, and
add buttons with tasks that can assist and guide analysts in their
investigation.

You can import a custom issue layout by clicking **Import** and
uploading the JSON file. You can also modify or task actions on an
existing layout existing layout by right-clicking the layout in the
layout table.

Create a custom issue layout

1.  Go to Settings \> Configurations \> Object Setup \> Issues \>
    Layouts \> New Layout.

2.  Enter a name for the layout.

3.  (Optional) Add new tabs to the layout, and drag them to change the
    order in which they appear.

- The **Issue Info** tab and any new tabs you create can be renamed,
  hidden, duplicated, or deleted. Hover over the tab name and click the
  settings button to see the available options. You cannot edit or
  delete the **War Room** and **Work Plan** tabs in the issue layout,
  but you can hide them by clicking the settings button, and selecting
  **Hide tab**.

  By default, empty fields within the tab are hidden in the issue
  layout. To show empty fields, hover over the tab name, click the
  settings button, and select **Show empty fields**.

4.  Add new sections to the **Issue Info** tab, or click **+New tab**.

- To add a new section, from the **Sections** tab of the **Library**
  drag a **New Section** into a tab. You can also add the predefined
  sections, such as **Malicious or Suspicious Indicators** and
  **War Room Entries**.

  ![](media/rId1378.png){width="3.6458333333333335in"
  height="1.7641119860017498in"}

5.  Customize the section

- Clicking the pencil icon for a section, to configure how a section
  appears. You can hide or show the section header, and configure the
  section fields to appear in rows or as cards.

  Some sections have additional configuration options. If you add a
  **Malicious or Suspicious Indicators** section, you can configure an
  indicator search query. If you add a **War Room Entries** section, you
  can filter by type of entry, such as chats, notes, or files.

  The **General Purpose Dynamic Section** enables you to configure a
  section that displays the results of a script. Only scripts to which
  you have added the `dynamic-section` tag appear in the dropdown list.
  You can use the **General Purpose Dynamic Section** to display
  widgets, text, markdown, or HTML. For an example of how to add a
  widget with this section, see [Add a custom widget to an issue
  layout](#UUIDed90d560747c493473629e1e17069bb2).

6.  Add custom or out-of-the-box issue fields to the layout.

- From the **Fields and Buttons** tab of the **Library**, drag fields
  into sections of the layout.

  > **Tip**

  > Limit the number of issue fields to 50 in each section. You can
  > create additional sections as needed.

7.  Add buttons to the layout.

- Buttons allow you to add tasks to your layout, which can assist an
  analyst. For example, you can add a button to scan a host or kill a
  process.

  a.  From the **Fields and Buttons** tab of the **Library**, drag a
      buttons into a section of the layout.

  b.  **Click to configure**.

  c.  Enter a descriptive name for the button, select a color, and
      select the script that you want to run when the button is clicked.

  - For fields (script arguments) that are optional, you can define
    whether to show them to analysts when they click on buttons. To
    expose an optional field, select the **Ask User** checkbox next to
    the script argument(s) in the button settings page.

    > **Note**

    > The script that runs when an action button is clicked accepts only
    > mandatory arguments through the pop up window and does not provide
    > an option for any non-mandatory arguments to be filled in when the
    > button is clicked. We recommend using a wrapper script to collect
    > and validate arguments in scenarios where there can be a
    > combination of mandatory and non-mandatory arguments for a button.

8.  Save the layout.

Export issue layouts

You can export custom issue layouts and duplicates of system issue
layouts

To export a single issue layout, right-click on the layout in the
layouts table, and select **Export**. To export all custom issue layouts
and duplicates of system issue layouts in a single JSON file, click the
**Export All** button above the layouts table.

####### Add a custom widget to an issue layout

You can add a custom or system widget to a custom issue layout by
uploading an auto script and using it in a
**General Purpose Dynamic Section** in your layout.

The following example shows how to add an Indicator Widget Bar. This
custom widget script shows the severity of indicators in an issue, as a
bar chart.

1.  Add the Indicator Widget Bar script to Cortex XSIAM.

    a.  Go to Investigation & Response \> Automation \> Scripts and
        upload the following script:

    - Expand script
          commonfields:
            id: ee3b9604-324b-4ab5-8164-15ddf6e428ab
            version: 49
          name: IndicatorWidgetBar
          script: |-
            # Constants
            HIGH = 3
            SUSPICIOUS = 2
            LOW = 1
            NONE = 0

            indicators = []
            scores = {HIGH: 0, SUSPICIOUS: 0, LOW: 0, NONE: 0}
            incident_id = demisto.incidents()[0].get('id')

            foundIndicators = demisto.executeCommand("findIndicators", {"query":'investigationIDs:{}'.format(incident_id), 'size':999999})[0]['Contents']

            for indicator in foundIndicators:
                scores[indicator['score']] += 1

            data = {
              "Type": 17,
              "ContentsFormat": "bar",
              "Contents": {
                "stats": [
                  {
                    "data": [
                      scores[HIGH]
                    ],
                    "groups": None,
                    "name": "high",
                    "label": "incident.severity.high",
                    "color": "rgb(255, 23, 68)"
                  },
                  {
                    "data": [
                      scores[SUSPICIOUS]
                    ],
                    "groups": None,
                    "name": "medium",
                    "label": "incident.severity.medium",
                    "color": "rgb(255, 144, 0)"
                  },
                  {
                    "data": [
                      scores[LOW]
                    ],
                    "groups": None,
                    "name": "low",
                    "label": "incident.severity.low",
                    "color": "rgb(0, 205, 51)"
                  },
                  {
                    "data": [
                      scores[NONE]
                    ],
                    "groups": None,
                    "name": "unknown",
                    "label": "incident.severity.unknown",
                    "color": "rgb(197, 197, 197)"
                  }
                ],
                "params": {
                    "layout": "horizontal"
                }
              }
            }

            demisto.results(data)
          type: python
          tags:
          - dynamic-section
          enabled: true
          scripttarget: 0
          subtype: python3
          runonce: false
          dockerimage: demisto/python3:3.7.3.286
          runas: DBotWeakRole
                                          

    b.  Click **Save**.

2.  Add the widget to an issue layout.

    a.  Go to Settings \> Configurations \> Object Setup \> Issues \>
        Layouts.

    b.  Create a new custom issue layout or right-click to open an
        existing custom issue layout or a detached or duplicated system
        layout.

    c.  Drag and drop the **General Purpose Dynamic Section** into a
        layout tab.

    d.  Edit the **General Purpose Dynamic Section** by clicking the
        pencil icon.

    e.  Enter a name for the section and choose the automation script
        you uploaded in Step 1.

    f.  Click **Ok**.

###### Create rules for issue layouts

Issue layouts are applied to issues according to layout rules. Using a
layout rule, you can assign a custom issue layout based on the issue
source, such as a specific layout for issues generated from a
correlation rule.

You can create multiple rules. If the first rule does not apply to the
incoming issue, the next rule is checked, and so on. If a content pack
is installed and it contains a layout rule, by default the layout rule
is placed at the top of the rules list. You can change the order of the
rules by dragging and dropping the rules in the list. You can filter the
rule list by name, description, rule, layout, and source. If no layout
rules apply to the issue, a default issue layout is used.

To edit or delete existing rules, right-click on the rule in the list
and select **Edit** or **Delete**.

**How to create layout rules**

1.  Go to Settings \> Configurations \> Object Setup \> Issues \> Layout
    Rules \> New Rule.

2.  Enter a rule name, select the layout to use if the rule is met, and
    provide a description.

3.  Search for issues that match the criteria you want to use for the
    layout rule. For example, you can search for issues from a specific
    issue source.

4.  Click **Create**.

5.  Repeat as needed to create multiple rules.

6.  Click **Save**.

####### SBAC considerations

Layout rules support SBAC (scoped based access control). The following
parameters are considered for editing access.

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to restrictive mode, you can edit a
  rule if you are scoped to all tags in the rule.

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to permissive mode, you can edit a
  rule if you are scoped to at least one tag listed in the rule.

- As a scoped user who has editing permissions to a rule, you can change
  the order among other rules that are locked.

- If a rule was added when set to restrictive mode, and then changed to
  permissive (or vice versa), you will only have view permissions.

##### Customize case fields and layouts

You can create custom case fields and custom case layouts. Custom case
layouts can include both out-of-the-box and custom case fields. Case
layouts are applied to cases according to layout rules.

###### Create case timers and SLAs

To help you to monitor and assess your key performance indicators
(KPIs), you can create SLAs at the case level. Case SLAs provide the
ability to track KPIs, obtain real-time insights into operational
performance, and ensure alignment with established objectives.

Case SLAs are based on case timer fields. When a case matches the
defined criteria, the timer starts running. If the timer field is linked
to an SLA, Cortex XSIAM tracks the progress of the case in relation to
the SLA.

To track your SLAs on the **Cases** page, add the timer and SLA fields
to the table layout, or create a custom layout with SLA fields. Note
that the timer field counts forward, and the SLA field counts backwards.

> **Prerequisite**
>
> Before you can create a case SLA, you must first create a timer field.
> A timer field can be associated with a single case SLA.

####### Create a case timer

Take the following steps to create a case timer field:

1.  Go to Settings \> Configurations \> Object Setup \> Case and open
    the **Fields** tab.

2.  Click **New Field**.

3.  Under **Field Type**, select **Timer**.

4.  Type a field name.

5.  Under **Tooltip**, enter a description to pop-up when you hover over
    the field.

6.  Under **Case Filter**, click **Set Filter** and define the subset of
    cases for which the timer will be activated. For example, you can
    define timers for specific domains or case source types.

- > **Note**

  > If you edit this filter after creation, the timer and associated SLA
  > will be removed from any case that no longer qualifies, even if the
  > timer is already running.

7.  Under **Conditions**, add filters that define when the timer will
    start and end. To add a pause condition to the timer, click
    **Pause** and define the pause criteria.

8.  Under **When case is reopened**, select the action that you want
    Cortex XSIAM to take.

9.  Click **Save**.

The following timer measures the amount of time a security case is
waiting in **New** status before an analyst starts investigating.

  -----------------------------------------------------------------------
  Field                               Value
  ----------------------------------- -----------------------------------
  Field Type                          Timer

  Field Name                          Security case response

  Tooltip                             Measure time from case opening to
                                      analyst response.

  Cases Filter                        Case Domain = Security

  Start when                          Status = New

  End when                            Status = Under Investigation

  When case is reopened               Reset timer
  -----------------------------------------------------------------------

####### Create a case SLA

Take the following steps to create a case SLA. You can set up multiple
goals for an SLA.

1.  Go to Settings \> Configurations \> Object Setup \> Cases and open
    the **Fields** tab.

2.  Click **New Field**.

3.  Under **Field Type**, select **SLA**.

4.  Type a name to identify the SLA.

5.  Under **Tooltip**, enter a description to pop-up when you hover over
    the field.

6.  Under **Timer**, select the timer field with which to associate the
    SLA.

7.  Under **Goals**, click **Add SLA Goal**.

- The default goal applies to all cases that meet the filter criteria
  specified in the timer field. You can set up addition goals that apply
  to subsets of the defined cases.

8.  In the SLA goal, type a goal name and set filter criteria.

9.  In the **Days**, **Hours**, or **Minutes** fields, define the time
    conditions for to the SLA goal.

10. Arrange the SLA goals by dragging them in order of goal priority.

11. Click **Save**.

The following SLA field sets goals for analyst response times for
security cases with Critical and High severity. This SLA is based on the
timer field created in the previous example. Because the timer field is
set up with the filter **Case Domain = Security**, this SLA will apply
to security cases only.

The first SLA goal applies to security cases with a severity level of
**Critical**. The SLA specifies that an analyst must respond to critical
severity cases within one hour.

The second SLA goal applies to security cases with a severity level of
**High**. The SLA specifies that an analyst must respond to high
severity cases within two hours.

+-----------------------------------+-----------------------------------+
| Field                             | Value                             |
+===================================+===================================+
| Field Type                        | SLA                               |
+-----------------------------------+-----------------------------------+
| Field Name                        | Security case response SLA        |
+-----------------------------------+-----------------------------------+
| Tooltip                           | Measure time from case opening to |
|                                   | analyst response.                 |
+-----------------------------------+-----------------------------------+
| Timer                             | Security case response            |
+-----------------------------------+-----------------------------------+
| Goals                             | - Name: Critical severity cases   |
|                                   |                                   |
|                                   | - Minutes: 60                     |
|                                   |                                   |
|                                   | - Filter: severity = Critical     |
+-----------------------------------+-----------------------------------+
|                                   | - Name: High severity cases       |
|                                   |                                   |
|                                   | - Minutes: 120                    |
|                                   |                                   |
|                                   | - Filter: severity = High         |
+-----------------------------------+-----------------------------------+

####### Display timer and SLA fields in the Cases page

After creating new timer and SLA fields, you can add them to the
**Cases** table layout and view them in the **Cases** detailed view:

- In the **Cases** table view, add the timer and SLA fields to the
  **Layout** tab in the **Table Setting Menu**.

- In the **Cases** detailed view, use the **Sort By** field to filter
  the cases list by the SLA field. Details of the SLA are shown in the
  list.

<!-- -->

- In addition, you can create a custom case layout with a new tab
  displaying SLA fields. For more information, see [Case
  layouts](#UUID83b9102c16974f5db068afe8c4222a9c).

####### Example of SLA and timer fields

This example is based on the fields created in the previous procedures:

- The **Security case response** timer field displays the number of
  minutes since case creation. When the case status moves from **New**
  to **Under Investigation**, the timer stops.

- The **Security case response SLA** field starts counting backwards to
  show the remaining time to meet the SLA. If the field is shown in red
  with a minus time, the SLA is breached.

  - For case 001, the critical severity case has been in **New** status
    for 5 minutes. An analyst must respond within the remaining 55
    minutes.

  - For case 002, the high severity case has been in **New** status for
    20 minutes. An analyst must respond within the remaining 1 hour and
    40 minutes.

  - For case 003, an analyst did not respond within 60 minutes and
    therefore the SLA was breached. The **Security case response SLA**
    field displays a minus value and a red icon.

  ------------------------------------------------------------------------------------------------------------
  Case ID           Severity          Security case     Security case response SLA
                                      response          
  ----------------- ----------------- ----------------- ------------------------------------------------------
  001               Critical          5m                55m 25s
                                                        ![](media/rId1395.png){width="0.23550634295713035in"
                                                        height="0.20833333333333334in"}

  002               High              20m               1h 40m 30s
                                                        ![](media/rId1395.png){width="0.23550634295713035in"
                                                        height="0.20833333333333334in"}

  003               Critical          65m               \- 5m 23s
                                                        ![](media/rId1400.png){width="0.21739063867016623in"
                                                        height="0.20833333333333334in"}
  ------------------------------------------------------------------------------------------------------------

####### Additional considerations

Consider the following information when working with timer and SLA
fields:

- When a case is resolved, the timer calculation stops.

- Updating timer logic affects open and new cases. Therefore, the timer
  and associated SLA will be removed from any case that no longer
  qualifies, even if the timer is already running.

- If you delete a timer field, the SLA associated to the timer is also
  deleted.

####### Update case timer and SLA fields

You can update case timer and SLA fields by running the following CLI
command in the War Room:

    !RefreshIncidentDynamicCustomFields

###### Case fields

Cortex XSIAM includes out-of-the-box case fields, case fields from
installed content packs, and user defined custom case fields. Case
fields can be used for custom case layouts, and for display in the
**Cases** table.

Custom case fields can be exported and imported. To export a single
custom case field, right-click on the field in the fields table, and
select **Export**. To export all custom case fields in a single JSON
file, click the **Export All** button above the fields table. System
case fields cannot be exported or imported.

After a custom case field is created, it can be edited, deleted, or
exported by right-clicking on the row. The field name and field type
cannot be changed after the field is created. System fields cannot be
edited, deleted, or exported.

> **Warning**
>
> Deleting a case field or uninstalling a content pack containing a case
> field may affect capabilities based on the deleted field, layouts and
> case scoring.

####### Case field types

You can create the following types of case fields:

+-----------------------------------+-----------------------------------------------+
| Field                             | Description                                   |
+===================================+===============================================+
| Boolean                           | True or False                                 |
|                                   |                                               |
|                                   | - Incoming values `0`, `false`, and `False`   |
|                                   |   are treated as **False**.                   |
|                                   |                                               |
|                                   | - Incoming values `true`, `True`, or any      |
|                                   |   number besides 0 are treated as **True**.   |
|                                   |                                               |
|                                   | - Other values are treated as null.           |
+-----------------------------------+-----------------------------------------------+
| Date picker                       | Adds the date to the field.                   |
|                                   |                                               |
|                                   | Supported time formats for validation are ISO |
|                                   | 8601 and Epoch. Other values are treated as   |
|                                   | null.                                         |
|                                   |                                               |
|                                   | > **Note**                                    |
|                                   | >                                             |
|                                   | > You cannot set filters, starring rules,     |
|                                   | > playbook triggers, layout rules, or issue   |
|                                   | > exclusions based on the values in custom    |
|                                   | > timestamp fields.                           |
+-----------------------------------+-----------------------------------------------+
| Grid (table)                      | Include an interactive, editable grid as a    |
|                                   | field. For details, see [Create a grid field  |
|                                   | for a                                         |
|                                   | case](#UUID712c3043bb1094db1be785bbb0265171). |
|                                   |                                               |
|                                   | > **Note**                                    |
|                                   | >                                             |
|                                   | > When grid field is shown in the **Cases**   |
|                                   | > table, if there are values in the field,    |
|                                   | > they do not display in the **Cases** table. |
|                                   | > Instead, the column shows                   |
|                                   | > **Data Available**.                         |
+-----------------------------------+-----------------------------------------------+
| HTML                              | Create and view HTML content.                 |
|                                   |                                               |
|                                   | > **Note**                                    |
|                                   | >                                             |
|                                   | > When an HTML field is shown in the          |
|                                   | > **Issues** table, if there is a value in    |
|                                   | > the field, it does not display in the       |
|                                   | > **Cases** table. Instead, the column shows  |
|                                   | > **Data Available**.                         |
+-----------------------------------+-----------------------------------------------+
| Long text                         | - Long text is analyzed and tokenized, and    |
|                                   |   entries are indexed as individual words,    |
|                                   |   enabling you to perform advanced searches   |
|                                   |   and use wildcards.                          |
|                                   |                                               |
|                                   | - Long text fields cannot be sorted and       |
|                                   |   cannot be used in graphical dashboard       |
|                                   |   widgets.                                    |
|                                   |                                               |
|                                   | - While editing a long text field, pressing   |
|                                   |   enter will create a new line. Case is       |
|                                   |   insensitive.                                |
+-----------------------------------+-----------------------------------------------+
| Markdown                          | Add markdown-formatted text as a **Template** |
|                                   | which is displayed to users in the field.     |
|                                   | Markdown lets you add basic formatting to     |
|                                   | text to provide a better end-user experience. |
|                                   |                                               |
|                                   | > **Note**                                    |
|                                   | >                                             |
|                                   | > When a Markdown field is shown in the       |
|                                   | > **Cases** table, if there is a value in the |
|                                   | > field, it does not display in the **Cases** |
|                                   | > table. Instead, the column shows            |
|                                   | > **Data Available**.                         |
+-----------------------------------+-----------------------------------------------+
| Multi select / Array              | Includes two options:                         |
|                                   |                                               |
|                                   | - Multi select from a pre-filled list.        |
|                                   |                                               |
|                                   | - An empty array field for the user to add    |
|                                   |   one or more values as a comma-separated     |
|                                   |   list.                                       |
|                                   |                                               |
|                                   | In the **Basic Settings** section, enter a    |
|                                   | comma-separated list of values.               |
+-----------------------------------+-----------------------------------------------+
| Number                            | Can contain any number. Default is 0.         |
+-----------------------------------+-----------------------------------------------+
| Short Text                        | - Short text is treated as a single unit of   |
|                                   |   text, and is not indexed by word. Advanced  |
|                                   |   search, including wildcards, is not         |
|                                   |   supported.                                  |
|                                   |                                               |
|                                   | - Short text fields are case insensitive.     |
|                                   |                                               |
|                                   | - While editing a short text field, pressing  |
|                                   |   enter will save and close.                  |
|                                   |                                               |
|                                   | - Recommended use is one word entries.        |
|                                   |   Examples: username, email address, etc.     |
+-----------------------------------+-----------------------------------------------+
| Single select                     | Select one from a list of options. Add a list |
|                                   | of comma-separated values. By default, the    |
|                                   | first value is used, unless the checkbox for  |
|                                   | **Use first as default** is cleared.          |
+-----------------------------------+-----------------------------------------------+
| SLA                               | SLA can be used to trigger a notification     |
|                                   | when the status affecting the SLA of a case   |
|                                   | changes. In this example, if the SLA is       |
|                                   | breached an email is sent to the owner\'s     |
|                                   | supervisor.                                   |
|                                   |                                               |
|                                   | For more information on SLAs, see [Create     |
|                                   | case timers and                               |
|                                   | SLAs](#UUID6e9f48d3a5f7d7606db02a01c72958d8). |
+-----------------------------------+-----------------------------------------------+
| Timer                             | Timer fields enable you to view how much time |
|                                   | has passed since the timer was started and    |
|                                   | how much time remains until the timer times   |
|                                   | out. You can also configure a script to run   |
|                                   | when a timer times out.                       |
+-----------------------------------+-----------------------------------------------+
| URL                               | Contains a URL.                               |
+-----------------------------------+-----------------------------------------------+

> **Note**
>
> If you make changes to case fields you can update the context data by
> running a playbook, script, or command. For more information, see
> [Update case fields](#UUIDc28ab57c96d1a1dde5571c072684dc62).
>
> To update dynamic custom case fields, such as SLA and Timer fields,
> see [Update case timer and SLA
> fields](#UUIDa71bcb3a560deb6f99affd5573ade478).

####### Create custom case fields

Create case fields so you add them to custom case layouts.

You can create custom case fields to:

- Map raw JSON fields from incoming issues.

- Display custom fields data in the **Cases** table.

- Create correlation rules that generate issues from XQL queries and map
  the output of the queries to custom case fields.

- Design custom case layouts that include custom case fields.

**How to create a new custom case field:**

1.  Select Settings \> Configurations \> Object Setup \> Cases \> Fields
    \> New Field.

2.  Choose a field type and enter a field name. You can add an optional
    tooltip to provide users with information about the field.

- If adding a grid, see [Create a grid field for a
  case](#UUID712c3043bb1094db1be785bbb0265171).

3.  Save your changes.

Custom case fields can be exported and imported. To export a single
custom case field, right-click on the field in the fields table, and
select **Export**. To export all custom case fields in a single JSON
file, click the **Export All** button above the fields table.

After a custom case field is created, it can be edited, deleted, or
exported by right-clicking on the row. The field name and field type
cannot be changed after the field is created.

######## Create a grid field for a case

Grid fields enable you to view and edit tables in a custom case layout.

1.  Select Settings \> Configurations \> Object Setup \> Cases \> Fields
    \> New Field.

2.  In the **New Case Field** window **Field Type** field drop down
    list, select **Grid (table)**.

3.  Complete the following parameters:

  -----------------------------------------------------------------------
  Parameter                           Description
  ----------------------------------- -----------------------------------
  Field Name                          A meaningful name for the grid
                                      field.

  Tooltip                             (*Optional*) A brief descriptive
                                      message that explains what the
                                      field is and how to use it.

  User can add rows                   (*Optional*) Enables users to
                                      add/remove rows in the grid.
  -----------------------------------------------------------------------

4.  In the **Grid** tab, add or remove the required rows and columns.

- How you design the grid determines how it appears to users. If the
  **user can add rows** field is selected, the user can add rows but not
  columns.

5.  Configure each column by selecting the required field types, such as
    short text, Boolean, URL, etc. You can move the columns, rename, add
    values, etc.

- If you select the **Lock** check box, the value for that field is
  static (not editable). If you do not select the **Lock** check box
  (default), users can perform inline editing.

6.  Click **Save**.

####### Update case fields

Sometimes you need to update case fields based on a change in an issue.
For example, after starting an investigation an analyst might want to
change the name of a case, star a case, or change the status of a case.

You can update the following case fields through a playbook, script, or
command:

- `manual_severity`

- `starred`

- `assigned_user_email`

- `status`

- `score`

- `incident_name`

- `description`

The following sections explain how to update case fields by running a
command in the CLI, and running a script, and running a playbook.

######## Use the CLI

Run the `!setParentIncidentFields` command in the issue or case
**War Room**.

When you start typing the CLI provides the available options. If you
select an enum field the CLI provides the available values.

**Examples**

- To change the name of the case to `Malware`, run

<!-- -->

- !setParentIncidentFields incident_name=Malware

<!-- -->

- To change the name of the case to `Malware` and star the case, run

<!-- -->

- !setParentIncidentFields incident_name=Malware starred=true

######## Use a script

When a script runs in an issue, the data from the script is added to the
issue context data and the issue fields. If you want to update case
fields, in a Json file, add the `setParentIncidentFields` to the
`demisto.executeCommand` function.

**Example**

To update the case status to `resolved`, run

    demisto.executeCommand("setParentIncidentFields", {"status":"resolved_other"})

> **Note**
>
> Ensure that you have the required RBAC permission to write scripts.

######## Use a playbook

When running a playbook, by default the data is added to the issue
context data and issue fields. You can additionally add this data to
case context data and case fields by configuring tasks in a playbook.

The following example explains how to add tasks to a playbook that
update the case fields to star a case, and add the key `starred: true`
to the case context data.

1.  Add the following tasks to a new or existing playbook.

    1.  Create a Conditional task to check whether the parent incident
        fields are starred using the `${parentIncidentFields.starred}`
        key.

    - ![](media/rId1415.png){width="5.833333333333333in"
      height="5.128472222222222in"}

    2.  Create a standard task using the `setParentIncidentFields`
        script to update the **starred** field.

    - ![](media/rId1418.png){width="5.833333333333333in"
      height="10.870587270341208in"}

    3.  Create a standard task to print the value to the **War Room**.

    - ![](media/rId1421.png){width="5.833333333333333in"
      height="4.203430664916885in"}

2.  Run the playbook.

- In the case context data, you can see the key `starred: true`. If
  running in an issue or a case, after refreshing the case, the case is
  now starred.

###### Case layouts

Cortex XSIAM includes default case layouts. The default case layouts and
any layouts that are added from content packs, are locked by default and
cannot be deleted, edited, exported or duplicated.

You can add customized case layouts, of which you can **Edit**,
**Duplicate**, **Delete** or **Export**. When creating or editing a case
layout, you can only add/edit tabs that you created. You cannot edit the
default tabs that exist in the layout.

####### Create custom case layouts

Custom case layouts let you choose the specific fields and buttons that
are displayed for different types of cases. You can create custom case
layouts that include both custom and out-of-the-box case fields.

Tabs that were created can be renamed, hid, duplicated, or deleted. To
make these changes, hover over the tab name, click the settings button,
and select the relevant option. You can drag and drop tabs to change the
order they appear. By default, empty fields within the tab are hidden in
the case layout. To show empty fields, hover over the tab name, click
the settings button, and select **Show empty fields**.

You cannot edit the **Overview**, **Key Assets & Artifacts**,
**Issues & Insights**, **Timeline**, **War Room**, and **Executions**
tabs in the case layout. Select **Hide Tab** to hide the tab, rather
than deleting the tab as you may want to use the tab again for future
use.

Custom case layouts and duplicates of system case layouts, can be
exported. To export a single case layout, right-click on the layout in
the layouts table, and select **Export**. To export all custom case
layouts and duplicates of system case layouts in a single JSON file,
click the **Export All** button above the layouts table.

You can import a custom case layout by clicking **Import** and uploading
the JSON file.

**How to create a custom case layout**

1.  Select Settings \> Configurations \> Object Setup \> Cases \>
    Layouts \> New Layout.

2.  Enter a name for the layout.

3.  To add a section, click on **New** or from the **Library** , under
    the **Sections** tab, drag and drop **New Section** into the new
    custom tab. You can also add a **Notes** section to the tab.

- By clicking on the pencil icon for a section, you can configure how a
  section appears, by hiding or showing the section header, as well as
  configuring the section fields to appear in rows or as cards.

4.  To add custom or out-of-the-box case fields to the layout, drag the
    fields from the **Fields** tab into existing sections or new
    sections that you added to the layout.

- > **Tip**

  > Limit the number of case fields to 50 in each section. You can
  > create additional sections as needed.

5.  Add buttons to the layout.

- Buttons allow you to add tasks to your layout, which can assist an
  analyst. For example, you can add a button to scan a host or kill a
  process.

  a.  From the **Fields and Buttons** tab of the **Library**, drag a
      buttons into a section of the layout.

  b.  **Click to configure**.

  c.  Enter a descriptive name for the button, select a color, and
      select the script that you want to run when the button is clicked.

  - For fields (script arguments) that are optional, you can define
    whether to show them to analysts when they click on buttons. To
    expose an optional field, select the **Ask User** checkbox next to
    the script argument(s) in the button settings page.

    > **Note**

    > The script that runs when an action button is clicked accepts only
    > mandatory arguments through the pop up window and does not provide
    > an option for any non-mandatory arguments to be filled in when the
    > button is clicked. We recommend using a wrapper script to collect
    > and validate arguments in scenarios where there can be a
    > combination of mandatory and non-mandatory arguments for a button.

  For information on **Filters and Transformers**, refer to [Filter and
  transform data](#UUID9d30fc2a99c0ff0469e40be239b972ba).

6.  Save the layout.

7.  (Optional) To modify an existing layout, right-click the layout in
    the layout table and select **Edit**, **Duplicate**, **Delete**, or
    **Export**.

####### Create rules for case layouts

Case layouts are applied to case according to layout rules. For example,
using a layout rule, you can assign a custom case layout based on the
case, such as a specific layout for cases with a high severity.

You can create multiple rules. If the first rule does not apply to the
incoming case, the next rule is checked, and so on. If a content pack is
installed and it contains a layout rule, the layout rule is placed at
the top of the rules list, by default. You can change the order of the
rules by dragging and dropping the rules in the list. You can filter the
rule list by name, description, rule, layout, and source. If no layout
rules apply to the case, a default case layout is used.

To edit or delete existing rules, right-click on the rule in the list
and select **Edit** or **Delete**.

> **Note**
>
> Layout rules support SBAC (scoped based access control). The following
> parameters are considered for editing access.

- > If **Scope-Based Access Control (SBAC)** is enabled and
  > **Endpoint Scoping Mode** is set to restrictive mode, you can edit a
  > rule if you are scoped to all tags in the rule.

- > If **Scope-Based Access Control (SBAC)** is enabled and
  > **Endpoint Scoping Mode** is set to permissive mode, you can edit a
  > rule if you are scoped to at least one tag listed in the rule.

- > As a scoped user who has editing permissions to a rule, you can
  > change the order among other rules that are locked.

- > If a rule was added when set to restrictive mode, and then changed
  > to permissive (or vice versa), you will only have view permissions.

**How to create rules for case layouts**

1.  Select Settings \> Configurations \> Object Setup \> Cases \> Layout
    Rules \> New Rule.

2.  Enter a **Rule Name**, select the custom or out-of-the-box
    **Layout to Display** if the rule is met, and provide a
    **Description**.

3.  Search for cases that match the criteria you want to use for the
    layout rule. For example, you can search for cases from a specific
    case source.

4.  Click **Create**.

5.  Repeat as needed to create multiple rules.

6.  Click **Save**.

##### Create a case domain

> **Warning**
>
> Before you add a custom domain, please review the built-in options.
> For more information, see [Case and issue
> domains](#UUID60c4e95d81e3f8730530e920dfd698e5).
>
> We recommend using the built-in domains where possible. Custom domains
> might not be supported by all content. In addition, custom domains
> affect Cortex XSIAM's ability to learn, correctly identify, and score
> future cases.
>
> Smart grouping and SmartScore are not supported for custom domains.

Custom domains help you to differentiate between your work efforts. You
can create tailored workflows for each domain, so that you can
effectively manage and prioritize your workload.

> **Note**

- > Adding custom domains requires a **View/Edit** RBAC permission for
  > **Case Properties** (under **Object Setup**).

- > Once created, a custom case domain cannot be deleted or renamed.

**How to create a case domain**

1.  Go to Settings \> Configurations \> Object Setup \> Cases \> Domains
    .

- The existing domains are listed.

2.  Click on **+ New Domain**.

3.  Assign a name and color to the domain, and an optional description.

4.  In the **Status** field, select one or more statuses that are
    relevant to the domain. These statuses will be available for
    selection in the cases and issues associated with this domain.

5.  In the **Resolution Type** field, select one or more resolution
    reasons that are relevant to the domain. These reasons will be
    available for selection in the cases and issues associated with this
    domain.

6.  Click **Save**.

7.  (Optional) Update SBAC scoping to enable access to the domain.

    a.  You can perform the following:

        - To enable access to the domain for a User Group, go to
          Settings \> Configurations \> Access Management \> User
          Groups.

        - To enable access to the domain for a User, go to Settings \>
          Configurations \> Access Management \> Users.

        - To enable access to the domain for an API key, got to Settings
          \> Configurations \> Integrations \> API Keys.

    b.  When editing an existing User Group, User, or API key, in the
        **Scope** tab you can update the granular scoping for the new
        **Endpoints** domain.

    c.  Click **Save**.

##### Create a sync profile

Sync profiles provide a blueprint for how information is exchanged
between Cortex XSIAM issues and external applications, by defining field
mapping. This ensures that relevant data, such as **Status** or
**Description**, is accurately transferred and maintains consistency,
even if the systems use different terminology.

When you link an issue with an external application (such as Jira), or
set up an automation, you can select the sync profile you want to use.
Cortex XSIAM provides default outbound and inbound sync profiles, or you
can create custom sync profiles as described in the following procedure.

**How to create a sync profile**

1.  Go to Settings \> Configurations \> Object Setup \> Issues \> Sync
    Profiles.

2.  Click **New Profile**.

3.  Type a profile name and description.

4.  Under **Integration**, select the external application with which
    you want to map fields, such as Jira V3 or ServiceNow V2.

5.  Under **Sync Direction**, select **Inbound** or **Outbound**. 

- If you select **Inbound**, you will define field mapping from the
  external application to Cortex XSIAM. If you select **Outbound**, you
  will define field mapping from Cortex XSIAM to the external
  application.

  > **Note**

  > If an issue is using bi-directional syncing, you need to provide
  > both an Inbound and an outbound sync profile.

6.  Under **Field Mapping**, select a field to map and select the
    corresponding field. For example, Jira: Priority, Cortex: Severity.

7.  Define one or more values for each field that you want to map.

- > **Note**

  - > Blank fields are skipped.

  - > You must define exact values.

  - > Custom status values are not currently supported.

  - > Support is currently limited to a specific set of fields.

8.  Click **Save**.

- In this example, the sync profile specifies Inbound mapping from Jira
  v3 fields to Cortex fields.

  ![](media/rId1319.png){width="5.833333333333333in"
  height="4.185416666666667in"}

##### Run indicator extraction in the CLI

In the issue **War Room** CLI you can run the following commands at the
issue level to extract and enrich indicators:

- `!extractIndicators`

<!-- -->

- If you want to extract indicators from non-War-Room-entry sources
  (such as extracting from files), use the `!extractIndicators` command
  from the issue **War Room** CLI. The command does not create
  indicators but extracts them only. Use the command to do the
  following:

  - **Validate regex:** Test a specific string to see if the relevant
    indicators are extracted correctly, such as a URL.

  - **In a playbook or automation:** The command extracts indicators in
    a playbook or automation non-war-room-source, and potentially also
    creates and enriches them (if required).

  You can extract from the following:

  - A specified entry (an entry ID)

  - Investigation (Investigation ID)

  - Text

  - File path

  For example, type
  `!extractIndicators text="some text 1.1.1.1 something" Auto extract=inline`.
  The entry text contains the text of the indicators, which is extracted
  and enriched. You can also extract indicators by adding the
  auto-extract parameter with the script and the mode for which you are
  setting it up. For example,
  `!ReadFile entryId=826@101 auto-extract=inline`. Usually, when using
  the CLI, you want to disable indicator extraction. For example, if you
  return internal/private data to the War Room, and you do not want it
  to be extracted and enriched in third-party services, add
  auto-extract=none to your CLI command.

<!-- -->

- `!enrichIndicators`

<!-- -->

- The `!enrichIndicators` command is usually used when you want to batch
  enrich indicators. This command works on existing indicators only (it
  does not create them on its own). When running the command, the
  relevant enrichment command is triggered (such as `!ip`), which is
  based on the indicator type that is found. The data is saved to
  context and to the indicator.

  > **Note**

  > Triggering enrichment on a substantial amount of indicators can take
  > time (since it\'s activating all enrichment integrations per
  > indicator) and can result in performance degradation.

<!-- -->

- Reputation commands (such as `!ip`)

<!-- -->

- This command can work on existing and non-existing indicators. If
  extraction is on, the data is saved both to the indicator and the
  issue's context. If not, then just to the context because the mapping
  flow is always triggered in enrichment commands. The default
  configuration is set to none in playbook tasks for extraction.

  The indicator does not need to exist to run the reputation command, as
  the command uses a third-party threat intel integration, such as Unit
  42, IPinfo, etc. You can also click the Enrich indicator button in the
  indicator layout.

#### Cortex Copilot

Cortex Copilot is an innovative AI tool specifically developed to
streamline various processes, including case triaging, investigation,
and remediation. By utilizing Cortex Copilot, you can uncover valuable
insights on a wide range of entities such as hashes, hosts, and more.
Its primary objective is to simplify these tasks, allowing for a more
efficient workflow and enhanced productivity.

One of the key features of Cortex Copilot is its ability to provide
personalized suggestions based on your specific needs and context. This
helps you find the most relevant information and solutions quickly and
effortlessly. Cortex Copilot offers easy access to the Help Center,
ensuring that users have comprehensive guidance and support readily
available.

Cortex Copilot allows users to execute commands using natural language
from anywhere within the interface. This means that users can interact
with the tool seamlessly, without losing their train of thought or
context.

##### Access Cortex Copilot

Cortex Copilot is conveniently accessible from the main menu in the left
pane, ensuring easy navigation and usage. Alternatively, you can
right-click on specific entities, such as an asset name or IP address,
and select **Open in Copilot** to immediately open the Cortex Copilot
with a focus on that entity.

To increase usability, you can create a personalized keyboard shortcut:
Settings \> Configurations \> Server Settings \> Keyboard Shortcuts and
choose the shortcut you want to use. You can use this shortcut anytime,
from anywhere within Cortex XSIAM, to instantly open Cortex Copilot. If
you highlight an entity and open Cortex Copilot with the keyboard
shortcut, it will open with a focus on that entity.

##### Cortex Copilot welcome screen

When you access Cortex Copilot, the welcome screen greets you with an
informative overview of the past 24 hours in your Cortex XSIAM
environment. This overview provides valuable insights at a glance,
including the number of cases resolved automatically, the count of
triggered playbooks, the average case score, and details about data
ingestion from various sources.

##### What can Cortex Copilot do for you?

- Ask a question and click **Ask the Help Center**. Cortex Copilot
  provides you with a summary of relevant documentation articles as well
  as a list of reference links to find in-depth information quickly.

- Use Cortex Copilot as a navigation tool to search for information,
  perform common investigation tasks, or initiate response actions.

- Perform investigations of entities such as cases, hashes, hosts,
  domains, IP addresses, and users, using advanced XQL queries and
  activate tailored responses.

##### Responsible AI

Cortex Copilot is developed in accordance with responsible AI
principles. Customer data is not used to train the AI models, and your
data is private and secure. For added security, user prompts are
processed within the tenant\'s region. For more information about
regional support in Cortex Copilot, see [regional
support](#UUIDcb4ea2d0c8ef3db435fe6b8398e0e9be). Safety and security
measures include user confirmation for write actions and adherence to
RBAC permissions. At the same time, explainability is maintained by
providing the logic behind answers and offering a feedback option for
user opinions. If you choose, you can disable the Cortex Copilot
functionality.

##### Cortex Copilot layout

Cortex Copilot consists of the following primary components:

###### Search bar

The search bar is located at the top of the Cortex Copilot screen. This
is where you interact with Cortex Copilot, providing a centralized
location to access assistance, obtain insights, and navigate the
platform efficiently.

###### Insights and suggestions

You can find Cortex Copilot\'s responses to your queries in the insights
and suggestions area. The insights section includes all the important
information Cortex Copilot can provide in response to your query.

Below that, Cortex Copilot offers suggestions, which are divided into
three columns, each with specific functionalities:

- **Investigate**: Choose from the recommended relevant questions you
  can ask to further your investigation. Responses leverage advanced XQL
  queries.

- **Respond**: Take action by running recommended playbooks or scripts,
  enabling you to initiate response actions based on Cortex Copilot\'s
  suggestions.

- **Navigate**: Ask the Help Center or navigate to related pages in
  Cortex XSIAM.

###### Action log

The action log in Cortex Copilot serves as a historical record of your
interactions and prompts. It maintains a log of each conversation
separately, including the date and time of each prompt you enter.

Any changes made to the prompt text are recorded as a new conversation
in the action log. This means that each prompt and its associated
actions are logged separately, allowing you to track and review your
interactions with Cortex Copilot. You can rerun a conversation or delete
a conversation from the action log. Opening a new tab or refreshing the
current tab will not reset the action log.

###### Feedback

In addition to tracking your prompts, the action log enables you to
provide feedback on Cortex Copilot\'s response. You can do this by
clicking on the thumbs-up or thumbs-down icons. If you choose to give
feedback, you have the option to provide as much detailed information as
you like, helping to improve the system\'s performance and accuracy.

##### Cortex Copilot capabilities

###### Ask the Help Center

When you ask a question of Cortex Copilot in natural language, the Help
Center provides summaries of product documentation together with links
to the source articles. When you ask Cortex Copilot questions, a link to
**Ask the Help Center** appears in the **Navigate** column. A summary of
the relevant documentation is displayed along with links to the
documentation sources.

The following are sample prompts:

- What are the minimum requirements for a Linux agent installation?

- What is a BIOC?

- How do I make a loop inside a playbook?

- Where can I review my data retention policies?

###### Entity investigation

The Cortex Copilot conducts investigations on entities entered in the
search bar. It can investigate a range of entities, including hosts,
users, hashes, domains, IP addresses, and cases. To initiate an
investigation, enter the entity name in the search bar or ask specific
questions about the entity, such as \"What are the events related to
\<entity\>?\". You can then select from the relevant options displayed
in the **Investigate** column, which includes a comprehensive set of
Cortex XQL library queries for conducting investigations. A summary of
the entity\'s details is displayed. For more details, click
**Show me more**.

![](media/rId1448.png){width="4.666666666666667in"
height="1.1783333333333332in"}

![](media/rId1451.png){width="5.425in" height="3.7975in"}

###### Respond

After entering an entity in the Cortex Copilot search bar, you have the
option to take action by selecting one of the suggestions listed in the
**Respond** column. These suggestions encompass a variety of actions,
such as running playbooks and scripts, performing scans, and collecting
support files.

> **Note**
>
> When you choose an option from the **Respond** column, Cortex Copilot
> will always prompt you to approve the action before executing.

###### RBAC

Cortex Copilot uses Cortex's role-based access control (RBAC) to control
the type of access and actions a user can perform in Cortex XSIAM.
Suggestions and responses offered by Cortex Copilot will be customized
according to that specific user's RBAC access. A user with Admin rights
can manage user roles that are assigned to Cortex XSIAM users or user
groups in Cortex XSIAM by selecting Settings \> Configurations \> Access
Management.

For more information on user roles and groups, see [Manage user roles
and access management](#UUIDe2101b004c635051f5a3eda9ac39aa5e).

###### Navigation mode

Use Cortex Copilot to navigate in Cortex XSIAM. You can search in
navigation mode in one of the following ways:

- Enter a forward slash "/" in the search bar, followed by your search
  string. For example, typing `/issues` searches for all pages that
  include the term \"issues\" and allows you to navigate to them
  directly.

- Enter your search string straight into the search bar. The relevant
  pages appear in the **Navigate** column.

Additionally, you can enter multiple search terms, and Cortex Copilot
will search for pages that include either of the terms (as if there were
a logical OR between the words).

###### Open a support case

By creating a support case directly from Cortex Copilot, you ensure that
relevant information is collected for troubleshooting, including tenant
details, Cortex XDR agent details, and optionally, screen and HAR
recording. Cortex Copilot also attaches the last conversation to the
support case for increased context.

To submit a support case:

1.  After entering a term in the search bar, select
    **Submit a support case** from the options provided.

2.  Follow the steps presented in the support case wizard to complete
    the submission.

Utilizing Cortex Copilot to open support cases streamlines the process
and ensures that key investigation details are retained, facilitating a
more efficient and effective resolution of issues.

###### Disable Cortex Copilot

Admin users can disable Cortex Copilot. To disable Cortex Copilot:

1.  In Cortex XSIAM, navigate to Settings \> Configurations \> Server
    Settings \> Cortex Copilot.

2.  Select **Disabled** and click **Save**.

- > **Note**

  > Disabling Cortex Copilot requires users to refresh their page.

###### Enable or disable Help Center LLM

Admin users can disable the Help Center LLM. In unsafe regions, the Help
Center is disabled by default. When it is enabled in an unsafe region,
user prompts may be sent out of the region. To enable or disable the
Help Center LLM:

1.  In Cortex XSIAM, navigate to Settings \> Configurations \> Server
    Settings \> Cortex Copilot.

2.  Under
    **Allow to interact with the Cortex Help Center in natural language**,
    select **Disabled** or **Enabled** and click **Save**.

###### Regional support

Support of various Cortex Copilot capabilities depends on the region
your tenant is in and how it is classified by Google. The following
describes which Cortex Copilot modules are supported in which region
type.

  -----------------------------------------------------------------------
  Cortex Copilot    Safe region       Beta regions      Unsafe regions
  module            (supported for    (supported for    (not supported
                    regional safety   regional safety   for regional
                    by Google)        by Google)        safety by Google)
  ----------------- ----------------- ----------------- -----------------
  Cortex Copilot    Enabled           Enabled           Enabled

  Help Center       Supported and     Supported and     Supported and
                    enabled by        enabled by        disabled by
                    default           default           default. If
                                                        enabled, prompts
                                                        may be sent out
                                                        of region.
  -----------------------------------------------------------------------

### Investigate cases

Start your investigation by reviewing the cases on the **Cases** page.
On this page, you can see details about the cases in your environment
and take actions to assign, investigate, and remediate your cases. For
more information about the connection between cases, issues, and
findings, see [What are cases?](#UUID7ce7cc737fa2a154a1361f612ff59896).

#### Overview of the Cases page

The **Cases** page is the first stop for investigating cases and issues.
On the **Cases** page, you can see information about the cases in your
environment. You can track and manage your cases, investigate issues
linked to a case, and take remedial action. If your cases are configured
with SLAs, you can monitor their progress and make sure that they are
aligned with your company\'s objectives.

By default, open cases are displayed, but you can change the filters to
browse through resolved cases too. To make it easy for you to identify
the most critical cases, Cortex XSIAM provides color-coded icons that
indicate severity, case scores, and starred cases. In addition, saved
table views provide customizable filter configurations, enabling you to
switch seamlessly between work queues and concentrate on the cases that
matter most to you.

> **Note**
>
> For MSSP and multi-tenant administrators, if the **Unified Case View**
> is enabled, this view consolidates all cases across your distributed
> environment, allowing you to view and perform actions on child
> tenants. If the **Unified Case view** is disabled, this view displays
> a single tenant at a time with a drop-down list for moving between
> tenants in read-only mode.
>
> You can enable this setting from Settings \> Configurations \> General
> \> Server Settings \> Unified Case View.

You can access the **Cases** page from Cases & Issues \> Cases. The page
is available in the following modes, and any changes that you make to
the case fields will persist between modes. To change between modes,
click on the menu icon
![](media/rId1465.png){width="0.2604166666666667in"
height="0.20833333333333334in"}.

- **Detailed view (default):** Displays cases in a split pane format
  that provides key details of each case and makes it easy to prioritize
  the most urgent cases. The list pane consolidates key information for
  each case based on filtering options. From the list, you can identify
  the most critical attacks and start prioritizing your cases.

- **Table view:** Displays a list of cases in a table format with
  widgets that summarize the table data. You can change the default
  fields used in the widgets to customize your page and display the
  fields that are most useful to you. By default all cases are
  displayed. You can use the saved table views (such as Posture Domain)
  to filter the displayed data, or create your own saved views. For more
  information, see [Saved table
  views](#UUIDb9a0582866ab2da82aca363ee587d86c).

##### Overview of case details

Click a case to see its full details in the details pane. The details
pane is split into the following sections and tabs:

+-----------------------------------+-------------------------------------------------+
| Section or tab                    | Description                                     |
+===================================+=================================================+
| Cases header                      | Displays detailed key information and provides  |
|                                   | administration actions for the case, such as    |
|                                   | assigning an analyst and setting the status.    |
|                                   | Hover and click on a field for more             |
|                                   | information, and edit where required.           |
+-----------------------------------+-------------------------------------------------+
| Overview                          | Displays the main case information, including   |
|                                   | the MITRE ATT&CK tactics and techniques         |
|                                   | identified in the case, the number of issues    |
|                                   | linked to the case, automation information      |
|                                   | about playbooks, and the key artifacts and      |
|                                   | assets involved in the case. You can click any  |
|                                   | of the widgets to start your investigation.     |
+-----------------------------------+-------------------------------------------------+
| Key Assets & Artifacts            | Displays asset and artifact information of the  |
|                                   | key artifacts, hosts, and users associated with |
|                                   | the case. Hover over an icon for more           |
|                                   | information, or click the more options icon to  |
|                                   | see the available views and actions. For more   |
|                                   | information about investigating key assets and  |
|                                   | artifacts, see [Investigate artifacts and       |
|                                   | assets](#UUIDa3fdf7d8b94a00147a543e7ea994f44b). |
+-----------------------------------+-------------------------------------------------+
| Issues & Insights                 | Displays a list of issues and insights linked   |
|                                   | to the case. Click on an issue or insight to    |
|                                   | open the issue card.                            |
|                                   |                                                 |
|                                   | > **Note**                                      |
|                                   | >                                               |
|                                   | > When an issue is resolved, it remains linked  |
|                                   | > to a case and appears in this section. Once   |
|                                   | > all of the issues in a case are resolved, the |
|                                   | > case is automatically closed.                 |
+-----------------------------------+-------------------------------------------------+
| Timeline                          | Displays a chronological representation of      |
|                                   | issues and actions relating to the case. Each   |
|                                   | timeline entry represents a type of action that |
|                                   | was triggered in the issue.                     |
|                                   |                                                 |
|                                   | Issues that include the same artifacts are      |
|                                   | grouped into one timeline entry and display the |
|                                   | common artifact in an interactive link. Click   |
|                                   | on an entry to view additional details in the   |
|                                   | Details pane. You can also filter the timeline  |
|                                   | by action type. Depending on the type of        |
|                                   | action, you can select the entry to further     |
|                                   | investigate and take action on it.              |
+-----------------------------------+-------------------------------------------------+
| Case War Room                     | The Case War Room is a collection of the Active |
|                                   | Response investigation actions, artifacts, and  |
|                                   | collaboration pieces for an issue or case. It   |
|                                   | is a chronological journal of the case          |
|                                   | investigation. You can run commands and         |
|                                   | playbooks from the War Room and filter the      |
|                                   | entries for easier viewing.                     |
|                                   |                                                 |
|                                   | The War Room facilitates real-time              |
|                                   | investigation. Powered by ChatOps, the War Room |
|                                   | helps analysts perform different tasks related  |
|                                   | to their case investigation using CLI commands. |
|                                   | For example, running real-time security actions |
|                                   | through the CLI, without switching consoles,    |
|                                   | and running security playbooks, scripts, and    |
|                                   | commands.                                       |
+-----------------------------------+-------------------------------------------------+
| Executions                        | Displays the causality chains associated with   |
|                                   | the case. On this tab you can investigate a     |
|                                   | causality chain and take actions on a host.     |
+-----------------------------------+-------------------------------------------------+

> **Tip**

- > Set a default tab in the details pane by selecting the pin icon next
  > to a tab.

- > Click on the **Notepad**, **Messenger**, and **Case Context Data**
  > icons to add notes on the case, and see existing notes from other
  > analysts.

##### Case fields and descriptions

To see a full list of case fields and descriptions, run the following
query in the **Query Builder**:

    datamodel dataset = cases

##### Saved table views

Saved table views are saved filter configurations of table data that
help you to focus on the data that most matters to you. You can filter
your table data by domain, context, work queue, or other criteria, and
save configurations that support your workflow.

Click the button on the left side of the filters to open your predefined
and custom table views. You can select a table view from the list, or
create your own custom configuration. Your saved table views are
available on any page where saved table views are supported.

![](media/rId1470.png){width="5.833333333333333in"
height="4.083333333333333in"}

###### Create a custom table view

You can create custom table views from scratch, or by editing an
existing table view.

Edit and existing table view

1.  Select a table view.

2.  Edit the filters on the table.

- You can also click Revert View the filters to the last saved version
  of the table view.

3.  Click the save icon and type a name for the table view. You can also
    choose whether to share the view with other users.

4.  Click **Save View**.

Create a table view from scratch

1.  Click the trash icon to remove all filters from the table.

2.  Configure filters on the table.

3.  Click the save icon and type a name for the table view. You can also
    choose whether to share the view with other users.

4.  Click **Save View**.

##### Unified case view

> **Note**
>
> Requires an MSSP license.
>
> **Note**

- > Requires the following RBAC permissions:

  - > Cases & Issues

  - > Investigation & Response \> Automation

- > This view is available for the parent tenant only.

- > To take actions on a child tenant from a parent tenant, you must
  > have the appropriate permissions for both tenants. If you do not
  > have the correct permissions, you can view cases in read-only mode.

For MSSP and multi-tenant administrators, the **Unified Case View**
provides a central location to view and perform actions on child tenants
across your distributed environment. You can see a consolidated view of
all cases, easily visualize and triage the cases in your environment,
and collaborate with child users.

You can access the **Unified Case View** from Cases & Issues \> Cases.

In the **Tenant Name** column you can see the name of the parent and
child tenants. Use this field to filter the table and see cases from a
specific child tenant. When you investigate a case on a child tenant
Cortex XSIAM pivots into the child tenant screen so that you can perform
actions directly in the case, and run commands in the **War Room**.

In addition, you can take bulk actions across multiple tenants, such as
changing the status and severity, and running playbooks. When running a
playbook on an issue, you can select from the playbooks that are
available in the child tenant. The **Tenant Name** column is also
displayed on the **Issues** page, and enables pivoting to the child
tenant.

> **Note**
>
> Custom case layouts of child tenants are not visible in the parent
> tenant.

Limitations

To ensure a streamlined user experience in the **Unified Case View**, we
want to make you aware of the current unsupported functionalities that
we are working to improve in the upcoming releases:

- Cases \> Table view

  - **Tags**, **Original Tags**, and Custom fields are not supported and
    therefore are not displayed in the table.

- Access Control

<!-- -->

- When viewing the **Unified Case View**, SBAC on the Parent Tenant is
  not enforced.

As a fallback option, you can disable the **Unified Case View** from
Settings \> Configurations \> Server Settings \> Unified Case View.

#### Review and investigate a case

On the **Cases** page you can track cases, investigate case details, see
the issues linked to a case, and take remedial action. Navigate to Cases
& Issues \> Cases and click on the case that you want to investigate.

> **Note**
>
> If you do not have permissions to access an asset of a case (which is
> shown as grayed out and locked), check your scoping permissions in
> **Manage Users** or **Manage User Groups**.

The following sections walk you through investigating case details on
the **Cases** page.

##### Review case list details

The case list provide a short summary of each case to help you to
quickly assess and prioritize your cases:

1.  Review the case severity, score, assigned domain, and assignee.
    Select whether to Star the case.

2.  Review the status of the case and when it was last updated.

3.  Review the case ID and case summary.

4.  Review the case assets and issue sources:

    - Review the host name associated with the case. If there is more
      than one host, select the `[+x]` to display the additional host
      names.

    - Review the user name associated with the case. If there is more
      than one user, select the `[+x]` to display the additional user
      names.

    - Hover over the issue source icons to display the issue source
      type. Select the issue source icon to display the three most
      common issues that were triggered and how many issues of each are
      associated with the case.

##### Update case details

Click on a case to open the case in the right panel. In the case header
you can update various data, such as the severity, case name, score, and
merge cases.

1.  Change the case severity.

- The default severity is based on the issue with the highest severity
  in the case. To manually change the severity select the severity tag
  and choose the new severity.

2.  Add or edit the case name.

3.  Edit the case description.

4.  Update the case score.

- Click on the assigned score to investigate how the score was
  calculated. The **Manage Case Score** dialog displays all rules that
  contributed to the case total score, including rules that have been
  deleted. Deleted scores appear with a **N/A**.

  You can override the **Rule based score** by selecting
  **Set score manually** or change the scoring method.

5.  Assign the case.

- Select the assignee (or **Unassigned**) and begin typing the
  assignee's email address for automated suggestions. Users must have
  logged in to the app to appear in the auto-generated list.

6.  Update the case status.

- Select the case **Status** to update the status to either **New**,
  **Under Investigation**, or **Resolved**. By updating the status you
  can indicate which cases have been reviewed and to filter by status in
  the cases table.

  When setting a case to **Resolved**, select the reason the resolution
  was resolved, add an optional comment, and select whether to
  **Mark all issues as resolved**. For more information, see [Resolution
  reasons for cases and issues](#UUID245034f82bc3db3f28264ec08c062aa2).

7.  Merge cases you think belong together. Click the more options icon
    and select **Merge Cases**.

- Information about merging scores and case assignees
  Case scoring is managed as follows:

  - **Rule Based Score:** Recalculates the case score to include the
    merged case scores.

  - **Manual Score:** Enter a score and override the rule-based score.

  Case assignees are managed as follows:

  - If both cases have been assigned, the merged case takes the target
    case assignee.

  - If both cases are unassigned, the merged case remains unassigned.

  - If the target case is assigned and the source case is unassigned,
    the merged case takes the target assignee.

  - If the target case is unassigned and the source case is assigned,
    the merged case takes the existing assignee.

  - In the merged case, all source context data is lost even if the
    target case does or doesn\'t contain context data. If the target
    case contains context data, that context data is preserved in the
    merged case.

8.  Create an exclusion.

- How to create an exclusion
  1.  Click the more options icon and select **Create Exclusion**.

  2.  Enter a rule name and description.

  3.  Filter the **Issues** table to define the issues that you want to
      include in the policy.

  4.  Select whether to apply the rule to existing issues.

  5.  Click **Create**.

9.  Review the remediation suggestions. Click the more options icon to
    open the **Remediation Suggestions** dialog.

10. Review the case assets.

- Review the number of issues, issue sources, hosts, users, and wildfire
  hits associated with the case. Select **Hosts**, **Users**, and
  **Wildfire Hits** to display the asset details.

11. Track and share your investigation progress.

- Add notes or comments to track your investigative steps and any
  remedial actions taken.

  - Select the Notepad
    (![](media/rId1483.png){width="0.14583333333333334in"
    height="0.20833333333333334in"}) to add and edit the case notes. You
    can use notes to add code snippets to the case or add a general
    description of the threat.

  - Use the Case Messenger
    (![](media/rId1486.png){width="0.14583333333333334in"
    height="0.20833333333333334in"}) to coordinate the investigation
    between analysts and track the progress of the investigation. Select
    the comments to view or manage comments.

  <!-- -->

  - If needed, **Search** to find specific words or phrases in Notepad
    and Messenger.

##### Review the case overview

The case **Overview** tab displays the MITRE tactics and techniques,
summarized timeline, and interactive widgets that visualize the number
of issues, types of sources, hosts, and users associated with the case.

1.  Review the MITRE tactics and techniques widget.

- Cortex XSIAM displays the number of issues associated with each tactic
  and technique. Select the centered arrow at the bottom of the widget
  to expand the widget and display the sub-techniques. Hover over a
  number of issues to display a link to the MITRE ATT&CK official site.

  > **Note**

  > In some cases, the number of issues associated with the techniques
  > will not be aligned with the number of the parent tactic because of
  > missing tags or in case an issue belongs to several techniques.

2.  Investigate information about the **Issues**,** Automation**,
    ** Issues Sources**, and **Assets** associated with the case.

    - In the **Issues** widget:

      - Select **See All** to pivot to the **Issues & Insights** table.

      - Review the **Total** number of issues and the colored line
        indicating the issue severity. Select the severity tag to pivot
        to the **Issues & Insights** table filtered according to the
        selected severity.

    - In the Automation widget:

      - If there is an issue that runs a playbook or a playbook
        recommends a playbook, either select the issue or to view all
        the issues in more detail, click the View in Issues & Insights
        tab.

      - If there are issues that did not trigger a playbook, click Go To
        Issues & Insights to view the issues and select a playbook, if
        relevant.

    - In the **Issue Sources** widget:

      - Select **See All** to pivot to the **Issues & Insights** table.

      - Select each of the issue source types to pivot to the
        **Issues & Insights** table filtered according to the selected
        issue source.

    - In the **Assets** widget:

      - Select **See All** to pivot to the **Key Assets and Artifacts**
        tab.

      - Select the host names to display the Details panel. The panel is
        only available for hosts with Cortex XDR agent installed and
        displays the host name, whether it's connected, along with the
        **Endpoint Details**, **Agent Details**, **Network**, and
        **Policy information**. Use the available actions listed in the
        top right-hand corner to take remedial actions.

      - Review Users that are marked as Featured.

      - If available, review the User Score allocated to each user.

3.  Review the artifacts and asset that are associated with the case.

- You can click the more options icon next to an asset or artifact to
  open an associated view, or you can see more details in the
  **Key Assets & Artifacts** tab.

##### Investigate key assets and artifacts

The **Key Assets & Artifacts** tab displays all the case asset and
artifact information of hosts, users, and key artifacts associated with
the case.

1.  Investigate artifacts.

- In the **Artifacts** section, search for and review the artifacts
  associated with the case. Each artifact displays, if available, the
  artifact information and available actions according to the type of
  artifact; File, IP Address, and Domain.

2.  Investigate hosts.

- In the **Hosts** section, search for and review the hosts associated
  with the case. Each host displays, if available, host information and
  available actions.

  To further investigate the host, select the host name to display the
  Details panel. The panel is only available for hosts with the agent
  installed and displays the host name, whether it's connected, along
  with the **Endpoint Details**, **Agent Details**, **Network**, and
  **Policy information** details. If the Details panel is not available,
  click the more options icon next to a host name to see the available
  options.

3.  Investigate users.

- In the **Users** section, search for and review the users associated
  with the case. Each user displays, if available, the user information
  and available actions

##### Investigate issues and insights

The **Issues & Insights** tab displays a table of the issues and
insights associated with the case.

1.  Use the table tabs to switch between issues and insights, and add
    filters to the table to refine the displayed entries.

2.  Click an issue to open the issue investigation panel. This panel
    provides detailed information about an issue, enables you to take
    actions on an issue, open the causality, and start remediation.

3.  If required, you can unlink the issue from the case or link it to
    other related cases. Click the more options icon and select
    **Link to case** or **Unlink from case**.

> **Note**
>
> When an issue is resolved it remains linked to a case. Once all of the
> issues in a case are resolved, the case is automatically closed.

##### Run an automation on an issue

You can run or rerun an automation on one or more issues. If there is
currently an automation running on one or more of the selected issues,
the **Run Automation** option does not appear. If an automation is
running on the issue, but has been paused (for example, waiting for a
user action), you can select to rerun the automation or select a new
automation.

1.  In the **Issues & Insights** tab, right-click one or more issue and
    click Run Automation.

2.  If the issues have an automation already assigned, choose Rerun
    current Automation or Choose another Automation. If the playbooks do
    not have an automation assigned, Choose an Automation.

3.  If you are not rerunning the current assigned automation, select an
    automation to run for the selected issues.

4.  Run the automation.

##### Investigate the case timeline

The case **Timeline** tab is a chronological representation of issues
and actions relating to the case.

1.  Navigate to the **Timeline** tab and filter the actions according to
    the action type.

2.  Investigate a timeline entry.

- Each timeline entry is a representation of a type of action that was
  triggered in the issue. Issues that include the same artifacts are
  grouped into one timeline entry and display the common artifact in an
  interactive link. Depending on the type of action, you can select the
  entry, host names, and artifacts to further investigate the action:

  - Locate the action you want to investigate:

    - For **Quick Actions** and **Case Management Actions**, you can add
      and view comments relating to the action.

    - For **Issues**, **Automatic Case Updates** and **Automation**
      actions, click the action to open the Details panel. In the panel,
      go to the **Issues** tab to view the issues table filtered by
      issues ID, the **Key Assets** to view a list of **Hosts** and
      **Users** associated to the issue, and an option to add
      **Comments**.

  - Select the Host name to display the endpoint data, if available.

  - Select the Artifact to display the following type of information:

    - **Hash artifact:** Displays the **Verdict**, **File name**, and
      **Signature status** of the hash value. Select the hash value to
      view the **Wildfire Analysis Report**, **Add to Block list**,
      **Add to Allow list** and **Search file**.

    - **Domain artifact:** Displays the **IP address** and **VT score**
      of the domain. Select the domain name to **Add to EDL**.

    - **IP address:** Display whether the IP address is **Internal** or
      **External**, the **Whois** findings, and the **VT score**. Expand
      **Whois** to view the findings and **Add to EDL**.

  - In action entries that involved more artifacts, expand
    **Additional artifacts found** to further investigate.

##### Investigate case executions

The **Executions** tab displays all the causality chains associated with
the case. The causality chains are aggregated according to the following
types of groupings:

- Host Name

  - Host with an agent installed

  - Host without an agent installed

  - Multiple Hosts

  - Undetected Host

- User Name

  - Username

  - Multiple Users

  - Undetected Users

> **Note**

- > Cloud related issues are displayed in the User Name grouping.

- > Prisma Cloud Compute issues are displayed in the Host Name grouping.

**How to investigate case executions**

1.  Investigate the host causality chains.

- In the **Executions** section, search for and review the hosts
  associated with the case. Review the host information and click the
  more options icon to perform actions on the host, or open related
  views.

2.  Investigate a causality chain.

- The causality chains are listed according to the Causality Group Owner
  (CGO), expand the CGO card you want to investigate. Each CGO card
  displays the CGO name, the following CGO event details, and the
  causality chain:

  - CGO Name

  - Issue Sources associated with the entire causality chain

  - Execution time of the causality chain

  - Number of issues that include the CGO according to severity.

  **Expand** the causality chain to further investigate and perform
  available Causality View actions. For more information, see [Causality
  view](#UUID791c9650b68681a6773a212fa63f65d2).

### Investigate issues

Issues help you to monitor and control the security of your system
framework by notifying you about risks to security in your framework.
Cortex XSIAM generates issues from the following:

- Rules that you set up, such as BIOC, IOC, correlation rules, malware
  rules, and vulnerability rules.

- Findings

<!-- -->

- Findings themselves are not issues; however, findings that match a
  specific logic can generate issues.

<!-- -->

- Agents

- Firewalls

- Analytics

- Integrations

<!-- -->

- Integrations enable you to ingest events, such as phishing emails,
  SIEM events, from third-party security and management vendors. You
  might need to configure the integrations to determine how events are
  classified as events. For example, for email integrations, you might
  want to classify items based on the subject field, but for SIEM
  events, you want to classify by event type.

To start an investigation, open a case and investigate the issues from
the **Issues & Insights** tab (recommended). You can also investigate
all issues from the **Issues** page.

#### Overview of the Issues page

The **Issues** page consolidates all non-informational issues from your
detection sources. By default, the **Issues** page displays the security
issues received over the last seven days. To access the **Issues** page,
go to Cases & Issues \> Issues.

Each issue is linked to one or more cases. A case provides the full
story of a problem by linking related issues, assets, and artifacts in
one place. To make sure that you understand the full picture of how an
issue fits into the bigger picture, we recommend that you start your
investigation from the **Cases** page. You can see the issues linked to
a case in the **Issues & Insights** tab of the selected case. Click on
an issue to open the Issue card. For more information see [Issue
card](#UUID74815c0f19a3aeac5c227fdd36c8f6c1).

For issues associated with the Health domain, these issues are not
linked to cases and should be investigated individually. You can also
see Health domain issues on the **Health Issues** page. For more
information, see [About health
issues](#UUIDdfd48b778b41de7955182409372663e9).

> **Note**
>
> Every 12 hours, the system enforces a cleanup policy to remove the
> oldest issues once the maximum limit is exceeded. The default issue
> retention period in Cortex XSIAM is 186 days.

##### Saved table views

On the **Issues** page you can change the displayed information by
changing the table view. When you open the page, the **Security Domain**
table view is displayed. Click the displayed table view to see your
predefined and custom table views. You can create custom table views
from scratch, or by editing the predefined options. For more
information, see [Saved table
views](#UUIDb9a0582866ab2da82aca363ee587d86c).

![](media/rId1470.png){width="5.833333333333333in"
height="4.083333333333333in"}

##### Standardized format of user names in issues

Cortex XSIAM processes and displays the names of users in the following
standardized format, also termed "normalized user".

`<company domain>\<username>`

As a result, any issue triggered based on network, authentication, or
login events displays the **User Name** in the standardized format in
the **Issues** and **Cases** pages. This impacts every issue for Cortex
XSIAM Analytics and Cortex XSIAM Analytics BIOC, including Correlation,
BIOC, and IOC issues triggered on one of these event types.

##### Deduplicated FW issues

To reduce noise in your environment, if firewall issues with the same
name and host are raised within 24 hours, the issues are deduplicated. A
label indicates the number of deduplicated issues up to 1,000 issue
counts, larger quantities display as 1000+.

##### Featured fields

You can highlight issues that are important to you by tagging speciﬁc
issue attributes, such as host names, user names, IP addresses, and
Active Directory, as featured fields. This can help you track issues.
For more information, see [Create a featured
field](#UUID8167cec1beb8c44a4fdfd9f67b3f681a).

##### Issue fields

To see a full list of issue fields and descriptions, run the following
query in the **Query Builder**:

    datamodel dataset = issues

#### Issue card

Click on an issue to start your investigation. The issue card is context
specific, therefore the content and tabs displayed in the card reflect
the context of the selected issue.

On the issue card you can see information about the cause of the issue,
take any actions required, and see the remediation suggestions. The
information displayed in each card is context specific. The following
tabs are common to most issues:

+-----------------------------------+--------------------------------------------------------+
| Tab                               | Description                                            |
+===================================+========================================================+
| Overview                          | Displays a description of the issue and provides key   |
|                                   | information, including:                                |
|                                   |                                                        |
|                                   | - Assignee                                             |
|                                   |                                                        |
|                                   | - Status                                               |
|                                   |                                                        |
|                                   | - Time that the issue was created and updated          |
|                                   |                                                        |
|                                   | - Suggested automations to run on the issue. Click the |
|                                   |   automation to open to the Work Plan tab with details |
|                                   |   of the automation.                                   |
|                                   |                                                        |
|                                   | - External tickets to which the issue is linked (such  |
|                                   |   as Jira or ServiceNow). Click the ticket number to   |
|                                   |   see the status of the ticket and the syncing         |
|                                   |   configuration. For more information, see [Issue      |
|                                   |   syncing](#UUID2bb6ef70767d1cb010f0c69c907b3fec).     |
|                                   |                                                        |
|                                   | - Affected Assets with links to the affected asset     |
|                                   |   cards                                                |
|                                   |                                                        |
|                                   | - Cases linked to the issue                            |
|                                   |                                                        |
|                                   | - (For issues related to Container images)             |
|                                   |   **Related Affected Assets** displays the assets that |
|                                   |   are related to the assets listed under               |
|                                   |   **Affected Assets**. For example, if one of the      |
|                                   |   associated assets is a container image running on a  |
|                                   |   VM, the VM will be listed under this section.        |
|                                   |                                                        |
|                                   | The Evidence section contains information to help you  |
|                                   | to investigate the issue, such as the causality chain. |
|                                   |                                                        |
|                                   | > **Note**                                             |
|                                   | >                                                      |
|                                   | > This section is context specific and shows data      |
|                                   | > according to the issue context.                      |
+-----------------------------------+--------------------------------------------------------+
| Issue Information                 | Displays a summary of the issue, such as issue details |
|                                   | , indicators, and outstanding tasks. Some fields are   |
|                                   | informational and some can be edited. Includes the     |
|                                   | following sections (depending on the layout):          |
|                                   |                                                        |
|                                   | - **ISSUE DETAILS**: A summary of the issue, such as   |
|                                   |   type, severity, and when the issue occurred. You can |
|                                   |   update these fields as required.                     |
|                                   |                                                        |
|                                   | - **COMMAND AND TASK RESULTS**: Lists any manual       |
|                                   |   commands and playbook task results.                  |
|                                   |                                                        |
|                                   | - **WORK PLAN**: View or take action on the following: |
|                                   |                                                        |
|                                   |   - **Playbook tasks**: When a playbook runs, any      |
|                                   |     outstanding tasks appear. You can take various     |
|                                   |     actions here or in the Work Plan tab.              |
|                                   |                                                        |
|                                   |   - **To-Do Tasks**: An ad-hoc item that is not        |
|                                   |     attached to the Work Plan. Create tasks for users  |
|                                   |     to complete as part of an investigation. These are |
|                                   |     like a To-Do list that you keep in an              |
|                                   |     investigation on an ad-hoc basis, rather than the  |
|                                   |     Work Plan which follows a pre-defined process. You |
|                                   |     can view or create To-Do tasks.                    |
|                                   |                                                        |
|                                   | - **NOTES:** Helps you understand specific actions     |
|                                   |   taken, and allow you to view conversations between   |
|                                   |   analysts to see how they arrived at a certain        |
|                                   |   decision. You can see the thought process behind     |
|                                   |   identifying key evidence and identifying similar     |
|                                   |   cases.                                               |
|                                   |                                                        |
|                                   | - **MALICIOUS OR SUSPICIOUS INDICATORS:** A list of    |
|                                   |   any malicious or suspicious indicators. If you have  |
|                                   |   the Threat Intel add-on you can pivot to the         |
|                                   |   Indicators page, where you can take further action   |
|                                   |   on the indicator.                                    |
|                                   |                                                        |
|                                   | - **INDICATORS HANDLING:** Take actions on indicators  |
|                                   |   from the displayed options.                          |
+-----------------------------------+--------------------------------------------------------+
| Technical Information             | Displays an overview of the information collected      |
|                                   | about the investigation, such as indicators, email     |
|                                   | information, URL screenshots, etc. When you run a      |
|                                   | playbook, the sections are automatically completed.    |
+-----------------------------------+--------------------------------------------------------+
| Investigation Tools               | Enables you to take action on the issue, such as       |
|                                   | converting a JSON file to CSV and check if the IP      |
|                                   | address is in CIDR.                                    |
+-----------------------------------+--------------------------------------------------------+
| War Room                          | A comprehensive collection of all investigation        |
|                                   | actions, artifacts, and collaboration. It is a         |
|                                   | chronological journal of the issue investigation. Each |
|                                   | issue has a unique War Room. For information, see [Use |
|                                   | the War Room in an                                     |
|                                   | investigation](#UUID2c0cd753c167d7894913ae53aec73a42). |
+-----------------------------------+--------------------------------------------------------+
| Work Plan                         | A visual representation of the running playbook that   |
|                                   | is assigned to the issue. For more information, see    |
|                                   | [Use the Work Plan in an                               |
|                                   | investigation](#UUID3b7e55c261ead80a61a75412eec0a2f7). |
+-----------------------------------+--------------------------------------------------------+
| Actions                           | Recommended actions to resolve the issue.              |
+-----------------------------------+--------------------------------------------------------+

##### Use the War Room in an investigation

The War Room contains an audit trail of all automatic or manual actions
that take place in a case or issue. A War Room is where you can review
and interact with your case or issue. Cortex XSIAM provides machine
learning insights to suggest the most effective analysts and
command-sets. Each case and issue has a unique War Room.

![](media/rId1507.png){width="5.833333333333333in"
height="3.339583333333333in"}

Within Cortex XSIAM, real-time investigation is facilitated through the
War Room, which is powered by ChatOps. In the War Room you can take the
following actions:

- Run real-time security actions through the CLI, without switching
  consoles

- Run security playbooks, scripts, and commands

- Collaborate and execute remote actions across integrated products

- Capture case context from different sources.

- Document all actions in one source.

- Communicate with others for joint investigations.

> **Note**
>
> The case War Room is usually used for communication capabilities, but
> unlike the issue War Room, it does not include playbook specific
> entries. The case War Room enables you to investigate an entire case,
> not just an issue.

Every case has a War Room, but every user has access, subject to
permissions, to a private War Room called the Playground.

**The Playground**

The Playground is a non-production environment where you can safely
develop and test data, such as scripts, APIs, and commands. It is an
investigation area that is not connected to a live (active)
investigation.

To access the Playground, do one of the following:

- Go to Investigation & Response \> Automation \> Playground

- In any browser, type
  `https://<tenant>.<region>.paloaltonetworks.com/playground`

> **Tip**
>
> In the Playground, you can clear the context data, if needed, which
> deletes everything in the Playground context data, but does not affect
> the actual issue or case. To clear the context, run
> `!DeleteContext all=yes'` from the CLI or
> click **Clear Context Data** while viewing the context data.

**The War Room**

When you open the War Room, you can see all the actions taken on a case,
such as commands and notes in several formats such as Markdown, and
HTML. When Markdown, HTML, or geographical information is received, the
content is displayed in the relevant format.

To view specific data entries, you can filter entries by selecting the
relevant checkbox, such as:

- **Chats**: Shows communication between team members.

- **Notes**: Any entries marked as notes.

- **Files**: Anything uploaded to the War Room in a playbook, script, or
  by the analyst.

- **Issue History**: Any issue field that was modified.

- **Commands and playbook tasks**: Any actions taken by playbook tasks
  or run manually by the analyst.

- **Tags**: Any tags added to the investigation.

> **Note**
>
> Cortex XSIAM does not index notes and chats.

In each War Room entry, you can take the following actions:

+-----------------------------------+-----------------------------------------------------+
| Action                            | Description                                         |
+===================================+=====================================================+
| Mark as note                      | Marks the entry as a note, which can help you       |
|                                   | understand why certain action was taken and assist  |
|                                   | future decisions.                                   |
|                                   |                                                     |
|                                   | You can also add a note by doing the following:     |
|                                   |                                                     |
|                                   | - Upload a file to the War Room by selecting        |
|                                   |   **Mark as Note**.                                 |
|                                   |                                                     |
|                                   | - If the **Issue Overview** tab includes a          |
|                                   |   **NOTES** section, add it to the section.         |
|                                   |                                                     |
|                                   | - In a playbook task (Advanced tab)                 |
|                                   |                                                     |
|                                   | <!-- -->                                            |
|                                   |                                                     |
|                                   | - Tasks can be automatically added from script      |
|                                   |   outputs as notes.                                 |
|                                   |                                                     |
|                                   | <!-- -->                                            |
|                                   |                                                     |
|                                   | - In the CLI by running the                         |
|                                   |   `!markAsNote entryIDs=<ID of the war room entry>` |
|                                   |   command.                                          |
|                                   |                                                     |
|                                   | <!-- -->                                            |
|                                   |                                                     |
|                                   | - In the relevant War Room entry, click             |
|                                   |   **Copy to CLI** to retrieve the                   |
|                                   |   `ID of the War Room entry`.                       |
|                                   |                                                     |
|                                   | When marked as a note, it is highlighted, so you    |
|                                   | can easily find them in the War Room or the         |
|                                   | **Issue Overview** tab.                             |
+-----------------------------------+-----------------------------------------------------+
| View artifact in new tab          | Opens a new tab for the artifact.                   |
+-----------------------------------+-----------------------------------------------------+
| Detach from task                  | Removes a task from the artifact.                   |
+-----------------------------------+-----------------------------------------------------+
| Attach to a task                  | Adds a task to the artifact.                        |
+-----------------------------------+-----------------------------------------------------+
| Add tags                          | Add any relevant tags to use that help you find     |
|                                   | relevant information.                               |
+-----------------------------------+-----------------------------------------------------+
| Copy to CLI                       | - ID: Entry IDs are used to uniquely identify War   |
|                                   |   Room entries and take the format                  |
|                                   |   `<ENTRY_IDENTIFER>@<CASE_ID>`, for example,       |
|                                   |   `54925dc3-a972-4489-8bef-793331fa6c77@1`. Many    |
|                                   |   out-of-the-box commands and scripts use entry IDs |
|                                   |   arguments to pass in files as inputs.             |
|                                   |                                                     |
|                                   | - URL: Copy the URL which is a direct link to the   |
|                                   |   War Room entry                                    |
|                                   |                                                     |
|                                   | To find the entry ID or URL of an entry in the War  |
|                                   | Room, click on the vertical ellipsis icon at the    |
|                                   | upper right of the entry, then copy the value.      |
+-----------------------------------+-----------------------------------------------------+

###### Run Commands in the War Room CLI

Cortex XSIAM enables you to run system commands, integration commands,
and scripts from an integrated command line interface (CLI), which
enables you to make comments in your case (in plain text or Markdown)
and to execute automation scripts, system commands, and integration
commands. This gives SOC teams the power to execute automations ad-hoc
to support their investigations or make notes as they investigate cases.

In the CLI, you can run various commands, by typing the following:

  -----------------------------------------------------------------------
  Action                              Description
  ----------------------------------- -----------------------------------
  `!`                                 Runs integration commands, scripts,
                                      and built-in commands, such as
                                      adding evidence and assigning an
                                      analyst.

  -----------------------------------------------------------------------

You can find relevant commands, scripts, and arguments with the CLI's
auto-complete feature. This also includes fuzzy searching to help you
find relevant commands based on keywords. If you type the exclamation
mark (**!**) and start typing, autocomplete populates with options that
might suit your needs. For example, if you want to work with tasks, type
`!task`, and all commands and scripts that include the `task` in their
name will display.

> **Tip**
>
> You can use the up/down arrow buttons in the CLI to do a reverse
> history search for previous commands with the same prefix.

Special characters

  ----------------------------------------------------------------------------
  Characters                               Description
  ---------------------------------------- -----------------------------------
  `&&, ||, !, {, }, [, ], (, ), ~, *, ?`   To use these characters, place them
                                           within single or double quotes. An
                                           escape character `\` is not
                                           required.

  `\, \n, \t, \r, ", ^, :,` comma, and     To use these characters, place them
  space                                    within single or double quotes and
                                           use an escape character `\`.
  ----------------------------------------------------------------------------

Common arguments

The following common arguments are available for every script run from
the CLI.

+-----------------------------------+------------------------------------------------------------------+
| Argument Name                     | Description                                                      |
+===================================+==================================================================+
| auto-extract                      | Whether/when to extract indicators. Possible values:             |
|                                   |                                                                  |
|                                   | - `inline`: Extracts indicators within the indicator extraction  |
|                                   |   run context (synchronously).                                   |
|                                   |                                                                  |
|                                   | - `outofBand`: Extracts indicators in parallel (asynchronously)  |
|                                   |   to other actions.                                              |
|                                   |                                                                  |
|                                   | - `none`: Does not extract indicators (recommended for scripts   |
|                                   |   with large outputs when indicator extraction is not required). |
+-----------------------------------+------------------------------------------------------------------+
| execution-password                | Supplies a password to run a password-protected script.          |
+-----------------------------------+------------------------------------------------------------------+
| execution-timeout                 | Defines how long a command waits in seconds before it times out. |
+-----------------------------------+------------------------------------------------------------------+
| extend-context                    | Select which information from the raw JSON you want to add to    |
|                                   | the context data.                                                |
|                                   |                                                                  |
|                                   | For a single value: `contextKey=RawJsonOutputPath`               |
|                                   |                                                                  |
|                                   | For multiple values:                                             |
|                                   | `contextKey1=RawJsonOutputPath1::contextKey2=RawJsonOutputPath2` |
+-----------------------------------+------------------------------------------------------------------+
| ignore-outputs                    | Possible values: `true` or `false`. If set to `true`, it does    |
|                                   | not store outputs in the context (besides extend context).       |
+-----------------------------------+------------------------------------------------------------------+
| raw-response                      | Possible values: `true` or `false`. If set to `true`, it returns |
|                                   | the raw JSON result from the script.                             |
+-----------------------------------+------------------------------------------------------------------+
| retry-count                       | Determines how many times the script attempts to run before      |
|                                   | generating an error.                                             |
+-----------------------------------+------------------------------------------------------------------+
| retry-interval                    | Determines the wait time (in seconds) between each script        |
|                                   | execution.                                                       |
+-----------------------------------+------------------------------------------------------------------+
| using                             | Selects which integration instance runs the command.             |
+-----------------------------------+------------------------------------------------------------------+
| using-brand                       | Selects which integration runs the command. If the selected      |
|                                   | integration has multiple instances, the script may run multiple  |
|                                   | times. Use the `using` argument to select a single integration   |
|                                   | instance.                                                        |
+-----------------------------------+------------------------------------------------------------------+
| using-category                    | Selects which category of integrations runs the command. If the  |
|                                   | selected category includes multiple integration instances, the   |
|                                   | script may run multiple times. Use the `using`argument to select |
|                                   | a single integration instance.                                   |
+-----------------------------------+------------------------------------------------------------------+

Run commands in the Automations browser

You can view and run commands and scripts (not system commands,
operations, and notifications) in the **Automations Browser**, by
clicking ![](media/rId1512.png){width="0.21577318460192477in"
height="0.20833333333333334in"} next to the CLI.

The **Automations Browser** enables you to run commands and all
associated arguments. The scripts and commands are separated into
sections such as scripts and built-in commands. In each argument, you
can do the following:

- Hardcode the value

- Use a dynamic value

<!-- -->

- You can dynamically pass information into the argument, by clicking
  the curly bracket. For example, the `EmailAskUser` command asks a user
  a question via email. In the `email` argument, rather than typing the
  user\'s email address, you can send it to whoever created the case.

  1.  In the **email** field, click the curly brackets.

  2.  In the search box, enter `created`.

  3.  Under **CASE DETAILS** click **Created by**.

  - The email argument appears as `${alert.dbotCreatedBy}`.

  4.  Run the command.

  - An email is sent to the user who created the case.

  You can use transformers and filters to filter and transform data from
  the command.

Common arguments when using the Automations browser

+-----------------------------------+------------------------------------------------------------------+
| Argument                          | Description                                                      |
+===================================+==================================================================+
| Using                             | Selects which integration instance runs the command.             |
+-----------------------------------+------------------------------------------------------------------+
| Extend context                    | Determines the wait time (in seconds) between each script        |
|                                   | execution.                                                       |
|                                   |                                                                  |
|                                   | For a single value: `contextKey=RawJsonOutputPath`               |
|                                   |                                                                  |
|                                   | For multiple values:                                             |
|                                   | `contextKey1=RawJsonOutputPath1::contextKey2=RawJsonOutputPath2` |
+-----------------------------------+------------------------------------------------------------------+
| Ignore outputs                    | Does not store outputs in the context (besides extend context).  |
+-----------------------------------+------------------------------------------------------------------+
| Execution timeout (seconds)       | Defines how long a command waits in seconds before it times out. |
+-----------------------------------+------------------------------------------------------------------+
| Number of retries                 | Determines how many times the script attempts to run before      |
|                                   | generating an error.                                             |
+-----------------------------------+------------------------------------------------------------------+
| Retry interval (seconds)          | Determines the wait time (in seconds) between each script        |
|                                   | execution.                                                       |
+-----------------------------------+------------------------------------------------------------------+

Examples using the CLI

To run the print script with a value of `"hello"` and the key `a` from
the context:

`!Print value="hello ${a}"`

To run the Python command returning Hello World using escape characters:

`!py script="demisto.results(\"hello world\")"`

To run the Python command returning Hello World using backticks:

`` !py script=`demisto.results("hello world")` ``

##### Use the Work Plan in an investigation

The Work Plan is a visual representation of the running playbook
assigned to the issue. Playbooks enable you to automate many security
processes, such as managing your investigations and handling tickets.
Work Plans enable you to monitor and manage a playbook workflow, and add
new tasks to tailor the playbook to a specific investigation.

In an investigation, when you open the **Work Plan** tab you can see the
playbook, the playbook name, and navigation tools.

By default, the **Follow** checkbox is checked, which allows you to see
the playbook executing in real-time. The playbook moves when a task is
completed.

In the Work Plan you can do the following:

+-----------------------------------+-----------------------------------+
| Action                            | Description                       |
+===================================+===================================+
| Change the default playbook       | On the left-hand side of the      |
|                                   | window, select the playbook you   |
|                                   | want to run.                      |
|                                   |                                   |
|                                   | When changing the playbook, all   |
|                                   | completed tasks are removed and   |
|                                   | the new playbook will run. If you |
|                                   | select playbooks several times    |
|                                   | you can view the history of which |
|                                   | playbooks ran.                    |
+-----------------------------------+-----------------------------------+
| Rerun the playbook                | When changing the playbook,       |
|                                   | select the current playbook to    |
|                                   | run again.                        |
+-----------------------------------+-----------------------------------+
| View inputs and outputs           | View the inputs and outputs of    |
|                                   | each task that has run. You       |
|                                   | can\'t view inputs and outputs of |
|                                   | any task that hasn\'t run.        |
+-----------------------------------+-----------------------------------+
| Manage tasks                      | View, create, and edit a playbook |
|                                   | task. For each task, you can do   |
|                                   | the following:                    |
|                                   |                                   |
|                                   | - Designate tasks as complete     |
|                                   |   either manually or by running a |
|                                   |   script.                         |
|                                   |                                   |
|                                   | - Assign an owner.                |
|                                   |                                   |
|                                   | - Set a due date.                 |
|                                   |                                   |
|                                   | - Add comments and completed      |
|                                   |   notes, as required.             |
|                                   |                                   |
|                                   | - View any automation exclusion   |
|                                   |   policies that affected the task |
|                                   |   execution. Automation exclusion |
|                                   |   policies prevent automated      |
|                                   |   remediation on critical assets  |
|                                   |   specified by admins. The        |
|                                   |   **Policies** tab only appears   |
|                                   |   if the task includes a command  |
|                                   |   or script affected by an        |
|                                   |   automation exclusion policy.    |
|                                   |                                   |
|                                   | You can manage these tasks in the |
|                                   | CLI by using the `/task` command. |
+-----------------------------------+-----------------------------------+
| Export to a PNG                   | Export the Work plan to a PNG     |
|                                   | format for easy analysis.         |
+-----------------------------------+-----------------------------------+

For a phishing investigation, after the initial playbook run parses the
email and extracts email addresses, as part of the manual investigation,
you could use the **Email Address Enrichment - Generic v2.1** playbook
as an ad-hoc playbook task to get more information about these email
addresses.

The color coding and symbols in the Work Plan help you to easily
troubleshoot errors or respond to manual steps. The following table
displays the playbook tasks and icons in the Work Plan.

###### Playbook tasks and icons in the Work Plan

+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| Task                                               | Description                                                                                   |
+====================================================+===============================================================================================+
| ![](media/rId1521.png){width="5.013888888888889in" | ![](media/rId1524.png){width="0.21666666666666667in"                                          |
| height="2.611111111111111in"}                      | height="0.20833333333333334in"}**Standard manual task**                                       |
|                                                    |                                                                                               |
|                                                    | An arrow with a light blue square background indicates a standard manual task. These tasks    |
|                                                    | can ether be manual (no lightning bolt logo) or automated (with lightning bolt logo).         |
|                                                    |                                                                                               |
|                                                    | - Manual Standard task (no lightning bolt logo):                                              |
|                                                    |                                                                                               |
|                                                    | <!-- -->                                                                                      |
|                                                    |                                                                                               |
|                                                    | - These tasks are used where usually it\'s not possible to automate them. You can add         |
|                                                    |   comments, assign them to an owner, and set a due date. The analyst who is responsible for   |
|                                                    |   the investigation needs to complete the task before the Work Plan can continue.             |
|                                                    |                                                                                               |
|                                                    | <!-- -->                                                                                      |
|                                                    |                                                                                               |
|                                                    | - Automated Standard task (with lightning bolt logo):                                         |
|                                                    |                                                                                               |
|                                                    | <!-- -->                                                                                      |
|                                                    |                                                                                               |
|                                                    | - A single command or script that is set to automatically run when the Work Plan reaches this |
|                                                    |   step. Some scripts need arguments in order to run - make sure to set them up properly. If   |
|                                                    |   left empty, the analyst who is responsible for the investigation will need to complete them |
|                                                    |   so the script will run and the Work Plancan continue.                                       |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1527.png){width="4.972222222222222in" | ![](media/rId1530.png){width="0.21505358705161856in"                                          |
| height="2.375in"}                                  | height="0.20833333333333334in"}**Conditional task**                                           |
|                                                    |                                                                                               |
|                                                    | A diamond icon in a purple square background indicates a conditional task, which is either an |
|                                                    | automated conditional task (with the lightning bolt logo) or a manual conditional task. These |
|                                                    | tasks are used as decision trees in your Work Plan.                                           |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1533.png){width="4.916666666666667in" | ![](media/rId1536.png){width="0.25143591426071743in"                                          |
| height="1.1111111111111112in"}                     | height="0.20833333333333334in"}**Data collection task / Communication task**                  |
|                                                    |                                                                                               |
|                                                    | The speech bubble in a turquoise background  indicates a data collection task. This task      |
|                                                    | prompts the receivers to respond to a multi-question form and submit replies, even if they    |
|                                                    | are not Cortex users.                                                                         |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1539.png){width="4.902777777777778in" | ![](media/rId1542.png){width="0.1899507874015748in"                                           |
| height="1.1388888888888888in"}                     | height="0.20833333333333334in"}**Sub-playbook task**                                          |
|                                                    |                                                                                               |
|                                                    | The workflow icon in a blue background indicates that the task is a playbook nested within    |
|                                                    | the parent playbook. You can view that playbook by opening the task and selecting             |
|                                                    | **Open sub-playbook**.                                                                        |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1545.png){width="5.833333333333333in" | ![](media/rId1548.png){width="0.2370680227471566in"                                           |
| height="1.2705172790901138in"}                     | height="0.20833333333333334in"}**Task containing a deprecated script or needs to be updated** |
|                                                    |                                                                                               |
|                                                    | Scripts that have updates or are deprecated are designated by a yellow triangle. You need to  |
|                                                    | update the scripts and integration commands in playbook tasks to their most current version.  |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1551.png){width="5.833333333333333in" | ![](media/rId1554.png){width="0.20182195975503062in"                                          |
| height="1.286438101487314in"}                      | height="0.20833333333333334in"}**Set to skip**                                                |
|                                                    |                                                                                               |
|                                                    | When a task is set to skip, the skip icon will be orange.                                     |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1557.png){width="5.833333333333333in" | ![](media/rId1560.png){width="0.22786417322834646in"                                          |
| height="1.264258530183727in"}                      | height="0.20833333333333334in"}**Breakpoint**                                                 |
|                                                    |                                                                                               |
|                                                    | When the playbook reaches a breakpoint, the task has an orange line at the top to indicate    |
|                                                    | the breakpoint.                                                                               |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1563.png){width="5.833333333333333in" | ![](media/rId1566.png){width="1.1067705599300088in"                                           |
| height="1.2815649606299213in"}                     | height="0.20833333333333334in"}**Overridden inputs or outputs**                               |
|                                                    |                                                                                               |
|                                                    | When a task is set to have overridden inputs or outputs, the word Input or Output appears in  |
|                                                    | orange.                                                                                       |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1569.png){width="5.833333333333333in" | ![](media/rId1572.png){width="0.21577318460192477in"                                          |
| height="1.2849245406824148in"}                     | height="0.20833333333333334in"}**Pending/in queue task**                                      |
|                                                    |                                                                                               |
|                                                    | When the Work Plan starts to run, all tasks that are about to be performed are gray.          |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1575.png){width="5.833333333333333in" | ![](media/rId1578.png){width="0.19444444444444445in"                                          |
| height="1.338234908136483in"}                      | height="0.20833333333333334in"}**Running/ in progress task**                                  |
|                                                    |                                                                                               |
|                                                    | A spinning circle inside the gray square indicates a running/in progress  task.               |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1581.png){width="5.833333333333333in" | ![](media/rId1584.png){width="0.19396544181977252in"                                          |
| height="1.272101924759405in"}                      | height="0.20833333333333334in"}**Completed task**                                             |
|                                                    |                                                                                               |
|                                                    | The green square indicates a completed task.                                                  |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1587.png){width="5.833333333333333in" | ![](media/rId1590.png){width="0.2148436132983377in"                                           |
| height="2.6905227471566056in"}                     | height="0.20833333333333334in"}**Waiting task**                                               |
|                                                    |                                                                                               |
|                                                    | The orange square indicates that the playbook is pending action.                              |
|                                                    |                                                                                               |
|                                                    | If you hover on the icon on the top left corner, details about the specific reason this task  |
|                                                    | is in waiting mode appears.                                                                   |
|                                                    |                                                                                               |
|                                                    | If the orange square is paired with the user icon ( ![](media/rId1593.png){width="0.21875in"  |
|                                                    | height="0.20833333333333334in"}), the task requires you to open it and manually mark it as    |
|                                                    | complete.                                                                                     |
|                                                    |                                                                                               |
|                                                    | If the orange square is paired with a speech bubble icon                                      |
|                                                    | (![](media/rId1596.png){width="0.19736767279090114in" height="0.20833333333333334in"}), the   |
|                                                    | task is waiting for a questionnaire to be completed.                                          |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1599.png){width="5.833333333333333in" | ![](media/rId1602.png){width="0.22849409448818897in"                                          |
| height="2.726071741032371in"}                      | height="0.20833333333333334in"}**Failed task**                                                |
|                                                    |                                                                                               |
|                                                    | The red warning icon indicates that the automation failed to complete as expected and         |
|                                                    | requires manual inspection and troubleshooting. Contact your Cortex XSIAM administrator.      |
|                                                    |                                                                                               |
|                                                    | If you hover on the icon on the top left corner details about the specific problem appears.   |
|                                                    |                                                                                               |
|                                                    | If red warning icon is paired with the clock icon                                             |
|                                                    | (![](media/rId1605.png){width="0.17045384951881015in" height="0.20833333333333334in"}), the   |
|                                                    | task's SLA is overdue.                                                                        |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
| ![](media/rId1608.png){width="5.833333333333333in" | ![](media/rId1611.png){width="0.20833333333333334in"                                          |
| height="1.3216141732283464in"}                     | height="0.20833333333333334in"}**Skipped task**                                               |
|                                                    |                                                                                               |
|                                                    | The task will look faded to indicate it was not executed. This can happen if this task was    |
|                                                    | set to be skipped when an error occurs, or if it is in a branch that was not executed if a    |
|                                                    | condition wasn't met.                                                                         |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+
|                                                    |                                                                                               |
+----------------------------------------------------+-----------------------------------------------------------------------------------------------+

###### Add ad-hoc tasks to the Work Plan

As part of your issue investigation, within the Work Plan you can create
tasks for a specific iteration of a playbook. The task type can be an
automation or another playbook. For example, within a manual task, you
might need to enrich some data and run an investigation playbook.

When you create a task, add a name, automation, and description. The
name and description should be meaningful so that the task corresponds
to the data that you are collecting.

1.  In the **Cases** page, select the case to update.

2.  In the **Issues & Insights** tab, click the issue to add the task to
    and then click the **Work Plan** tab.

3.  In the Work Plan, go to the task where you want to add a new task
    and click the + sign at the bottom right-hand corner of the task.

- The ad-hoc task is added after the task you clicked.

4.  Select the task type.

    - **Standard**: Runs a single automation.

    - **Playbook**: Runs a playbook to enhance the investigation.

    <!-- -->

    - The playbook functions as any playbook would and requires you to
      define the inputs and outputs, as well as any other details.

    <!-- -->

    - Click **Save**.

5.  To run the Work Plan again click the **Run Again** icon.

#### Triage and investigate issues

Issues are displayed in the **Issues** table in the
**Issues & Insights** table on the **Cases** page, and on the **Issues**
page. Use the following steps to investigate and triage an issue:

1.  Review the data shown in the issue such as the command-line
    arguments (CMD), process info, etc.

2.  Analyze the chain of execution in the causality view.

- When the app correlates an issue with additional endpoint data, the
  **Issues** table displays a green dot to the left of the row to
  indicate the issue is eligible for analysis in the causality view. If
  the issue has a gray dot, the issue is not eligible for analysis in
  the causality view. This can occur when there is no data collected for
  an event, or the app has not yet finished processing the EDR data. To
  view the reason analysis is not available, hover over the gray dot.

3.  If deemed malicious, consider responding by isolating the endpoint
    from the network.

4.  Remediate the endpoint and return the endpoint from isolation.

5.  Inspect the information again to identify any behavioral details
    that you can use to create a correlation rule or a BIOC rule. If you
    can create a BIOC or Correlation rule, test and tune the logic for
    the rule, and then save it.

##### Copy issues

You can copy issue text into memory and paste it into an email. This is
helpful if you need to share or discuss a specific issue with someone.
If you copy a field value, you can also paste it into a search or begin
a query.

**How to copy an issue value**

1.  From the **Issues** page, right-click the issue you want to send.

2.  Select one of the following options: .

    - **Copy text to clipboard**

    - **Copy entire row**

    - **Copy issue URL**

- Cortex XSIAM saves the copied text to memory.

3.  Paste the URL into an email or use it as needed to share the
    information.

##### Analyze an issue

To help you understand the full context of an issue, Cortex XSIAM
provides the issue card and the causality view to help you to quickly
make a thorough analysis of the issue.

The causality view is available for XDR agent issue that are based on
endpoint data and for issues raised on network traffic logs that have
been stitched with endpoint data. In addition, you can use the cloud
causality view to analyze cloud Cortex XSIAM issues and cloud audit
logs. While the SaaS causality view enables you to analyze and
investigate software-as-a-service (SaaS) related issues for audit
stories, such as Office 365 audit logs and normalized logs.

**How to view issue analysis**

1.  From the **Issues** table, click in issue to open the issue card, or
    right-click an issue and select and select
    **Investigate Causality Chain**.

2.  Review the chain of execution and available data for the process
    and, if available, navigate through the process tree.

##### Run an automation on an issue

You can automate issue investigation and remediation by running a
playbook or Quick Action on one or more issues. Automations can help to
improve efficiency by automating and standardizing your workflows,
promoting consistent and effective case response and management. For
example, automations can automatically remediate a case by interacting
with a third-party integration or open tickets in a ticketing system
such as Jira.

You can view the playbook that is running on an issue or the playbooks
that have already run in the **Work Plan** for an issue. You can view
Quick Actions in the **War Room** for an issue.

> **Note**
>
> In addition to automation, some playbooks contain manual tasks that
> prompt the analyst for input. This enables you to enhance an
> automation workflow with analyst input.

You can run automations in the following ways:

Manually run a playbook or Quick Action on one or more issues

1.  Right-click one or more issues in the Issues table and select Run
    Automation.

- If there is currently an automation running on one or more of the
  selected issues, the **Run Automation** option does not appear. If an
  automation is running on the issue, but has been paused (for example,
  waiting for a user action), you can select to rerun the automation or
  select a new automation.

2.  If the issues have an automation already assigned, choose Rerun
    current Automation or Select another Automation. If the issues do
    not have an automation assigned, Select Automation.

3.  If you are not rerunning the current assigned automation, select an
    automation to run for the selected issue(s).

4.  Click Run.

> **Note**
>
> You can also manually select a playbook to run from the Issue
> **Work Plan** tab.

Apply automation rules

You can create automation rules that automatically run a playbook or
Quick Action when an issue is created that meets specific criteria. For
more information, see [Create an automation
rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c).

For more information, see [Automation in Cortex
XSIAM](#UUID5227be4a84c78144050433f8b3bfdaf2).

##### Create profile exceptions

For Cortex XDR agent related issues, you can create profile exceptions
for Window processes, BTP, and JAVA deserialization issues directly from
the **Issues** table.

1.  Identify an **XDR Agent** issue which has a category of **Exploit**,
    right-click and select Manage Issue.

2.  Select an **Exception Scope**:

    - **Global:** Apply the exception across your organization.

    - **Profile:** Apply the exception to an existing profile or click
      and enter a **Profile Name** to create a new profile.

3.  Click **Add** to add the scope.

4.  (Optional) View your profile exceptions.

    a.  Go to Inventory \> Endpoints \> Policy Management \> Profiles.

    b.  In the **Profiles** table, locate the OS in which you created
        your global or profile exception and right-click to view or edit
        the exception properties.

##### Investigate contributing events

When investigating an issue generated by a correlation rule, you can
view all of the events created for the issue. You can have up to 1000
events per correlation rule.

In addition, if the correlation rule includes a drilldown query you can
run the query in the **Query Builder**. The drilldown query provides
additional information about an issue for further investigation.

**How to investigate contributing events**

1.  From the **Issues** table, locate an issue created by a correlation
    rule.

2.  Right-click the row, and select Manage Issue \> Investigate
    Contributing Events.

3.  (*Optional*) Open the drilldown query, if available.

- Right-click the row and select Manage Issue \> Open Drilldown Query.

  The drilldown query can accept parameters from the issue output for
  the correlation rule. In addition, the issue time frame used to run
  the drilldown query provides more details about the issue generated by
  the correlation rule. The time frame is the minimum and maximum
  timestamps of the events for the issue. If there is only one event,
  the event timestamp is the time frame used for the query.

##### Retrieve additional issue details

To help you with issue analysis, Cortex XSIAM can provide related files
and memory content analysis.

1.  From the **Issues** page, locate the issue for which you want to
    retrieve information.

2.  Right-click anywhere in the issue, and select one of the following
    options:

    - **Retrieve Additional Data:** Cortex XSIAM can provide related
      files and additional analysis of the memory contents when an
      exploit protection module raises an issue.

      - Select **Retrieve issue data and analyze** to retrieve issue
        data consisting of the memory contents at the time the issue was
        raised. You can also enable Cortex XSIAM to automatically
        retrieve issue data for every relevant issue. After Cortex XSIAM
        receives the data and performs the analysis, it issues a verdict
        for the issue. You can monitor the retrieval and analysis
        progress from the **Action Center** (pivot to view
        **Additional data**). When the analysis is complete, it displays
        the verdict in the **Advanced Analysis** field.

      - **Retrieve related files:** To further examine files that are
        involved in an issue, you can request the agent send them to the
        Cortex XSIAM tenant. If multiple files are involved, the tenant
        supports up to 20 files and 200MB in total size. The agent
        collects all requested files into one archive and includes a log
        in JSON format containing additional status information. When
        the files are successfully uploaded, you can download them from
        the **Action Center** for up to one week.

      - Pivot to views \> View in source system: For issues ingested
        from third-party vendors, this option pivots to the issue in the
        third-party system.

      <!-- -->

      - To enable this feature, ensure that Cortex XSIAM has a
        correlation rule that contains the **External URL** field. For
        more information, refer to [Create a correlation
        rule](#UUIDbc7d0a56c8fe8a89f01dd5c7d9a93090).

    - (For **PAN NGFW** source type issues)
      **Download triggering packet:** Download the session PCAP
      containing the first 100 bytes of the triggering packet directly
      from Cortex XSIAM. To access the PCAP, you can download the file
      from the Issues table, Cases, or Causality view.

3.  Navigate to Investigation & Response \> Response \> Action Center to
    view the retrieval status.

4.  Download the retrieved files locally.

- In the **Action Center**, wait for the data retrieval action to
  complete successfully. Then, right-click the action row and select
  **Additional Data**. From the **Detailed Results** view, right-click
  the row and select **Download Files**. A ZIP folder with the retrieved
  data is downloaded locally.

  > **Tip**

  > If you require assistance from Palo Alto Networks support to
  > investigate the issue, make sure to provide the downloaded ZIP file.

##### Add a file path to a malware profile allow list

During investigation, if you deem a file path to be safe you can add the
file path to an existing malware profile allow list directly from the
**Issues** table.

1.  In the **Issues** table, select the **Initiator Path**,
    **CGO path**, and/or **File Path** field values you want to add to
    your malware profile allow list.

2.  Right-click and select
    **Add \<path type\> to malware profile allow list**.

3.  In the **Add \<path type\> to malware profile allow list** dialog,
    select from your existing **Profiles** and **Modules** to which you
    want to add the file path to the allow list.

4.  (Optional) View your Malware profile allow list.

    a.  Go to Inventory \> Endpoints \> Policy Management \> Prevention
        \> Profiles and locate the malware profile you selected.

    b.  Right-click, select **Edit Profile** and locate in the
        **Files / Folders in Allow List** section the path file you
        added.

For more information about malware prevention profiles, see
[/document/preview/953906#UUID-96637ab0-4b96-ac8c-66cc-61dc18f3aa5e](/document/preview/953906#UUID-96637ab0-4b96-ac8c-66cc-61dc18f3aa5e).

##### Create a featured field

To help you to track issues involving specific hosts, users, and IP
addresses, you can label specific issue attributes as featured fields.
Issues that contain a matching featured field value are identified with
a ![](media/rId1627.png){width="0.14583333333333334in"
height="0.20833333333333334in"} flag in the **Name** field of the
**Issues** table. After setting up featured fields, you can use them
filter the **Issues** table and to create case scoring rules.

> **Note**
>
> Featured Active Directory values are displayed in the **User** and
> **Host** fields accordingly.

**How to create a featured field**

1.  Go to Cases & Issues \> Case Configuration \> Featured Fields and
    select a type of featured field.

2.  Click **Add featured \<field-type\>** and select one of the
    following options:

    - **Create New**

    <!-- -->

    - To create a new featured field from scratch, enter one or more
      field-type values and click **Add**.

    <!-- -->

    - **Upload from File**

    <!-- -->

    - To upload field values from a CSV file, upload your file and click
      **Import**. Click **Download example file** to ensure you are
      using the correct format.

3.  Find issues containing featured fields.

- In the **Issues** table, use the **Contains Featured** filters.

4.  (Optional) Create a case scoring rule using the
    **Contains Featured** fields to further highlight and prioritize
    issues containing the Host, User, and IP address attributes. For
    more information, see <urn:resource:component:1159841>.

##### View generating BIOC or IOC rule

You can easily view and edit the BIOC and IOC rules that generated
issues directly from the **Issues** table:

1.  From the **Issues** page, locate issues with **Detection methods**:
    **XDR BIOC** and **XDR IOC**.

2.  Right-click the row, and select Manage Issue \> View generating
    rule.

- Cortex XSIAM opens the BIOC rule that generated the issue in the
  **BIOC Rules** page. If the rule has been deleted, an empty table is
  displayed.

3.  Review the rule, if necessary, right-click to perform available
    actions.

##### Export issue details to a file

To archive, continue investigation offline, or parse issue details, you
can export issues to a tab-separated values (TSV) file:

1.  From the **Issues** page, adjust the filters to identify the issues
    you want to export.

2.  When you are satisfied with the results, click the download icon
    (![](media/rId1633.png){width="0.20833333333333334in"
    height="0.20833333333333334in"}).

- The icon is grayed out when there are no results.

  Cortex XSIAM exports the filtered result set to the TSV file.

##### Exclude an issue

During the process of triaging and investigating issues, you might
determine that an issue does not indicate threat. You can choose to
exclude the issue, which hides the issue, excludes it from cases, and
excludes it from search query results.

You can also set up issue exclusion rules that automatically exclude
issues that match certain criteria. For more information, see [Issue
exclusions](#UUIDd623d28b4e65af47888dde2fbc48d4c4).

**How to exclude an issue**

1.  From the **Issues** page, locate the issue you want to exclude.

2.  Right-click the row, and select Manage Issue \> Exclude Issue.

- A notification displays indicating the exclusion is in progress.

##### Query case and issue data

Cortex XSIAM uses Cortex Query Language (XQL) as the primary language
for searching, analyzing, and transforming security data. XQL allows for
highly efficient querying across vast amounts of security telemetry,
such as:

- Threat hunting: Proactively search your entire environment for
  malicious activity, anomalies, and indicators of compromise (IOCs).
  Formulate queries to look for specific patterns of behavior that might
  indicate an ongoing attack, even if no alert has been triggered.

- Investigation: When a case or issue is generated, XQL allows security
  analysts to drill down into the underlying data, understand the full
  scope of an attack, identify affected assets, and trace the
  attacker\'s actions.

- Forensics: Extract detailed information about past events for
  post-incident analysis and compliance audits.

- Reports and dashboards: Create custom reports and dashboards to
  visualize security posture, track key metrics, and communicate
  insights to stakeholders.

To view and use sample investigative queries, such as the
**Top Unresolved High Severity Cases** query, go to Investigation &
Response \> Search \> Query Builder \> XQL \> Query Library. For more
information about using XQL, see
[#UUIDdc1e23f871b8f89cfe4fe0ede35ee4af](#UUIDdc1e23f871b8f89cfe4fe0ede35ee4af).

You can query case and issue data in the `cases` and `issues` datasets.
When using the `issues` dataset, keep in mind the following:

- Informational issues are not included in this dataset.

- Issue fields are limited to certain fields available in the API. For
  the full list, see [Get Alerts Multi-Events v2
  API](https://docs-cortex.paloaltonetworks.com/r/Cortex-XSIAM-REST-API/Get-Alerts-Multi-Events-v2).

The `issues` dataset is categorized by domain. To query only security
issues, use the following XQL:

    dataset = issues | filter issue_domain = "SECURITY"

To query only posture issues, use the following XQL:

    dataset = issues | filter issue_domain = "POSTURE"

##### Update issue fields

You can update issue fields by running the `setIssue` and
`setIssueStatus` commands in the CLI, in a script, or a playbook task.

- `setIssue`**:** Sets values for specific issue fields. The supported
  fields are presented in the list of arguments.

<!-- -->

- Examples of the setIssue command in the CLI
  The following examples show how to run the `setIssue` command in
  the CLI. You can run CLI commands in the **War Room**. When you start
  typing the CLI provides the available options and if you select an
  enum field, the CLI provides the available values.

  - To change the issue severity to `high`, run

  <!-- -->

  - !setIssue severity=high

  <!-- -->

  - To change the issue severity to `high` and star the issue, run

  <!-- -->

  - !setIssue severity=high starred=true

<!-- -->

- `setIssueStatus`**:** Sets the status or resolution value for an
  issue. This command supports the `status` argument, which presents a
  list of status and resolution type values. The selected status is set
  in the `custom_status` field.

<!-- -->

- If you specify a resolution status, the issue is closed and the
  `resolution_status` and `closeReason` fields are updated to the same
  value as the `custom_status` field. If you specify a New, Reopened, or
  Under Investigation status, the issue remains open and the
  `resolution_status` and `closeReason` fields are empty.

  > **Tip**

  > You can create custom issue statuses and resolution reasons, and use
  > the `setIssueStatus` command to set these custom statuses for
  > issues.

  > For example, when a user starts investigating an issue, the issue
  > status is automatically changed from **New** to
  > **Under Investigation**. In some cases, it is useful to create an
  > interim status, such as **Triage**. After you create the custom
  > status, the new status will be available for selection. To create a
  > custom status, follow the instructions in [Create custom case
  > statuses and resolution
  > reasons](#UUID704840aae2cb9ec981b243f33786256c).

  Examples of using the setIssueStatus command in the CLI
  The following examples show how to run the `setIssueStatus` command in
  the CLI. You can run CLI commands in the **War Room**. When you start
  typing, the CLI provides the available options and if you select an
  enum field, the CLI provides the available values.

  - To change the issue status to `Resolved - Known Issue`, run

  <!-- -->

  - !setIssueStatus status="Resolved - Known Issue"

  <!-- -->

  - To change the issue status to custom status `Triage`, run

  <!-- -->

  - !setIssueStatus status=Triage

    > **Note**

    > You must create a custom status before you can select it.

  Example of using the setIssueStatus command in a playbook
  The following example shows how the `setIssueStatus` command can be
  used in a playbook task. In this example, the task sets a custom issue
  status (Triage). The custom issue status was created before setting up
  the playbook.

  ![](media/rId1642.png){width="5.833333333333333in"
  height="3.7041666666666666in"}

##### Close an issue

Once you complete your investigation, perform one of the following
actions to close an issue:

- **Manually close an issue:** Right-click an issue and select Change
  Status \> Resolved and select a resolution reason.

- **Automatically close an issue:** Run the `closeInvestigation` command
  in the CLI, in a script, or a playbook task. You can configure this
  command to run as part of a flow when automating issue investigation.

The `closeInvestigation` command supports the `closeReason` and
`closeNotes` arguments. The `closeReason` argument accepts a free text
value; however, if the free text value doesn\'t match one of the defined
resolution reasons the `resolution_status` field is set to
`Resolved - Other`. To see a description of the resolution reasons, see
[Resolution reasons for cases and
issues](#UUID245034f82bc3db3f28264ec08c062aa2).

> **Note**
>
> When an issue is resolved it remains linked to a case. Once all of the
> issues in a case are resolved, the case is automatically closed.

Example of using the closeInvestigation command in the CLI

In this example, the command specifies to close the issue and set values
for `closeReason` and `closeNotes`.

    !closeInvestigation closeReason="Resolved - Known Issue" closeNotes= "Mitigated"

Example of using the closeInvestigation command in a playbook

In this example, the `closeInvestigation` command is used in a playbook
and values are set for `closeReason` and `closeNotes`.

![](media/rId1648.png){width="5.833333333333333in"
height="3.0479166666666666in"}

Example of using a variable in the closeReason field

In this example the close reason field specifies the `${tmpCloseReason}`
variable value. The `tmpCloseReason` key was added to the issue context
data, and the value is drawn from this field.

1.  Add the `tmpCloseReason` key and set the value, run the following
    command in the issue **War Room**:

- !Set key=tmpCloseReason value="Resolved - True Positive"

2.  Create a task in your playbook for the closeInvestigation command
    and set the closeReason field to `${tmpCloseReason}`.

- ![](media/rId1652.png){width="5.833333333333333in"
  height="3.0260411198600177in"}

  When the playbook runs, it draws the value from this field in the
  context data:

  ![](media/rId1655.png){width="4.736111111111111in"
  height="2.361111111111111in"}

#### What is Causality?

Causality is the idea of telling a story in a simple and coherent manner
and in a proper context. With the purpose of leading security teams to
actionable outcomes.

Palo Alto Networks products, such as Next-Generation Firewall (NGFW) or
the Cortex XDR Agent, can be configured to send rich and detailed data
about all activities to the Strata Logging Service, not only items
related to attacks. This means that millions of data points are
collected about every entity every single day. Analyzing so much data as
log lines is practically impossible, so Cortex XSIAM takes these data
points and continuously stitches them automatically to 'Causality
Chains'. This automates the dot-connection process that an investigator
would otherwise have to do manually during an investigation. This
process happens constantly for all collected data points, such as
processes, files, network connections, and more, regardless of
prevention, detection, or alerts of any kind. With causality, when
analysts decide to investigate alerts or go on a hunt, they don\'t need
to manually connect the dots getting distracted with millions of
irrelevant data points, and instead they can focus only on data related
to the investigation.

Even the most complicated investigations take just a few moments for a
novice analyst, during which causality reveals answers to critical
questions, such as:

- What was the root cause?

- What might be the damage?

- What's the scope? Are there any related issues?

- Who's involved?

- Which steps are required to contain, mitigate and recover?

- Are similar threats prevalent in the environment?

- What can be done to reduce the risk of the same thing happening again?

To achieve this, Palo Alto Networks invested and patented the causality
engine and the ways it works.

How it works

Causality chains are built using a deep understanding of each operating
system (OS) and the way it works, which processes fulfil the various
functions and more. Causality chains in Windows, macOS, and Linux work
with the same guidelines, with different processes and methods used to
decide how to build chains.

There are some processes in the OS that have very specific roles to
fill. For example, `services.exe` and `explorer.exe` are used mainly to
spawn other processes. This means that causality chains don't show these
processes by default and start from their child processes as these are
only OS processes doing their job; yet, you can manually add them by
right clicking on the Causality Group Owner (CGO) and adding the parent
process.

Cortex XSIAM tracks Remote Procedure Call (RPC) requests between
processes and it doesn\'t break the casualty chain into sub chains, so
the analyst still sees the full chain of execution, including actions
done via RPC. Same goes for code injection, as Cortex XSIAM tracks the
new threads that are started as a result of such actions and can tie
anything that happens as a result to the original injecting processes
and its causality chain.

Spawners

Processes that are used to spawn other sub processes are called
spawners. Those processes are known to start other processes as part of
the normal flow of the operating system (OS). Examples of such processes
are `explorer.exe`, `services.exe`, `wininit.exe`, `userinitt.exe`, and
more. When spawner processes are started by a non-spawner process, they
are not considered spawners. In Cortex XSIAM, we don't distinguish
between a Causality Group Owner (CGO) and spawner, calling both CGO.

- `userinit.exe` starts `explorer.exe`: `explorer.exe` is considered a
  spawner, as this is what we expect to see in the OS.

- `cmd.exe` starts `explorer.exe`: `explorer.exe` is NOT considered as a
  spawner as it's not the role of `cmd.exe` to start `explorer.exe`.

The child processes of a spawner are considered as CGOs and they start
off the causality chain.

Causality Chain

When a malicious file, behavior, or technique is detected, Cortex XSIAM
correlates available data across your detection sensors to display the
sequence of activity that led to the alert. This sequence of events is
called the causality chain. The causality chain is built from processes,
events, insights, and alerts associated with the activity. During the
alert investigation, you should review the entire causality chain to
fully understand why the alert occurred.

Causality Analysis Engine

The Causality Analysis Engine correlates activity from all detection
sensors to establish causality chains that identify the root cause of
every alert. The Causality Analysis Engine also identifies a complete
forensic timeline of events that helps you to determine the scope and
damage of an attack and provide an immediate response. The Causality
Analysis Engine determines the most relevant artifacts in each alert and
aggregates all alerts related to an event into an incident.

Causality Group Owner (CGO)

The Causality Group Owner (CGO) is the process in the causality chain
that the Causality Analysis Engine identified as being responsible for
or causing the activities that led to the alert. A CGO is always the
child of a spawner, so it's the first process in the operating system
(OS) chain of execution that is not loaded by default as part of what's
expected in a normal OS flow. All sub-processes started by the CGO are
linked to it, and help analysts quickly identify the root cause of why
something happened.

> **Note**
>
> There are no CGOs in the Cloud Causality View, when investigating
> cloud Cortex XSIAM alerts and Cloud Audit Logs, or SaaS Causality
> View, when investigating SaaS-related alerts for 501 audit events,
> such as Office 365 audit logs and normalized logs.

CID

Each causality chain gets a unique ID called  a CID. All actions on this
chain, such as process execution, registry changes, and network
connections, receive the same ID. This means that whenever the user
queries about a given action, for example who connected to a malicious
IP, the response not only includes the process who performed it or the
user, it includes all actions related to the same CID. This shows the
entire chain of execution alongside all other actions performed with the
connection to the malicious IP.

This concept is important because any alert that is triggered about any
action is also mapped to the same CID, meaning that one chain of
execution displays all processes and alerts associated with the relevant
CID. Alerts on the same CID is also one of the methods Cortex XSIAM uses
to group alerts into an incident.

##### Causality view

The causality view provides an interactive visualization of a Causality
Instance (CI) associated with an issue. On this view you can see the
causality (cause and effect) of events of the entire process execution
chain that led up to the issue. By automating the dot-connection
process, Cortex XSIAM helps you to streamline your investigations by
providing immediate, actionable insights into security issues and the
related processes in the causality chain.

To open the casualty, right-click on an issue in the **Cases** or
**Issues** pages. The causality view comprises the causality instance
chain, **Information overview**, **Forensics highlights**, and the
**All Events** table. Click on nodes on the causality chain to see
details about each entity in the **Information overview** and
**All Events** table. You can also take actions on the processes in the
chain by clicking **Actions** or right-clicking a specific node.

![](media/rId1157.png){width="0.19166666666666668in"
height="0.20833333333333334in"} Show me more

![](media/rId1672.gif){width="5.833333333333333in" height="2.8in"}

The following sections describe the different areas of the causality
view:

###### Causality instance chain

Includes the graphical representation of the Causality Instance (CI),
built from process nodes, events, and issues. The chain presents the
process execution and might include events that the processes caused,
and issues that were triggered by the events or processes.

The Causality Group Owner (CGO) is displayed on the left side of the
chain. The CGO is the process that is responsible for all the other
processes, events, and issues in the chain. You need the entire CI to
fully understand why the issue occurred. The process node displays icons
to indicate when an RPC protocol or code injection event was executed on
another process from either a local or remote host.

- ![](media/rId1676.png){width="0.23977909011373577in"
  height="0.20833333333333334in"} Injected Node

- ![](media/rId1679.png){width="0.2786450131233596in"
  height="0.20833333333333334in"} Remote IP address

Causality data is displayed as follows:

- Visualization of the branch between the CGO and the actor process of
  the issue/event.

- Displays up to nine additional process branches that reveal issues
  related to the issue/event. Branches containing issues with the
  nearest timestamp to the original issue/event are displayed first.

- Causality cards that contain more causality data display a
  **Showing Partial Causality** flag. You can manually add additional
  child or parent processes branches by right-clicking on the process
  nodes displayed in the graph.

####### Navigation

You can move the chain, extend it, and modify it. To adjust the
appearance of the CI chain, use the size controls on the right. You can
also move the chain by selecting and dragging it. To return the chain to
its original position and size, click
![](media/rId1682.png){width="0.14583333333333334in"
height="0.20833333333333334in"} in the lower-right of the CI graph.

####### Identity Threat data

When the Identity Threat Module is enabled, Cortex XSIAM displays the
anomaly that triggered the issue against the backdrop of baseline
behavior for some issues. To see the profiles that are generated by the
detector, **Open Issue Visualization**. Each tab displays the factors
that triggered the issue, the event and the baseline information in
tabular format or in timeline format, depending on the type of event.
The graphs display the information in full mode, covering 30 days.

- The tabular view displays the baseline behavior in a table, with the
  anomaly highlighted and in a separate line.

- The timeline view displays the highlighted atypical value, and if
  applicable, the minimum, maximum, and average values, for the selected
  period.

####### Actions

Hover over a process node to display a **Process Information** pop-up
listing useful information about the process. From any process node, you
can also right-click to display additional actions that you can perform
during your investigation:

- **Show parents and children:** If the parent is not presented by
  default, you can display it. If the process has children, Cortex XSIAM
  opens a dialog displaying the **Children** **Process Start Time**,
  **Name**, **CMD**, and **Username** details.

- **Hide branch:** Hide a branch from the causality view.

- **Add to block list or allow list, terminate, or quarantine a process:**
  If after investigating the activity in the CI chain, you want to take
  action on the process, you can select the desired action to allow or
  block the process across your organization.

<!-- -->

- In the causality view of a **Detection (Post Detected)** type issue,
  you can also **Terminate process by hash**.

###### Information overview

Summarizes information about the selected node in the causality chain.

If you select an issue node, you can see the issue name, source,
timestamp, severity, the action taken, the tags assigned to it, and
MITRE ATT&CK tactics and techniques identified. If more than one issues
is available, you can scroll through the related issues.

If you select a process node, you can see the path, parent Pid, Sha256,
associated username, and MITRE ATT&CK details. You can also see the
Wildfire Score and download the Wildfire report.

###### Forensics Highlights

Forensics Highlights serves as the central cockpit for investigating and
navigating the entire causality view, offering a comprehensive breakdown
of events, processes, and different activities to uncover and respond to
potential threats with precision. In each section, you can click on data
points to highlight the related process in the CI. Forensic Highlights
includes the following sections:

- **MITRE ATT&CK:** Explore forensic insights aligned with the MITRE
  ATT&CK framework to correlate adversarial techniques with forensics
  data.

- **Script Engines:** Delve into detailed activity logs of script
  engines to uncover potential execution of malicious scripts and code.

- **Issus:** Gain clarity on triggered issues for the entire causality
  chain.

- **Process:** Investigate process activities to identify unusual
  behavior or unauthorized process executions.

- **Network:** Analyze forensic data related to network activities,
  highlighting potential threats in communication flows.

- **File:** Uncover file-related forensic evidence to pinpoint
  suspicious file operations or unauthorized access.

- **Registry:** Examine registry-level insights to detect tampering or
  malicious configuration changes.

- **System Calls:** Track low-level system call activities for signs of
  exploitation or atypical behavior.

- **RPC Calls:** Analyze RPC (Remote Procedure Call) forensic data to
  trace unauthorized remote operations.

###### All Events table

The **All Events** table displays up to 100,000 related events for the
process node which matches the issue criteria that were not triggered in
the issues table, but are informational. The **Prevention Actions** tab
displays the actions Cortex XSIAM takes on the endpoint based on the
threat type discovered by the agent.

To continue the investigation, you can perform the following actions
from the right-click pivot menu:

- **Add \<path type\> to malware profile allow list** from the
  **Process** and **File** table. For example, **target_process_path**,
  **src_process_path**, **file_path**, or **os_parent_path**.

- For the behavioral threat protection results, you can take action on
  the initiator to add it to an allow list or block list, terminate it,
  or quarantine it.

- Revise the event results to see possible related events near the time
  of an event using an updated timestamp value to
  **Show rows 30 days prior** or **30 days after**.

> **Tip**
>
> To view statistics for files on VirusTotal, you can pivot from the
> Initiator MD5 or SHA256 value of the file on the Files tab.

##### Network causality view

On the network causality view you can analyze and respond to stitched
firewall and endpoint issues. On this view you can see the causality
(cause and effect) of events of the entire process execution chain that
led up to the issue. The network causality view presents the network
processes that triggered the issue, generated by Cortex XSIAM, Palo Alto
Networks next-generation firewalls, and supported sources, such as 3rd
party network sources.

On each node in the CI chain, Cortex XSIAM provides information to help
you understand what happened around the issue. The CI chain visualizes
the firewall logs, endpoint files, and network connections that
triggered issues connected to a security event.

> **Note**
>
> The network causality view displays only the information it collects
> from the detectors. It is possible that the CI may not show some of
> the firewall or agent processes.

The following sections describe the different areas of the network
causality view:

###### Causality instance chain

Includes the graphical representation of the Causality Instance (CI)
along with other information and capabilities to enable you to conduct
your analysis.

The Causality View presents a CI chain for each of the processes and the
network connection. The CI chain is built from process nodes, events,
and issues. The chain presents the process execution and might also
include events that these processes caused and issues that were
triggered by the events or processes. The Causality Group Owner (CGO) is
displayed on the left side of the chain. The CGO is the process that is
responsible for all the other processes, events, and issues in the
chain. You need the entire CI to fully understand why the issue
occurred.

The color of a process node correlates to the WildFire verdict.

WildFire verdict descriptions

- **Blue:** Benign.

- **Yellow:** Grayware.

- **Red:** Malware.

- **Light gray:** Unknown verdict.

- **Dark gray:** The verdict is inconclusive.

<!-- -->

- You can view and download the WildFire report in the **Entity Data**
  section.

####### Navigation

You can move the chain, extend it, and modify it. To adjust the
appearance of the CI chain, use the size controls on the right. You can
also move the chain by selecting and dragging it. To return the chain to
its original position and size, click
![](media/rId1682.png){width="0.14583333333333334in"
height="0.20833333333333334in"} in the lower-right of the CI graph.

####### Actions

Hover over a process node to display a **Process Information** pop-up
listing useful information about the process. From any process node, you
can also right-click to display additional actions that you can perform
during your investigation:

- **Show parents and children:** If the parent is not presented by
  default, you can display it. If the process has children, Cortex XSIAM
  opens a dialog displaying the **Children** **Process Start Time**,
  **Name**, **CMD**, and **Username** details.

- **Hide branch:** Hide a branch from the causality view.

- **Add to block list or allow list, terminate, or quarantine a process:**
  If after investigating the activity in the CI chain, you want to take
  action on the process, you can select the desired action to allow or
  block the process across your organization.

<!-- -->

- In the causality view of a **Detection (Post Detected)** type issue,
  you can also **Terminate process by hash**.

###### Information Overview

Summarizes information about the issue you are analyzing, including the
host name, the process name on which the issue was raised, and the host
IP address. For issues raised on endpoint data or activity, this section
also displays the endpoint connectivity status and operating system.

###### Host isolation

You can choose to isolate the host, on which the issue was triggered,
from the network or initiate a live terminal session to the host to
continue investigation and remediation.

###### All Events table

Displays all related events for the process node which match the issue
criteria that were not triggered in the issue table but are
informational. You can also export the table results to a tab-separated
values (TSV) file.

For the Behavioral Threat Protection table, right-click to add to allow
list or block list, terminate, and quarantine a process.

> **Tip**
>
> To view statistics for files on VirusTotal, you can pivot from the
> Initiator MD5 or SHA256 value of the file on the Files tab.

##### Cloud causality view

On the cloud causality view you can analyze and respond to Cortex XSIAM
issues and cloud audit logs. On this view you can see the causality
(cause and effect) of events of the entire process execution chain that
led up to the issue. The cloud causality view presents the event
identity and /or IP address and the actions performed by the identity on
the cloud resource. On each node in the CI chain, Cortex XSIAM provides
information to help you understand what happened around the event.

The following sections describe the different areas of the cloud
causality view:

###### Causality instance chain

Includes the graphical representation of the Causality Instance (CI)
along with other information and capabilities to enable you to conduct
your analysis.

The view presents a single event CI chain. The CI chain is built from
Identity and Resource nodes. The Identity node represents for example
keys, service accounts, and users, while the Resource node represents
for example network interfaces, storage buckets, or disks. When
available, the chain might also include an IP address and issue that
were triggered on the Identity and Cloud Resource.

Causality data is displayed as follows:

- **Identity node:** Displays the name of the identity, generated issue
  information, and if available the associated IP address.

<!-- -->

- To further investigate the user
  1.  Hover over an Identity node to display, if available, the identity
      **Analytics Profiles**.

  2.  Select the Identity node to display in the Entity Data section
      additional information about the Identity entity.

  3.  Select the issue icon to display additional information in the
      Forensic Highlights section.

<!-- -->

- **IP address node:** Displays the IP address associated with the
  Identity.

- **Operations:** Lists the type of operations performed by the identity
  on the cloud resources. Hover over the operation to display the
  original operation name as provided by the cloud Provider.

- **Cloud resource node:** Displays the referenced resource on which the
  operation was performed. For more information about the cloud
  resources icons, see [Key of cloud causality
  icons](#X8dbfe29152b9f5a8794750162985dad50481113).

<!-- -->

- To further investigate the resource
  1.  Hover over a resource node to display, if available, the resource
      **Analytics Profiles** and **Resource Editors** statistics.

  2.  Select the resource node to display in the Entity Data section
      additional information about the resource entity.

####### Navigation

You can move the chain, extend it, and modify it. To adjust the
appearance of the CI chain, use the size controls on the right. You can
also move the chain by selecting and dragging it. To return the chain to
its original position and size, click
![](media/rId1682.png){width="0.14583333333333334in"
height="0.20833333333333334in"} in the lower-right of the CI graph.

###### Information Overview

Summarizes information about the issue you are analyzing, including the
type of Cloud Provider, Project, and Region on which the event occurred.
Select **View Raw Log** to view the raw log as provided by the Cloud
Provider in JSON format.

###### All Events table

Displays up to 100,000 related events and up to 1,000 related issues. In
the **All Events** table, Cortex XSIAM displays detailed information
about each of the related events. To simplify your investigation, Cortex
XSIAM scans your Cortex XSIAM data aggregating the events that have the
same Identity or Resource and displays the entry with an
![](media/rId1708.png){width="0.14583333333333334in"
height="0.20833333333333334in"} aggregated icon. Right-click and select
**Show Grouped Events** to view the aggregated entries.

Entries highlighted in red indicate that the specific event created an
issue. To continue the investigation, right-click to **View in XQL**. To
continue the investigation, in the **Issues** table, right-click an
issue to see the available actions.

###### Key of cloud resource icons

The following table lists the cloud resource icons:

  -----------------------------------------------------------------------------------------
  Icon                                                  Type of Resource
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1711.png){width="1.1388888888888888in"   Compute instance resource
  height="1.0in"}                                       

  ![](media/rId1714.png){width="0.9027777777777778in"   Disk resource
  height="0.8888888888888888in"}                        

  ![](media/rId1717.png){width="0.8055555555555556in"   General resource
  height="0.8333333333333334in"}                        

  ![](media/rId1720.png){width="0.9027777777777778in"   Image resource
  height="0.8472222222222222in"}                        

  ![](media/rId1723.png){width="0.8055555555555556in"   Network interface resource
  height="0.8472222222222222in"}                        

  ![](media/rId1726.png){width="0.8611111111111112in"   Security group (FW rule) resource
  height="0.8333333333333334in"}                        

  ![](media/rId1729.png){width="0.7777777777777778in"   Storage bucket resource
  height="0.8333333333333334in"}                        

  ![](media/rId1732.png){width="0.9722222222222222in"   Virtual private cloud (VPC)
  height="0.9166666666666666in"}                        resource
  -----------------------------------------------------------------------------------------

##### SaaS causality view

The SaaS causality view provides a powerful way to analyze and
investigate software-as-a-service (SaaS) related issues for audit
stories, such as Office 365 audit logs and normalized logs, by
highlighting the most relevant events and issues associated with a
SaaS-related issue. To help you identify and investigate SaaS-specific
data associated with SaaS-related issues and SaaS audit logs, Cortex
XSIAM displays a SaaS causality view, which enables you to swiftly
investigate a SaaS issue by displaying the series of events and
artifacts that are shared with the issue.

A SaaS causality view is only available when Cortex XSIAM is configured
to collect SaaS audit logs and data. For example, this is possible by
configuring an Office 365 data collector or Google Workspace data
collector with the applicable SaaS audit logs. This enables you to
investigate any Cortex XSIAM issue generated from any IOC, BIOC, or
correlation rules, including SaaS events. The SaaS causality view is
available from the **Issues** table, or from the **Query Results** after
running a query on the SaaS related data. From both places, you can
right-click to pivot to the SaaS causality view.

The scope of the SaaS causality view is the Causality Instance (CI) of
an event to which this issue pertains. The SaaS causality view presents
the event identity and /or IP address and the actions performed by the
identity on the SaaS resource. On each node in the CI chain, Cortex
XSIAM provides information to help you understand what happened around
the event.

The SaaS causality view contains the following sections:

###### Information Overview

Summarizes information about the issue you are analyzing, including the
type of SaaS provider, project, and region on which the event occurred.
Select **View Raw Log** to view the raw log as provided by the SaaS
provider in JSON format.

###### SaaS causality instance chain

Includes the graphical representation of the SaaS Causality Instance
(CI) along with other information and capabilities to enable you to
conduct your analysis.

The SaaS causality view presents a single event CI chain. The CI chain
is built from Identity and Resource nodes. The Identity node represents
for example keys, service accounts, and users, while the Resource node
represents for example network interfaces, storage buckets, or disks.
When available, the chain can also include an IP address and issues that
were triggered on the Identity and SaaS resource.

- **Identity node:** Displays the name of the identity, generated issue
  information, and if available the associated IP address.

<!-- -->

- To further investigate the user
  1.  Hover over an Identity node to display, if available, the identity
      **Analytics Profiles**.

  2.  Select the Identity node to display in the Entity Data section
      additional information about the Identity entity.

  3.  Select the issue icon to display additional information in the
      Forensics Highlights tab.

<!-- -->

- **IP address node:** Displays the IP address associated with the
  Identity.

- **Resource node:** Displays the referenced resource on which the
  operation was performed. Cortex XSIAM displays information on the
  following resources.

<!-- -->

- To further investigate the resource
  1.  Hover over a Resource node to display, if available, the resource
      **Analytics Profiles** and **Resource Editors** statistics.

  2.  Select the Resource node to display in the Entity Data section
      additional information about the Resource entity.

####### Navigation

You can move the chain, extend it, and modify it. To adjust the
appearance of the CI chain, use the size controls on the right. You can
also move the chain by selecting and dragging it. To return the chain to
its original position and size, click
![](media/rId1682.png){width="0.14583333333333334in"
height="0.20833333333333334in"} in the lower-right of the CI graph.

###### All Events table

Displays up to 100,000 related events and up to 1,000 related issues. In
the **All Events** table, Cortex XSIAM displays detailed information
about each of the related events. To simplify your investigation, Cortex
XSIAM scans your Cortex XSIAM data aggregating the events that have the
same Identity or Resource and displays the entry with an
![](media/rId1708.png){width="0.14583333333333334in"
height="0.20833333333333334in"} aggregated icon. Right-click and select
**Show Grouped Events** to view the aggregated entries.

Entries highlighted in red indicate that the specific event created an
issue. To continue the investigation, right-click to **View in XQL**. To
continue the investigation, in the **Issues** table, right-click an
issue to see the available actions.

###### Key of SaaS resources

The following table lists the SaaS resource icons:

  -----------------------------------------------------------------------------------------
  Icon                                                  Type of resource
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1748.png){width="0.75in"                 Google Workspace Admin Console
  height="0.75in"}                                      

  ![](media/rId1751.png){width="0.8611111111111112in"   Google Workspace for Google Drive
  height="0.7361111111111112in"}                        

  ![](media/rId1754.png){width="0.8055555555555556in"   Microsoft Office 365 Exchange
  height="0.7361111111111112in"}                        Online

  ![](media/rId1757.png){width="0.7777777777777778in"   Microsoft 365 Office Groups
  height="0.7638888888888888in"}                        

  ![](media/rId1760.png){width="0.8611111111111112in"   Microsoft Office 365 OneDrive
  height="0.75in"}                                      

  ![](media/rId1763.png){width="0.7916666666666666in"   Microsoft Office 365 SharePoint
  height="0.8472222222222222in"}                        Online

  ![](media/rId1766.png){width="0.8055555555555556in"   Microsoft Office 365 Skype for
  height="0.7916666666666666in"}                        Business

  ![](media/rId1769.png){width="0.8472222222222222in"   Microsoft Office 365 Teams
  height="0.8194444444444444in"}                        
  -----------------------------------------------------------------------------------------

##### Timeline

The Timeline provides a forensic timeline of the sequence of events,
issues, and informational BIOCs, and correlation rules involved in an
attack. While the causality view of an issue surfaces related events and
processes that Cortex XSIAM identifies as important or interesting, the
Timeline displays all related events, issues, and informational BIOCs
and correlation rules over time.

> **Note**
>
> The Timeline view is not available when investigating cloud Cortex
> XSIAM issues and cloud audit logs or SaaS-related issues for 501 audit
> events, such as Office 365 audit logs and normalized logs. Only the
> applicable cloud causality view and SaaS causality view is available
> for this data.

The Timeline comprises the following parts:

###### CGO and process instances that are part of the CGO

Cortex XSIAM displays the Causality Group Owner (CGO) and the host on
which the CGO ran in the top left of the timeline. The CGO is the parent
process in the execution chain that Cortex XSIAM identified as being
responsible for initiating the process tree. In the example above,
`wscript.exe` is the CGO and the host it ran on was `HOST488497`. You
can also click the blue corner of the CGO to view and filter related
processes from the Timeline. This will add or remove the process and
related events or issues associated with the process from the Timeline.

###### Timespan

By default, Cortex XSIAM displays a 24-hour period from the start of the
investigation and displays the start and end time of the CGO at either
end of the timescale. You can move the slide bar to the left or right to
focus on any time-gap within the timescale. You can also use the time
filters above the table to focus on set time periods.

###### Activity

Depending on the type of activities involved in the CI chain of events,
the activity section can present any of the following three lanes across
the page:

- **Issues:** The issue icon indicates when the issue occurred.

- **BIOCs and correlation rules:** The category of the issue is
  displayed on the left (for example tampering or lateral movement).
  Each BIOC event also indicates a color associated with the issue
  severity. An informational severity can indicate something interesting
  has happened but there were not any triggered issues. These events are
  likely benign but are byproducts of the actual issue.

- **Event Information:** The event types include process execution,
  outgoing or incoming connections, failed connections, data upload, and
  data download. Process execution and connections are indicated by a
  dot. One dot indicates one connection while many dots indicates
  multiple connections. Uploads and Downloads are indicated by a bar
  graph that shows the size of the upload and download.

The lanes depict when the activity occurred and provide additional
statistics that can help you investigate. For BIOC, correlation rules,
and issues, the lanes also depict activity nodes, highlighted with their
severity color: high (red), medium (yellow), low (blue), or
informational (gray), and provide additional information about the
activity when you hover over the node.

###### Related events, issues, and informational BIOCs

Cortex XSIAM displays up to 100,000 issues, BIOCs and Correlation Rules
(triggered and informational), and events. Click on a node in the
activity area of the Timeline to filter the results. You also can create
filters to search for specific events.

##### Causality icons key

The following tables describe the causality chain icons, broken down by
type:

###### Action icons

Causality action icons mark the actions that were taken on a process or
event. Pending actions are shown with a dotted line.

+-----------------------------------------------------+-----------------------------------+
| Icon                                                | Description                       |
+=====================================================+===================================+
| ![](media/rId1779.png){width="2.1666666666666665in" | Blocklist                         |
| height="2.111111111111111in"}                       |                                   |
|                                                     |                                   |
| ![](media/rId1782.png){width="2.111111111111111in"  |                                   |
| height="2.111111111111111in"}                       |                                   |
+-----------------------------------------------------+-----------------------------------+
| ![](media/rId1785.png){width="2.0555555555555554in" | Quarantine                        |
| height="2.0416666666666665in"}                      |                                   |
|                                                     |                                   |
| ![](media/rId1788.png){width="2.125in"              |                                   |
| height="2.138888888888889in"}                       |                                   |
+-----------------------------------------------------+-----------------------------------+
| ![](media/rId1791.png){width="2.1944444444444446in" | Allowlist                         |
| height="2.138888888888889in"}                       |                                   |
|                                                     |                                   |
| ![](media/rId1794.png){width="2.1666666666666665in" |                                   |
| height="2.0972222222222223in"}                      |                                   |
+-----------------------------------------------------+-----------------------------------+

###### Causality alert icons

Causality alert icons indicate the type of alert that was triggered.

  -----------------------------------------------------------------------------------------
  Icon                                                  Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1798.png){width="1.9166666666666667in"   3rd party
  height="1.7638888888888888in"}                        

  ![](media/rId1801.png){width="1.6944444444444444in"   XDR Agent
  height="1.8888888888888888in"}                        

  ![](media/rId1804.png){width="1.375in"                Analytics
  height="1.4722222222222223in"}                        

  ![](media/rId1807.png){width="1.3194444444444444in"   BIOC
  height="1.4861111111111112in"}                        

  ![](media/rId1810.png){width="1.7222222222222223in"   Firewall
  height="1.9305555555555556in"}                        

  ![](media/rId1813.png){width="0.9027777777777778in"   General alert
  height="1.9444444444444444in"}                        

  ![](media/rId1816.png){width="1.9027777777777777in"   Identity analytics
  height="1.8194444444444444in"}                        

  ![](media/rId1819.png){width="0.9861111111111112in"   IOC
  height="1.8055555555555556in"}                        
  -----------------------------------------------------------------------------------------

A number next to the alert icon indicates that there are multiple
alerts. This icon show that there are three alerts and the selected
alert is a BIOC alert. You can scroll through the alerts in the
**Information Overview**.

![](media/rId1822.png){width="2.4305555555555554in"
height="1.8055555555555556in"}

###### Cloud event icons

Cloud event icons indicate the type of cloud event or process.

  -----------------------------------------------------------------------------------------
  Icon                                                  Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1827.png){width="2.5972222222222223in"   Cloud admin
  height="2.4444444444444446in"}                        

  ![](media/rId1830.png){width="2.138888888888889in"    Compute disks
  height="2.111111111111111in"}                         

  ![](media/rId1833.png){width="2.2916666666666665in"   Compute instances
  height="2.3055555555555554in"}                        

  ![](media/rId1836.png){width="2.7916666666666665in"   Container escaped
  height="2.5972222222222223in"}                        

  ![](media/rId1839.png){width="2.6944444444444446in"   Drive
  height="2.513888888888889in"}                         

  ![](media/rId1842.png){width="2.7083333333333335in"   Exchange
  height="2.5694444444444446in"}                        

  ![](media/rId1845.png){width="2.1944444444444446in"   General resource
  height="2.1944444444444446in"}                        

  ![](media/rId1848.png){width="2.625in"                Groups
  height="2.5833333333333335in"}                        

  ![](media/rId1851.png){width="2.138888888888889in"    Images
  height="2.138888888888889in"}                         

  ![](media/rId1854.png){width="2.4027777777777777in"   Network
  height="2.4305555555555554in"}                        

  ![](media/rId1857.png){width="2.5555555555555554in"   Onedrive
  height="2.013888888888889in"}                         

  ![](media/rId1860.png){width="2.236111111111111in"    Security groups- FW rules
  height="2.1944444444444446in"}                        

  ![](media/rId1863.png){width="2.5694444444444446in"   Sharepoint
  height="2.513888888888889in"}                         

  ![](media/rId1866.png){width="2.4027777777777777in"   Skype
  height="2.361111111111111in"}                         

  ![](media/rId1869.png){width="2.1527777777777777in"   Storage buckets
  height="2.138888888888889in"}                         

  ![](media/rId1872.png){width="2.25in"                 Subnets
  height="2.1944444444444446in"}                        

  ![](media/rId1875.png){width="2.75in"                 Teams
  height="2.4027777777777777in"}                        

  ![](media/rId1878.png){width="2.125in"                VPCs
  height="2.0833333333333335in"}                        
  -----------------------------------------------------------------------------------------

###### Event icons

Event icons indicate the type of activity that occurred.

  -----------------------------------------------------------------------------------------
  Icon                                                  Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1882.png){width="2.513888888888889in"    DotNet
  height="2.5555555555555554in"}                        

  ![](media/rId1885.png){width="2.4166666666666665in"   Event log
  height="2.25in"}                                      

  ![](media/rId1888.png){width="1.7222222222222223in"   File
  height="2.0416666666666665in"}                        

  ![](media/rId1891.png){width="1.6944444444444444in"   Firewall
  height="1.9444444444444444in"}                        

  ![](media/rId1894.png){width="2.263888888888889in"    Host
  height="1.9027777777777777in"}                        

  ![](media/rId1897.png){width="2.3194444444444446in"   Host group
  height="1.875in"}                                     

  ![](media/rId1900.png){width="1.9305555555555556in"   Identity analytics
  height="1.8472222222222223in"}                        

  ![](media/rId1903.png){width="2.5694444444444446in"   Internet
  height="2.5416666666666665in"}                        

  ![](media/rId1906.png){width="1.9027777777777777in"   Malware
  height="2.388888888888889in"}                         

  ![](media/rId1909.png){width="1.5833333333333333in"   Mobile
  height="2.5416666666666665in"}                        

  ![](media/rId1912.png){width="2.5833333333333335in"   Module load
  height="2.638888888888889in"}                         

  ![](media/rId1915.png){width="1.9305555555555556in"   Multi-user
  height="1.8194444444444444in"}                        

  ![](media/rId1918.png){width="2.4166666666666665in"   Network
  height="2.263888888888889in"}                         

  ![](media/rId1921.png){width="2.6527777777777777in"   Potential prevention
  height="2.6527777777777777in"}                        

  ![](media/rId1924.png){width="2.6805555555555554in"   Range
  height="1.8472222222222223in"}                        

  ![](media/rId1927.png){width="2.4444444444444446in"   Registry
  height="2.4166666666666665in"}                        

  ![](media/rId1930.png){width="2.388888888888889in"    TCP Protocol
  height="1.7361111111111112in"}                        

  ![](media/rId1933.png){width="2.2083333333333335in"   Server
  height="1.7916666666666667in"}                        

  ![](media/rId1936.png){width="1.1666666666666667in"   Unknown event
  height="1.6944444444444444in"}                        

  ![](media/rId1939.png){width="2.6666666666666665in"   User session
  height="2.4722222222222223in"}                        

  ![](media/rId1942.png){width="2.3194444444444446in"   VOIP
  height="2.0694444444444446in"}                        

  ![](media/rId1945.png){width="2.6666666666666665in"   VPN
  height="2.0in"}                                       
  -----------------------------------------------------------------------------------------

###### Left node icons

Left node icons provide additional information about a process.

  -----------------------------------------------------------------------------------------
  Icon                                                  Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1949.png){width="2.888888888888889in"    Injected node
  height="2.8194444444444446in"}                        

  ![](media/rId1952.png){width="2.875in"                Last actor
  height="2.8333333333333335in"}                        

  ![](media/rId1955.png){width="5.833333333333333in"    Remote terminal session
  height="5.847952755905512in"}                         

  ![](media/rId1958.png){width="2.9027777777777777in"   RPC
  height="2.8055555555555554in"}                        

  ![](media/rId1961.png){width="3.8472222222222223in"   Unknown process
  height="3.8194444444444446in"}                        
  -----------------------------------------------------------------------------------------

###### Node icons

Node icons indicate the type of process or event that occurred in the
chain.

  -----------------------------------------------------------------------------------------
  Icon                                                  Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId1965.png){width="1.8611111111111112in"   Adobe
  height="1.875in"}                                     

  ![](media/rId1968.png){width="1.875in"                Attachment
  height="1.9305555555555556in"}                        

  ![](media/rId1971.png){width="1.8194444444444444in"   Chrome
  height="1.8055555555555556in"}                        

  ![](media/rId1974.png){width="2.0277777777777777in"   Remote IP Address
  height="1.6388888888888888in"}                        

  ![](media/rId1977.png){width="1.7777777777777777in"   Email
  height="1.5416666666666667in"}                        

  ![](media/rId1980.png){width="1.9166666666666667in"   Endpoint
  height="1.6944444444444444in"}                        

  ![](media/rId1983.png){width="1.9722222222222223in"   Excel
  height="1.9166666666666667in"}                        

  ![](media/rId1986.png){width="1.875in"                Firefox
  height="1.7638888888888888in"}                        

  ![](media/rId1989.png){width="1.375in"                Generic process
  height="1.4305555555555556in"}                        

  ![](media/rId1992.png){width="1.9583333333333333in"   Internet Explorer
  height="1.8472222222222223in"}                        

  ![](media/rId1995.png){width="1.8472222222222223in"   IP address
  height="1.8472222222222223in"}                        

  ![](media/rId1998.png){width="1.9722222222222223in"   Link
  height="2.0833333333333335in"}                        

  ![](media/rId2001.png){width="2.2777777777777777in"   mySQL
  height="2.138888888888889in"}                         

  ![](media/rId2004.png){width="1.9305555555555556in"   Outlook
  height="1.9166666666666667in"}                        

  ![](media/rId2007.png){width="1.9027777777777777in"   Powerpoint
  height="1.7916666666666667in"}                        

  ![](media/rId2010.png){width="2.3472222222222223in"   Putty
  height="2.0in"}                                       

  ![](media/rId2013.png){width="1.9444444444444444in"   Sender
  height="1.6666666666666667in"}                        

  ![](media/rId2016.png){width="1.4861111111111112in"   Unknown
  height="2.0277777777777777in"}                        

  ![](media/rId2019.png){width="1.7361111111111112in"   User
  height="1.7916666666666667in"}                        

  ![](media/rId2022.png){width="1.8888888888888888in"   Word
  height="1.9444444444444444in"}                        
  -----------------------------------------------------------------------------------------

###### Other icons

  -----------------------------------------------------------------------------------------
  Icons                                                 Description
  ----------------------------------------------------- -----------------------------------
  ![](media/rId2026.png){width="1.8333333333333333in"   Benign
  height="1.9583333333333333in"}                        

  ![](media/rId2029.png){width="1.5in"                  Container
  height="1.6527777777777777in"}                        

  ![](media/rId2032.png){width="2.9722222222222223in"   Causality Group Owner (CGO).
  height="2.013888888888889in"}                         

  ![](media/rId2035.png){width="1.7916666666666667in"   Default
  height="2.1805555555555554in"}                        

  ![](media/rId2038.png){width="1.9027777777777777in"   Grayware
  height="1.9583333333333333in"}                        

  ![](media/rId2041.png){width="1.8888888888888888in"   In-evaluation
  height="1.9861111111111112in"}                        

  ![](media/rId2044.png){width="1.9027777777777777in"   Malware
  height="1.9861111111111112in"}                        

  ![](media/rId2047.png){width="2.25in"                 Quarantine
  height="1.8472222222222223in"}                        

  ![](media/rId2050.png){width="1.7361111111111112in"   Still running
  height="1.3194444444444444in"}                        

  ![](media/rId2053.png){width="1.8472222222222223in"   Unknown sample
  height="2.0555555555555554in"}                        

  ![](media/rId2056.png){width="1.5555555555555556in"   User
  height="1.5416666666666667in"}                        

  ![](media/rId2059.png){width="1.6527777777777777in"   WF download
  height="1.5972222222222223in"}                        

  ![](media/rId2062.png){width="1.5694444444444444in"   WF download unsuccessful
  height="1.5138888888888888in"}                        
  -----------------------------------------------------------------------------------------

###### Examples

 

The following example shows a XDR Agent alert was triggered on a File.

![](media/rId2066.png){width="3.1805555555555554in"
height="4.583333333333333in"}

 

In this example, a NGFW alert was triggered on a TCP Protocol that
called a remote IP address, that created an unknown process.

![](media/rId2070.png){width="5.833333333333333in"
height="6.338383639545057in"}

 

In this example, the highlighted process node represents the real parent
that executed the process. Click on the node for more details about the
parent process. The pen icon on the first process nodes indicates that
this process is \"last actor\". The syringe icon on the last process
node indicates that this process is an \"injected node\".

![](media/rId2074.png){width="5.833333333333333in"
height="2.1072911198600175in"}

 

In this example, two alerts were triggered on an email that was sent to
two recipients and included attachments and links.

![](media/rId2078.png){width="5.833333333333333in" height="3.71875in"}

#### Cortex Response and Remediation content pack

The Cortex Response and Remediation content pack delivers a powerful
collection of automated playbooks designed to streamline incident
response and remediation processes, built to support an Autonomous SOC
vision.

The playbooks in this pack are tightly coupled to Issues, leveraging
detector logic to provide highly accurate and context-aware responses.
This ensures seamless integration with Cortex XSIAM, enabling SOC teams
to focus on high-priority threats while automating repetitive tasks.

##### Key principles of the Cortex Response and Remediation playbooks

- **Focused Security Response:** Playbooks prioritize high-quality
  security responses while delegating bureaucratic tasks to
  incident-level or sub-playbooks.

- **Research-Based Design:** The playbooks in the Cortex Response and
  Remediation pack are designed by the Cortex and Prisma Research team
  with extensive expertise and knowledge in responding to incidents and
  issues.

- **Detector Alignment:** Playbooks are tailored to specific Cortex or
  Prisma issues, ensuring precision by aligning with detector logic.

- **Cortex Analytics Integration:** Playbooks leverage Cortex analytics
  capabilities to derive precise verdicts for accurate and effective
  remediation.

- **AI-driven Investigations:** Advanced AI capabilities enrich
  investigations by providing deeper insights and contextual data to
  improve decision-making.

- **Clear Design:** Understandable within minutes.

##### Playbook features

- **Prebuilt:** Use out-of-the-box (OOTB) playbooks to ensure rapid
  deployment and reliable functionality.

- **Context-aware Actions:** Implement responsive actions based on issue
  triggers.

- **Seamless Integrations:** Fully compatible with Palo Alto Networks
  products and compatible with third-party solutions.

- **Granular Monitoring:** Provides detailed logs for tracking
  execution.

##### Integrations in the Cortex Response and Remediation content pack

For a full list and description of each of the integrations in the
Cortex Response and Remediation content pack, see the *Content* tab in
[Cortex Response And
Remediation](https://cortex.marketplace.pan.dev/marketplace/details/CortexResponseAndRemediation/).

##### Investigate an issue using Cortex Response and Remediation playbooks

Issues help you to monitor and control the security of your system
framework by alerting you to security risks in your framework. Cortex
XSIAM generates issues from the following:

- Agents

- Firewalls

- Analytics

- Integrations

By analyzing an issue, you can better
understand the cause of the issue, and take actions where required.

Select an issue to investigate

The **Issues** page displays a table of the issues associated with the
incident. By default, the **Issues** page displays the security issues
received over the last seven days. To see detailed information
about an issue, click an issue to open the issue panel. You can then
investigate the issue further by opening the issue investigation panel.

1.  Go to Cases & Issues \> Issues.

- ![](media/rId2089.png){width="5.833333333333333in" height="0.875in"}

2.  Click the issue and review the information in the issue side panel. 

- ![](media/rId2092.png){width="5.833333333333333in"
  height="2.0416666666666665in"}

3.  To see more information about the issue, click the
    **Issue Overview** tab.

- ![](media/rId2095.png){width="5.833333333333333in"
  height="3.310416666666667in"}

Adopt a automation rule suggestion

An automation rule is a filter on an issue that creates conditions, so
if an issue with specific characteristics is created (for example by
source, severity, or MITRE TTP), a suitable response is issued via a
playbook. This saves the analyst time and expense when investigating an
issue.

You can assign a playbook to an issue so that whenever the same issue is
triggered in the future, the same playbook will automatically run. You
can add an automation rule from the **Automation R Recommendations**
table. These playbooks are recommended to run whenever the issue is
triggered. These recommendations are part of the
*Cortex Response and Remediation* content pack.

1.  Go to Investigation & Response \> Automation \> Automation Rules.

2.  Click **View Recommendations**.

3.  Select the automation rule you want and click
    **Add selected rules**.

Reviewing the playbook response

After running the playbook, you can investigate an issue to gain more
information about the cause of the issue, and take any actions required.
In the issue investigation panel. The following tabs are common to most
issue:

+-----------------------------------+--------------------------------------------------------+
| Tab                               | Description                                            |
+===================================+========================================================+
| Issue Overview                    | A summary of the issue, such as issue details,         |
|                                   | outstanding tasks, and indicators. Some fields are     |
|                                   | informational and some are editable. Includes the      |
|                                   | following sections (depending on the layout):          |
|                                   |                                                        |
|                                   | - **ISSUE DETAILS**: A summary of the issue, such as   |
|                                   |   type, severity, and when the issue occurred. Update  |
|                                   |   these fields as required.                            |
|                                   |                                                        |
|                                   | - **COMMAND AND TASK RESULTS**: Lists any manual       |
|                                   |   commands and playbook task results.                  |
|                                   |                                                        |
|                                   | - **WORK PLAN**: When you click on the section, you    |
|                                   |   can view or take action on the following:            |
|                                   |                                                        |
|                                   |   - **Playbook tasks**: When a playbook runs, any      |
|                                   |     outstanding tasks appear. You can take various     |
|                                   |     actions here or in the Work Plan tab.              |
|                                   |                                                        |
|                                   |   - **To-Do Tasks**: An ad-hoc item that is not        |
|                                   |     attached to the Work Plan. Create tasks for users  |
|                                   |     to complete as part of an investigation. These are |
|                                   |     like a To-Do list that you keep in an              |
|                                   |     investigation on an ad-hoc basis rather than the   |
|                                   |     Work Plan which follows a pre-defined process. You |
|                                   |     can view or create To-Do tasks.                    |
|                                   |                                                        |
|                                   | - **NOTES**: Helps you understand specific actions     |
|                                   |   taken, and allow you to view conversations between   |
|                                   |   analysts to see how they arrived at a certain        |
|                                   |   decision. You can see the thought process behind     |
|                                   |   identifying key evidence and identifying similar     |
|                                   |   incidents.                                           |
|                                   |                                                        |
|                                   | - **MALICIOUS OR SUSPICIOUS INDICATORS**: A list of    |
|                                   |   any malicious or suspicious indicators. If you have  |
|                                   |   the Threat Intel add-on you can pivot to the         |
|                                   |   Indicators page, where you can take further action   |
|                                   |   on the indicator.                                    |
+-----------------------------------+--------------------------------------------------------+
| Technical Information             | Displays an overview of the information collected      |
|                                   | about the investigation, such as indicators, email     |
|                                   | information, URL screenshots, etc. When you run a      |
|                                   | playbook, the sections are automatically completed.    |
+-----------------------------------+--------------------------------------------------------+
| Investigation Tools               | Enables you to take action on the issue , such as      |
|                                   | converting a JSON file to CSV and check if the IP      |
|                                   | address is in CIDR.                                    |
+-----------------------------------+--------------------------------------------------------+
| War Room                          | A comprehensive collection of all investigation        |
|                                   | actions, artifacts, and collaboration. It is a         |
|                                   | chronological journal of the issue investigation. Each |
|                                   | incident has a unique War Room. For information, see   |
|                                   | [Use the War Room in an                                |
|                                   | investigation](#UUID2c0cd753c167d7894913ae53aec73a42). |
+-----------------------------------+--------------------------------------------------------+
| Work Plan                         | A visual representation of the running playbook that   |
|                                   | is assigned to the incident. For more information, see |
|                                   | [Use the Work Plan in an                               |
|                                   | investigation](#UUID3b7e55c261ead80a61a75412eec0a2f7). |
+-----------------------------------+--------------------------------------------------------+

Use the following steps to investigate and triage the issue:

1.  Review the data shown in the issue such as the command-line
    arguments (CMD), process info, etc.

2.  Analyze the chain of execution in the causality view.

- When the app correlates an issue with additional endpoint data, the
  **Issues** table displays a green dot to the left of the issue row to
  indicate the issue is eligible for analysis in the causality view. If
  the issue has a gray dot, the issue is not eligible for analysis in
  the causality view. This can occur when there is no data collected for
  an event, or the app has not yet finished processing the EDR data. To
  view the reason analysis is not available, hover over the gray dot.

3.  Review the timeline of the sequence of events over time. The
    timeline is available for issues that have been stitched with
    endpoint data.

4.  If deemed malicious, consider responding by isolating the endpoint
    from the network.

5.  Remediate the endpoint and return the endpoint from isolation.

##### Example use cases

The following are examples of Cortex Response and Remediation use cases.

###### SSO password spray

- **Detection:** Identifies suspicious login attempts against SSO
  endpoints.

- **Triage:** The playbook checks the IP reputation and fetches the
  events related to the SSO login attempts.

- **Early Containment:** The playbook checks if the IP is suspicious. If
  it is, the playbook suggests blocking the IP.

- **Investigation:**

  - The playbook assesses the risk score of the user who successfully
    logged in and examines the legitimacy of the user agent.

  - It verifies if the user has MFA configured and analyzes the
    timestamps of the login attempts to detect potential malicious
    automated patterns.

- **Containment:**

  - If there is a successful login attempt and the user\'s risk score is
    high, or if the user agent is detected as suspicious, or if the time
    intervals were automated, the playbook clears the user\'s session.

  - If the user doesn\'t have MFA, the playbook recommends expiring the
    user\'s password.

- **Requirements:** For any response action, you need one of the
  following integrations:

  - Microsoft Graph User

  - Okta

###### Credential dumping using a known tool

- **Detection:** Recognizes credential dumping activities.

- **Response:**

  - **Early Containment:** Handles malicious issues by terminating the
    causality process.

  - **Remediation:** Handles malicious issues by suggesting the analyst
    to isolate the endpoint. endpoints identified in the detection.

###### User added to local administrator group using PowerShell

- **Detection:** Detects unauthorized privilege escalations via
  PowerShell commands.

- **Response:**

  - **Investigation:** Check the following parameters to determine if
    remediation actions are needed:

    - Cortex XSIAM issues related to the hostname by MITRE tactics
      indicating malicious activity.

    - Whether the process is unsigned.

  - **Remediation:** Handles malicious issues by terminating the
    relevant processes and requesting the analyst\'s approval to remove
    the user from the local Administrators group. Handles non-malicious
    issues identified during the investigation.

### Investigate findings

Findings provide knowledge about an asset by leveraging the data we
collect from various sources. This process helps build a more accurate
and comprehensive understanding of the asset's current state, including
its configuration, behavior, and context within the environment.
Additionally, findings provide visibility into potential exposures and
vulnerabilities, contributing to a clearer assessment of the asset's
risk level. By continuously analyzing and updating findings, we can
maintain an up-to-date view of the asset's security posture and support
more informed decision-making for detection, prioritization, and
remediation efforts. For more information, see [Findings and
events](#UUIDbf161f3cb4dca8f66e01758cc950c3ea).

Click on a finding from any location in the UI to open the findings
card. For more information, see [Findings
card](#UUID2a8cd3eda2d4dbec2b935cdfa639ba8c). To view all findings, go
to . You can also see findings for a specific asset by opening the asset
card.

![](media/rId1157.png){width="0.19166666666666668in"
height="0.20833333333333334in"} Show me more

![](media/rId2110.gif){width="5.833333333333333in" height="3.28125in"}

#### Types of findings

The following table describes the different types of findings:

  -----------------------------------------------------------------------
  Type                                Description
  ----------------------------------- -----------------------------------
  Code                                Discovery of security issues within
                                      application source code, such as
                                      bugs, logic flaws, and insecure
                                      coding practices.

  Compliance                          Discovery of compliance violations
                                      that do not adhere to the security
                                      standards for your organization.

  Configuration                       Discovery of incorrect settings or
                                      configurations in systems,
                                      applications, or devices that
                                      reduce the environment\'s
                                      resilience and increase the
                                      potential for compromise.

  Data                                Discovery of sensitive data misuse,
                                      secrets, and shadow data.

  Identity                            Discovery of suspicious user
                                      identities, highlighting
                                      authentication and access control
                                      to prevent unauthorized access and
                                      minimize the risk of
                                      over-permissive access rights that
                                      could lead to security breaches.

  Malware                             Discovery of malicious files within
                                      cloud workloads.

  Posture                             Discovery of posture risks that
                                      might expose critical assets to
                                      potential cyberattacks and
                                      operational disruption.

  Vulnerability                       Discovery of weaknesses or flaws in
                                      software or hardware that attackers
                                      can exploit to gain unauthorized
                                      access, disrupt operations, or
                                      steal data.
  -----------------------------------------------------------------------

#### Set up rules to trigger issues from findings

Findings themselves are not issues, however findings that match a
specific logic can generate issues. You can also set up your own
policies and rules to trigger issues when the following types of
findings are recorded:

- Compliance, Malware, or Secrets findings, for more information see
  [Cloud workload policies and
  rules](/document/preview/1281553#UUID-89429ef6-a51c-8d9d-f9d7-f9d0afad28aa).

- Vulnerability findings, for more information see [Vulnerability
  policies](#UUIDd48badaed793601045c70fe385a252e4).

#### Query findings data

You can query finding data in the `findings` data set.

The following query searches for all findings for AssetA:

    dataset = findings | filter xdm.finding.asset_name = "AssetA"

#### Findings card

The Findings card displays information about the selected finding. On
this card you can see the following information.

> **Note**
>
> The information in this card is context specific, therefore some
> sections are not available for all findings.

+-----------------------------------+-----------------------------------+
| Section                           | Description                       |
+===================================+===================================+
| Header                            | Finding ID, name, category (such  |
|                                   | as, Vulnerability or Compliance), |
|                                   | time created, and time updated.   |
+-----------------------------------+-----------------------------------+
| Description                       | Reason that the finding was       |
|                                   | created.                          |
+-----------------------------------+-----------------------------------+
| Impact                            | Information about the possible    |
|                                   | impact of the finding on your     |
|                                   | system.                           |
+-----------------------------------+-----------------------------------+
| Asset                             | Name and type of the affected     |
|                                   | asset.                            |
|                                   |                                   |
|                                   | To investigate the asset, click   |
|                                   | on the asset name to open a new   |
|                                   | tab displaying the asset card.    |
+-----------------------------------+-----------------------------------+
| Evidence                          | Visualization of the finding in   |
|                                   | your environment.                 |
+-----------------------------------+-----------------------------------+
| Data                              | Normalized finding data.          |
+-----------------------------------+-----------------------------------+

### Investigate artifacts and assets

From the **Cases** view, open the **Key Assets & Artifact** tab to see
the assets and artifacts that are associated with the case, including
hosts, IP addresses, and users. Icons represent properties of the
artifacts and assets. Hover over an icon for more information. Click the
more options icon to drill down in dedicated views, or take actions on
the asset or artifact. The **Key Assets & Artifact** tab shows the
following information:

- Artifacts

<!-- -->

- To aid you with threat investigation, Cortex XSIAM displays the
  WildFire-issued verdict for each key artifact in a case. To provide
  additional verification sources, you can integrate external threat
  intelligence services with Cortex XSIAM.

<!-- -->

- Assets

<!-- -->

- Displays **Hosts** and **Users** details. For hosts with a Cortex XDR
  agent installed, click on the host name to see more information in the
  Details panel.

#### Investigate an IP address

Drilldown on an IP address on the **IP View**. On this view you can
investigate and take actions on IP addresses, and see detailed
information about an IP address over a defined 24-hour or 7-day time
frame. In addition, to help you determine whether an IP address is
malicious, the **IP View** displays an interactive visual representation
of the collected activity for a specific IP address.

**How to investigate an IP address**

1.  Open the **IP View**.

- Right-click the IP address that you want to investigate and select
  **Open IP View**.

2.  In the left panel, review the overview of the IP address.

- The overview displays network operations, cases, actions, and threat
  intelligence information relating to the selected IP address, and
  provides a summary of the network operations and processes related to
  the IP address.

  The displayed information and available actions are context specific.

  a.  Add an **Alias** or **Comment** to the IP address.

  b.  Review the location of the IP address. By default, Cortex XSIAM
      displays information on whether the IP address is an internal or
      external IP address.

      - **External**---**Connection Type: Incoming** displaying IP
        address is located outside of your organization. Displays the
        country flag if the location information is available.

      - **Internal**---**Connection Type: Outgoing** displaying IP
        address is from within your organization. The XDR Agent icon is
        displayed if the endpoint identified by the IP address had an
        agent installed at that point in time.

  c.  Identify the IOC severity.

  - The color of the IP address value is color-coded to indicate the IOC
    severity.

  d.  Review threat intelligence for the IP address.

  - Depending on the threat intelligence sources that are integrated
    with Cortex XSIAM, the following threat intelligence might be
    available:

    - **Virus Total** score and report

    <!-- -->

    - > **Note**

      > Requires a license key. Select Settings \> Configurations \>
      > Integrations \> Threat Intelligence.

    <!-- -->

    - **Whois** identification data for the specific IP address.

    - **IOC** Rule, if applicable, includes the IOC **Severity**,
      **Number of hits**, and **Source**.

    - **EDL** IP address if the IP address was added to an EDL.

  e.  Review the related cases.

  - **Recent Open Cases** lists the most recent cases that contain the
    IP address as part of the case's key artifacts, according to the
    Last Updated timestamp. If the IP address belongs to an endpoint
    with a Cortex XDR agent installed, the cases are displayed according
    to the host name rather than the IP address. To dive deeper into a
    specific case, select the case ID.

3.  In the right hand view, use the filter criteria to refine the scope
    of the IP address information that you want to visualize in the map.

- In the Type field, select **Host Insights** to pivot to
  the **Asset View** of the host associated with the IP address, or
  select **Network Connections** to display the **IP View** of the
  network connections made with the IP address.

4.  Review the selected data.

    - Select each node for additional information.

    - Select **Recent Outgoing Connections** to view the most recent
      connections made by the IP address.
      **Search all Outgoing Connections** to run a Network Connections
      query on all the connections made by the IP address.

5.  Perform actions on IOC or EDL.

- Depending on the current IOC and EDL status, the **Actions** button is
  displayed.

#### Investigate an asset

Drilldown on an asset on the **Asset View**. On this view you can
investigate host assets, view host insights, and see a list of cases
related to a host.

> **Note**
>
> The Asset view is available for hosts with a Cortex XDR agent
> installed.

**How to investigate an asset**

1.  Open the **Asset View**.

- Identify a host with a Cortex XDR agent installed and select
  **Open Asset View**.

2.  In the left panel, review the overview of the host asset.

- The overview displays the host name and any related cases.

  a.  Add an **Alias** or **Comment** to the host name.

  b.  Review the related cases.

  - **Recent Open Cases** lists the most recent cases that contain the
    host as part of the case's key artifacts, according to the Last
    Updated timestamp. To dive deeper into a specific case, select the
    Case ID.

3.  In the right hand view, use the filter criteria to refine the scope
    of the host information that you want to display.

- In the Type field, select one of the following:

  - **Host Insights:** View a list of the host artifacts.

  - **Network Connections:** Pivot to the **IP view** displaying the IP
    addresses associated with the host.

  - **Host Risk View:** View insights and profiling information.
    Available with the the Identity Threat Module.

4.  Review the data.

- Select **Run insights collection** to initiate a new collection. The
  next time the Cortex XDR agent connects, the insights are collected
  and displayed.

5.  Perform actions on the host.

#### Investigate a host

> **Note**
>
> The Host Risk View requires the Identity Threat Module add-on.

Drilldown on a host on the **Host Risk View**. On this view you can see
insights and profiling information about a host. When investigating
issues and cases, you can view anomalies in the context of the host that
can help you to make better and faster decisions about risks. On the
**Host View View** you can take the following actions:

- Assess the host\'s behavior and score.

- Analyze the host\'s behavior over time, and compare it to peer hosts
  with the same asset role.

- Review related cases and past issues for the host.

- Star the host to be included in the watchlist.

**How to investigate a host**

1.  Right-click the host that you want to investigate and select
    **Open Host Risk View**.

- > **Tip**

  > You can also see a list of all hosts under Inventory \> Assets \>
  > Asset Scores.

2.  In the left panel, review the overview of the host.

- The overview displays network operations, cases, actions, and threat
  intelligence information relating to the selected host. You can see
  the host score, the metadata aggregated by Cortex XSIAM, and review
  the CVEs breakdown by severity. The displayed information and
  available actions are context specific.

  Common Vulnerabilities and Exposures (CVE) are grouped by severity.
  For more information on each of the CVEs, refer to **Related CVEs**.

3.  Review the **Score Trend** graph.

- The graph is based on new cases created within the selected time
  frame, and updates on past cases that are still active. The straight
  line represents the host score, which is based on the scores of the
  cases associated with the host.

  The bubbles in the graph represent the number of issues and insights
  generated on the selected day. Bigger bubbles indicate more issues and
  insights, and a possible risk.

4.  Drilldown on a score for a specific day by clicking a bubble.
    Alternatively, review the host information for the selected
    timeframe (Last 7D, 30D, or custom timeframe). The widgets in the
    right panel reflect the selected timeframe.

5.  Review the **Related Cases** for the selected timeframe or score
    selected in the **Score Trend** graph. If you are drilling down on a
    score, you can see the cases that contributed to the total score on
    the selected day. Review the following data:

    - The **Status** column provides visibility into the reason for the
      score change. For example, if a case is resolved, its score will
      decrease, bringing down the host score.

    - The **Points** column displays the risk score that the case
      contributed to the host score. The points are calculated according
      to SmartScore or Case Scoring Rules.

6.  Review the **Related Issues and Insights** for the selected
    timeframe or score selected in the **Score Trend** graph.

- The timeline displays all detection activities associated with the
  host. The issues are grouped into buckets according to MITRE ATT&CK
  tactics. Click on a tactic to filter the issues in the table. To
  further investigate an issue, click the issue to open the Issue Panel
  and click **Investigate**.

7.  Review the **Latest Logins to Host** during the selected timeframe
    or on the day selected in the **Score Trend** graph.

- You can see details of the related login attempts, and whether the
  attempts were successful. To further investigate login activity for
  the host, click **View In XQL** to link to a prefilled query in the
  **Query Builder**. Using Cortex Query Language you can create queries
  to refine your search.

8.  Review the host\'s **Latest Authentication Attempts** during the
    selected timeframe or on the day selected in the **Score Trend**
    graph.

- You can see details of the related authentication attempts, and
  whether the attempts were successful. To further investigate
  authentication attempts by the host, click **View In XQL** to link to
  a prefilled query in the **Query Builder**. Using Cortex Query
  Language you can create queries to refine your search.

9.  Review the **Related CVEs** during the selected timeframe or on the
    day selected in the **Score Trend** graph.

- You can see details of the specified CVEs. This information can help
  you to access and prioritize security threats on each of the
  endpoints. To further investigate related CVEs, click **View In XQL**
  to link to a prefilled query in the **Query Builder**. Using Cortex
  Query Language you can create queries to refine your search.

10. For hosts with associated asset roles, compare the data with other
    peer hosts with the same asset role. In the **Score Trend** graph
    click **Compare To** and select an asset role to which you want to
    compare the data.

- The dashed line presents the average score for peers with the same
  asset role as the host, over the same time period. Hover over a bubble
  on the dashed line to see the Average score for the selected peer, and
  a breakdown of the score per endpoint. Click **Show *x* Hosts** to see
  a full breakdown of the score on the Peer Score Breakdown, filtered by
  the selected asset role. From the Peer Score Breakdown you can select
  any host name and pivot to additional views for further investigation.

11. (Optional) Take actions on the host.

- In the left panel, click **Actions** to see a list of available
  actions. Actions are context specific.

#### Investigate a file and process hash

Drilldown on a file or process hash on the **Hash View**. On this view
you can investigate and take actions on SHA256 hash processes and files,
and see information about a specific SHA256 hash over a defined 24-hour
or 7-day time frame. In addition, you can drill down on each of the
process executions, file operations, cases, actions, and threat
intelligence reports relating to the hash.

**How to investigate a file or process hash**

1.  Open the **Hash View**.

- Identify the file or process hash that you want to investigate and
  select **Open Hash View**.

2.  In the left panel, review the overview of the hash.

    a.  Review the signature of the hash, if available.

    b.  Identify the WildFire verdict.

    - The color of the hash value is color-coded to indicate the
      WildFire report verdict:

      WildFire color key
      - Blue---Benign

      - Yellow---Grayware

      - Red---Malware

      - Light gray---Unknown verdict

      - Dark gray---The verdict is inconclusive

    c.  Add an **Alias** or **Comment** to the hash value.

    d.  Review threat intelligence for the hash.

    - Depending on the threat intelligence sources that are integrated
      with Cortex XSIAM, the following threat intelligence might be
      available:

      - **Virus Total** score and report.

      <!-- -->

      - > **Note**

        > Requires a license key. Go to Settings \> Configurations \>
        > Integrations \> Threat Intelligence.

      <!-- -->

      - **IOC** Rule, if applicable, including the IOC **Severity**,
        **Number of hits**, and **Source** according to the color-coded
        values:

      - **WildFire** analysis report.

    e.  Review if the hash has been added to:

        - **Allow List** or **Block List**.

        - **Quarantined**, select the number of endpoints to open the
          **Quarantine Details** view.

    f.  Review the recent open cases that contain the hash as part of
        the case\'s **Key Artifacts** according to the **Last Updated**
        timestamp. To dive deeper into specific cases, select the Case
        ID.

3.  In the right hand view, use the filter criteria to refine the scope
    of the IP address information that you want to visualize.

- Filter criteria

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  **Event Type**                      Main set of values that you want to
                                      display. The values depend on the
                                      selected type of process or file.

  **Primary**                         Set of values that you want to
                                      apply as the primary set of
                                      aggregations. Values depend on the
                                      selected **Event Type**.

  **Secondary**                       Set of values that you want to
                                      apply as the secondary set of
                                      aggregations.

  **Showing**                         Number of **Primary** and
                                      **Secondary** aggregated values to
                                      display.

  **Timeframe**                       Time period over which to display
                                      your defined set of values.
  -----------------------------------------------------------------------

4.  Review the selected data.

- To view the most recent processes executed by the hash, select
  **Recent Process Executions**. To run a query on the hash, select
  **Search all Process Executions**.

5.  (Optional) Perform actions on the hash.

#### Investigate a user

Drilldown on a user in the **User Risk View** or the **User View**. On
this view Cortex XSIAM aggregates all of the data collected for a user,
displays the information in graphs and tables, and provides further
drilldown options for easy investigation. Cortex XSIAM uses Identity
Analytics to aggregate information on a user and displays insights about
the user.

> **Note**
>
> If the Identity Threat module is enabled you can open the
> **User Risk View**. This view displays insights and profiling
> information to help you investigate issues and cases. Viewing
> anomalies in the context of baseline behavior facilitates risk
> assessment and shortens the time you require for making verdicts.
>
> If the Identity Threat module is *not* enabled you can open the
> **User View**. This view displays an overview of the user and
> information about the user\'s score and activity.

You can take the following actions to investigate a user:

- Assess the user\'s behavior and score.

- Star the user to be included in the watchlist.

- (User Risk View only) Review the user\'s working hours and related
  issues.

- (User Risk View only) Analyze the user\'s behavior over time and
  compare to their peers with the same asset role.

**How to investigate a user**

1.  Right-click a user name and select **Open User Risk View** or
    **Open User Card**.

- > **Tip**

  > You can also see a list of all users under Assets \> Asset Scores.

2.  Select the timeframe to view the user\'s details.

- > **Note**

  > Cortex XSIAM normalizes and displays case and issue times in your
  > time zone. If you\'re in a half-hour time zone, the activity in the
  > Normal Activity and the Actual Activity charts is displayed in the
  > whole-hour time slot preceding it. For example, if you\'re in a UTC
  > +4.5 time zone, the time displayed for the activity will be UTC
  > +4.5, however, the visualization in the Normal Activity and the
  > Actual Activity charts will be in the UTC +4 slot.

3.  Investigate the user.

- User Risk View
  Review the sections of the **User Risk View**. Depending on your
  permissions, some information might be limited by your scope.

  1.  In the left panel, review the overview of the user:

      - **User Score:** Displays the score assigned on the last day of
        the selected time frame and the change in the score for the
        selected time frame. The score is updated continuously as new
        issues are associated with cases.

      - **Common Locations:** Displays the countries from which the user
        connected most in the past few weeks.

      - **Common UAs:** Displays the user agents that the user used most
        in the past few weeks.

      - **Regular Activity Hours:** This data is based on the preceding
        several weeks and takes into account holidays and seasonality to
        present an accurate picture. Cortex XSIAM leverages endpoint
        telemetry to provide the activity data.

  2.  Review the **Score Trend** graph.

  - The graph is based on new cases created within the selected time
    frame, and updates on past cases that are still active. The straight
    line represents the user score, which is based on the scores of the
    cases associated with the user.

    The bubbles in the graph represent the number of issues and insights
    generated on the selected day. Bigger bubbles indicate more issues
    and insights, and a possible risk.

  3.  Drilldown on a score for a specific day by clicking a bubble.
      Alternatively, review the user information for the selected
      timeframe (Last 7D, 30D, or custom timeframe). The widgets in the
      right panel reflect the selected timeframe.

  4.  Review the **Related Cases** for the selected timeframe or score
      selected in the **Score Trend** graph. If you are drilling down on
      a score, you can see the cases that contributed to the total score
      on the selected day. Review the following data:

      - The **Status** column provides visibility into the reason for
        the score change. For example, if a case is resolved, its score
        will decrease, bringing down the host score.

      - The **Points** column displays the risk score that the case
        contributed to the host score. The points are calculated
        according to SmartScore or Case Scoring Rules.

  5.  Review the **Related Issues and Insights** for the selected
      timeframe or score selected in the **Score Trend** graph.

  - The timeline displays all detection activities associated with the
    user. The issues are grouped into buckets according to MITRE ATT&CK
    tactics. Click on a tactic to filter the issues in the table. To
    further investigate an issue, click the issue to open the Issue
    Panel and click **Investigate**.

  6.  Review the user activity per day in the **Actual Activity**
      widget.

  - In this widget Cortex XSIAM compares the user\'s actual activity
    data with the **Regular Activity Hours**, and highlights any
    differences or anomalies in the user\'s expected activity.

    The cells are marked according to the activity that took place:, and
    a dashed frame indicates that Cortex XSIAM detected uncommon
    activity in the time slot.

    - A dashed ribbon highlights discrepancies between regular activity
      hours and actual activity.

    - A colored ribbon indicates the level of activity on a specific
      day/hour.

    - A numbered ribbon indicates the number of issues and insights that
      occurred on a specific day/hour.

  7.  Review the user\'s **Login Attempts** during the selected
      timeframe or on the day selected in the **Score Trend** graph.

  - You can see details of the related login attempts, and whether the
    attempts were successful. To further investigate login activity for
    the user, click **View In XQL** to link to a prefilled query in the
    **Query Builder**. Using Cortex Query Language you can create
    queries to refine your search.

  8.  Review the user\'s **Latest Authentication Attempts** during the
      selected timeframe or on the day selected in the **Score Trend**
      graph.

  - You can see details of the related authentication attempts, and
    whether the attempts were successful. To further investigate
    authentication attempts by the user, click **View In XQL** to link
    to a prefilled query in the **Query Builder**. Using Cortex Query
    Language you can create queries to refine your search.

  9.  Review the user\'s **SAAS Log** activity during the selected
      timeframe or on the day selected in the **Score Trend** graph. You
      can see details of the SaaS logs that were ingested into the
      platform in context of the user.

  - To further investigate SaaS log activity for the user, click
    **View In XQL** to link to a prefilled query in the
    **Query Builder**. Using Cortex Query Language you can refine your
    search.

  10. For users with associated asset roles, compare the data with other
      peers with the same asset role. In the **Score Trend** graph click
      **Compare To** and select an asset role to which you want to
      compare the data.

  - The dashed line presents the average score for peers with the same
    asset role as the user, over the same time period. Hover over a
    bubble on the dashed line to see the Average score for the selected
    peer, and a breakdown of the score per endpoint. Click
    **Show *x* Hosts** to see a full breakdown of the score on the Peer
    Score Breakdown, filtered by the selected asset role. From the Peer
    Score Breakdown you can select any user name and pivot to additional
    views for further investigation.

  User View
  Review the sections of the **User View**. Depending on your
  permissions, some information might be limited by your scope.

  1.  In the left panel, review the overview of the user. The displayed
      information is aggregated by Cortex XSIAMfrom cases, Workday, and
      Active Directory data.

  - The **User Score** displays the score that is currently assigned to
    the user and is updated continuously as new issues are associated
    with cases.

  2.  Review the **Score Trend** graph.

  - The graph is based on new cases created within the selected time
    frame, and updates on past cases that are still active. The straight
    line represents the user score, which is based on the scores of the
    cases associated with the user.

    Select a score to display in the **Cases** table the cases that
    contributed to the total user score on a specific day.

  3.  Click a score to drilldown on the score for a specific day.
      Alternatively, review the user information for the selected
      timeframe (Last 7D, 30D, or custom timeframe).

  - The widgets in the right panel reflect the selected timeframe.

  4.  Review the **Related Cases** for the selected timeframe or score
      selected in the **Score Trend** graph. If you are drilling down on
      a score, you can see the cases that contributed to the total score
      on the selected day. Review the following data:

      - The **Status** column provides visibility into the reason for
        the score change. For example, if a case is resolved, its score
        will decrease, bringing down the host score.

      - The **Points** column displays the risk score that the case
        contributed to the host score. The points are calculated
        according to SmartScore or Case Scoring Rules.

  5.  Review the following additional widgets:

      - **User Associated Insights**

      - **Top 5 Hosts Logged Into**

      - **Top 5 Authentication Target Hosts**

      - **Top 5 Authentication Source Hosts**

      - **Recent Login**

      - **Recent Authentications**

### Investigate endpoints

You can investigate and take actions on your endpoints in the
**Action Center**.

#### Overview of the Action Center

The **Action Center** is a central location from which you can track the
progress of all investigation, response, and maintenance actions
performed on your Cortex XSIAM protected endpoints. To access the
**Action Center**, go to Investigation & Response \> Response \> Action
Center.

The main **All Actions** tab displays the most recent actions initiated
in your deployment. To narrow down the results, use the table filters.
You can also choose from the filtered **Action Center** views to see
details of the following actions:

- **File Quarantine:** View details about quarantined files on your
  endpoints. You can also switch to an **Aggregated by SHA256** view
  that collapses results per file and lists the affected endpoints in
  the **Scope** field.

- **Block List and Allow List:** View files that are permitted and
  blocked from running on your endpoints regardless of file verdict.

<!-- -->

- > **Note**

  > Blocking files on endpoints is enforced by the endpoint malware
  > profile. To block a hash value, ensure the hash value is configured
  > in the Malware security profile.

  > Select **Override Report mode** to allow the agent to block hashes,
  > even if the Malware Profile is set to **Report**.

<!-- -->

- **Endpoint Isolation:** View the endpoints in your organization that
  have been isolated from the network. For more information, see
  [Isolate an endpoint](#UUID0e0b35ddc1c1c408430f57f4582ceb8c).

- **External Dynamic List:** View the list of IP addresses and domain
  names in your EDL. For more information, see
  [/document/preview/1048655#UUID-83e72920-374a-34e3-6fb4-9d6ea86cc034](/document/preview/1048655#UUID-83e72920-374a-34e3-6fb4-9d6ea86cc034).

- **Endpoint Blocked IP Addresses:** View remote IP addresses that the
  Cortex XDR agent has automatically blocked from communicating with
  endpoints in your network.

- **Agent Scripts Library:** View Palo Alto Networks and
  administrator-uploaded scripts that you can run on your endpoints.

For actions that can take a while to complete, the **Action Center**
tracks the action progress and displays the action status and current
progress description for each stage. For example, after initiating an
agent upgrade action, Cortex XSIAM monitors all stages from the
**Pending** request until the action status is **Completed**. Throughout
the action lifetime, you can view the number of endpoints on which the
action was successful and the number of endpoints on which the action
failed. After a period of 90 days since the action creation, the action
is removed from Cortex XSIAM and is no longer displayed in the
**Action Center**. You cannot delete actions manually.

##### Initiate and monitor endpoint actions

In the **Action Center** you can initiate and monitor actions on your
endpoints. In addition, you can initiate endpoint actions when viewing
details about an endpoint on the **All Endpoints** page.

###### Initiate an endpoint action from the Action Center

Create new administrative actions using the **Action Center** wizard:

1.  Go to Investigation & Response \> Response \> Action Center \> New
    Action.

2.  Select the action you want to initiate and follow the required steps
    and parameters you need to define for each action.

- Cortex XSIAM displays only the endpoints eligible for the action you
  want to perform.

3.  Review the action summary and click **Done**.

- Cortex XSIAM will inform you if any of the agents in your action scope
  will be skipped.

4.  Track your action.

- Track the new action in the **Action Center**. The action status is
  updated according to the action progress.

###### Monitor endpoint actions

1.  Go to Investigation & Response \> Response \> Action Center.

2.  Select the relevant view from the left-side menu on the
    **Action Center** page.

3.  Use the table filters to filter the results.

4.  Take further actions. Right-click the action to see the available
    options:

    - **Additional data:** Display additional details for the action,
      such as file paths for quarantined files or operating systems for
      agent upgrades. For actions with **Status**, **Failed** or
      **Completed with partial success**, you can create an upgrade
      action to rerun the action on endpoints that have not been
      completed successfully.

    - **Archive:** Archive the action for future reference. You can
      select multiple actions to archive at the same time.

    - **Cancel for Pending endpoints:** Cancel the original action for
      agents that are still in `Pending` status.

    - **Download output:** Download a zip file with the files received
      from the endpoint for actions such as file and data retrieval.

    - **Rerun:** Launch the **Define an Action** wizard populated with
      the same details as the original action.

    - **Run on additional agents:** Launch the action wizard populated
      with the details as the original action except for the agents
      which you have to fill in.

    - **Restore:** Restore quarantined files.

##### Action Center reference information

The following table describes both the default and additional optional
fields that you can view from the **All Actions** tab of the
**Action Center** and lists the fields in alphabetical order.

+-----------------------------------+----------------------------------------------+
| Field                             | Description                                  |
+===================================+==============================================+
| Action Type                       | Type of action initiated on the endpoint.    |
+-----------------------------------+----------------------------------------------+
| Agent Restart                     | Status of the restart action on the          |
|                                   | endpoint.                                    |
|                                   |                                              |
|                                   | Statuses:                                    |
|                                   |                                              |
|                                   | - **In progress:** Action initiated, but no  |
|                                   |   start indication from agent after stop.    |
|                                   |                                              |
|                                   | - **Failed:** Agent reports failed back to   |
|                                   |   the Cortex XSIAM server if it was started  |
|                                   |   after more than 10 minutes after restart   |
|                                   |   initiation.                                |
|                                   |                                              |
|                                   | - **Expired:** After 4 days.                 |
|                                   |                                              |
|                                   | - **Success:** Agent reports success to the  |
|                                   |   Cortex XSIAM server if it was started      |
|                                   |   within 10 minutes after restart            |
|                                   |   initiation.                                |
+-----------------------------------+----------------------------------------------+
| Created By                        | Name of the user who initiated the action.   |
+-----------------------------------+----------------------------------------------+
| Creation Timestamp                | Date and time the action was created.        |
+-----------------------------------+----------------------------------------------+
| Description                       | Action scope of affected endpoints and       |
|                                   | additional data relevant to each of the      |
|                                   | specific actions, such as agent version,     |
|                                   | file path, and file hash.                    |
+-----------------------------------+----------------------------------------------+
| Expiration Date                   | Time the action will expire. To set an       |
|                                   | expiration date, the action must apply to    |
|                                   | one or more endpoints.                       |
|                                   |                                              |
|                                   | By default, Cortex XSIAM assigns a 30-day    |
|                                   | expiration limit to the following actions:   |
|                                   |                                              |
|                                   | - Agent Uninstall                            |
|                                   |                                              |
|                                   | - Agent Upgrade                              |
|                                   |                                              |
|                                   | - Files Retrieval                            |
|                                   |                                              |
|                                   | - Isolate                                    |
|                                   |                                              |
|                                   | - Cancel Endpoint Isolation                  |
|                                   |                                              |
|                                   | Additional actions such as malware scans,    |
|                                   | quarantine, and endpoint data retrieval are  |
|                                   | assigned a 4-day expiration limit.           |
|                                   |                                              |
|                                   | After the expiration limit, the status for   |
|                                   | any remaining **Pending** actions on         |
|                                   | endpoints change to **Expired** and these    |
|                                   | endpoints will not perform the action.       |
+-----------------------------------+----------------------------------------------+
| Status                            | Current status of the action.                |
+-----------------------------------+----------------------------------------------+
| **Additional data:** If           |                                              |
| additional details are available  |                                              |
| for an action or for specific     |                                              |
| endpoints, you can pivot to the   |                                              |
| **Additional data** view. You can |                                              |
| also export the additional data   |                                              |
| to a TSV file. The page can       |                                              |
| include details in the following  |                                              |
| fields but varies depending on    |                                              |
| the type of action.               |                                              |
+-----------------------------------+----------------------------------------------+
| Endpoint Name                     | Target host name of each endpoint for which  |
|                                   | an action was initiated.                     |
+-----------------------------------+----------------------------------------------+
| IP Addresses                      | IP address associated with the endpoint.     |
+-----------------------------------+----------------------------------------------+
| Status                            | Status of the action for the specific        |
|                                   | endpoint.                                    |
|                                   | (Linux)---**Completed with Partial Success** |
|                                   | for a single endpoint that did not complete  |
|                                   | the action successfully.                     |
+-----------------------------------+----------------------------------------------+
| Action Last Update                | Time at which the last status update         |
|                                   | occurred for the action.                     |
+-----------------------------------+----------------------------------------------+
| Advanced Analysis                 | For **Retrieve issue data** requests related |
|                                   | to Cortex XSIAM issues triggered by exploit  |
|                                   | protection modules, Cortex XSIAM can analyze |
|                                   | the memory state for additional verdict      |
|                                   | verification. This field displays the        |
|                                   | analysis progress and resulting verdict.     |
+-----------------------------------+----------------------------------------------+
| Action Parameters                 | Summary of the action including the issue    |
|                                   | name and ID.                                 |
+-----------------------------------+----------------------------------------------+
| Additional Data \| Malicious      | Additional data, if any is available, for    |
| Files                             | the action. For malware scans, this field is |
|                                   | titled **Malicious Files** and indicates the |
|                                   | number of malicious files identified during  |
|                                   | the scan.                                    |
+-----------------------------------+----------------------------------------------+

#### Manage endpoints

The **All Endpoints** page provides a central location from which you
can view and manage the endpoints on which the agent is installed. To
access the **All Endpoints** page, go to Inventory \> Endpoints \> All
Endpoints.

To ensure the **All Endpoints** table is displaying the most accurate
list of endpoints, you can perform a one-time or periodic cleanup of
duplicated entities. After the cleanup, duplicated entities are removed
leaving only one endpoint entry, which is the last endpoint to connect
with the server. Deleted endpoint data is retained for 90 days from the
last connection timestamp. If a deleted endpoint reconnects, Cortex
XSIAM recovers and redisplays the endpoint's existing data.

Go to Settings \> Configurations \> General \> Agent Configurations \>
Endpoint Administration Cleanup. Enable the
**Periodic duplicate cleanup** and select either **One-time cleanup** or
define a periodic cleanup to run according to the Host Name, Host IP
Address, and/or MAC Address fields at a specific time interval.

##### Endpoint actions

The right-click pivot menu displays the actions you can perform on your
endpoints. For more information about these actions, see the topics in
this section, and the topics under [Manage endpoint
protection](#UUID54148bcdc511816d1f2fbbb456e25356).

> **Note**
>
> For the **Include endpoints from auto upgrade** action, you cannot
> enable auto upgrade for Mobile, VDI, and TS installations.

##### All Endpoints reference information

The following table describes both the default and additional optional
fields that you can view in the **All Endpoints** table and lists.
Clicking on a row in the **All Endpoints** table opens a detailed view
of the endpoint.

+-----------------------------------+---------------------------------------+
| Field                             | Description                           |
+===================================+=======================================+
| Active Directory                  | Active Directory Groups and           |
|                                   | Organizational Units to which the     |
|                                   | user belongs.                         |
+-----------------------------------+---------------------------------------+
| Assigned Extensions Policy        | Policy related to extensions and      |
|                                   | devices connected to the endpoint.    |
+-----------------------------------+---------------------------------------+
| Assigned Prevention Policy        | Policy assigned to the endpoint.      |
+-----------------------------------+---------------------------------------+
| Agent Version                     | Agent version that is installed on    |
|                                   | the endpoint.                         |
+-----------------------------------+---------------------------------------+
| Auto Upgrade Status               | When Cortex XDR agent auto upgrades   |
|                                   | are enabled, this field indicates the |
|                                   | action status.                        |
|                                   |                                       |
|                                   | > **Note**                            |
|                                   | >                                     |
|                                   | > If an endpoint is excluded, the     |
|                                   | > auto upgrade profile configuration  |
|                                   | > is not available.                   |
|                                   | >                                     |
|                                   | > If you exclude the endpoint from    |
|                                   | > auto upgrade while the auto upgrade |
|                                   | > action is **In progress**, the      |
|                                   | > ongoing upgrade will still take     |
|                                   | > place.                              |
+-----------------------------------+---------------------------------------+
| Cloud Account ID                  | Unique identifier for the cloud       |
|                                   | account that owns or manages the      |
|                                   | workload.                             |
+-----------------------------------+---------------------------------------+
| Cloud Info                        | IBM and Alibaba Cloud metadata        |
|                                   | reported by the workload.             |
+-----------------------------------+---------------------------------------+
| Cloud Instance ID                 | (Agent 8.9 and later) Unique          |
|                                   | identifier for the cloud instance     |
|                                   | hosting the workload.                 |
+-----------------------------------+---------------------------------------+
| Cloud Provider                    | (Agent 8.9 and later) Cloud service   |
|                                   | provider hosting the workload.        |
+-----------------------------------+---------------------------------------+
| Cloud Region                      | (Agent 8.9 and later) Geographical    |
|                                   | region of the cloud infrastructure    |
|                                   | where the workload is hosted.         |
+-----------------------------------+---------------------------------------+
| Cluster Name                      | (Agent 8.9 and later) Cluster name to |
|                                   | which the workload belongs.           |
+-----------------------------------+---------------------------------------+
| Content Auto Update               | Whether automatic content updates are |
|                                   | **Enabled** or **Disabled** for the   |
|                                   | endpoint in the agent settings        |
|                                   | profile.                              |
+-----------------------------------+---------------------------------------+
| Content Release Timestamp         | Time and date of when the current     |
|                                   | content version was released.         |
+-----------------------------------+---------------------------------------+
| Content Rollout Delay (days)      | If you configured delayed content     |
|                                   | rollout, the number of days for delay |
|                                   | is displayed here.                    |
+-----------------------------------+---------------------------------------+
| Content Status                    | Status of the content version on the  |
|                                   | relevant endpoint. The Cortex XSIAM   |
|                                   | tenant attempts to contact an         |
|                                   | endpoint and check the content        |
|                                   | version over a 7-day period. After    |
|                                   | this period the tenant displays one   |
|                                   | of the following statuses:            |
|                                   |                                       |
|                                   | - **Up to Date:** The endpoint is     |
|                                   |   running with the latest content     |
|                                   |   version                             |
|                                   |                                       |
|                                   | - **Waiting for Update:** Cortex      |
|                                   |   XSIAM is in the process of updating |
|                                   |   the new content version. Depending  |
|                                   |   on your bandwidth and network       |
|                                   |   connection, updating the content    |
|                                   |   version may take time.              |
|                                   |                                       |
|                                   | - **Outdated:** The endpoint is       |
|                                   |   running on an outdated content      |
|                                   |   version.                            |
|                                   |                                       |
|                                   | - **Offline:** The endpoint is        |
|                                   |   disconnected.                       |
|                                   |                                       |
|                                   | > **Note**                            |
|                                   | >                                     |
|                                   | > Content Status is calculated every  |
|                                   | > 30 minutes. Therefore, there might  |
|                                   | > be a delay of up to 30 minutes in   |
|                                   | > displaying the data.                |
+-----------------------------------+---------------------------------------+
| Content Version                   | Content update version used with the  |
|                                   | agent.                                |
+-----------------------------------+---------------------------------------+
| Disabled Capabilities             | List of capabilities that were        |
|                                   | disabled on the endpoint. Options are |
|                                   | **Live Terminal**,                    |
|                                   | **Script Execution**, and             |
|                                   | **File Retrieval**.                   |
|                                   |                                       |
|                                   | You can disable these capabilities    |
|                                   | during agent installation on the      |
|                                   | endpoint or through                   |
|                                   | **Endpoint Administration**.          |
|                                   | Disabling any of these actions is     |
|                                   | irreversible. If you later want to    |
|                                   | enable the action on the endpoint,    |
|                                   | you must uninstall the agent and      |
|                                   | install a new package on the          |
|                                   | endpoint.                             |
+-----------------------------------+---------------------------------------+
| Domain                            | Domain or workgroup to which the      |
|                                   | endpoint belongs.                     |
|                                   |                                       |
|                                   | > **Note**                            |
|                                   | >                                     |
|                                   | > Only supported for Windows and      |
|                                   | > macOS.                              |
+-----------------------------------+---------------------------------------+
| Endpoint Alias                    | If you assigned an alias to represent |
|                                   | the endpoint in Cortex XSIAM, the     |
|                                   | alias is displayed here. To set an    |
|                                   | endpoint alias, right-click in the    |
|                                   | endpoint row, select Endpoint Control |
|                                   | \> Change Endpoint Alias. The alias   |
|                                   | can contain any of the following      |
|                                   | characters:                           |
|                                   |                                       |
|                                   | `a-Z, 0-9, !@#$%^&:()-'{}~_.`         |
+-----------------------------------+---------------------------------------+
| Endpoint ID                       | Unique ID that identifies the         |
|                                   | endpoint.                             |
+-----------------------------------+---------------------------------------+
| Endpoint Isolated                 | Isolation status, either:             |
|                                   |                                       |
|                                   | - **Isolated:** The endpoint has been |
|                                   |   isolated from the network with      |
|                                   |   communication permitted to only     |
|                                   |   Cortex XSIAM and to any IP          |
|                                   |   addresses and processes included in |
|                                   |   the allow list.                     |
|                                   |                                       |
|                                   | - **Not Isolated:** Normal network    |
|                                   |   communication is permitted on the   |
|                                   |   endpoint.                           |
|                                   |                                       |
|                                   | - **Pending Isolation:** The          |
|                                   |   isolation action has reached the    |
|                                   |   server and is pending contact with  |
|                                   |   the endpoint.                       |
|                                   |                                       |
|                                   | - **Pending Isolation Cancellation:** |
|                                   |   The cancel isolation action has     |
|                                   |   reached the server and is pending   |
|                                   |   contact with the endpoint.          |
+-----------------------------------+---------------------------------------+
| Endpoint Name                     | Hostname of the endpoint. If the      |
|                                   | agent enables Pro features, this      |
|                                   | field also includes a **PRO** badge.  |
|                                   | For Android endpoints, the hostname   |
|                                   | comprises the                         |
|                                   | \<`firstname`\>`—`\<`lastname`\> of   |
|                                   | the registered user, with a           |
|                                   | separating dash.                      |
+-----------------------------------+---------------------------------------+
| Endpoint Status                   | Registration status of the agent on   |
|                                   | the endpoint:                         |
|                                   |                                       |
|                                   | - **Connected:** The agent has        |
|                                   |   checked in within 10 minutes for    |
|                                   |   standard endpoints, and within 3    |
|                                   |   hours for mobile endpoints.         |
|                                   |                                       |
|                                   | - **Connection Lost:** The agent has  |
|                                   |   not checked in within 30 to 180     |
|                                   |   days for standard endpoints, and    |
|                                   |   between 90 minutes and 6 hours for  |
|                                   |   VDI and temporary sessions.         |
|                                   |                                       |
|                                   | - **Disconnected:** The agent has not |
|                                   |   checked in within the defined       |
|                                   |   inactivity window: between 10       |
|                                   |   minutes and 30 days for standard    |
|                                   |   and mobile endpoints, and between   |
|                                   |   10 minutes and 90 minutes for VDI   |
|                                   |   and temporary sessions.             |
|                                   |                                       |
|                                   | - **VDI Pending Log-on:** (Windows    |
|                                   |   only) Indicates a non-persistent    |
|                                   |   VDI endpoint is waiting for user    |
|                                   |   logon, after which the agent        |
|                                   |   consumes a license and starts       |
|                                   |   enforcing protection.               |
|                                   |                                       |
|                                   | - **Uninstalled:** The agent has been |
|                                   |   uninstalled from the endpoint.      |
+-----------------------------------+---------------------------------------+
| Endpoint Type                     | Type of endpoint.                     |
+-----------------------------------+---------------------------------------+
| Endpoint Version                  | Versions of the agent that runs on    |
|                                   | the endpoint.                         |
+-----------------------------------+---------------------------------------+
| First Seen                        | Date and time the agent first checked |
|                                   | in (registered) with Cortex XSIAM.    |
+-----------------------------------+---------------------------------------+
| Golden Image ID                   | For endpoints with a System Type of   |
|                                   | Golden Image, the image ID is a       |
|                                   | unique identifier for the golden      |
|                                   | image.                                |
+-----------------------------------+---------------------------------------+
| Group Names                       | Endpoint Groups to which the endpoint |
|                                   | is a member, if applicable.           |
+-----------------------------------+---------------------------------------+
| Incompatibility Mode              | Agent incompatibility status, either: |
|                                   |                                       |
|                                   | - **Agent Incompatible:** The agent   |
|                                   |   is incompatible with the            |
|                                   |   environment and cannot recover.     |
|                                   |                                       |
|                                   | - **OS Incompatible:** The agent is   |
|                                   |   incompatible with the operating     |
|                                   |   system.                             |
|                                   |                                       |
|                                   | When agents are compatible with the   |
|                                   | operating system and environment,     |
|                                   | this field is blank.                  |
+-----------------------------------+---------------------------------------+
| Isolation Date                    | Date and time of when the endpoint    |
|                                   | was **Isolated**. Displayed only for  |
|                                   | endpoints in **Isolated** or          |
|                                   | **Pending Isolation Cancellation**    |
|                                   | status.                               |
+-----------------------------------+---------------------------------------+
| Install Date                      | Date and time at which the agent was  |
|                                   | first installed on the endpoint.      |
+-----------------------------------+---------------------------------------+
| Installation Package              | Installation package name used to     |
|                                   | install the agent.                    |
+-----------------------------------+---------------------------------------+
| Installation Type                 | Type of installation.                 |
+-----------------------------------+---------------------------------------+
| IP Address                        | Last known IPv4 address of the        |
|                                   | endpoint.                             |
+-----------------------------------+---------------------------------------+
| IPv6 Address                      | Last known IPv6 address of the        |
|                                   | endpoint.                             |
+-----------------------------------+---------------------------------------+
| Is EDR Enabled                    | Whether EDR data is enabled on the    |
|                                   | endpoint.                             |
+-----------------------------------+---------------------------------------+
| IT Metric Collection              | Whether the endpoint is collecting IT |
|                                   | performance data.                     |
+-----------------------------------+---------------------------------------+
| Last Certificate Enforcement      | (For Windows and MacOS Endpoints) If  |
| Fallback                          | Certificate Enforcement is Enabled,   |
|                                   | this column shows the date and time   |
|                                   | of use of a fallback certificate from |
|                                   | the local store. If no fallback is    |
|                                   | used, this will remain empty.         |
+-----------------------------------+---------------------------------------+
| Last Content Update Time          | Time and date when the agent last     |
|                                   | deployed a content update.            |
+-----------------------------------+---------------------------------------+
| Last Origin IP                    | Last IPv4 address from which the XDR  |
|                                   | agent connected.                      |
+-----------------------------------+---------------------------------------+
| Last Origin IPv6                  | Last IPv6 address from which the XDR  |
|                                   | agent connected.                      |
+-----------------------------------+---------------------------------------+
| Last Scan                         | Date and time of the last malware     |
|                                   | scan on endpoint.                     |
+-----------------------------------+---------------------------------------+
| Last Seen                         | Date and time of the last change in   |
|                                   | an agent\'s status. This can occur    |
|                                   | when Cortex XSIAM receives a periodic |
|                                   | status report from the agent (once an |
|                                   | hour), a user performed a manual      |
|                                   | Check In, or a security event         |
|                                   | occurred.                             |
|                                   |                                       |
|                                   | > **Note**                            |
|                                   | >                                     |
|                                   | > Changes to the agent status can     |
|                                   | > take up to ten minutes to display   |
|                                   | > on Cortex XSIAM .                   |
+-----------------------------------+---------------------------------------+
| Last Used Proxy                   | IP address and port number of proxy   |
|                                   | that was last used for communication  |
|                                   | between the agent and Cortex XSIAM.   |
+-----------------------------------+---------------------------------------+
| Last Used Proxy Port              | Last proxy port used on endpoint.     |
+-----------------------------------+---------------------------------------+
| Linux Operation Mode              | (Agent 7.7 and later for Linux) Type  |
|                                   | of operation mode your Linux endpoint |
|                                   | is running by the agent.              |
+-----------------------------------+---------------------------------------+
| Last Upgrade Failure Reason       | Reason an upgrade failed.             |
+-----------------------------------+---------------------------------------+
| Last Upgrade Source               | Source of the upgrade installation    |
|                                   | file.                                 |
+-----------------------------------+---------------------------------------+
| Last Upgrade Status               | Status of the last upgrade.           |
+-----------------------------------+---------------------------------------+
| Last Upgrade Status Time          | Date and time of the last upgrade.    |
+-----------------------------------+---------------------------------------+
| MAC Address                       | Endpoint MAC address that corresponds |
|                                   | to the IP address. Currently, this    |
|                                   | information is available only for     |
|                                   | IPv4 addresses.                       |
+-----------------------------------+---------------------------------------+
| Mobile ID                         | Unique identifier of the agent        |
|                                   | located on an Android or iOS mobile.  |
+-----------------------------------+---------------------------------------+
| Network Interface                 | Relationship between the MAC address  |
|                                   | and the IP address for agents that    |
|                                   | can report the network interfaces     |
|                                   | information. Information is displayed |
|                                   | in JSON format, and searches can be   |
|                                   | performed on attributes in JSON.      |
+-----------------------------------+---------------------------------------+
| Network Location                  | (Agent 7.1 and later for Windows and  |
|                                   | agent 7.2 and later for macOS and     |
|                                   | Linux) Endpoint location is reported  |
|                                   | by the agent when you enable this     |
|                                   | capability in the Agent Settings      |
|                                   | profile.                              |
+-----------------------------------+---------------------------------------+
| Operating System                  | Name of the operating system.         |
+-----------------------------------+---------------------------------------+
| Operational Status                | Cortex XDR agent operational status:  |
|                                   |                                       |
|                                   | - **Protected:** The agent is running |
|                                   |   as configured and did not report    |
|                                   |   any exceptions.                     |
|                                   |                                       |
|                                   | - **Partially protected:** The agent  |
|                                   |   reported one or more exceptions.    |
|                                   |   Clicking on the row shows in the    |
|                                   |   detailed view why an endpoint may   |
|                                   |   be partially protected.             |
|                                   |                                       |
|                                   | - **Unprotected:** The Cortex XDR     |
|                                   |   agent was shut down.                |
+-----------------------------------+---------------------------------------+
| OS Description                    | Operating system version name.        |
+-----------------------------------+---------------------------------------+
| OS Type                           | Name of the operating system.         |
+-----------------------------------+---------------------------------------+
| OS Version                        | Operating system version number.      |
+-----------------------------------+---------------------------------------+
| Platform                          | Platform architecture.                |
+-----------------------------------+---------------------------------------+
| Proxy                             | IP address and port number of the     |
|                                   | configured proxy server.              |
+-----------------------------------+---------------------------------------+
| Scan Status                       | Malware scan status.                  |
+-----------------------------------+---------------------------------------+
| Managed Device                    | Whether an iOS device has a corporate |
|                                   | profile installed on it and is to     |
|                                   | some extent controlled and managed by |
|                                   | the corporation.                      |
+-----------------------------------+---------------------------------------+
| Tags                              | Tags associated with the endpoint.    |
|                                   |                                       |
|                                   | Tags created in the agent are         |
|                                   | displayed with a shield icon.         |
+-----------------------------------+---------------------------------------+
| User                              | User that was last logged into the    |
|                                   | endpoint. On Android endpoints, the   |
|                                   | Cortex XSIAM tenant identifies the    |
|                                   | user from the email prefix specified  |
|                                   | during app activation.                |
+-----------------------------------+---------------------------------------+

#### Retrieve files from an endpoint

During an investigation, you can retrieve files from one or more
endpoints by initiating a files retrieval request. For each file
retrieval request, Cortex XSIAM supports up to:

- 20 files

- 500MB in total size

- 10 different endpoints

The request instructs the agent to locate the files on the endpoint and
upload them to Cortex XSIAM. The agent collects all requested files into
one archive and includes a log in JSON format containing additional
status information. When the files are successfully uploaded, you can
download them from the **Action Center**.

**How to retrieve files from an endpoint**

1.  Go to Investigation & Response \> Response \> Action Center \> New
    Action.

2.  Select **Files Retrieval**.

3.  Select the operating system and enter the paths for the files you
    want to retrieve. Press **ADD** after each completed path.

- > **Note**

  > You cannot define a path using environment variables on Mac and
  > Linux endpoints.

4.  Click **Next**.

5.  Select the target endpoints (up to 10) from which you want to
    retrieve files and click **Next**.

6.  Review the action summary and click **Done**.

- To track the status of a file retrieval action, return to the
  **Action Center**. Cortex XSIAM retains retrieved files for up to 30
  days.

  If at any time you need to cancel the action, right-click, and select
  **Cancel for pending endpoint**. You can cancel the retrieval action
  only if the endpoint is still in **Pending** status and no files have
  been retrieved from it yet. The cancellation does not affect endpoints
  that are already in the process of retrieving files.

7.  To view additional data and download the retrieved files,
    right-click the action and select **Additional data**.

- This view displays all endpoints from which files are being retrieved,
  including their **IP Address**, **Status**, and **Additional Data**
  such as error messages of names of files that were not retrieved.

8.  When the action status is **Completed Successfully**, right-click
    the action and download the retrieved files logs.

- > **Note**

  > If the **Password Protection (for downloaded files)** setting under
  > Settings \> Configuration \> General \> Server Settings is enabled,
  > enter the password \'suspicious\' to download the file.

##### Disable file retrieval

If you want to prevent Cortex XSIAM from retrieving files from an
endpoint running the agent, you can disable this capability during agent
installation or later on from the **All Endpoints** page. Disabling
script execution is irreversible. If you later want to re-enable this
capability on the endpoint, you must re-install the agent. See the XDR
agent administrator's guide for more information.

> **Note**
>
> Disabling File Retrieval does not take effect on file retrieval
> actions that are in progress.

#### Retrieve support logs from an endpoint

When you need to investigate or share additional forensic data, you can
initiate a request to retrieve all the support logs and issue data dump
files from an endpoint. After Cortex XSIAM receives the logs, you can
download the log files or generate a secured link to access them on the
Cortex XSIAM server.

**How to retrieve support files**

1.  Retrieve support files.

    a.  Go to Investigation & Response \> Response \> Action Center \> +
        New Action.

    b.  Select **Retrieve Support File** and click **Next**.

    c.  Select the target endpoints (up to 10) from which you want to
        retrieve logs and click **Next**.

    d.  Review the action summary and click **Done**.

    - In the next heartbeat, the agent will retrieve the request to
      package and send all logs to Cortex XSIAM .

- You can also retrieve support files from the **All Endpoints** table
  by right-clicking and selecting Endpoint Control \> Retrieve Support
  File.

2.  In the **Action Center**, locate your **Support File Retrieval**
    action type and wait for the **Status** field to display
    **Completed Successfully**.

- If you need to cancel the action, you can right-click it and select
  **Cancel for pending endpoint**. You can cancel the retrieval action
  only if the endpoint is still in `Pending` status and no files have
  been retrieved from it yet. The cancellation does not affect endpoints
  that are already in the process of retrieving files.

3.  When the status is **Completed Successfully**, right-click and
    select **Additional data**.

- In the **Actions** table, you can see the endpoints from which support
  files were retrieved.

4.  Select an endpoint, right-click and select either **Download files**
    or **Generate support file link**.

- Cortex XSIAM retains retrieved files for up to 30 days.

  The secured link is valid for only 7 days. Following the 7 day period,
  in order to access the files, you will need to initiate a new support
  file link.

  To open the file you will need the support file password. For more
  information, see [Retrieve support file
  password](#UUID6571632510f68eead291067f4070ff85).

#### Retrieve support file password

From Cortex XDR agent, the Tech Support File (TSF) is generated in a zip
format protected by an encrypted password. The TSF file is archived
inside another file which also includes a metadata file that contains a
token. The token is used to retrieve the password to unzip the TSF file.

- To retrieve the password for the TSF file from the endpoint, go to the
  Cortex XSIAM server from the **Tokens and Passwords** option.

- To retrieve the password for the TSF file from the server, go to the
  **Action Center**.

1.  **Retrieve Support File Password** from Inventory \> Endpoints \>
    All Endpoints.

    a.  At the top of the page, click the key icon
        ![](media/rId1140.png){width="0.22693350831146106in"
        height="0.20833333333333334in"} (**Tokens and Passwords**) and
        select **Retrieve Support File Password**.

    b.  In the **Retrieve Support File Password** dialog box, in the
        **Encrypted Password** field, paste the token that you copied
        from the metadata file located in the saved file when running
        the Cytool log collect.

    c.  Click the copy button to copy the password displayed and then
        click **Ok**. Use the password to unzip the TSF file.

2.  **Retrieve Support File Password** from Action Center \> All
    Actions.

    a.  Right-click the relevant action of action type
        **Support File Retrieval** and select **Additional Data**.

    b.  Right-click the action and select
        **Retrieve Support File Password**.

    c.  In the **Retrieve Support File Password** dialog box, in the
        **Encrypted Password** field, paste the token that you copied
        from the metadata file located in the download file.

    d.  Click the copy button to copy the password displayed and then
        click **Ok**. Use the password to unzip the TSF file.

#### Scan an endpoint for malware

In addition to blocking the execution of malware, the Cortex XDR agent
can scan your Windows, Mac and Linux endpoints and attached removable
drives for dormant malware that is not actively attempting to run. The
agent examines the files on the endpoint according to the Malware
Security Profile that is in effect on the endpoint (quarantine settings,
unknown file upload, etc.) When a malicious file is detected during the
scan, the agent reports the malware to Cortex XSIAM so you can manually
take action to remove the malware before it is triggered and attempts to
harm the endpoint.

You can scan the endpoint in the following ways:

- **System scan:** Initiate a full system scan on demand from
  **Endpoints Administration** for an endpoint, as explained in the
  following procedure.

- **Periodic scan:** Configure periodic full scans that run on the
  endpoint as part of the malware security profile. To configure
  periodic scans, see [Set up malware prevention
  profiles](#UUID1f44d8175b934c96b2d133de77ca389f).

- **Custom scan:** (*Windows, requires agent v7.1 or later*) The end
  user can initiate a scan on demand to examine a specific file or
  folder. For more information, see the Cortex XDR Agent
  Administrator\'s Guide for Windows.

##### Initiate a full system scan

You can initiate full scans of one or more endpoints from the
**All Endpoints** table or the **Action Center**. After initiating a
scan, you can monitor the scan progress in the **Action Center**. Scan
time varies depending on the number of endpoints, connectivity to those
endpoints, and the number of files for which Cortex XSIAM needs to
obtain verdicts.

1.  Select Investigation & Response \> Response \> Action Center \> New
    Action.

2.  Select **Malware Scan**.

3.  Click **Next**.

4.  Select the target endpoints (up to 100) on which you want to scan
    for malware.

- Scanning is available on Windows, Mac and Linux endpoints. Cortex
  XSIAM automatically filters out any endpoints for which scanning is
  not supported. Scanning is also not available for inactive endpoints.

5.  Click **Next**.

6.  Review the action summary and click **Done**. Cortex XSIAM initiates
    the action at the next heartbeat and sends the request to the agent
    to initiate a malware scan.

7.  To track the status of a scan, return to the **Action Center**.

- When the status is **Completed Successfully**, you can view the scan
  results.

8.  View the scan results.

- After an agent completes a scan, it reports the results to Cortex
  XSIAM. To view the scan results for an endpoint:

  a.  In the **Action Center**, right-click the scan action and select
      **Additional data**.

  - Cortex XSIAM displays additional details about the endpoint.

  b.  Right-click the endpoint for which you want to view the scan
      results and select **View related security events**.

  - Cortex XSIAM displays a filtered list of malware issues for files
    that were detected on the endpoint during the scan.

### Investigate files

You can take actions to manage and investigate files, including:

- Manage file execution on your endpoints by adding file hashes to your
  allow and block lists.

- Quarantine files and manage the files automatically quarantined by
  Cortex XSIAM.

- Review the file verdict and the WildFire Analysis Report for a file.

- Import hashes from the Endpoint Security Manager or from external
  feeds.

#### Manage file execution

You can manage file execution on your endpoints by adding file hashes to
your allow and block lists. If you trust a certain file and know it to
be benign, you can add the file hash to the allow list. This allows the
file to be executed on all your endpoints regardless of the WildFire or
local analysis verdict. Similarly, if you want to always block a file
from running on your endpoints, you can add the associated hash to the
block list.

Adding files to the allow and block lists takes precedence over any
other policy rules that are applied to these files. In the
**Action Center**, you can monitor the allow and block list actions
performed in your network, and add or remove files from these lists.

Supported file types are:

+-----------------------------------+-----------------------------------+
| Operating system                  | Supported file types              |
+===================================+===================================+
| Windows                           | - PE, PE64                        |
|                                   |                                   |
|                                   | - doc, docx, xls, xlsx (only if   |
|                                   |   they contain macro files)       |
|                                   |                                   |
|                                   | - PS1                             |
+-----------------------------------+-----------------------------------+
| Mac                               | macho, DMG                        |
+-----------------------------------+-----------------------------------+
| Linux                             | ELF                               |
+-----------------------------------+-----------------------------------+

**How to add a file to the allow or block list or allow list**

1.  Go to Investigation & Response \> Response \> Action Center \> New
    Action.

2.  Select **Add to Block List** or **Add to Allow List**.

3.  Enter the SHA-256 hash of the file and click
    ![](media/rId2150.png){width="0.15625in"
    height="0.20833333333333334in"}.

- You can add up to 100 file hashes at one time. If you add a comment,
  it is added to all the hashes you added in this action.

4.  Click **Next**.

5.  Review the summary and click **Done**.

- In the next heartbeat, the agent retrieves the updated lists from
  Cortex XSIAM.

6.  You are automatically redirected to the **Block List** or
    **Allow List** that corresponds to the action in the
    **Action Center**.

7.  To manage the file hashes on the **Block List** or the
    **Allow List**, right-click a file to see the available actions.

#### Manage quarantined files

When the agent detects malware on a Windows endpoint, you can take
additional precautions to quarantine the file. When the agent
quarantines malware, it moves the file from the location on a local or
removable drive to a local quarantine folder
(`%PROGRAMDATA%\Cyvera\Quarantine`) where it isolates the file. This
prevents the file from attempting to run again from the same path or
causing any harm to your endpoints.

To evaluate whether an executable file is considered malicious, the
agent calculates a verdict using information from the following sources
in order of priority:

- Hash exception policy

- WildFire threat intelligence

- Local analysis

##### How to quarantine a file

You can quarantine a file in the following ways:

- Enable the agent to automatically quarantine malicious executables by
  configuring quarantine settings in a Malware prevention profile. For
  more information, see
  [/document/preview/880913#UUID-4ed8f88f-bba4-5afa-f8cf-dfbc14756787](/document/preview/880913#UUID-4ed8f88f-bba4-5afa-f8cf-dfbc14756787).

- Right-click a specific file from the causality view and select
  **Quarantine**. For more information, see
  <urn:resource:component:1159449>.

##### View and manage quarantined files

1.  To view the quarantined files in your network, go to Investigation &
    Response \> Response \> Action Center \> File Quarantine.

- Toggle between the **Detailed** and **Aggregated By SHA256** tabs to
  see information on your quarantined files.

2.  Review details about quarantined files.

- In the **Detailed** view, filter and review the **Endpoint Name**,
  **Domain**, **File Path**, **Quarantine Source**, and
  **Quarantine Date** of all the quarantined files. You can take the
  following actions:

  - **Reinstate a quarantined file:** Right-click one or more rows and
    select **Restore all files by SHA256**.

  <!-- -->

  - > **Note**

    > This will restore all files with the same hash on all of your
    > endpoints.

  <!-- -->

  - **Review the quarantined file inspection results on VirusTotal:**
    Right-click the **Hash** field and select **Open in VirusTotal**.

  - **Drill down on the hash value:** Right-click the **Hash** field and
    select **Open Hash View**. You can see each of the process
    executions, file operations, cases, actions, and threat intelligence
    reports relating to the hash value.

  - **Search for where the hash value appears in Cortex XSIAM:**
    Right-click the **Hash** field and select
    **Open in Quick Launcher**.

  - **Export to file:** Click the icon on the top right corner to
    download a detailed list of the quarantined hashes in a TSV format.

3.  In the **Aggregated by SHA256** view, filter and review the
    **Hash**, **File Name**, **File Path**, and **Scope** of all the
    quarantined files. You can take the following actions:

    - **Open the Quarantine Details page:** Right-click a row and select
      **Additional Data** to open the page detailing the
      **Endpoint Name**, **Domain**, **File Path**,
      **Quarantine Source**, and **Quarantine Date** of a specific file
      hash.

    - **Reinstate a file hash:** Right-click and select **Restore**.

    - **Permanently delete quarantined files on the endpoint:**
      Right-click and select **Delete all files by SHA256**.

#### Review WildFire analysis details

For each file, Cortex XSIAM receives a file verdict and the [WildFire
Analysis
Report](https://docs.paloaltonetworks.com/wildfire/9-1/wildfire-admin/monitor-wildfire-activity/wildfire-analysis-reportsclose-up).
This report contains detailed sample information and behavior analysis
in different sandbox environments, leading to the WildFire verdict. You
can use the report to assess whether the file poses a real threat on an
endpoint. The details in the WildFire analysis report for each event
vary depending on the file type and the behavior of the file.

Drill down into WildFire analysis details

WildFire analysis details are available for files that receive a
WildFire verdict. The Analysis Reports section includes the WildFire
analysis for each testing environment based on the observed behavior for
the file.

1.  Open the WildFire report.

- If you are investigating a case in the case detail view you can see
  artifact details on the **Key Assets & Artifacts** tab. Under
  **Artifacts**, identify a file with a WildFire verdict and click
  **Wildfire Analysis Report**
  (![](media/rId2160.png){width="0.13541666666666666in"
  height="0.20833333333333334in"}). If you are analyzing an issue, hover
  over the issue and **Investigate**. You can open
  (![](media/rId2160.png){width="0.13541666666666666in"
  height="0.20833333333333334in"}) the WildFire report of any file
  included in the issue\'s Causality Chain.

  > **Note**

  > Cortex XSIAM displays the preview of WildFire reports that were
  > generated within the last couple of years. To view a report that was
  > generated more than two years ago, you can download the report.

2.  Analyze the WildFire report.

- On the left side of the report, you can see all the environments in
  which the Wildfire service tested the sample. If a file is low risk
  and WildFire can easily determine that it is safe, only static
  analysis is performed on the file. Select the testing environment to
  review the summary and additional details. To learn more about the
  behavior summary, see [WildFire Analysis Reports---Close
  Up](https://docs.paloaltonetworks.com/wildfire/9-1/wildfire-admin/monitor-wildfire-activity/wildfire-analysis-reportsclose-up).

3.  (Optional) Download the WildFire report.

- If you want to download the WildFire report as it was generated by the
  WildFire service, click (![](media/rId2165.png){width="0.15625in"
  height="0.20833333333333334in"}). The report is downloaded in PDF
  format.

Report an incorrect verdict to Palo Alto Networks

If you know the WildFire verdict is incorrect, for example, WildFire
assigned a Malware verdict to a file you wrote and know to be Benign,
you can report an incorrect verdict to Cortex XSIAM to request the
verdict change.

1.  Open the WildFire report and verify the verdict that you are
    reporting.

2.  Click **Report Verdict as Incorrect**
    (![](media/rId2169.png){width="0.13541666666666666in"
    height="0.20833333333333334in"}).

3.  Under **Suggested Verdict**, suggest a new verdict.

4.  Under **Comment**, enter any details that can help us to better
    understand why you disagree with the verdict.

5.  Under **Email**, verify your email address.

6.  Click **OK**.

- The threat team will perform further analysis of the sample to
  determine whether it should be reclassified. If a malware sample is
  determined to be safe, the signature for the file is disabled in an
  upcoming antivirus signature update. If a benign file is determined to
  be malicious, a new signature is generated. After the investigation is
  complete, you will receive an email describing the action that was
  taken.

#### Import file hash exceptions

The **Action Center** displays information on files that are
quarantined, or included in the allow list and block list. To import
hashes from the Endpoint Security Manager or from external feeds, take
the following steps:

1.  Go to Investigation & Response \> Response \> Action Center \> New
    Action.

2.  Select **Import Hash Exceptions**.

3.  Drag your file to the drop area.

- Files must be in csv format, for example
  `Verdict_Override_Exports.csv`. If necessary, resolve any conflicts
  encountered during the upload and retry.

4.  Click **Next**.

5.  Review the action summary, and click **Done**.

- Cortex XSIAM imports your hashes. Depending on the assigned verdict,
  Cortex XSIAM then distributes them to the allow list or block list.

### Automations

Automations leverage playbooks to execute predefined workflows, use
context data to make informed decisions, and interact with lists to
store and retrieve information as needed during the automation process.

#### Automation in Cortex XSIAM

Automation enables you to improve efficiency and response times by
performing actions on one or more issues, either automatically in
response to predetermined conditions or manually triggered during your
investigation workflow. In Cortex XSIAM, you can use playbooks, scripts,
and commands, and Quick Actions to streamline operations, accelerate
triage, and boost productivity.

- **Playbooks**

<!-- -->

- Playbooks enable you to organize and document security monitoring,
  orchestration, and response activities. Playbooks are self-contained,
  fully documented prescriptive procedures that query, analyze, and take
  action based on the gathered results.

  Playbooks are built from regular tasks, quick actions, and
  sub-playbooks. Playbook tasks can run out-of-the-box or custom scripts
  and integrations to communicate with third-party systems. You can use
  out-of-the-box playbooks as is, or customize them according to your
  requirements. You can also reuse individual playbook tasks as building
  blocks for new playbooks, saving time and streamlining knowledge
  retention.

  Playbooks can run automatically on issues based on automation rules,
  run automatically by jobs on a schedule or based on a delta, or can be
  run manually on one or more issues.

  > **Note**

  > You can build end-to-end automation workflows from within the
  > playbook editor, including creating automation rules, configuring
  > integration instances, and creating and editing tasks. For more
  > information, see [Playbooks](#UUID4d25f6a6678aed2733c9a5068333ba4c).

<!-- -->

- **Scripts and commands**

<!-- -->

- Cortex XSIAM includes built-in commands, as well as commands and
  scripts from the core content packs. In addition, when you adopt
  playbooks, any necessary scripts and integrations for the playbook are
  automatically downloaded. You can also write your own scripts or edit
  existing scripts.

  Scripts and commands can be used in playbook tasks or run manually
  from the **War Room**.

<!-- -->

- **Quick Actions**

<!-- -->

- Quick actions are single commands that enable you to respond rapidly
  without requiring complex playbooks.

  Quick Actions can be included within playbooks, run automatically on
  issues based on automation rules, or run manually on one or more
  issues.

**Automation rules**

Automation rules enable you to run playbooks or Quick Actions
automatically on issues, based on preset criteria. Automation rules
follow a WHEN / IF / THEN structure. For example, WHEN an issue is
created, IF the severity is critical, THEN set the case assignee to a
specific analyst. For more information, see [Create an automation
rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c).

**Manually trigger automation**

Playbooks and Quick Actions can also be run on demand. For more
information, see
[/document/preview/1305402#UUID-8a475e1f-9ee1-1e9d-f3ec-ece941208179](/document/preview/1305402#UUID-8a475e1f-9ee1-1e9d-f3ec-ece941208179).

#### Quick Actions

Quick Actions are preset single commands that enable you to automate
basic tasks such as creating tickets in third-party systems, sending
Slack messages, and changing issue severity.

You can create quick actions using the following:

- **Automation rules**: You can create predefined rules to run Quick
  Actions as issues are created. For more information, see [Create an
  automation rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c)

- **Playbooks**: You can use Quick Actions as tasks within playbooks.

> **Note**
>
> When investigating an issue, in the Issues table, you can right-click
> to **Run an Automation** on one or more issues. For more information,
> see
> [/document/preview/1305402#UUID-8a475e1f-9ee1-1e9d-f3ec-ece941208179_sidebar-idm234878761672908](/document/preview/1305402#UUID-8a475e1f-9ee1-1e9d-f3ec-ece941208179_sidebar-idm234878761672908).

#### Manage automation exclusion policies

Automation exclusion policies enable you to protect critical assets from
automated remediation, without having to detach and customize playbooks,
scripts, and integrations.

Automation exclusion policies prevent commands and scripts from
performing automated remediation actions on critical assets, such as
users, IP addresses, and domains. For example, a playbook task might
block multiple domains, but mission-critical domains in the policy list
would not be blocked.

Automation exclusion policies apply any time a relevant command or
script runs, whether in a playbook task, a Quick Action, or the CLI.

When an automation exclusion policy prevents a command or script from a
remediation action, the exclusion appears in the issue War Room.

When a playbook task contains a command or script that is included in an
automation exclusion policy, a **Policy** tab appears in the task
details pane, showing the relevant policy.

To enable an automation exclusion policy, admins add critical assets to
a list. Each policy uses one or more lists to exclude assets from
remediation. By default, all policies are enabled, but lists are empty
until assets are added to the list.

Policies can be enabled or disabled and lists can be edited, but you
cannot add or remove policies.

Each policy can include one or more scripts or commands. Commands and
scripts only appear if the content is installed. The policy affects only
these scripts and commands. Scripts and commands cannot be added, edited
or removed from the policy.

Policies can be sorted, filtered, and searched, using the category,
status, policy, exclude, and description columns.

To manage automation exclusion policies:

1.  Go to Settings \> Configurations \> Automation \> Automation
    Exclusion Center.

2.  Right-click on a policy and choose **Edit**.

3.  From the **Edit Policy** page, you can do the following:

    - Enable or disable the policy. Policies are enabled by default.

    - Select one or more lists of excluded assets.

    <!-- -->

    - Clicking the list icon opens a new browser tab for the **Lists**
      page, where you can create and edit lists.

      > **Note**

      > For the IAM User Hard Remediation and User Soft Remediation
      > policies, we recommend including username, email, and ID for
      > each user you want to exclude. Example:
      > `username1, user@example.com, userID112`.

    <!-- -->

    - Under
      **THEN skip execution of the following commands and scripts**,
      click to view the scripts and commands affected by the policy.
      Commands only appear if they are part of an active integration
      instance. You cannot edit the list of scripts and commands.

4.  **Save** your changes.

> **Note**
>
> You can also right click on a policy from the main
> **Automation Exclusion Center** page to disable or enable the policy.
>
> If you click on a list name in the **Exclude** column, that list opens
> in the **Lists** page.

#### Playbooks

Playbooks automate and standardize workflows, ensuring consistent and
efficient incident response and management.

##### Playbooks overview

Playbooks are a series of tasks that run in a predefined flow to save
time and improve the efficiency and results of the investigation and
response process. They enable you to automate many security processes,
including handling investigations and managing tickets. For example, a
playbook task can parse the information in an issue, whether it is an
email or a PDF attachment.

###### One-stop playbook development

Before you start building your playbook,  go to the **Playbooks** page
and review the Org playbook list, which are playbooks that are currently
used in your organization. On the **Playbook Catalog** page, you can
find available out-of the-box playbooks that are not in use in your
organization which you can adopt and use. If an existing playbook does
not meet your use case, you can develop a playbook from scratch. Whether
editing an existing playbook or creating a new one, you can manage the
entire automation development flow in the playbook editor, including
creating and editing tasks, configuring automation rules to trigger your
playbooks, and setting up all relevant integrations.

###### Task Library

The **Task Library** in the playbook editor contains the following
objects you can add to your playbook. For example, you can create new
tasks from scripts, repurpose existing tasks, and use existing playbooks
as sub-playbooks.

  --------------------------------------------------------------------------------------------------
  Task Library Object      Action                  See More
  ------------------------ ----------------------- -------------------------------------------------
  **Quick Actions**        Add single commands     See
                           requiring minimal       [topic](#UUID1552fcd072b83f7db2aa17bb135fe54f).
                           configuration.          

  **Commands & Scripts**   Add commands and        See
                           scripts from            [topic](#UUID1552fcd072b83f7db2aa17bb135fe54f).
                           integrations that you   
                           install and configure   
                           instances for as        
                           needed.                 

  **Playbooks**            Add sub-playbooks to    See
                           your playbook from your [topic](#UUID2ede8a7dcde5fbc41bb8821974a834e4).
                           Org repository or from  
                           the Playbooks Catalog.  

  **Manual Tasks**         Add tasks from          See
                           playbooks in your Org   [topic](#UUID54881a1bcad662b0ffe2c23791461eaf).
                           repository.             

  **Header**               Add section headers to  See
                           organize your playbook. [topic](#UUID6d7d7f4c462bece88bd7739867c401f9).

  **Blank Task**           Create a new task from  See
                           scratch.                [topic](#UUID54881a1bcad662b0ffe2c23791461eaf).
  --------------------------------------------------------------------------------------------------

###### Post-development playbook testing

After developing the playbook (including setting automation rules to
trigger the playbook), run the debugger to initially test the playbook.

Once you confirm the playbook runs without errors, start ingesting
issues to check that the playbook runs properly with data. The
automation rule you defined for the playbook will trigger it to run when
a relevant issue is ingested into Cortex XSIAM.

After verifying the playbook is triggered and runs properly with issues,
it is ready to use in production.

You can see which playbook ran for an issue by going to
**Cases & Issues**, selecting **Issues** and scrolling to the
**Playbook** column. You can view or update the playbook by selecting an
issue and clicking the **Work Plan** tab. Select another playbook to run
from the dropdown list.

You can see which playbook ran in a case, if any, by going to
**Cases & Issues**, selecting **Cases** and looking at the
**Automation** section in the **Overview** tab for the case. You can
view or update the playbook by going to the **Issues & Insights** tab,
selecting an issue, and then clicking the **Work Plan** tab. In the
**Work Plan**, you can select another playbook to run from the dropdown
list.

For more information, see [Investigate
cases](#UUID635a92a349ac52b8a5f774e748bccb51).

##### Playbook development checklist

The playbook development checklist follows the logical flow for
developing a playbook.

![](media/rId2185.png){width="5.833333333333333in"
height="1.1010411198600174in"}

We recommend that you review the following steps to successfully
implement your playbook.

+-----------------------+-----------------------+-----------------------------------------------+
| Step                  | Details               | See More                                      |
+=======================+=======================+===============================================+
| Step 1. Plan your     | During the initial    | [See                                          |
| playbook              | planning stage when   | topic](#UUID5479cc3060653184d3d7d816c26278dc) |
|                       | designing your use    |                                               |
|                       | case, start defining  |                                               |
|                       | the playbook flow.    |                                               |
|                       |                       |                                               |
|                       | Consider the process  |                                               |
|                       | you want to automate  |                                               |
|                       | and the steps and the |                                               |
|                       | decisions during the  |                                               |
|                       | process. These steps  |                                               |
|                       | and decisions become  |                                               |
|                       | the playbook tasks.   |                                               |
+-----------------------+-----------------------+-----------------------------------------------+
| Step 2. Build your    | Consider whether to   | [See                                          |
| playbook              | use a playbook        | topic](#UUID5080fa9ad980f921fa888cc5f738d9ab) |
|                       | out-of-the-box,       |                                               |
|                       | customize an existing |                                               |
|                       | playbook, or create a |                                               |
|                       | new playbook from     |                                               |
|                       | scratch. Create       |                                               |
|                       | playbook tasks,       |                                               |
|                       | inputs, and outputs.  |                                               |
|                       | Maintain playbook     |                                               |
|                       | versioning to keep    |                                               |
|                       | track of playbook     |                                               |
|                       | development history.  |                                               |
+-----------------------+-----------------------+-----------------------------------------------+
| Step 3. Customize     | Fine tune your        | [See                                          |
| your playbook         | playbook for your     | topic](#UUIDeacab49cfbeff21b5b7b6093d98676b4) |
|                       | needs, including      |                                               |
|                       | extracting            |                                               |
|                       | indicators, extending |                                               |
|                       | context, and adding   |                                               |
|                       | issue fields to the   |                                               |
|                       | system.               |                                               |
+-----------------------+-----------------------+-----------------------------------------------+
| Step 4. Test your     | Debug errors in your  | [See                                          |
| playbook              | playbook. Use         | topic](#UUIDe8d7bd184fa0c0d595e939f9be0681b9) |
|                       | playbook metadata to  |                                               |
|                       | troubleshoot playbook |                                               |
|                       | performance.          |                                               |
+-----------------------+-----------------------+-----------------------------------------------+

##### Plan your playbook

When defining the workflow of your playbook, consider the following:

- What processes do you need to automate?

- Are there any decisions that require manual intervention?

- Are there any time-sensitive aspects to the playbook?

- When is the case considered remediated?

Review the Phishing use case

Review the following workflow for a phishing use case. Also, review the
playbooks in the [Phishing content
pack](https://cortex.marketplace.pan.dev/marketplace/details/Phishing/)
to see how they work.

- Detection

- Identification

- Analysis

- Remediation

Each of these high-level processes can contain a number of sub-processes
that require step-by-step actions, all of which can be automated with
either customized or new playbooks.

##### Manage playbooks

The **Playbooks** page is organized to help easily access and utilize
playbooks specific to your use cases. It contains two main sections, key
playbook details on the top and a table listing all the playbooks in
your Org repository on the bottom.

###### Playbook status

Playbook statuses enable tracking the progress of automation tasks and
identifying any issues or delays. If needed, you can then take
corrective actions to ensure smooth workflow execution and operational
efficiency. The status includes how many playbooks:

- Are in your Org repository

- Are enabled

- Are active

- Are using an automation rule

- Are used as sub-playbooks

- Ran in the past week

###### The Org repository table

The playbooks listed in the Org repository table have been either
adopted by or built by your organization. The table shows high level
details about the playbooks, including:

- Playbook name

- Description

- Status

- Source

- Trigger status

- How many playbooks it serves as a sub-playbook in

- Last updated

- Updated by

When you right-click a specific playbook, you can choose to open it in
the editor, duplicate, disable, download, or remove it.

Playbooks in your **Org Playbooks** can be triggered to run by
automation rules, jobs, or can be manually run on one or more issues.

Playbooks that you adopted are part of content packs. When a playbook is
adopted, the content pack for that playbook is downloaded and appears in
Marketplace. If you remove a playbook from your Org Playbooks, the
content pack remains installed, but the playbook is no longer available
for automation rules or manual runs.

###### Playbook Catalog

The **Playbook Catalog** contains all the playbooks available in
Marketplace, organized by cards. You can search for a playbook, and the
system also recommends playbooks based on name, tag, or description.

Clicking a card provides a preview of the playbook. If it is relevant
for your use case, click **Adopt this playbook** to bring it into your
Org repository and make it available to run.

> **Note**

- > The library by default shows only playbooks that are not adopted.
  > Click the **Show Adopted** checkbox to show the adopted playbooks,
  > indicated by an **Adopted** mark.

- > The library shows the most updated playbook version. Adopting an
  > older version than shown should be done through Marketplace.

- > Adopting a playbook does not make it run. Some content packs include
  > recommended automation rules. When you configure automation rules,
  > you can view the recommendations. See [Create an automation
  > rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c).

##### Build your playbook

Depending on your use case, you can use or customize a system playbook
or develop a new playbook from scratch.

Developing a new playbook from scratch enables a tailored solution for
your use case, whereas customizing a system playbook can save time,
reduce complexity, and can be a more efficient way to meet your
organization\'s specific security and issue response needs.

Follow these steps to build a playbook.

  -------------------------------------------------------------------------------------------------
  Task                    Description             See More
  ----------------------- ----------------------- -------------------------------------------------
  Task 1. Choose from     Search for an           See
  existing playbooks or   out-of-the-box playbook [topic](#UUID8c1d339b07d10b7aedd744225ce65502).
  create your own         to use, customize it,   
                          or create one based on  
                          your use case.          

  Task 2. Configure       Define playbook         See
  playbook settings       settings, such as       [topic](#UUID9bca1fca99bf083446a9dfe10576bb10).
                          playbook triggers,      
                          inputs and outputs, and 
                          general settings.       

  Task 3. Add objects     The **Task Library**    See
  from the Task Library   contains Quick Actions, [topic](#UUID89943da687ebe253a1ac3ae428e73bd4).
                          scripts, sub-playbooks, 
                          and tasks that enable   
                          you to communicate with 
                          end users, set          
                          conditions, and store   
                          relevant data.          

  Task 4. Add custom      Customize your          See
  playbook features       playbook, including     [topic](#UUIDabe902a78df6bebf68b892a1ed59888e).
                          adding scripts and      
                          sub-playbook loops,     
                          filtering and           
                          transforming data,      
                          extracting indicators,  
                          extending context,      
                          creating issue fields,  
                          and polling.            

  Task 5. Test and debug  Set breakpoints,        See
  the playbook            conditional             [topic](#UUIDab5ac8d137af7bcd87f91f2f98e538ee).
                          breakpoints, skip       
                          tasks, and input and    
                          output overrides in the 
                          playbook debugger.      

  Task 6. Manage playbook Save versions of your   See
  content                 playbook in Cortex      [topic](#UUID3555a20938818a423fe339212d251d63).
                          XSIAM, or manage your   
                          playbook content        
                          development and testing 
                          using a remote          
                          repository.             
  -------------------------------------------------------------------------------------------------

###### Task 1. Choose from existing playbooks or create your own

Go to the Investigation & Response \> Automation \> Playbooks page to
customize or create a playbook.

Find an existing playbook

Playbooks in your Org Repository have already been adopted by your
organization and are available to run. The Playbook Catalog contains all
available playbooks in Marketplace that you can adopt into your Org
Repository. You can preview before adopting.

1.  View the list of playbooks in the Org Repository table. You can also
    search for a playbook that exists in your Org repository by clicking
    **Add Filter**.

- Use free text in the search box, entering part or all of the
  playbooks\' names or description. You can also search for an exact
  match of the playbook name by putting quotation marks around the
  search text. For example, searching for `"Block Account - Generic"`
  returns the playbook with that name.

  Search for more than one exact match by including the logical operator
  \"or\" in-between your search texts in quotation marks. For example,
  searching for `"Block Account - Generic" or "NGFW Scan"` returns the
  two playbooks with those names. Wildcards are not supported in free
  text search.

  > **Tip**

  > If there are additional relevant playbooks in Marketplace that are
  > not in your Org repository, you can click **Explore them now** to
  > see them in the **Playbook Catalog** and choose to adopt.

2.  Click **Playbook Catalog** to browse all available playbooks in
    Marketplace that you can adopt. Click **Playbook Library** to go
    back to the main **Playbooks** page.

    a.  Click a playbook card for a preview of the playbook.

    b.  Click **Adopt this playbook** to add the playbook to your Org
        repository.

    - A confirmation message displays when the playbook is successfully
      added.

    c.  Click **View in Org Playbooks** to select the adopted playbook
        from the Org repository table.

You can use the playbook as-is, or customize it as needed.

Edit a playbook

From the list of playbooks in your Org repository, right-click the
playbook you want to edit and select **Open in Editor**. You can also
duplicate, disable, download, or delete the playbook.

When you adopt a playbook, it is locked and you can only make limited
changes to the playbook settings from the **Playbook Starts** task.

For full editing capabilities, click
![](media/rId2196.png){width="0.18055555555555555in"
height="0.20833333333333334in"} and select either **Duplicate Playbook**
(create a copy of the playbook to edit) or **Edit Playbook** (detach the
playbook). A detached playbook does not receive updates in future
content releases. If you reattach the playbook, the latest content
updates will be applied and any edits you made will be overridden.

You can then configure the playbook settings or add quick actions,
scripts, sub-playbooks, or tasks from the **Task Library**.

> **Tip**

- > To open multiple playbooks at the same time, edit the first playbook
  > and then click **New** next to the playbook name to create a new
  > tab. You can either create a new playbook, or add an existing one.

- > You can view recently modified or deleted playbooks by clicking
  > version history for all playbooks
  > ![](media/rId2199.png){width="0.2202373140857393in"
  > height="0.20833333333333334in"}.

Create a playbook

1.  In the **Playbooks** page, click **Build New Playbook**.

2.  In the **Create new** pop up, enter a name, description, and tags
    for the playbook and click **Save**.

- A blank playbook opens in the playbook editor. You can then configure
  the playbook settings or add quick actions, scripts, sub-playbooks, or
  tasks from the **Task Library**.

####### Collapse and expand playbook sections

You can easily navigate playbooks and focus on the parts you need to
work on by collapsing and expanding playbook sections. Collapsing
sections provides a condensed view of the playbook flow, reducing visual
clutter and enabling quick access to specific sections. Expanding
sections allows you to view or edit specific parts of a playbook while
keeping the rest of the playbook compact and maintaining focus on the
relevant playbook details. You can also hover over a section header to
highlight all tasks under the section and easily identify the section
scope.

To collapse and expand a section, in the **Playbooks** page, after
selecting a playbook from the library or creating a new playbook and
adding tasks, click ![](media/rId2204.png){width="0.15782808398950132in"
height="0.20833333333333334in"} on a section header.

When you collapse a section, you can see the number of tasks included
under the section. For example:

![](media/rId2207.png){width="4.152777777777778in" height="1.75in"}

Click ![](media/rId2210.png){width="0.3442027559055118in"
height="0.20833333333333334in"} to collapse or expand the entire
playbook.

![](media/rId1157.png){width="0.19166666666666668in"
height="0.20833333333333334in"} Show me more

![](media/rId2215.gif){width="5.833333333333333in"
height="3.1791666666666667in"}

###### Task 2. Configure playbook settings

After selecting the playbook you want to edit or after creating a new
playbook, configure playbook settings as relevant, including:

- Triggers: Define the condition applied to a specific issue that will
  trigger the playbook to run. Leave these settings empty to use the
  playbook as a sub-playbook or to only run the playbook manually.

<!-- -->

- For more information, see [Create an automation
  rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c).

<!-- -->

- Inputs and outputs: Define and fill in input and output parameters
  required for the playbook to function correctly, grouping them as
  needed.

<!-- -->

- Playbook input and output grouping
  Playbook input and output fields are collected into groups. This
  organizes the inputs and outputs, providing clarity and context to
  understand which inputs are relevant to which playbook flow.

  **Playbook group permissions**

  Users with permission to edit playbooks can add, edit, and delete
  groups and input and output fields. Users without this permission can
  only view groups, inputs, and outputs.

  **Work with playbook input and output groups**

  You can do the following with groups:

  - Add or delete a group. Deleting a group deletes all the fields
    defined in the group.

  - Change the name and/or description of the group.

  - Change the order groups appear by dragging.

  - Collapse and expand a group.

  **Manage input or output fields within a group**

  You can do the following with input or output fields within a group:

  - Add, edit, or delete fields within a group. Input or output fields
    are always part of a group.

  - Move fields between groups by dragging.

  - Change field order within a group by dragging.

<!-- -->

- General settings: Define roles for edit access and whether to run the
  playbook in Quiet Mode. In Quiet Mode, playbook tasks do not save
  inputs and outputs or extract indicators. Tasks are not indexed, so
  you cannot search on the results of the specific tasks. All the
  information is still available in the context data, and errors and
  warnings are written to the War Room.

**How to configure playbook settings**

1.  In the playbook editor, click the settings wheel on the
    **Playbook Starts** task.

- The **Playbook Settings** pane opens, showing the playbook name,
  description and tags at the top. You can edit these fields by clicking
  the pencil icon.

  The pane opens with the **Triggers** tab on the bottom.

  > **Note**

  > If the playbook has inputs and outputs, the **Playbook Starts** task
  > will show back and forth arrows. Clicking them opens the
  > **Playbook Settings** pane **Inputs/Outputs** tab.

  The playbook is by default **Enabled**. If the playbook is disabled,
  it will not run on an issue.

2.  In the **Triggers** tab, under **Automation Rules**, define the rule
    that will trigger the playbook.

    a.  Click **Add a rule**.

    b.  Set the name and description for the rule.

    - The **Status** is by default enabled.

    c.  Define the condition and select the issue to apply the condition
        to that will trigger the playbook.

    - To add rule conditions, in the **Issues** table use the filter to
      select a field and its value or right-click on a table cell to
      select that field and value.

      For example, to define a trigger condition for Malware issues with
      severity Critical, find a Malware issue with Critical severity in
      the **Issues** table, right click the cell in the **Name** column
      and select **Show rows with \'Malware\'**, and right click the
      cell in the **Severity** column and select
      **Show rows with \'Critical\'**. This sets the filter for this
      condition.

    d.  Click **Create**.

- > **Note**

  > This rule will trigger the playbook to run if no other Automation
  > Rule triggers the playbook first. You can view and edit the order
  > the rules run in the **Automation Rules** page.

  **Playbooks** lists any playbooks that use this playbook as a
  sub-playbook.

3.  In the **Inputs/Outputs** tab, add groups with input and output
    fields.

- Add a group
  1.  Click **+ Add Input Group** or **+ Add Output Group**.

  2.  Enter a group name and description and click the check mark.

  3.  Add fields to the group.

  - > **Note**

    > If you do not add any fields, the group will be deleted when you
    > click **Save**.

  Add an input field in a group
  1.  Within a group, click **+ Add Input** at the bottom of the list of
      input fields. You may need to scroll down to see it.

  2.  Enter the input field **Name** (required), **Value**, and
      **Description**.

  3.  When you are done adding fields, click **Save**.

  Add an output field in a group
  1.  Within a group, click **+ Add Output** or **+ Add Manually** at
      the bottom of the list of output fields. You may need to scroll
      down to see these options.

      - If you click **+ Add Output**, select from the outputs from
        previous tasks.

      - If you click **+ Add Manually**, enter the context path and
        description for the output.

  2.  When you are done adding fields, click **Save**.

4.  In the **General** tab, configure the following:

    - Add roles for edit access to the playbook.

    - Optionally select **Quiet Mode** for playbooks with a heavy data
      load that might adversely affect performance, for example a
      playbook that processes indicators from threat intel feeds.

    <!-- -->

    - In Quiet Mode, playbook tasks do not save inputs and outputs or
      extract indicators. Tasks are not indexed, so you cannot search on
      the results of the specific tasks. All the information is still
      available in the context data, and errors and warnings are written
      to the War Room.

      In the War Room (under the **Case War Room** tab for cases, and
      the **War Room** tab for issues) you can run the
      `!getInvPlaybookMetadata` command to analyze the size of playbook
      tasks in a specific issue Work Plan to determine whether to
      implement Quiet Mode for playbooks or tasks.

###### Task 3. Add objects from the Task Library

The **Task Library** contains the following objects you can add to your
playbook. For example, you can create new tasks from scripts, repurpose
existing tasks, and use existing playbooks as sub-playbooks.

+------------------------+-----------------+-----------------+-------------------------------------------------+
| Task Library Object    | Action          | Possible Task   | See More                                        |
|                        |                 | Types           |                                                 |
+========================+=================+=================+=================================================+
| **Quick Actions**      | Add a Quick     | - Standard task | See                                             |
|                        | Action to run a |                 | [topic](#UUID1552fcd072b83f7db2aa17bb135fe54f). |
|                        | single command  | - Conditional   |                                                 |
|                        | with minimal    |   task          |                                                 |
|                        | configuration   |                 |                                                 |
|                        | required. Only  |                 |                                                 |
|                        | predefined      |                 |                                                 |
|                        | Quick Actions   |                 |                                                 |
|                        | are available.  |                 |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+
| **Commands & Scripts** | Add commands    | - Standard task | See                                             |
|                        | and scripts     |                 | [topic](#UUID1552fcd072b83f7db2aa17bb135fe54f). |
|                        | from            | - Conditional   |                                                 |
|                        | integrations    |   task          |                                                 |
|                        | that you        |                 |                                                 |
|                        | configure       |                 |                                                 |
|                        | instances for   |                 |                                                 |
|                        | as needed.      |                 |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+
| **Playbooks**          | Add             | Not relevant    | See                                             |
|                        | sub-playbooks   |                 | [topic](#UUID2ede8a7dcde5fbc41bb8821974a834e4). |
|                        | to your         |                 |                                                 |
|                        | playbook from   |                 |                                                 |
|                        | your Org        |                 |                                                 |
|                        | repository or   |                 |                                                 |
|                        | from the        |                 |                                                 |
|                        | Playbooks       |                 |                                                 |
|                        | Catalog.        |                 |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+
| **Manual Tasks**       | Add tasks from  | - Standard task | See                                             |
|                        | playbooks in    |                 | [topic](#UUID54881a1bcad662b0ffe2c23791461eaf). |
|                        | your Org        | - Conditional   |                                                 |
|                        | repository.     |   task          |                                                 |
|                        |                 |                 |                                                 |
|                        |                 | - Data          |                                                 |
|                        |                 |   collection    |                                                 |
|                        |                 |   task          |                                                 |
|                        |                 |                 |                                                 |
|                        |                 | - Section       |                                                 |
|                        |                 |   Header task   |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+
| **Header**             | Add section     | Section Header  | See                                             |
|                        | headers to      | task            | [topic](#UUID54881a1bcad662b0ffe2c23791461eaf). |
|                        | organize your   |                 |                                                 |
|                        | playbook.       |                 |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+
| **Blank Task**         | Create a new    | - Standard task | See                                             |
|                        | task from       |                 | [topic](#UUID54881a1bcad662b0ffe2c23791461eaf). |
|                        | scratch.        | - Conditional   |                                                 |
|                        |                 |   task          |                                                 |
|                        |                 |                 |                                                 |
|                        |                 | - Data          |                                                 |
|                        |                 |   collection    |                                                 |
|                        |                 |   task          |                                                 |
|                        |                 |                 |                                                 |
|                        |                 | - Section       |                                                 |
|                        |                 |   Header task   |                                                 |
+------------------------+-----------------+-----------------+-------------------------------------------------+

####### Playbook task types

Playbooks have different task types for each action you want to take.
When you add an object from the Task Library, you associate it with a
task type in the **Task Details** pane.

The possible task types are:

+-----------------------------------+-----------------------------------+
| Task type                         | Description                       |
+===================================+===================================+
| Standard                          | Standard tasks can be configured  |
|                                   | to prompt for a response, such as |
|                                   | prompting an analyst to verify    |
|                                   | the severity or classification of |
|                                   | an issue before proceeding with   |
|                                   | automated actions. They can also  |
|                                   | be automated tasks such as        |
|                                   | parsing a file or enriching       |
|                                   | indicators.                       |
|                                   |                                   |
|                                   | Automated tasks are based on      |
|                                   | scripts that exist in the system. |
|                                   | These scripts can be created by   |
|                                   | you or come out-of-the-box as     |
|                                   | part of a content pack. For       |
|                                   | example, the `!ad-get-user`       |
|                                   | command retrieves detailed        |
|                                   | information about a user account  |
|                                   | using the                         |
|                                   | **Active Directory Query V2**     |
|                                   | integration.                      |
|                                   |                                   |
|                                   | You can also automatically        |
|                                   | remediate an issue by interacting |
|                                   | with a third-party integration,   |
|                                   | open tickets in a ticketing       |
|                                   | system such as Jira, or detonate  |
|                                   | a file using a sandbox.           |
+-----------------------------------+-----------------------------------+
| Conditional                       | Conditional tasks validate        |
|                                   | conditions based on values or     |
|                                   | parameters and take appropriate   |
|                                   | direction in the playbook         |
|                                   | workflow, like a decision tree in |
|                                   | a flow chart.                     |
|                                   |                                   |
|                                   | For example, a conditional task   |
|                                   | may ask whether indicators are    |
|                                   | found. If yes, you can have a     |
|                                   | task to enrich them, and if not   |
|                                   | you can proceed to determine that |
|                                   | the issue is not malicious.       |
|                                   | Alternatively, you can use        |
|                                   | conditional tasks to check if a   |
|                                   | certain integration is available  |
|                                   | and enabled in your system. If    |
|                                   | yes, you can use that integration |
|                                   | to perform an action, and if not, |
|                                   | you can continue on a different   |
|                                   | branch in the decision tree.      |
|                                   |                                   |
|                                   | Conditional tasks can also be     |
|                                   | used to communicate with users    |
|                                   | through a single question survey, |
|                                   | the answer to which determines    |
|                                   | how a playbook will proceed.      |
+-----------------------------------+-----------------------------------+
| Data Collection                   | Data collection tasks interact    |
|                                   | with users through a survey, for  |
|                                   | example to collect responses or   |
|                                   | escalate an issue.                |
|                                   |                                   |
|                                   | All responses are collected and   |
|                                   | recorded in the issue context     |
|                                   | data, from a single user or       |
|                                   | multiple users. You can use the   |
|                                   | survey questions and answers as   |
|                                   | input for subsequent playbook     |
|                                   | tasks.                            |
|                                   |                                   |
|                                   | You can collect responses in      |
|                                   | custom fields, for example, a     |
|                                   | grid field.                       |
+-----------------------------------+-----------------------------------+
| Section Header                    | Use a section header task to      |
|                                   | group related tasks to organize   |
|                                   | and manage the flow of your       |
|                                   | playbook.                         |
|                                   |                                   |
|                                   | Section headers can also be used  |
|                                   | for time tracking between phases  |
|                                   | in a playbook. This data can be   |
|                                   | used to display in dashboards and |
|                                   | report time trends.               |
|                                   |                                   |
|                                   | For example, in a phishing        |
|                                   | playbook you would have a section |
|                                   | for the investigative phase of    |
|                                   | the playbook such as indicator    |
|                                   | enrichment, and a section for     |
|                                   | communication tasks with the user |
|                                   | who reported the phishing.        |
|                                   |                                   |
|                                   | You can easily navigate playbooks |
|                                   | and focus on the parts you need   |
|                                   | to work on by collapsing and      |
|                                   | expanding playbook sections.      |
|                                   | Collapsing sections provides a    |
|                                   | condensed view of the playbook    |
|                                   | flow, reducing visual clutter and |
|                                   | enabling quick access to specific |
|                                   | sections. Expanding sections      |
|                                   | allows you to view or edit        |
|                                   | specific parts of a playbook      |
|                                   | while keeping the rest of the     |
|                                   | playbook compact and maintaining  |
|                                   | focus on the relevant playbook    |
|                                   | details. You can also hover over  |
|                                   | a section header to highlight all |
|                                   | tasks under the section and       |
|                                   | easily identify the section       |
|                                   | scope.                            |
+-----------------------------------+-----------------------------------+

####### Add Quick Actions, commands, and scripts

Adding Quick Actions, commands, and scripts to playbooks enables
automating repetitive tasks and executing custom actions to enhance
efficiency and streamline workflow processes.

######## Add Quick Actions

Quick Actions are predefined commands that require minimal configuration
and can be added to playbooks.

1.  From the **Task Library** pane, click **Quick Actions**.

2.  Hover over the Quick Action you want and click **Add**.

3.  Select the **Task Type** the script will be based on, either
    **Standard Task** or **Conditional Task**.

    - Standard task: Use a Standard task when an analyst to run a Quick
      Action and then proceed in the playbook.

    - Conditional task: Use a Conditional task to validate
      conditions based on values or parameters and take appropriate
      direction in the playbook workflow.

- > **Note**

  > If the Quick Action requires an integration instance and it is not
  > yet configured, you have the option to create an integration
  > instance from within the playbook editor.

4.  Configure the Quick Action inputs.

- Each Quick Action has its own set of required and optional input
  arguments You can set each argument to a specific value (by typing
  directly on the line under the argument name) or you can click the
  curly brackets to define a source field to populate the argument.

5.  Click **OK**.

6.  Connect the task you added by dragging and dropping a wire.

######## Add commands and scripts

> **Note**
>
> If you want to add a script that is not yet adopted, Cortex XSIAM
> automatically installs the content pack containing the script. If the
> script requires an integration instance, you are prompted to configure
> one.

1.  From the **Task Library** pane, click **Commands & Scripts**.

2.  Search for a specific script, or click an integration from the list.

- If you click an integration, it expands to show all the scripts it
  includes.

3.  Hover over the script you want and click **Add**.

- A green check mark next to the script indicates the script is adopted
  and the integration instance containing the script is configured.

4.  In the **Task Details** pane, if the content pack containing the
    script you want is not installed, it will automatically install. You
    then configure an integration instance, if required, by clicking
    **Create an instance now**.

- If the script belongs to multiple content packs, select from a drop
  down list which one to install.

  If you add the script and it requires an integration instance, Cortex
  XSIAM indicates you need to set up an integration to run the script.

  > **Note**

  > If you do not have permission to download the script, contact your
  > administrator for help. You can also filter by \"show only
  > configured\" to show scripts you can use.

5.  In the integration instance settings pane, enter values for the
    settings fields.

6.  Click **Save & Exit** for the integration instance.

7.  Select the **Task Type** the script will be based on, either
    **Standard Task** or **Conditional Task**.

    - Standard task: Use a Standard task when you want to perform
      a manual or automated action as part of a workflow, for example
      when an analyst needs to confirm information or escalate a case.

    - Conditional task: Use a Conditional task to validate
      conditions based on values or parameters and take appropriate
      direction in the playbook workflow.

8.  Configure the script or command settings as follows.

+-----------------------------------+---------------------------------------------------------------+
| Tab                               | Details                                                       |
+===================================+===============================================================+
| Inputs                            | Each script has its own set of input arguments (or none). You |
|                                   | can set each argument to a specific value (by typing directly |
|                                   | on the line under the argument name) or you can click the     |
|                                   | curly brackets to define a source field to populate the       |
|                                   | argument.                                                     |
+-----------------------------------+---------------------------------------------------------------+
| Outputs                           | Each script has its own set of output arguments (or none).    |
+-----------------------------------+---------------------------------------------------------------+
| Mapping                           | Map the output from a playbook task directly to an issue      |
|                                   | field.                                                        |
|                                   |                                                               |
|                                   | The value for an output key populates the specified field per |
|                                   | issue. This is a good alternative to using a task with the    |
|                                   | `setIssue` command.                                           |
|                                   |                                                               |
|                                   | > **Note**                                                    |
|                                   | >                                                             |
|                                   | > The output value is dynamic and is derived from the context |
|                                   | > at the time that the task is processed. As a result,        |
|                                   | > parallel tasks that are based on the same output may return |
|                                   | > inconsistent results.                                       |
|                                   |                                                               |
|                                   | 1.  In the **Mapping** tab, click                             |
|                                   |     **Add custom output mapping**.                            |
|                                   |                                                               |
|                                   | 2.  Under **Outputs**, select the context output to map to an |
|                                   |     issue field. Click the curly brackets to see a list of    |
|                                   |     the output parameters available from the script.          |
|                                   |                                                               |
|                                   | 3.  Under **Field to fill**, select the field that you want   |
|                                   |     to populate with the output.                              |
|                                   |                                                               |
|                                   | 4.  Click **Save**.                                           |
+-----------------------------------+---------------------------------------------------------------+
| Advanced                          | Includes the following fields.                                |
|                                   |                                                               |
|                                   | - **Using**: Choose which integration instance will execute   |
|                                   |   the command, or leave empty to use all integration          |
|                                   |   instances.                                                  |
|                                   |                                                               |
|                                   | - **Extend context**: Append the extracted results of the     |
|                                   |   action to the context. For example,                         |
|                                   |   \"newContextKey1=path1::newContextKey2=path2\" returns      |
|                                   |   \"\\\[path1:\'aaa\',path2: \'bbb\', newContexKey1:          |
|                                   |   \'aaa\',newContextKey2:\'bbb\'\\\]\"                        |
|                                   |                                                               |
|                                   | - **Ignore outputs**: If set to true, will not store outputs  |
|                                   |   into the context (besides the extended outputs).            |
|                                   |                                                               |
|                                   | - **Execution timeout (seconds)**: Sets the command execution |
|                                   |   timeout in seconds.                                         |
|                                   |                                                               |
|                                   | - **Indicator Extraction mode**: Choose when to extract       |
|                                   |   indicators:                                                 |
|                                   |                                                               |
|                                   |   - **Use system default:** This is the default setting.      |
|                                   |                                                               |
|                                   |   - **None:** Do not perform indicator extraction             |
|                                   |                                                               |
|                                   |   - **Inline:** Before other playbook tasks                   |
|                                   |                                                               |
|                                   |   - **Out of band:** While other tasks are running            |
|                                   |                                                               |
|                                   | - **Mark results as note**                                    |
|                                   |                                                               |
|                                   | - **Run without a worker**                                    |
|                                   |                                                               |
|                                   | - **Skip this branch if this script/playbook is unavailable** |
|                                   |                                                               |
|                                   | - **Quiet Mode**: When in quiet mode, tasks do not display    |
|                                   |   inputs and outputs or extract indicators. Errors and        |
|                                   |   warnings are still documented. You can turn quiet mode on   |
|                                   |   or off at the task or playbook level.                       |
+-----------------------------------+---------------------------------------------------------------+
| Details                           | Includes the following fields.                                |
|                                   |                                                               |
|                                   | - **Tag the result with**: Add a tag to the task result. You  |
|                                   |   can use the tag to filter entries in the War Room.          |
|                                   |                                                               |
|                                   | - **Task description (Markdown supported)**: Provide a        |
|                                   |   description of what this task does. You can enter objects   |
|                                   |   from the context data in the description. For example, in a |
|                                   |   communication task, you can use the recipient's email       |
|                                   |   address. The value for the object is based on what appears  |
|                                   |   in the context every time the task runs.                    |
+-----------------------------------+---------------------------------------------------------------+
| On Error                          | Includes the following fields.                                |
|                                   |                                                               |
|                                   | - **Number of retries**: How many times the task should retry |
|                                   |   running if there is an error. Default is 0.                 |
|                                   |                                                               |
|                                   | - **Retry interval (seconds)**: How long to wait between      |
|                                   |   retries. Default is 30 seconds.                             |
|                                   |                                                               |
|                                   | <!-- -->                                                      |
|                                   |                                                               |
|                                   | - The maximum retry interval is 800 seconds (13.3 minutes).   |
|                                   |   If you enter a value greater than 800 seconds, the retry    |
|                                   |   interval will be limited to 800 seconds.                    |
|                                   |                                                               |
|                                   | <!-- -->                                                      |
|                                   |                                                               |
|                                   | - **Error handling**: How the task should behave if there is  |
|                                   |   an error while running the script. Options are:             |
|                                   |                                                               |
|                                   |   - **Stop**                                                  |
|                                   |                                                               |
|                                   |   - **Continue**                                              |
|                                   |                                                               |
|                                   |   - **Continue on error path(s)**                             |
|                                   |                                                               |
|                                   |   <!-- -->                                                    |
|                                   |                                                               |
|                                   |   - This option configures the task to handle potential       |
|                                   |     errors that may occur when executing the current task\'s  |
|                                   |     script.                                                   |
+-----------------------------------+---------------------------------------------------------------+

9.  Click **OK**.

10. Connect the task you added by dragging and dropping a wire.

####### Add sub-playbooks

Sub-playbooks are playbooks that are nested under other playbooks. They
appear as tasks in the parent playbook flow and are indicated by the
sub-playbook icon ![](media/rId2230.png){width="0.20833333333333334in"
height="0.20833333333333334in"}. A sub-playbook can also be a parent
playbook in a different use case.

For example, [IP Enrichment - Generic
v2](https://xsoar.pan.dev/docs/reference/playbooks/ip-enrichment---generic-v2)
and [Retrieve File From Endpoint - Generic
v3](https://xsoar.pan.dev/docs/reference/playbooks/retrieve-file-from-endpoint---generic-v3)
playbooks are usually used as part of a bigger investigation.

Since sub-playbooks are building blocks that can be used in other
playbooks and use cases, you should define generic inputs for them.

Inputs can be passed to sub-playbooks from the parent playbook, used and
processed in the sub-playbook, and sent as output to the parent
playbook.

1.  From the **Task Library** pane, click **Playbooks**.

2.  Find the relevant sub-playbook by either searching for a specific
    playbook by name in your Org repository from the **Org Playbooks**
    tab, or by adopting a playbook from the **Playbooks catalog** tab.

- You can sort alphabetically (**ABC**) or by **Last Modified**.

3.  Hover over the playbook you want and and drag it onto the playbook
    editor canvas.

- When you adopt a playbook from the **Playbooks Catalog**, installation
  may take some time.

  When you adopt a system playbook, it is locked and you can only make
  limited changes to the playbook settings from the **Playbook Starts**
  task. For full editing capabilities, click
  ![](media/rId2196.png){width="0.18055555555555555in"
  height="0.20833333333333334in"} and select either **Duplicate**
  (create a copy of the playbook to edit) or **Edit Playbook** (detach
  the playbook). A detached playbook does not receive updates in future
  content releases. If you reattach the playbook, the latest content
  updates will be applied and any edits you made will be overridden.

  a.  If after adopting a playbook you see a warning
      ![](media/rId2237.png){width="0.23692804024496938in"
      height="0.20833333333333334in"} indicating the sub-playbook is not
      ready to use, click the playbook to open its **Task Details**
      pane.

  b.  In the error message, click the **Open it** link to view the
      sub-playbook in a new tab in the playbook editor.

  c.  Scroll through the sub-playbook. If there is a task that requires
      integration setup, click the task to open the **Task Details**
      pane and click the **Create an instance now** link.

  d.  In the integration instance settings pane, enter values for the
      settings fields.

  e.  Click **Save & Exit** for the integration instance.

4.  Configure the sub-playbook.

    a.  In your main playbook editor, click the sub-playbook you added.
        The **Task Details** pane opens.

    b.  Click the **Open sub-playbook** link to open the sub-playbook in
        a new tab. You can then view and edit the tasks in the
        sub-playbook.

    c.  Click the curly brackets next to the sub-playbook name to select
        the data source for the sub-playbook.

    d.  Configure the sub-playbook settings from the following tabs.

+-----------------------------------+---------------------------------------------------------------------------+
| Tab                               | Settings                                                                  |
+===================================+===========================================================================+
| **Inputs**                        | Any required input arguments for the sub-playbook.                        |
+-----------------------------------+---------------------------------------------------------------------------+
| **Outputs**                       | Any outputs defined for the sub-playbook.                                 |
+-----------------------------------+---------------------------------------------------------------------------+
| **Advanced**                      | - **Skip this branch if this script/playbook is unavailable**             |
|                                   |                                                                           |
|                                   | - **Quiet Mode**: Determines whether this task uses the playbook default  |
|                                   |   setting for quiet mode. When in quiet mode, tasks do not display inputs |
|                                   |   and outputs or extract indicators. Errors and warnings are still        |
|                                   |   documented. You can turn quiet mode on or off at the task or playbook   |
|                                   |   level.                                                                  |
+-----------------------------------+---------------------------------------------------------------------------+
| **Loop**                          | Click one of the following options to define loop settings:               |
|                                   |                                                                           |
|                                   | - **None**: (Default) The sub-playbook does not loop.                     |
|                                   |                                                                           |
|                                   | - **Built-in**: Use built-in functions to define loop settings:           |
|                                   |                                                                           |
|                                   | +-----------------------------------+-----------------------------------+ |
|                                   | | Option                            | Description                       | |
|                                   | +===================================+===================================+ |
|                                   | | Exit when                         | Enables you to define when to     | |
|                                   | |                                   | exit the loop. Click {} and       | |
|                                   | |                                   | expand the source category. Hover | |
|                                   | |                                   | over the required source and      | |
|                                   | |                                   | click **Filter & Transform** to   | |
|                                   | |                                   | the left of the source to         | |
|                                   | |                                   | manipulate the data.              | |
|                                   | +-----------------------------------+-----------------------------------+ |
|                                   | | Equals (String)                   | Select the operator to define how | |
|                                   | |                                   | the values should be evaluated.   | |
|                                   | +-----------------------------------+-----------------------------------+ |
|                                   | | Max iterations                    | The number of times the loop      | |
|                                   | |                                   | should run.                       | |
|                                   | |                                   |                                   | |
|                                   | |                                   | > **Tip**                         | |
|                                   | |                                   | >                                 | |
|                                   | |                                   | > Balance between the number of   | |
|                                   | |                                   | > iterations and the interval so  | |
|                                   | |                                   | > you do not overload the server. | |
|                                   | +-----------------------------------+-----------------------------------+ |
|                                   | | Sleep                             | The number of seconds to wait     | |
|                                   | |                                   | between iterations.               | |
|                                   | |                                   |                                   | |
|                                   | |                                   | recommends that you balance       | |
|                                   | |                                   | between the number of iterations  | |
|                                   | |                                   | and the number of seconds to wait | |
|                                   | |                                   | between iterations so you don\'t  | |
|                                   | |                                   | overload the server.              | |
|                                   | +-----------------------------------+-----------------------------------+ |
|                                   |                                                                           |
|                                   | - **For each input**: Runs the sub-playbook based on defined inputs.      |
|                                   |   Enter the number of seconds to wait between iterations.                 |
|                                   |                                                                           |
|                                   | - **Choose Loop automation**: Select the automation from the drop-down    |
|                                   |   list to define when to exit the loop. The parameters that appear are    |
|                                   |   applicable to the selected automation.                                  |
|                                   |                                                                           |
|                                   | For more information, see [Configure a sub-playbook                       |
|                                   | loop](#UUIDabee2878da723d088573af74ddd75ea4).                             |
+-----------------------------------+---------------------------------------------------------------------------+
| **Details**                       | **Task description (Markdown supported)**: Displays a description for     |
|                                   | this playbook (if one exists).                                            |
+-----------------------------------+---------------------------------------------------------------------------+
| **Timers**                        | - **Timer.start**: The trigger for starting to send a message or survey   |
|                                   |   to recipients. You can change this trigger or add a trigger for         |
|                                   |   **Timer.stop** or **Timer.pause**. Select the trigger timer field from  |
|                                   |   the drop down.                                                          |
|                                   |                                                                           |
|                                   | - **Add Trigger**: You can add other trigger timer fields from the drop   |
|                                   |   down.                                                                   |
+-----------------------------------+---------------------------------------------------------------------------+

5.  Select whether the outputs of the sub-playbook are
    **Shared globally** or **Private to sub-playbook** (default).

6.  Click **OK**.

7.  Connect the sub-playbook you\'ve added by dragging and dropping a
    wire.

####### Add manual tasks and blank tasks

 Cortex XSIAM supports different task types for different actions to be
taken in a playbook.

You can a manual task or a blank task from the Task Library.

Add a manual task

**Manual Tasks** contains a list of playbooks from your Org repository
with the manual tasks they contain. A manual task does not run a script
and may require manual inputs. By default, they are ordered by latest
updated playbook. You can also order the playbooks alphabetically.

1.  From the **Task Library** pane, click **Manual Tasks**.

2.  Click a playbook to view the tasks contained within that playbook.

3.  Hover over the task you want and click **Add**.

4.  Connect the playbook you added by dragging and dropping a wire.

5.  Save the playbook.

Add a blank task

A **Blank Task** can be used to create a custom task from scratch.

1.  From the **Task Library** pane, click **Blank Task**.

2.  In the **Task Details** pane, select the **Task Type** you want.

- The following are the types of tasks you can create for your playbook.

  - Standard task: Use a Standard task when an analyst needs to confirm
    information or escalate a case.

  - Conditional task: Use a Conditional task to validate
    conditions based on values or parameters and take appropriate
    direction in the playbook workflow.

  - Data Collection task: Use a Data Collection task to interact with
    users in your organization.

  - Section Header: Use a Section Header task to group related tasks to
    organize and manage the flow of your playbook.

3.  Enter a meaningful name in the **Task Name** field.

4.  Configure the settings relevant for the task type you selected. For
    more information, see:

    - [Create a standard task](#UUIDf3f760605a841f990f8696f642432496)

    - [Create a conditional task](#UUIDcb6bdd093710d40bada11fd1d7a0cabf)

    - [Create a communication
      task](#UUID143de8b117959ba5d715c7de22659889)

    - [Create a section header](#UUID6d7d7f4c462bece88bd7739867c401f9)

5.  Click **Save**.

- The task is added in the playbook editor.

6.  Connect the tasks you\'ve added in their logical order by dragging
    and dropping a wire from one task to another.

7.  Save the playbook.

######## Create a standard task

Standard tasks can be manual tasks such as manual verification to prompt
an analyst to verify the severity or classification of an issue before
proceeding with automated actions. They can also be automated tasks such
as parsing a file or enriching indicators.

1.  From the **Task Library** pane, click the task you want, for example
    **Blank Task**.

2.  In the **Task Details** pane, select the Standard icon for
    **Task Type**.

3.  Enter a meaningful name in the **Task Name** field for the task that
    corresponds to the data you are collecting.

4.  Select the options you want to configure for the Standard task.

- Standard tasks include the following field and tabs.

+-----------------------------------+-----------------------------------------------------------------+
| Field / tab                       | Settings                                                        |
+===================================+=================================================================+
| **Choose script** field           | From a drop down list, select a script for the playbook to run. |
|                                   | In the following tabs you can set:                              |
|                                   |                                                                 |
|                                   | - **Inputs**: Each script has its own set of input arguments    |
|                                   |   (or none). You can set each argument to a specific value (by  |
|                                   |   typing directly on the line under the argument name) or you   |
|                                   |   can click the curly brackets to define a source field to      |
|                                   |   populate the argument.                                        |
|                                   |                                                                 |
|                                   | - **Outputs**: Each script has its own set of output arguments  |
|                                   |   (or none).                                                    |
|                                   |                                                                 |
|                                   | - **Mapping**:                                                  |
|                                   |                                                                 |
|                                   | <!-- -->                                                        |
|                                   |                                                                 |
|                                   | - Map the output from a playbook task directly to an issue      |
|                                   |   field.                                                        |
|                                   |                                                                 |
|                                   |   The value for an output key populates the specified field per |
|                                   |   issue. This is a good alternative to using a task with the    |
|                                   |   `setIssue` command.                                           |
|                                   |                                                                 |
|                                   |   > **Note**                                                    |
|                                   |                                                                 |
|                                   |   > The output value is dynamic and is derived from the context |
|                                   |   > at the time that the task is processed. As a result,        |
|                                   |   > parallel tasks that are based on the same output may return |
|                                   |   > inconsistent results.                                       |
|                                   |                                                                 |
|                                   |   1.  In the **Mapping** tab, click                             |
|                                   |       **Add custom output mapping**.                            |
|                                   |                                                                 |
|                                   |   2.  Under **Outputs**, select the output parameter whose      |
|                                   |       output you want to map. Click the curly brackets to see a |
|                                   |       list of the output parameters available from the script.  |
|                                   |                                                                 |
|                                   |   3.  Under **Field to fill**, select the field that you want   |
|                                   |       to populate with the output.                              |
|                                   |                                                                 |
|                                   |   4.  Click **Save**.                                           |
|                                   |                                                                 |
|                                   | <!-- -->                                                        |
|                                   |                                                                 |
|                                   | - **Advanced**: Includes the following fields.                  |
|                                   |                                                                 |
|                                   |   - **Using**: Choose which integration instance will execute   |
|                                   |     the command, or leave empty to use all integration          |
|                                   |     instances.                                                  |
|                                   |                                                                 |
|                                   |   - **Extend context**: Append the extracted results of the     |
|                                   |     action to the context. For example,                         |
|                                   |     \"newContextKey1=path1::newContextKey2=path2\" returns      |
|                                   |     \"\\\[path1:\'aaa\',path2: \'bbb\', newContexKey1:          |
|                                   |     \'aaa\',newContextKey2:\'bbb\'\\\]\"                        |
|                                   |                                                                 |
|                                   |   - **Ignore outputs**: If set to true, will not store outputs  |
|                                   |     into the context (besides the extended outputs).            |
|                                   |                                                                 |
|                                   |   - **Execution timeout (seconds)**: Sets the command execution |
|                                   |     timeout in seconds.                                         |
|                                   |                                                                 |
|                                   |   - **Indicator Extraction mode**: Choose when to extract       |
|                                   |     indicators:                                                 |
|                                   |                                                                 |
|                                   |     - **None:** Do not perform indicator extraction             |
|                                   |                                                                 |
|                                   |     - **Inline:** Before other playbook tasks                   |
|                                   |                                                                 |
|                                   |     - **Out of band:** While other tasks are running            |
|                                   |                                                                 |
|                                   |   - **Mark results as note**                                    |
|                                   |                                                                 |
|                                   |   - **Mark results as evidence**                                |
|                                   |                                                                 |
|                                   |   - **Run without a worker**                                    |
|                                   |                                                                 |
|                                   |   - **Skip this branch if this script/playbook is unavailable** |
|                                   |                                                                 |
|                                   |   - **Quiet Mode**: When in quiet mode, tasks do not display    |
|                                   |     inputs and outputs or extract indicators. Errors and        |
|                                   |     warnings are still documented. You can turn quiet mode on   |
|                                   |     or off at the task or playbook level.                       |
|                                   |                                                                 |
|                                   | - **Details**: Includes the following fields.                   |
|                                   |                                                                 |
|                                   |   - **Tag the result with**: Add a tag to the task result. You  |
|                                   |     can use the tag to filter entries in the War Room.          |
|                                   |                                                                 |
|                                   |   - **Task description (Markdown supported)**: Provide a        |
|                                   |     description of what this task does. You can enter objects   |
|                                   |     from the context data in the description. For example, in a |
|                                   |     communication task, you can use the recipient's email       |
|                                   |     address. The value for the object is based on what appears  |
|                                   |     in the context every time the task runs.                    |
|                                   |                                                                 |
|                                   | - **Timers**: Includes the following fields.                    |
|                                   |                                                                 |
|                                   |   - **Timer.start**: The trigger for starting to send a message |
|                                   |     or survey to recipients. You can change this trigger or add |
|                                   |     a trigger for **Timer.stop** or **Timer.pause**. Select the |
|                                   |     trigger timer field from the drop down.                     |
|                                   |                                                                 |
|                                   |   - **Add Trigger**: You can add other trigger timer fields     |
|                                   |     from the drop down.                                         |
|                                   |                                                                 |
|                                   | - **On Error**: Includes the following fields.                  |
|                                   |                                                                 |
|                                   |   - **Number of retries**: How many times the task should retry |
|                                   |     running if there is an error. Default is 0.                 |
|                                   |                                                                 |
|                                   |   - **Retry interval (seconds)**: How long to wait between      |
|                                   |     retries. Default is 30 seconds.                             |
|                                   |                                                                 |
|                                   |   <!-- -->                                                      |
|                                   |                                                                 |
|                                   |   - The maximum retry interval is 800 seconds (13.3 minutes).   |
|                                   |     If you enter a value greater than 800 seconds, the retry    |
|                                   |     interval will be limited to 800 seconds.                    |
|                                   |                                                                 |
|                                   |   <!-- -->                                                      |
|                                   |                                                                 |
|                                   |   - **Error handling**: How the task should behave if there is  |
|                                   |     an error. Options are:                                      |
|                                   |                                                                 |
|                                   |     - **Stop**                                                  |
|                                   |                                                                 |
|                                   |     - **Continue**                                              |
|                                   |                                                                 |
|                                   |     - **Continue on error path(s)**                             |
|                                   |                                                                 |
|                                   |     <!-- -->                                                    |
|                                   |                                                                 |
|                                   |     - This option configures the task to handle potential       |
|                                   |       errors that may occur when executing the current task\'s  |
|                                   |       script.                                                   |
+-----------------------------------+-----------------------------------------------------------------+
| **Manual task settings** tab      | - **Default assignee**: Assign an owner to this task.           |
|                                   |                                                                 |
|                                   | - **Only the assignee can complete the task**: Stop the         |
|                                   |   playbook from proceeding until the task assignee completes    |
|                                   |   the task. By default, in addition to the task assignee, the   |
|                                   |   default administrator can also complete the blocked task. You |
|                                   |   can also block tasks until a user with an external email      |
|                                   |   address completes the task.                                   |
|                                   |                                                                 |
|                                   | - **Task SLA**: Set the SLA in granularity of weeks, days,      |
|                                   |   hours, and minutes.                                           |
|                                   |                                                                 |
|                                   | - **Set task Reminder at**: Set a reminder for the task in      |
|                                   |   granularity of weeks, days, hours, and minutes.               |
+-----------------------------------+-----------------------------------------------------------------+
| **Advanced** tab                  | **Quiet Mode**: Determines whether this task uses the playbook  |
|                                   | default setting for quiet mode. When in quiet mode, tasks do    |
|                                   | not display inputs and outputs or extract indicators. Errors    |
|                                   | and warnings are still documented. You can turn quiet mode on   |
|                                   | or off at the task or playbook level.                           |
+-----------------------------------+-----------------------------------------------------------------+
| **Details** tab                   | - **Tag the result with**: Add a tag to the task result. You    |
|                                   |   can use the tag to filter entries in the War Room.            |
|                                   |                                                                 |
|                                   | - **Task description (Markdown supported)**: Provide a          |
|                                   |   description of what this task does. You can enter objects     |
|                                   |   from the context data in the description. For example, in a   |
|                                   |   communication task, you can use the recipient's email         |
|                                   |   address. The value for the object is based on what appears in |
|                                   |   the context every time the task runs.                         |
+-----------------------------------+-----------------------------------------------------------------+
| **Timers** tab                    | - **Timer.start**: The trigger for starting to send a message   |
|                                   |   or survey to recipients. You can change this trigger or add a |
|                                   |   trigger for **Timer.stop** or **Timer.pause**. Select the     |
|                                   |   trigger timer field from the drop down.                       |
|                                   |                                                                 |
|                                   | - **Add Trigger**: You can add other trigger timer fields from  |
|                                   |   the drop down.                                                |
+-----------------------------------+-----------------------------------------------------------------+

5.  Click **Save**.

- The task is added in the playbook editor.

6.  Connect the tasks you\'ve added in their logical order by dragging
    and dropping a wire from one task to another.

7.  Save the playbook.

######## Create a conditional task

Conditional tasks are used for determining different paths for your
playbook. For example, in a playbook for handling phishing emails, a
conditional task can be used to check if an email contains suspicious
attachments. If the attachment is identified as malicious, the playbook
can automatically quarantine the email; otherwise, it can proceed to
manual review by a security analyst.

**Conditional task types**

You can create different types of conditional tasks.

- **Built-in**: Creates a logical statement using an entity from within
  the playbook. For example, in an access investigation playbook, you
  can determine that if the Asset ID of the person whose account was
  being accessed exists in a VIP list, set the issue severity to High.
  Otherwise, proceed as normal.

- **Manual**: Creates a conditional task that must be manually resolved.
  For example, a security analyst is prompted to review and validate a
  suspicious file. The playbook task might involve instructions for the
  analyst to analyze the file, determine if it is malicious, and provide
  feedback or take specific actions based on their assessment.

- **Ask**: Creates a single-question survey communication task, the
  answer to which determines how a playbook proceeds. For more details
  about ask tasks, see [Create a communication
  task](#UUID143de8b117959ba5d715c7de22659889).

- **Choose script**: Creates a conditional task based on the result of a
  script. For example, check if an IP address is internal or external
  using the `IsIPInRanges` script. When using a script, the inputs and
  outputs are generated by the automation script.

**How to create a conditional task**

1.  From the **Task Library** pane, click the task you want, for example
    **Blank Task**.

2.  In the **Task Details** pane, select the Conditional **Task Type**.

3.  In the **Task Name** field, type a meaningful name for the task that
    corresponds to the data you are collecting.

4.  Select the relevant conditional task option. Some field
    configurations are required, and some are optional.

- Built-in
  - **Condition**: Define one or more logical conditions for the task.

  - **Details**: Includes the following fields.

    - **Tag the result with**: Add a tag to the task result. You can use
      the tag to filter entries in the War Room.

    - **Task description (Markdown supported)**: Provide a description
      of what this task does. You can enter objects from the context
      data in the description. For example, in a communication task, you
      can use the recipient's email address. The value for the object is
      based on what appears in the context every time the task runs.

  - **Timers**: Includes the following fields.

    - **Timer.start**: The trigger for starting to send a message or
      survey to recipients. You can change this trigger or add a trigger
      for **Timer.stop** or **Timer.pause**. Select the trigger timer
      field from the drop down.

    - **Add Trigger**: You can add other trigger timer fields from the
      drop down.

  - **Advanced**: Determines whether this task uses the playbook default
    setting for Quiet Mode. When in Quiet Mode, tasks do not display
    inputs and outputs or extract indicators. Errors and warnings are
    still documented. You can turn Quiet Mode on or off at the task or
    playbook level.

  - **On Error**: Includes the following fields.

    - **Number of retries**: How many times the task should retry
      running if there is an error. Default is 0.

    - **Retry interval (seconds)**: How long to wait between retries.
      Default is 30 seconds.

  Manual
  - **Manual task settings**: Includes the following fields.

    - **Default assignee**: Assign an owner to this task.

    - **Only the assignee can complete the task**: Stop the playbook
      from proceeding until the task assignee completes the task. By
      default, in addition to the task assignee, the default
      administrator can also complete the blocked task. You can also
      block tasks until a user with an external email address completes
      the task.

    - **Task SLA**: Set the SLA in granularity of weeks, days, hours,
      and minutes.

    - **Set task Reminder at**: Set a reminder for the task in
      granularity of weeks, days, hours, and minutes.

  - **Advanced**: Determines whether this task uses the playbook default
    setting for Quiet Mode. When in Quiet Mode, tasks do not display
    inputs and outputs or extract indicators. Errors and warnings are
    still documented. You can turn Quiet Mode on or off at the task or
    playbook level.

  - **Details**: Includes the following fields.

    - **Tag the result with**: Add a tag to the task result. You can use
      the tag to filter entries in the War Room.

    - **Task description (Markdown supported)**: Provide a description
      of what this task does. You can enter objects from the context
      data in the description. For example, in a communication task, you
      can use the recipient's email address. The value for the object is
      based on what appears in the context every time the task runs.

  - **Timers**: Includes the following fields.

    - **Timer.start**: The trigger for starting to send a message or
      survey to recipients. You can change this trigger or add a trigger
      for **Timer.stop** or **Timer.pause**. Select the trigger timer
      field from the drop down.

    - **Add Trigger**: You can add other trigger timer fields from the
      drop down.

  Ask
  - **Message**: Includes the following fields.

    - **Ask by**: The method for sending the message and survey. Options
      are:

      - **Task (can always be completed directly in the Workplan)**

      - **Generated link (appears in the context data)**

      - **Email**

    - **To**: The message and survey recipients. You can define by:

      - Selecting from a predefined drop down list.

      - Manually typing email addresses for users and/or external users.

      - Clicking the context icon to define recipients from a context
        data source.

    - **CC of the email**: A CC email address.

    - **Subject of the email**: The message subject that displays to
      message recipients. You can write the survey question in the
      subject field or in the message body field.

    - **Message body**: The text that displays in the body of the
      message. This field is optional, but if you don\'t write the
      survey question in the subject field, include it in the message
      body. This is a long-text field.

    - **Reply options**: Reply options are sent via the selected
      channels as options for an answer.

    - **Require users to authenticate**: Enable this option to have your
      SAML or AD authenticate the recipient before allowing them to
      answer. You must first set up an authentication integration
      instance and check
      **Use this instance for external users authentication only** in
      the integration instance settings.

  - **Timing**: Includes the following fields.

    - **Retry interval (minutes)**: Determines the wait time between
      each execution of a command. For example, the frequency (in
      minutes) that a message and survey are resent to recipients before
      the response is received.

    - **Number of retries**: Determines how many times a command
      attempts to run before generating an error. For example, the
      maximum number of times a message is sent. If a reply is received,
      no additional retry messages will be sent.

    - **Task SLA**: Set the SLA in granularity of weeks, days, and
      hours.

    - **Set task Reminder at**: Set a task reminder in granularity of
      weeks, days, and hours.

    - **Complete automatically if SLA passed without a reply**: Select
      this checkbox to complete the task if the SLA is breached before a
      reply is received. You can select yes or no.

  - **Advanced**: Includes the following fields.

    - **Using**: Choose which integration instance will execute the
      command, or leave empty to use all integration instances.

    - **Extend context**: Append the extracted results of the action to
      the context. For example,
      \"newContextKey1=path1::newContextKey2=path2\" returns
      \"\\\[path1:\'aaa\',path2: \'bbb\', newContexKey1:
      \'aaa\',newContextKey2:\'bbb\'\\\]\"

    - **Ignore outputs**: If set to true, will not store outputs into
      the context (besides the extended outputs).

    - **Execution timeout (seconds)**: Sets the command execution
      timeout in seconds.

    - **Indicator Extraction mode**: Choose when to extract indicators:

      - **None:** Do not perform indicator extraction

      - **Inline:** Before other playbook tasks

      - **Out of band:** While other tasks are running

    - **Mark results as note**

    - **Mark results as evidence**

    - **Run without a worker**

    - **Skip this branch if this script/playbook is unavailable**

    - **Quiet Mode**: When in quiet mode, tasks do not display inputs
      and outputs or extract indicators. Errors and warnings are still
      documented. You can turn quiet mode on or off at the task or
      playbook level.

  - **Details**: Includes the following fields.

    - **Tag the result with**: Add a tag to the task result. You can use
      the tag to filter entries in the War Room.

    - **Task description (Markdown supported)**: Provide a description
      of what this task does. You can enter objects from the context
      data in the description. For example, in a communication task, you
      can use the recipient's email address. The value for the object is
      based on what appears in the context every time the task runs.

  Choose script
  From a drop down list, select a script for the playbook to run. In the
  following tabs you can set:

  - **Inputs**: Each script has its own set of input arguments (or
    none). You can set each argument to a specific value (by typing
    directly on the line under the argument name) or you can click the
    curly brackets to define a source field to populate the argument.

  - **Outputs**: Each script has its own set of output arguments (or
    none).

  - **Mapping**:

  <!-- -->

  - Map the output from a playbook task directly to an issue field.

    The value for an output key populates the specified field per issue.
    This is a good alternative to using a task with a `setIssue`
    command.

    > **Note**

    > The output value is dynamic and is derived from the context at the
    > time that the task is processed. As a result, parallel tasks that
    > are based on the same output may return inconsistent results.

    1.  In the **Mapping** tab, click **Add custom output mapping**.

    2.  Under **Outputs**, select the output parameter whose output you
        want to map. Click the curly brackets to see a list of the
        output parameters available from the automation.

    3.  Under **Field to fill**, select the field that you want to
        populate with the output.

    4.  Click **Save**.

  <!-- -->

  - **Advanced**: Includes the following fields.

    - **Using**: Choose which integration instance will execute the
      command, or leave empty to use all integration instances.

    - **Extend context**: Append the extracted results of the action to
      the context. For example,
      \"newContextKey1=path1::newContextKey2=path2\" returns
      \"\\\[path1:\'aaa\',path2: \'bbb\', newContexKey1:
      \'aaa\',newContextKey2:\'bbb\'\\\]\"

    - **Ignore outputs**: If set to true, will not store outputs into
      the context (besides the extended outputs).

    - **Execution timeout (seconds)**: Sets the command execution
      timeout in seconds.

    - **Indicator Extraction mode**: Choose when to extract indicators:

      - **None:** Do not perform indicator extraction

      - **Inline:** Before other playbook tasks

      - **Out of band:** While other tasks are running

    - **Mark results as note**

    - **Mark results as evidence**

    - **Run without a worker**

    - **Skip this branch if this script/playbook is unavailable**

    - **Quiet Mode**: When in quiet mode, tasks do not display inputs
      and outputs or extract indicators. Errors and warnings are still
      documented. You can turn quiet mode on or off at the task or
      playbook level.

  - **Details**: Includes the following fields.

    - **Tag the result with**: Add a tag to the task result. You can use
      the tag to filter entries in the War Room.

    - **Task description (Markdown supported)**: Provide a description
      of what this task does. You can enter objects from the context
      data in the description. For example, in a communication task, you
      can use the recipient's email address. The value for the object is
      based on what appears in the context every time the task runs.

  - **Timers**: Includes the following fields.

    - **Timer.start**: The trigger for starting to send a message or
      survey to recipients. You can change this trigger or add a trigger
      for **Timer.stop** or **Timer.pause**. Select the trigger timer
      field from the drop down.

    - **Add Trigger**: You can add other trigger timer fields from the
      drop down.

  - **On Error**: Includes the following fields.

    - **Number of retries**: How many times the task should retry
      running if there is an error. Default is 0.

    - **Retry interval (seconds)**: How long to wait between retries.
      Default is 30 seconds.

    - **Error handling**: How the task should behave if there is an
      error. Options are:

      - **Stop**

      - **Continue**

      - **Continue on error path(s)**

      <!-- -->

      - This option configures the task to handle potential errors that
        may occur when executing the current task\'s script.

5.  Click **Save**.

- The task is added in the playbook editor.

6.  Connect the tasks you\'ve added in their logical order by dragging
    and dropping a wire from one task to another.

7.  Save the playbook.

######## Create a communication task

Communication tasks enable you to send surveys to users, both internal
and external, to collect data for an issue. The collected data can be
used for issue analysis, and also as input for subsequent playbook
tasks. For example, you can send a scheduled survey requesting analysts
to send specific issue updates or send a single (stand-alone) question
survey to determine how an issue was handled.

There are two types of communication tasks:

- **Ask tasks**: A conditional task that sends a single question survey.
  The answer is used to determine how the playbook proceeds.

- **Data collection tasks**: A data collection task sends a survey of
  one or more questions. The answers are recorded in context data and
  can be used as input for subsequent tasks.

######### About ask tasks

An ask task is a type of conditional task that sends a single question
survey, the answer to which determines how a playbook proceeds. If you
send the survey to multiple users, the first answer received is used,
and subsequent responses are disregarded. For more information about ask
task settings, see [Create a conditional
task](#UUIDcb6bdd093710d40bada11fd1d7a0cabf).

Because this is a conditional task, you need to create a condition for
each of the answers. For example, if the survey answers include,
`Yes, No, and Maybe`, there should be a corresponding condition (path)
in the playbook for each of these answers.

Users interact with the survey directly from the message, meaning the
question appears in the message and they click an answer from the
message.

The survey question and the first response is recorded in the issue
context data. This enables you to use this response as the input for
subsequent playbook tasks.

For all ask conditional tasks, a link is generated for each possible
answer the recipient can select. If the survey is sent to more than one
user, a unique link is created for each possible answer for each
individual recipient. These links are visible in the context data of the
issue\'s Work Plan. The links appear under **Ask.Links** in the context
data.

Send a survey

In this example, the message and survey will be sent to recipients every
hour for six hours, until a reply is received (it is repeated every 60
minutes, 6 times). The SLA is six hours. If the SLA is breached, the
playbook will proceed according to the Yes condition.

![](media/rId2249.png){width="5.833333333333333in"
height="6.293221784776903in"}

Send email to users

In this example, a message and survey are sent by email to all users
with the Analyst role. We are not including a message body because the
message subject is the survey question we want recipients to answer.
There are three reply options, **Yes**, **No**, and **Not sure**. In the
playbook, we will only add conditions for the Yes and No replies. We
require recipient authentication, which first involves setting up
authentication.

![](media/rId2253.png){width="5.833333333333333in"
height="10.82753280839895in"}

######### Create a data collection task

The data collection task is a multi-question survey (form) that survey
recipients access from a link in the message. Users do not need to log
in to access the survey, which is located on a separate site.

All responses are collected and recorded in the issue context data,
whether you receive responses from a single user or multiple users. This
enables you to use the survey questions and answers as input for
subsequent playbook tasks. If responses are received from multiple
users, data for multi-select fields and grid fields are aggregated. For
all other field types, the response received most recently will override
previous responses as it displays in the field. All responses are always
available in the context data.

For all data collection tasks, a single link is generated for each
recipient of the survey. These links are visible in the context data of
the issue\'s Work Plan. The links appear in the context data under the
**Links** section of that survey.

You can include the following types of questions in the survey.

- Stand alone questions. These are presented to users directly in the
  message, and from which users answer directly in the message (not an
  external survey).

- Field-based questions. These are based on a specific issue field
  (either system or custom), for example, an Asset ID field. The
  response (data) received for these fields automatically populates the
  field for this issue. For single-select field based questions, the
  default option is taken from the field's defined default.

**How to create a Data Collection task**

1.  From the **Task Library** pane, click the task you want, for example
    **Blank Task**.

2.  In the **Task Details** pane, select the Data Collection
    **Task Type**.

3.  Enter a meaningful name in the **Task Name** field for the task that
    corresponds to the data you are collecting.

4.  Select the communication options you want to use to collect the
    data.

- Tabs and configuration fields

+-----------------------------------+-----------------------------------------------------------------+
| Tab                               | Configuration fields in the tab                                 |
+===================================+=================================================================+
| **Message**                       | - **Ask by**: The method for sending the message and survey.    |
|                                   |   Options are:                                                  |
|                                   |                                                                 |
|                                   |   - **Task (can always be completed directly in the Workplan)** |
|                                   |                                                                 |
|                                   |   - **Generated link (appears in the context data)**: A link to |
|                                   |     the data collection survey is available in the context data |
|                                   |     of the task.                                                |
|                                   |                                                                 |
|                                   |   - **Email**: If you select this option, enter below the       |
|                                   |     subject and message of the email and the email addresses of |
|                                   |     the users who should receive this message or survey.        |
|                                   |                                                                 |
|                                   | - **To**: The message and survey recipients. You can define by: |
|                                   |                                                                 |
|                                   |   - Selecting from a predefined drop down list.                 |
|                                   |                                                                 |
|                                   |   - Manually typing email addresses for users and/or external   |
|                                   |     users.                                                      |
|                                   |                                                                 |
|                                   |   - Clicking the context icon to define recipients from a       |
|                                   |     context data source.                                        |
|                                   |                                                                 |
|                                   | - **CC of the email**: A CC email address.                      |
|                                   |                                                                 |
|                                   | - **Subject of the email**: The message subject that displays   |
|                                   |   to message recipients. You can write the survey question in   |
|                                   |   the subject field or in the message body field.               |
|                                   |                                                                 |
|                                   | - **Message body**: The message question body to be used in the |
|                                   |   notification sent to the given users along with the reply     |
|                                   |   options.                                                      |
|                                   |                                                                 |
|                                   | - **Require users to authenticate**: Enable this option to have |
|                                   |   your SAML or AD authenticate the recipient before allowing    |
|                                   |   them to answer. You must first set up an authentication       |
|                                   |   integration instance and check                                |
|                                   |   **Use this instance for external users authentication only**  |
|                                   |   in the integration instance settings.                         |
+-----------------------------------+-----------------------------------------------------------------+
| **Questions**                     | - **Web Survey Title**: The title displayed for the web survey. |
|                                   |                                                                 |
|                                   | - **Short Description**: A description displayed above the      |
|                                   |   questions on the web survey. Click **Preview** to see how it  |
|                                   |   displays.                                                     |
|                                   |                                                                 |
|                                   | - **Question**: A question to ask recipients.                   |
|                                   |                                                                 |
|                                   | - **Answer Type**: The field type for the answer field. Options |
|                                   |   are:                                                          |
|                                   |                                                                 |
|                                   |   - Short text                                                  |
|                                   |                                                                 |
|                                   |   - Long text                                                   |
|                                   |                                                                 |
|                                   |   - Number                                                      |
|                                   |                                                                 |
|                                   |   - Single Select (requires you to define a reply option)       |
|                                   |                                                                 |
|                                   |   - Multi select/Array (requires you to define a reply option)  |
|                                   |                                                                 |
|                                   |   - Date picker                                                 |
|                                   |                                                                 |
|                                   |   - Attachments                                                 |
|                                   |                                                                 |
|                                   | - **Mandatory**: If this checkbox is selected for a question,   |
|                                   |   survey recipients will not be able to submit the survey until |
|                                   |   they answer this question.                                    |
|                                   |                                                                 |
|                                   | - **Help Message**: The message that displays when users hover  |
|                                   |   over the question mark help button for the survey question.   |
|                                   |                                                                 |
|                                   | - **Placeholder**: A sample value displayed until a real value  |
|                                   |   is entered.                                                   |
|                                   |                                                                 |
|                                   | > **Note**                                                      |
|                                   | >                                                               |
|                                   | > You can drag questions to rearrange the order in which they   |
|                                   | > display in the survey.                                        |
+-----------------------------------+-----------------------------------------------------------------+
| **Timing**                        | - **Retry interval (minutes)**: Determines the wait time        |
|                                   |   between each execution of a command. For example, the         |
|                                   |   frequency (in minutes) that a message and survey are resent   |
|                                   |   to recipients before the response is received.                |
|                                   |                                                                 |
|                                   | - **Number of retries**: Determines how many times a command    |
|                                   |   attempts to run before generating an error. For example, the  |
|                                   |   maximum number of times a message is sent. If a reply is      |
|                                   |   received, no additional retry messages will be sent.          |
|                                   |                                                                 |
|                                   | <!-- -->                                                        |
|                                   |                                                                 |
|                                   | - > **Note**                                                    |
|                                   |                                                                 |
|                                   |   > Retries are not supported for data collection tasks that    |
|                                   |   > have errors sending emails (indicated by a server timeout). |
|                                   |   > This is because retries only work on automation execution   |
|                                   |   > failures, not on email delivery issues.                     |
|                                   |                                                                 |
|                                   | <!-- -->                                                        |
|                                   |                                                                 |
|                                   | - **Task SLA**: Set the SLA in granularity of weeks, days, and  |
|                                   |   hours.                                                        |
|                                   |                                                                 |
|                                   | - **Set task Reminder at**: Set a task reminder in granularity  |
|                                   |   of weeks, days, and hours.                                    |
|                                   |                                                                 |
|                                   | - **Complete automatically if**:                                |
|                                   |                                                                 |
|                                   |   - **Reached task SLA (with or without a reply)**: This option |
|                                   |     is grayed out.                                              |
|                                   |                                                                 |
|                                   |   - **Received \<enter a number\> reply**                       |
+-----------------------------------+-----------------------------------------------------------------+
| **Details**                       | - **Tag the result with**: Add a tag to the task result. You    |
|                                   |   can use the tag to filter entries in the War Room.            |
|                                   |                                                                 |
|                                   | - **Task description (Markdown supported)**: Provide a          |
|                                   |   description of what this task does. You can enter objects     |
|                                   |   from the context data in the description. For example, in a   |
|                                   |   communication task, you can use the recipient's email         |
|                                   |   address. The value for the object is based on what appears in |
|                                   |   the context every time the task runs.                         |
+-----------------------------------+-----------------------------------------------------------------+
| **Advanced**                      | - **Using**: Choose which integration instance will execute the |
|                                   |   command, or leave empty to use all integration instances.     |
|                                   |                                                                 |
|                                   | - **Extend context**: Append the extracted results of the       |
|                                   |   action to the context. For example,                           |
|                                   |   \"newContextKey1=path1::newContextKey2=path2\" returns        |
|                                   |   \"\\\[path1:\'aaa\',path2: \'bbb\', newContexKey1:            |
|                                   |   \'aaa\',newContextKey2:\'bbb\'\\\]\"                          |
|                                   |                                                                 |
|                                   | - **Ignore outputs**: If set to true, will not store outputs    |
|                                   |   into the context (besides the extended outputs).              |
|                                   |                                                                 |
|                                   | - **Execution timeout (seconds)**: Sets the command execution   |
|                                   |   timeout in seconds.                                           |
|                                   |                                                                 |
|                                   | - **Indicator Extraction mode**: Choose when to extract         |
|                                   |   indicators:                                                   |
|                                   |                                                                 |
|                                   |   - **None:** Do not perform indicator extraction               |
|                                   |                                                                 |
|                                   |   - **Inline:** Before other playbook tasks                     |
|                                   |                                                                 |
|                                   |   - **Out of band:** While other tasks are running              |
|                                   |                                                                 |
|                                   | - **Mark results as note**                                      |
|                                   |                                                                 |
|                                   | - **Mark results as evidence**                                  |
|                                   |                                                                 |
|                                   | - **Run without a worker**                                      |
|                                   |                                                                 |
|                                   | - **Skip this branch if this script/playbook is unavailable**   |
|                                   |                                                                 |
|                                   | - **Quiet Mode**: When in quiet mode, tasks do not display      |
|                                   |   inputs and outputs or extract indicators. Errors and warnings |
|                                   |   are still documented. You can turn quiet mode on or off at    |
|                                   |   the task or playbook level.                                   |
+-----------------------------------+-----------------------------------------------------------------+

5.  (*Optional*) To customize the look and feel of your email message,
    click **Preview**.

- You can determine the color scheme and how the text in the message
  header and body appear, as well as the appearance and text of the
  button the user clicks to submit the survey.

6.  Click **Save**.

- The task is added in the playbook editor.

7.  Connect the tasks you\'ve added in their logical order by dragging
    and dropping a wire from one task to another.

8.  Save the playbook.

Data collection task examples

**Stand-alone question with a single-select answer**

In this example, we create a stand-alone question, with a single-select
answer. This question is not mandatory. If we selected the
**First option is default** checkbox, the reply option \"0\" is the
default value in the answer field.

![](media/rId2259.png){width="5.833333333333333in"
height="8.847222222222221in"}

**Field-based using a custom field**

In this example, we create a question based on a custom issue field that
is marked as mandatory. You can add a question based on a field. To add
a field, click the **Add Question based on field**.

![](media/rId2262.png){width="5.833333333333333in"
height="6.274073709536308in"}

######### Configure communication task authentication

When sending a form in a communication task, you can configure user
authentication to ensure only authorized users gain access to the form.

The authorized users are usually external users not in Cortex XSIAM, and
they will not be able to access anything else in Cortex XSIAM.

Set up playbook communication task authentication

1.  Set up your SSO if it is not already configured. See [Authenticate
    users using SSO](#UUID45dd7c3552d746b91bbd909c0dac5034) for more
    details.

2.  In the **Task details** of your playbook communication task, check
    **Require users to authenticate** to have your SAML or AD
    authenticate the recipient before allowing them access to the form.

- ![](media/rId2267.png){width="5.833333333333333in"
  height="8.942042869641295in"}

######### Configure NGINX as a reverse proxy to access data collection links in emails

If you are using NGINX as a reverse proxy with SSL termination,
configure the NGINX configuration file to enable accessing data
collection links in emails.

1.  Navigate to `/etc/nginx/sites-available/` and open the NGINX
    configuration file.

2.  Update the file with the following configurations:

- server {
          listen 443 ssl;
          server_name <PROXY DOMAIN>;


          ssl_certificate <path to CRT file>;
          ssl_certificate_key <path to KEY file>;
          ssl_protocols TLSv1.2 TLSv1.3;
          ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384';
          ssl_prefer_server_ciphers on;


          location / {
              proxy_pass https://<XSOAR DOMAIN>;
              proxy_cookie_domain <XSOAR DOMAIN> <PROXY DOMAIN>;
              proxy_pass_header Set-Cookie;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
              }

          } 

####### Create a section header

Section headers are used to manage the flow of your playbook and help
you organize your tasks efficiently. You create a section header to
group a number of related tasks.

1.  From the **Task Library** pane, click **Header** or **Blank Task**.

2.  In the **Task Details** pane, for **Task Type**, select the
    **Section Header** icon.

3.  Enter a meaningful name in the **Task Name** field for the section
    header.

4.  In the **Details** tab, configure the following.

    - **Tag the result with**: Add a tag to the task result. You can use
      the tag to filter entries in the War Room.

    - **Sub Section**: If selected, this section becomes a subsection of
      the parent section above it, and it collapses when its parent
      section collapses.

    - **Task description (Markdown supported)**: Provide a description
      of what this task does. In the **Playbooks** page, click
      ![](media/rId2275.png){width="0.17156824146981628in"
      height="0.20833333333333334in"} on the section header to display
      the description.

5.  In the **Timers** tab, for a time tracking header, select the action
    to take when the timer is triggered (start, stop, or pause).

    - **Timer.start**: The trigger for starting to send a message or
      survey to recipients. You can change this trigger or add a trigger
      for **Timer.stop** or **Timer.pause**. Select the trigger timer
      field from the drop down.

    - **Add Trigger**: You can add other trigger timer fields from the
      drop down.

6.  Click **Save**.

####### Configure script error handling in a playbook

You can determine how the playbook behaves if there are script errors
during execution.

When defining a standard task that uses a script or a conditional task
that uses an script, you can define how a playbook task continues by
selecting one of the following options:

- **Stop**: The playbook stops, if the task errors during execution. For
  example, if the task requires a manual review, you may want the
  playbook to stop until completion.

- **Continue**: The playbook continues to execute if the task errors.
  For example, the playbook task requires EWS, but EWS is not required
  for the playbook to proceed.

- **Continue on error path**: If a task errors, the playbook continues
  on an error path.

<!-- -->

- The error path may be useful if you want to take action on an error,
  like clean-up, retry, etc. You may also want to handle errors in
  different ways. For example, in case of a quota expired error you may
  want to retry in 1 minute, but if you receive an internal error 500,
  you may want to stop the playbook.

  You may want to create a separate path when an analyst manually
  reviews the issue and research is needed outside Cortex XSIAM. Once an
  analysis is complete, you can add a task to consider escalating to a
  customer and, if so, generate a report which can be attached to a
  ticket system such as Jira or ServiceNow.

  Instead of a playbook waiting on manual input, which displays an error
  state, such as missing an argument in a script, you can add a separate
  path for these kinds of issues.

> **Note**
>
> Use the `GetErrorsFromEntry` script (part of the Common Scripts Pack)
> to check whether the given entry returns an error and returns an error
> message. For example, when using the script in a playbook, you can
> fetch the error message from a given task, such as a runtime error.
> You can then add a step in the playbook flow to send those error
> messages to the relevant stakeholder through Slack, email, opening a
> Jira ticket, etc.

When errors are created, they are added to context under
`task.id.error`.

**How to set up error handling in your playbook**

1.  In a playbook, edit a task or create a task from the Task Library.

2.  In the **Task Details** pane, set the **Task Type** to either
    Standard or Conditional.

- > **Note**

  > You can set up script error handling only when running a script in a
  > Standard task or a Conditional task. For more information about
  > error handling settings for these tasks, see [Create a standard
  > task](#UUIDf3f760605a841f990f8696f642432496) or [Create a
  > conditional task](#UUIDcb6bdd093710d40bada11fd1d7a0cabf).

  > Built-in, Manual, and Ask Conditional tasks have **On Error**
  > settings for number of retries and retry interval, but not
  > **Error Handling**.

3.  Select a script.

4.  Click the **On Error** tab.

5.  In the **Number of retries** field, type the number of times the
    tasks attempts to run before generating an error.

6.  In the **Retry Interval (seconds)** field, type the wait time
    between retrying the task.

7.  In the **Error Handling** field, select one of the following:

    - **Stop**

    - **Continue**

    - **Continue on error path(s)**

8.  Click **Save**.

9.  When adding a connector from this task to the next task, a dialog
    box appears which enables you to select one of the following paths:

    - **Standard Path**: When adding a task to this path, it executes
      without any exceptions.

    <!-- -->

    - If you select the **Standard Path**, the task continues on this
      path and executes without exceptions.

    <!-- -->

    - **Error Path**: When adding a task to this path, it executes where
      the source task errors during execution.

    <!-- -->

    - If you select **Error path**, if the task errors, the playbook
      continues with this path.

###### Task 4. Add custom playbook features

You can customize your playbook to do the following.

+-------------------------------------------------------------------------------+-----------------------------------+
| Custom action                                                                 | Description                       |
+===============================================================================+===================================+
| [Configure a sub-playbook loop](#UUIDabee2878da723d088573af74ddd75ea4)        | Automate the execution of a       |
|                                                                               | series of actions in a            |
|                                                                               | sub-playbook loop to enable       |
|                                                                               | handling repetitive tasks         |
|                                                                               | efficiently, increasing workflow  |
|                                                                               | productivity and consistency.     |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Filter and transform data](#UUID9d30fc2a99c0ff0469e40be239b972ba)            | Filters extract relevant data to  |
|                                                                               | help focus on relevant            |
|                                                                               | information and discard           |
|                                                                               | irrelevant or unnecessary data.   |
|                                                                               |                                   |
|                                                                               | Transformers take one value and   |
|                                                                               | transform or render it to another |
|                                                                               | value or format.                  |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Use                                                                          | Perform specific automated        |
| scripts](/document/preview/1330174#UUID-15e9a063-93b4-12e0-7dd6-a02de1c74b4f) | actions using commands which are  |
|                                                                               | also used in playbook tasks and   |
|                                                                               | in the War Room.                  |
|                                                                               |                                   |
|                                                                               | Configure script error handling.  |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Extract indicators](#UUID6c8a727d63af3808a1f3cc371be497e0)                   | Extract indicators from issue     |
|                                                                               | fields and enrich them using      |
|                                                                               | commands and scripts defined for  |
|                                                                               | the indicator type.               |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Extended                                                                     | Save additional data from the raw |
| context](/document/preview/899386#UUID-34319540-a38f-dc41-0247-f0152b78172d)  | response of commands that return  |
|                                                                               | data.                             |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Update issue fields with playbook                                            | Use the **setIssue** script to    |
| tasks](#UUID093fd0cb370c7f25f92d2ba0d5a3c8c7)                                 | set and update all system issue   |
|                                                                               | fields.                           |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Create an automation rule](#UUIDf3f2283c6b1861350c2ce967e4e9017c)            | Create conditions so if an issue  |
|                                                                               | with specific characteristics is  |
|                                                                               | created, a suitable response is   |
|                                                                               | issued via a playbook.            |
+-------------------------------------------------------------------------------+-----------------------------------+
| [Use playbook polling](#UUID7350cc0d13e15a4b352bf34ba1b45057)                 | Configure a playbook to stop and  |
|                                                                               | wait for a process to complete on |
|                                                                               | a third-party product, and        |
|                                                                               | continue when it is done.         |
+-------------------------------------------------------------------------------+-----------------------------------+

###### Task 5. Test and debug the playbook

The debugger provides a test environment where you can make changes to
data and playbook logic and view the results in real-time to test and
troubleshoot playbooks. You can see exactly what is written to the
context at each step and which indicators are extracted.

For more information, see [Test your
playbook](#UUIDe8d7bd184fa0c0d595e939f9be0681b9).

###### Task 6. Manage playbook content

Manage playbook content by either using a remote repository, or by
saving versions of your playbook in Cortex XSIAM to maintain version
history. For more details, see [Manage playbook
content](#UUIDa993ff3e5060d4349bf2b208d5e0262c).

##### Customize your playbook

Customizing a playbook helps you automate tasks to match your needs,
making workflows more efficient, accurate, and easier to integrate with
your existing processes.

###### Configure a sub-playbook loop

Looping uses sub-playbooks to create loops within the main playbook.
When running the loop, the values are calculated based on the context
data for the sub-playbook and not the main playbook.

> **Note**
>
> Consider the following when adding a loop:

- > The maximum number of loops (default is 100). A high number of loops
  > or a high wait time combined with a large number of issues may
  > affect performance.

- > Periodically check looping conditions to ensure they are still valid
  > for the data set.

- > If you want a sub playbook task to loop over an array passed into
  > its input, you need to configure a loop. Otherwise it takes in the
  > whole array and runs once.

**How to create a sub-playbook loop**

1.  In the **Playbooks** page, select the parent playbook that contains
    the sub-playbook task you want to run in a loop.

2.  Right click and select **Edit**.

- If the playbook is installed from a content pack, you need to
  duplicate or detach the playbook before editing.

3.  Click the sub-playbook for which you want to create the loop.

4.  In the **Task Details** pane, click the **Loop** tab.

5.  Click one of the following options to define loop settings:

    - **None**: (Default) The sub-playbook does not loop.

    - **Built-in**: Use built-in functions to define loop settings:

+-----------------------------------+-----------------------------------+
| Option                            | Description                       |
+===================================+===================================+
| Exit when                         | Enables you to define when to     |
|                                   | exit the loop. Click {} and       |
|                                   | expand the source category. Hover |
|                                   | over the required source and      |
|                                   | click **Filter & Transform** to   |
|                                   | the left of the source to         |
|                                   | manipulate the data.              |
+-----------------------------------+-----------------------------------+
| Equals (String)                   | Select the operator to define how |
|                                   | the values should be evaluated.   |
+-----------------------------------+-----------------------------------+
| Max iterations                    | The number of times the loop      |
|                                   | should run.                       |
|                                   |                                   |
|                                   | > **Tip**                         |
|                                   | >                                 |
|                                   | > Balance between the number of   |
|                                   | > iterations and the interval so  |
|                                   | > you do not overload the server. |
+-----------------------------------+-----------------------------------+
| Sleep                             | The number of seconds to wait     |
|                                   | between iterations.               |
|                                   |                                   |
|                                   | recommends that you balance       |
|                                   | between the number of iterations  |
|                                   | and the number of seconds to wait |
|                                   | between iterations so you don\'t  |
|                                   | overload the server.              |
+-----------------------------------+-----------------------------------+

- **For each input**: Runs the sub-playbook based on defined inputs.
  Enter the number of seconds to wait between iterations.

- **Choose Loop automation**: Select the automation from the drop-down
  list to define when to exit the loop. The parameters that appear are
  applicable to the selected automation.

6.  To save the changes, click **OK**.

####### Example: Exit looping after running for all inputs

In the parent playbook (the task that contains the sub-playbook), you
can configure to exit a loop running the sub-playbook automatically when
the last item in the sub-playbook input is executed.

- If the input is a single item, the sub-playbook runs once, but if the
  input is a list of items (such as a list of issue IDs), the
  sub-playbook runs as many times as there are items in the list. Each
  iteration of the sub-playbook uses the next item in the list as the
  input.

- If there are multiple input lists with the same amount of items, the
  sub-playbook runs once for each set of inputs.

- If there are multiple input lists with different amounts of items, the
  sub-playbook runs the first set of inputs, followed by the second,
  third, and so on, until the end.

<!-- -->

- For example:

  -----------------------------------------------------------------------
  Input                               Value
  ----------------------------------- -----------------------------------
  Input x                             1,2,3,4

  Input y                             a,b,c,d

  Input z                             9
  -----------------------------------------------------------------------

- The first loop: 1, a, 9

  The second loop: 2, b, 9

  The third loop: 3, c, 9

  The fourth loop: 4, d, 9

###### Filter and transform data

In Cortex XSIAM, data is extracted and collected from various sources,
such as playbook tasks, command results, and fetched issues, and
presented in JSON format. The data can be manipulated by using filters
and transformers.

**Filters**

Filters enable you to extract relevant data which you can use elsewhere
in Cortex XSIAM. For example, if an issue has several files with varying
file types and extensions, you can filter the files by file extension or
file type, and use the filtered files in a detonation playbook. You can
filter as many objects as required. Cortex XSIAM automatically
calculates the context root to which to filter. You can change the
context root as necessary.

> **Caution**
>
> You can change the context data root to filter, but it is not
> recommended to select a different root, as it affects the filter
> results. The drop-down list displays the filter root for backward
> compatibility.

**Transformers**

Transformers modify or format data to make it suitable for further
processing or presentation. For example, you can convert a date in
non-Unix format to Unix format. Another example is applying the `count`
transformer, which renders the number of elements. When you have more
than one transformer, they apply in the order that they appear. You can
reorder them using click-and-drag.

**Add filters and transformers in a playbook task**

1.  Create or edit a playbook task.

2.  In the field you want to add a filter or transformer (for example,
    inputs or outputs), click the curly brackets and then select
    **Filters and Transformers**.

3.  In the **Get** field, type or select data you want to filter or
    transform. For example, `EWS.Items.Name`.

4.  (*Optional*) To filter the data, do the following.

    a.  In the **Filter** section, click **Add filter**.

    - When adding a filter, the context root to filter is automatically
      populated.

    b.  Select the data you want to filter.

    c.  Select the filter operators.

    d.  Add the value.

    e.  Click the checkbox to save the filter.

5.  (*Optional*) To apply transformers to the field, click
    **Add transformer**.

    a.  Click the transformer and select the relevant transformer.

    - By default, the transformer is set to `To upper case(String)`.
      Click it to pick a different transformer, for example to change
      the date format for when issues occurred.

    b.  Select the transformer operators.

    c.  Click the tick box to save.

6.  (*Optional*) To test the filter or transformation click **Test** and
    select the investigation or add it manually.

Example: Filter items with an EXE extension

In this example, we want to filter all EWS Item names that have the
extension `exe`.

![](media/rId2289.png){width="5.833333333333333in"
height="2.094016841644794in"}

1.  From the **Filters & transformers** window, in the **Get** field,
    type `EWS.Items.Name` to extract all Item names in EWS.

- The context root to filter is `EWS,Items`.

  ![](media/rId2292.png){width="5.833333333333333in"
  height="0.9244072615923009in"}

2.  In the **Filter** section, click **Add filter.**

3.  In the left-hand side, add `Extension` to the filter.

4.  Select Equals (String) \> ignore case.

5.  In the right-hand side add `exe`.

- ![](media/rId2295.png){width="5.833333333333333in"
  height="5.02372375328084in"}

6.  Click the tick box to save the filter.

7.  Click **Test**.

- You should see Item names are filtered with the extension `exe`.

Example (advanced): Filter hostname for the last resolved time

In this example, we want to see the `LastResolved` time only from the
`demisto.com` host name.

This is part of the data where we want to filter:

    {
        "IP": [
           {
            "Address": "192.168.10.96",
            "AutoFocus": {
                "Resolutions": [
                    {
                        "Hostname": "79463wwfqq,dattolocal.net",
                        "LastResolved": "2022-08-02 04:01:02"
                    },
                    {
                        "Hostname": "demisto.com",
                        "LastResolved": "2022-09-10 09:47:17"
                    },
                    {
                        "Hostname": "securesense.call4pchelp.com",
                        "LastResolved": "2022-04-22 11:49:06"
                    }
                ]
            }
           },
           {
            "Address":"192.168.10.96",
            "AutoFocus": {
                "Resolutions":[
                    {
                        "Hostname":"79463wwfqq,dattolocal.net",
                        "LastResolved":"2022-08-02 04:01:02"
                    },
                    {
                        "Hostname":"demisto.com",
                        "LastResolved":"2022-09-10 09:47:17"
                    },
                    {
                        "Hostname":"securesense.call4pchelp.com",
                        "LastResolved":"2022-04-22 11:49:06"
                    }
                ]
            }
           }
        ]
    }

1.  From the **Filters & transformers** window, in the **Get** field,
    type `IP.AutoFocus.Resolutions.LastResolve`.

- ![](media/rId2299.png){width="3.0416666666666665in"
  height="0.96875in"}

2.  In the **Filter** section, click **Add filter**.

- Cortex XSIAM automatically calculates that the context root to filter
  is `IP.AutoFocus.Resolutions`.

  ![](media/rId2302.png){width="3.34375in" height="0.375in"}

3.  In the left-hand side, add `Hostname` to the filter.

4.  Select Equals (String) \> Ends with

5.  In the right-hand side add `demisto.com`.

6.  Click the checkbox to save.

- ![](media/rId2305.png){width="3.0416666666666665in"
  height="1.6979166666666667in"}

7.  Click **Test**.

- ![](media/rId2308.png){width="2.9479166666666665in"
  height="3.3958333333333335in"}

**Create custom filters and transformers**

If you require a filter or transformer that is not provided
out-of-the-box, you can create your own by creating a script and then
adding to the operators window.

1.  Select Investigation & Response \> Automation \> Scripts \> New
    Script.

2.  Type a meaningful name for the script, and click **Save**.

3.  To create a filter operator script, do the following:

    a.  In the **Tags** field, add the `filter` tag.

    - If you want a custom transformer that operates on an entire array
      rather than on each individual item, you need to add the
      `entirelist` tag.

    b.  In the **Arguments** section, add the following arguments:

  -----------------------------------------------------------------------
  Argument                            Description
  ----------------------------------- -----------------------------------
  left                                Mark as mandatory. This argument
                                      defines the left-side value of the
                                      transformer operation. In this
                                      example, this is the value being
                                      checked if it falls within the
                                      range specified in the right-side
                                      value.

  right                               Mark as mandatory. This argument
                                      defines the right-side value of the
                                      transformer operation. In this
                                      example, this is the range to check
                                      if the left-side value is in.
  -----------------------------------------------------------------------

c.  Add the script syntax and save.

<!-- -->

4.  To create a transformer operator script do the following:

    a.  In the **Tags** field, add the `transformer` tag.

    b.  In the **Arguments** section, add the following arguments:

  -----------------------------------------------------------------------
  Argument                            Description
  ----------------------------------- -----------------------------------
  value                               Mark as mandatory. The value to
                                      transform. In this example, this is
                                      the UNIX epoch timestamp to convert
                                      to ISO format.

  -----------------------------------------------------------------------

c.  Add the script syntax and save.

<!-- -->

5.  Go to the filters and transformers window and select the operator.

####### Filter considerations, categories, and built-in filters

You can use built-in filters to define your filter, they are grouped by
category. Before defining a filter, consider the following.

######## Filter considerations

- Filters try to cast the transformed value and arguments to the
  appropriate type. The task fails if casting fails. For example, "a"
  Equals {"some": "object"} =\> Error

- If the filter\'s left-side value expects a single item but receives a
  list, the filter passes if at least one item meets the requirements.
  For example, \["a", "b", "c"\] Equals "b" =\> true.

- If the filter\'s left-side value expects a list but receives a single
  item, it converts it to a list with a single item. For example, "a"
  Contains "a" =\> True.

- Some custom filters are implemented as scripts with the `filter` tag.
  You can find examples in the playbook automation task description.

- Filters in conditional tasks do not iterate the items of the root.
  Instead, they fetch the left-side value and the right-side value and
  compare them.

######## Filter categories and built-in filters

When adding a filter, clicking the default **Equals (String)** field
opens a search window showing the available built-in filters. They are
defined by category as follows:

######### General

General filters such as Contains, Doesn't Contain, In, and Is empty.

+-----------------------------------+-----------------------------------+
| Filter                            | Description                       |
+===================================+===================================+
| Contains                          | Tests whether the value on the    |
|                                   | left is contained in the value on |
|                                   | the right. Can be used for any    |
|                                   | kind of object (not limited to a  |
|                                   | string).                          |
+-----------------------------------+-----------------------------------+
| Doesn\'t Contain                  | Tests whether the value on the    |
|                                   | left is NOT contained in the      |
|                                   | value on the right. Can be used   |
|                                   | for any kind of object (not       |
|                                   | limited to a string).             |
+-----------------------------------+-----------------------------------+
| Has length of                     | Tests whether a list specified on |
|                                   | the left has the number of items  |
|                                   | specified on the right.           |
+-----------------------------------+-----------------------------------+
| In                                | Tests whether the value on the    |
|                                   | left is contained in the object   |
|                                   | on the right.                     |
+-----------------------------------+-----------------------------------+
| Is defined                        | Tests whether a key on the left   |
|                                   | exists in context.                |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > `Is defined` considers false    |
|                                   | > and empty strings and lists to  |
|                                   | > be defined values. If you       |
|                                   | > don\'t want those to be         |
|                                   | > included as defined, use        |
|                                   | > `Is not empty`.                 |
+-----------------------------------+-----------------------------------+
| Is empty                          | Tests whether the value of a key  |
|                                   | is empty.                         |
+-----------------------------------+-----------------------------------+
| Is not empty                      | Tests whether the value of a key  |
|                                   | is NOT empty.                     |
+-----------------------------------+-----------------------------------+
| Not defined                       | Tests whether a key on the left   |
|                                   | does NOT exist in context.        |
|                                   |                                   |
|                                   | > **Note**                        |
|                                   | >                                 |
|                                   | > `Not defined` considers false   |
|                                   | > and empty strings and lists to  |
|                                   | > be defined values. If you       |
|                                   | > don\'t want those to be         |
|                                   | > included as defined, use        |
|                                   | > `Is empty`.                     |
+-----------------------------------+-----------------------------------+
| Not in                            | Tests whether the value on the    |
|                                   | left is NOT contained in the      |
|                                   | object on the right.              |
+-----------------------------------+-----------------------------------+

######### String

Determines the relationship between the left-side string value and the
right-side string value, such as starts with, includes, and in the list.
The string filter returns partial matches as True.

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  Doesn\'t end with                   Tests whether the string on the
                                      left is NOT the end of the string
                                      on the right.

  Doesn\'t equal                      Tests whether the strings are NOT
                                      the same.

  Doesn\'t include                    Tests whether the string on the
                                      right is NOT a substring of the
                                      string on the left.

  Doesn\'t start with                 Tests whether the string on the
                                      right is NOT the beginning of the
                                      string on the left.

  Ends with                           Tests whether the string on the
                                      left is the end of the string on
                                      the right.

  Equals                              Tests whether the strings are the
                                      same.

  Has length                          Tests whether the two strings have
                                      the same length.

  In list                             Tests whether the string on the
                                      left is in the list on the right.

  Includes                            Tests whether the string on the
                                      right is a substring of the string
                                      on the left.

  Matches - regex                     Tests whether the string on the
                                      left matches the regex on the
                                      right. Uses Go-style regex.

  Not in list                         Tests whether the string on the
                                      left is NOT a substring of the
                                      string on the right.

  Starts with                         Tests whether the string on the
                                      right is the beginning of the
                                      string on the left.

  StringContainsArray                 Tests whether a substring or an
                                      array of substrings on the left is
                                      within a string array on the right.
                                      Supports single strings as well.
                                      For example, for substrings
                                      \[\'a\', \'b\', \'c\'\] in string
                                      \'a\' the script returns true.
  -----------------------------------------------------------------------

######### Number

Determines the relationship between the left-side number value and the
right-side number value, such as Equals, Greater than, and Less than.

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  Doesn\'t equal                      Tests whether the number on the
                                      left does NOT equal the number on
                                      the right.

  Equals                              Tests whether the number on the
                                      left equals the number on the
                                      right.

  Greater or equal                    Tests whether the number on the
                                      left is greater than or equal to
                                      the number on the right.

  Greater than                        Tests whether the number on the
                                      left is greater than the number on
                                      the right.

  InRange                             Tests whether the number on the
                                      left is within a range specified on
                                      the right. For example, if the left
                                      value is 4, and the range on the
                                      right is 1,8, the condition is
                                      true.

  Less or equal                       Tests whether the number on the
                                      left is less than or equal to the
                                      number on the right.

  Less than                           Tests whether the number on the
                                      left is less than the number on the
                                      right.
  -----------------------------------------------------------------------

######### Date

Determines whether the left-side time value is earlier than, later than,
or the same time as the right-side time value.

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  After                               Tests whether the date on the left
                                      is after the date on the right.

  AfterRelativeDate                   Tests whether the date on the left
                                      occurred after the provided
                                      relative time (such as \'6 months
                                      ago\') on the right. Returns True
                                      or False.

  Before                              Tests whether the date on the left
                                      is before the date on the right.

  Same as                             Tests whether the two dates are the
                                      same.
  -----------------------------------------------------------------------

Supported time and date formats

  -------------------------------------------------------------------------
  Format                              Example
  ----------------------------------- -------------------------------------
  ANSIC                               Tues Jan \_2 15:04:05 2019

  UnixDate                            Tues Jan \_2 15:04:05 MST 2019

  RubyDate                            Tues Jan 02 15:04:05 -0700 2019

  RFC822                              02 Jan 19 15:04 MST

  RFC822Z                             02 Jan 19 15:04 -0700 // RFC822 with
                                      numeric zone

  RFC850                              Tuesday, 02-Jan-19 15:04:05 MST

  RFC1123                             Tues, 02 Jan 2019 15:04:05 MST

  RFC1123Z                            Tues, 02 Jan 2019 15:04:05 -0700 //
                                      RFC1123 with numeric zone

  RFC3339                             2019-01-02T15:04:05Z07:00

  RFC3339Nano                         2019-01-02T15:04:05.999999999Z07:00

  Kitchen                             3.04PM

  Stamp                               Jan \_2 15:04:05

  StampMilli                          Jan \_2 15:04:05.000

  StampMicro                          Jan \_2 15:04:05.000000

  StampNano                           Jan \_2 15:04:05.000000000
  -------------------------------------------------------------------------

######### Boolean

Determines whether a field is true or false, or the string
representation is true or false.

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  Is false                            Tests whether the value on the left
                                      evaluates to false.

  Is true                             Tests whether the value on the left
                                      evaluates to true.
  -----------------------------------------------------------------------

######### Other

Miscellaneous filters, including CheckIfSubdomain and IsInCidrRanges.

  -----------------------------------------------------------------------
  Filter                              Description
  ----------------------------------- -----------------------------------
  CheckIfSubdomain                    Tests whether the value on the left
                                      is a subdomain of the value on the
                                      right.

  CIDRBiggerThanPrefix                Tests whether the CIDR prefix on
                                      the left is bigger than the defined
                                      maximum prefix on the right.

  GreaterCidrNumAddresses             Tests whether the number of
                                      available addresses in IPv4 or IPv6
                                      CIDR on the right is greater than
                                      the input given on the left.

  IsInCidrRanges                      Tests whether the IPv4 address on
                                      the left is contained in at least
                                      one of the comma-delimited CIDR
                                      ranges on the right. Multiple IPv4
                                      addresses can be passed in a
                                      comma-delimited list and each
                                      address is tested.

  IsNotInCidrRanges                   Tests whether the IPv4 address on
                                      the left is NOT contained in at
                                      least one of the comma-delimited
                                      CIDR ranges on the right. Multiple
                                      IPv4 addresses can be passed in a
                                      comma-delimited list and each
                                      address is tested.

  IsRFC1918Address                    Tests whether an IPv4 address on
                                      the left is in the private RFC-1918
                                      address space (10.0.0.0/8,
                                      172.16.0.0/12, 192.168.0.0/16) on
                                      the right.

  LowerCidrNumAddresses               Tests whether the number of
                                      available addresses in IPv4 or IPv6
                                      CIDR on the right is less than the
                                      input given on the left.
  -----------------------------------------------------------------------

####### Transformer considerations, categories, and built-in transformers

You can use built-in transformers to define your transformer, they are
grouped by category. Before defining a transformer, consider the
following.

######## Transformer considerations

- Transformers try to cast the transformed value (and arguments) to the
  necessary type. Tasks will fail if casting has failed, for example
  `{“some”: “object”}` To upper case =\> `Error`.

- Some transformers are applied on each item of the result. For example,
  `a, b, c` To upper case =\> `A, B, C`.

- Some transformers operate on the entire list. For example, `a, b, c`
  **count** =\> `3`.

- Some custom transformers are implemented as scripts with the
  `transformer` tag. You can find examples in the playbook automation
  task description.

######## Transformer categories and built-in transformers

When adding a transformer, clicking the default
**To upper case (String)** field opens a search window showing the
available built-in transformers. They are defined by category as
follows.

+-----------------------+------------------------+---------------------------------------------------------------------------------------------------------+
| Transformer category  | Description            | Built-in transformers                                                                                   |
+=======================+========================+=========================================================================================================+
| General               | Generic transformers   | NameDescriptionExampleUniqueReturns a de-duped version of a list.`a, b, a, c, d, a, b` =\>              |
|                       |                        | `a, b, c, d`SliceReturns part of a specified list in a range of `from` index (included) through `to`    |
|                       |                        | index (not included)`from`: Zero based index at which to begin extraction (default: 0).`to`: Zero based |
|                       |                        | index before which to end extraction (default: list length).`a, b, c, d` from: `1,` to: `3`=\>          |
|                       |                        | `b, c`Slice by itemReturns part of a list specified in a range of from item (included) through to item  |
|                       |                        | (not included).`from`: Item from which to begin the extraction. If not specified, extracts from the     |
|                       |                        | beginning of the list.`to`: Item before which to end the extraction. If not specified, extracts from    |
|                       |                        | the end of the list.`a, b, c, d` from: `b, to: d` =\> `b, c`SortSorts an entire list. Supports strings  |
|                       |                        | and numbers.descending: `true` to sort in descending order, default is false.`b, c, a` =\>              |
|                       |                        | `a, b, c``2.1, 1.2, 3.4` descending: `true`=\> `3.4, 2.1, 1.2`Get indexGet item at the given            |
|                       |                        | index.`index`: Index of the item to get.`b, c, a` index: `0` =\>`b``b, c, a` index `-1` =\>             |
|                       |                        | `nil`SpliceAdds or removes items to/from an array.`index`: (required) Zero-based index at which to      |
|                       |                        | begin add/remove items.`deleteCount`: Number of elements to remove from 'index', default is 0.`item`:   |
|                       |                        | Item to add to the array after 'index' position.`a, b, c, d,`index: `1` deleteCount: `2`=\>             |
|                       |                        | `a, d``a, b, c, d,` index: `2` item: `w`=\> `a, b, c, w, d`Index ofReturns the first index of the       |
|                       |                        | element in the array, or -1 if not found.`item`: Item to locate in the array.`fromLast`: `true` to get  |
|                       |                        | the index from last. (default is false).`a, b, a, c, d, a, b,` item: `b`=\> `1``a, b, a, c, d, a, b,`   |
|                       |                        | item: `a` fromLast: `true`=\> `5``a, b, a, c, d, a, b,` item: `w`=\> `-1`Get fieldExtracts a given      |
|                       |                        | field from the given object.`field`: (required) The field to extract from the                           |
|                       |                        | result`{“name”: “john”, “color”: “white”} field: “color”` "white"StringifyConverts the given item to a  |
|                       |                        | string.`{ “name”:“john”, “color”: “white” }` =\>`‘{“name”:“john”,“color”:“white”}’`CountReturns the     |
|                       |                        | number of elements.`b, c, a` =\> `3``null` =\> `0``a` =\> `1`JoinConcatenates all elements.`separator`: |
|                       |                        | Specifies a string to separate each pair of adjacent elements of the array, default is an empty         |
|                       |                        | string.`b, c, a`separator: `,`=\> `b,c,a``b, c, a`=\> `bca`                                             |
+-----------------------+------------------------+---------------------------------------------------------------------------------------------------------+
| String                | String transformers    | NameDescriptionExamplereplace matchReturns a string with some or all matches of a regex pattern, and    |
|                       |                        | replaces with a specified string.regex: A regex pattern to be replaced by the replaceWith               |
|                       | > **Note**             | argument.replaceWith: The string that replaces the string specified in the toReplace argument, default  |
|                       | >                      | is an empty string.Detailed RegEx syntax can be found at                                                |
|                       | > To make regex case   | <https://github.com/google/re2/wiki/Syntax>.`pluto,is,not,a,planet regex: “,” replaceWith: “;”`         |
|                       | > non-sensitive, use   | =\>`“pluto;is;not;a;planet”``“pluto is not a planet”` regex `.*to` replaceWith `vega`=\>                |
|                       | > the `(?i)` prefix    | `vega is not a planet`SubstringReturns a subset of a string between one index and another, or through   |
|                       | > (for example         | the end of the string.from (required): An integer between 0 and the length of the string, specifying    |
|                       | > `(?i)yourRegexText`. | the offset into the string of the first character to include in the returned substring.to (optional):   |
|                       |                        | An integer between 0 and the length of the string, which specifies the offset into the string of the    |
|                       |                        | first character not to include in the returned substring.`pluto is not a planet`from:`4`to: `10` =\>    |
|                       |                        | `o is n`"SplitSplits a string into an array of strings, using a specified delimiter string to determine |
|                       |                        | where to make each split.delimiter: Specifies the string which denotes the points at which each split   |
|                       |                        | should occur, default delimiter is`,`.`hello world,bye bye world` =\>                                   |
|                       |                        | `hello world, bye bye world``hello world`delimiter=\> `hello, world`Split & trimSplits a string into an |
|                       |                        | array of strings and removes whitespace from both ends of the string, using a specified delimiter       |
|                       |                        | string to determine where to make each split.Argumentsdelimiter: Specifies the string which denotes the |
|                       |                        | points at which each split should occur (default delimiter is`”,”)`.`hello & world` delimiter: `&` =\>  |
|                       |                        | `hello, world`From stringReturns a subset of a string from the first from string occurrence.from        |
|                       |                        | (required): String to substring from.`pluto is not a planet` from: `pluto is` =\> `not a planet`To      |
|                       |                        | stringReturns a subset of a string until the first to string occurrence.to (required): String to        |
|                       |                        | substring until.`pluto is not a planet`to: `a planet` =\> `pluto is not`concatReturns a string          |
|                       |                        | concatenated with given prefix and suffix.prefix: A prefix to concat to the start of the                |
|                       |                        | argument.suffix: A suffix to concat to the end of the argument.`night` prefix `good` =\>                |
|                       |                        | `good night``night` suffix `shift`=\> `night shift`                                                     |
+-----------------------+------------------------+---------------------------------------------------------------------------------------------------------+
| Number                | Number transformers    | NameDescriptionExampleFloorReturns the highest integer less than or equal to the number.`1.2`=\>        |
|                       |                        | `1`CeilReturns the lowest integer greater than or equal to the number.`1.2` =\>`2`RoundReturns the      |
|                       |                        | nearest integer, rounding half way from zero.`7.68` =\> `8``2.43` =\> `2``2.5` =\> `3`AbsoluteReturns   |
|                       |                        | the absolute value of the given number.`-2` =\> `2`Decimal precisionTruncates the number of digits      |
|                       |                        | after the decimal point, according to the by argument.by: Number of digits to keep after the decimal    |
|                       |                        | point, default is 0.`8.6666` by: `2` =\> `8.66`Modulus (remainder)The modular operator (%) returns the  |
|                       |                        | division remainder.by (required): Modulo by, default:0`20` by: `3`=\> `2`To percentConverts a number to |
|                       |                        | a percent.withsign: Specify true to include %. Default is false`0.22` =\> `20``0.22` withsign: `true`   |
|                       |                        | =\>`20%`Quadratic equationReturns the result of the Quadratic Formula.b (required): The b number of:    |
|                       |                        | ax2 + bx + c = 0, default is 0.c (required): The c number of: ax2 + bx + c = 0, default is 0.`1` b: `3` |
|                       |                        | c: `2`=\> `-1.00, -2.00``3` b: `2` c: `4`=\> `(-0.333 +1.106i), (-0.333 -1.106i)`                       |
+-----------------------+------------------------+---------------------------------------------------------------------------------------------------------+
| Date                  | Date transformers      | NameDescriptionExampleDate to stringConverts any date to a specified string format. The date input must |
|                       |                        | be in ISO format. For example, `2021-10-06T13:44:07`. The default output format is RFC822.`format:` The |
|                       |                        | desired string output format. For example, if you want to convert to RFC822 format, enter               |
|                       |                        | `02 Jan 06 15:04 MST`.The following are available output format options:Layout =                        |
|                       |                        | `01/02 03:04:05PM '06 -0700` // The reference time, in numerical orderRFC3339Nano =                     |
|                       |                        | `2006-01-02T15:04:05.999999999Z07:00`Kitchen = `3:04PM` // Handy time stampsStamp =                     |
|                       |                        | `Jan _2 15:04:05`StampMilli = `Jan _2 15:04:05.000`StampMicro = `Jan _2 15:04:05.000000`StampNano =     |
|                       |                        | `Jan _2 15:04:05.000000000`This transformer is in [GO](https://pkg.go.dev/time)                         |
|                       |                        | language.`2021-10-06T13:44:07 => 06 Oct 21 13:44 EDT`Date to UnixConverts any date to Unix              |
|                       |                        | format.`Mon, 02 Jan 2006 15:04:05 MST` =\> `1136214245`FormatExampleANSICTues Jan \_2 15:04:05          |
|                       |                        | 2019UnixDateTues Jan \_2 15:04:05 MST 2019RubyDateTues Jan 02 15:04:05 -0700 2019RFC82202 Jan 19 15:04  |
|                       |                        | MSTRFC822Z02 Jan 19 15:04 -0700 // RFC822 with numeric zoneRFC850Tuesday, 02-Jan-19 15:04:05            |
|                       |                        | MSTRFC1123Tues, 02 Jan 2019 15:04:05 MSTRFC1123ZTues, 02 Jan 2019 15:04:05 -0700 // RFC1123 with        |
|                       |                        | numeric                                                                                                 |
|                       |                        | zoneRFC33392019-01-02T15:04:05Z07:00RFC3339Nano2019-01-02T15:04:05.999999999Z07:00Kitchen3.04PMStampJan |
|                       |                        | \_2 15:04:05StampMilliJan \_2 15:04:05.000StampMicroJan \_2 15:04:05.000000StampNanoJan \_2             |
|                       |                        | 15:04:05.000000000                                                                                      |
+-----------------------+------------------------+---------------------------------------------------------------------------------------------------------+

###### Extract indicators

In Cortex XSIAM, the indicator extraction feature extracts indicators
from issue fields and enriches them using commands and scripts.

For more information about indicator extraction, see [Extract and enrich
an indicator](#UUID2d878fe6eedc065f07c1b8c788966634).

**How to set up indicator extraction in a playbook task**

1.  Select the playbook where you want to add indicator extraction, and
    click **Edit**.

2.  In the playbook, click a task to open the **Task Details** pane.

3.  Click the **Advanced** tab.

4.  For **Indicator Extraction mode**, select the mode you want to use
    (default is none).

5.  Click **OK**.

The following scenario shows how indicator extraction is used in the
**Process Email - Generic v2** playbook to extract and enrich a very
specific group of indicators.

This playbook parses the headers in the original email used in a
phishing attack. It is important to parse the original email used in the
phishing attack and not the email that was forwarded to ensure that you
only extract the email headers from the malicious email and not the one
your organization uses to report phishing attacks.

1.  Navigate to the **Playbooks** page and search for the
    **Process Email - Generic v2** playbook.

2.  Click ![](media/rId2196.png){width="0.18055555555555555in"
    height="0.20833333333333334in"} and select either **Duplicate**
    (create a copy of the playbook to edit) or **Edit Playbook** (detach
    the playbook).

3.  Open the **Add original email details to context** task, and for the
    **Script** drop down, change the script from **Set** to
    **ParseEmailFilesV2**.

- Under the **Outputs** tab, you can see all of the different data that
  the task extracts.

  ![](media/rId2330.png){width="5.833333333333333in"
  height="8.38923775153106in"}

4.  Click the **Advanced** tab and set **Indicator Extraction mode** to
    `Inline`. This ensures all the outputs are processed before the
    playbook moves ahead to the next task.

5.  Open the **Display email information in layout - Email.Headers**
    task. This task receives the data from the saved attachment tasks
    and sets the various data points to context.

6.  Click the **Advanced** tab and set **Indicator Extraction mode** to
    `None` , because the indicators were already extracted earlier in
    the **Extract email artifacts and attachments** task and there is no
    need to extract them again.

####### Indicator extraction modes

Indicator extraction supports the following modes:

- **None:** Indicators are not extracted automatically. Use this option
  when you do not want to further evaluate the indicators.

- **Inline:** Indicators are extracted within the context that indicator
  extraction runs (synchronously). The findings are added to the context
  data. For example, if indicator extraction for a playbook task is
  inline, extraction occurs before the next playbook tasks run.

<!-- -->

- > **Note**

  > This configuration may delay playbook execution (issue creation).

  > While indicator creation is asynchronous, indicator extraction and
  > enrichment are run synchronously. Data is placed into the issue
  > context and is available via the context for subsequent tasks.

<!-- -->

- **Out of band:** Indicators are extracted in parallel (asynchronously)
  to other actions. The extracted data will be available within the
  issue, however, it is not available for immediate use in task inputs
  or outputs because the information is not available in real-time.

<!-- -->

- > **Note**

  > When using out of band, the extracted indicators do not appear in
  > the context. If you want the extracted indicators to appear select
  > inline.

<!-- -->

- If system-wide indicator extraction is enabled, indicators are
  extracted according to the following rules:

  - Issue creation - inline

  - Issue field change - inline

  - Tasks - none, can be overridden on a per task basis

  - CLI - out of band, but can be overridden on a per-command basis

####### Troubleshoot indicator extraction

If indicators are not extracted, check whether the indicator mode is set
to none. Even if you select the relevant issue fields and the indicators
to extract, if the mode is set to none, indicators do not extract.

###### Extend context

By design, integrations do not write all of the data returned from a
command to the context. This prevents large context size and enables you
to store only the most relevant information.

The Extend Context feature enables you to save additional data from the
raw response of the command. For example, when a command runs to
retrieve events from a SIEM, only some of the event fields are written
to context, according to the integration design. With Extend Context,
you can save additional fields specific to your use case.

Extend Context can also be used when the same command runs multiple
times in the same playbook, but the outputs need to be saved to
different context keys. For example, you can execute the `!ad-get-user`
command twice, once to retrieve the user\'s information and again to
retrieve the user\'s manager's information. By default, an integration
command writes the data from the same command to the same context key.
By using Extend Context, you can write the command's response to a
custom context key of your choice.

You can extend context either in a playbook task or directly from the
command line. Whichever method you use, first run your command with the
`raw-response=true` flag. This helps you identify the information that
you want to add to your extended data.

**Filter for specific keys from lists of dictionaries**

You can use DT to get select keys of interest from a command that
returns a list of dictionaries containing many keys. For example, the
`findIndicators` automation returns a long list of indicator properties,
but you may only be interested in saving the value and the
indicator_type to minimize the size of the context data. For more
information about DT, [see Cortex XSOAR Transform Language
(DT)](https://xsoar.pan.dev/docs/integrations/dt).

1.  Run the command
    `!findIndicators size=2 query="type:IP" raw-response=true`.

- You will see a list of two dictionaries containing 20+ items.

2.  Use the following value for extend-context to save
    only value and indicator_type into a context key
    called FoundIndicators:

- !findIndicators size=2 query="type:IP" extend-context=`FoundIndicators=.={"value": val.value, "indicator_type": val.indicator_type}`

3.  Use the following value for extend-context to save only the issue
    name, status, and id to a key called FoundIssues:

- !SearchIssuesV2 id=<ANY_ISSUE_ID> extend-context=`FoundIssues=Contents.data={"name": val.name, "status": val.status, "id": val.id}` ignore-outputs=true

####### Extend context in a playbook task

1.  Go to the **Advanced** tab of the relevant playbook task, such as a
    Data Collection task.

2.  In the **Extend Context** field, enter the name of the field in
    which you want the information to appear and the value you want to
    return. For example, using the `!ad-get-user` command, enter
    `name="john" attributes=displayname` to place the user\'s name in
    the `displayName` key.

- The following image shows the result of the
  `!IPReuptation ip=20.8.1.5 raw-response=true` command.

  ![](media/rId2339.png){width="5.833333333333333in"
  height="7.5241535433070865in"}

  To include more than one field, separate the fields with a double
  colon. For example:
  `attributes=displayName::manager=attributes.manager`

3.  To output only the values for Extend context and ignore the standard
    output for the command, select the **Ignore Outputs** checkbox.

- While this will improve performance, only the values that you request
  in the **Extend Context** field are returned. You cannot use Field
  Mapping as there is no output to which to map the fields.

####### Extend context using the CLI

1.  Run your command with the extend-context flag
    `!<commandName><argumentName> <value>extend-context=contextKey=JsonOutputPath`.

- For example, to add the user and manager fields to context use the
  ad-get-user command, as follows:

  `!ad-get-user=${user.manager.username} extend-context=manager=attributes.manager::attributes=displayName`

2.  To output only the values that you set as Extend context, run the
    command with the ignore-ouput flag=true.
    `!ad-get-user=${user.manager.username} extend-context=manager=attributes.manager::attributes=displayName ignore-output=true`

###### Update issue fields with playbook tasks

During the investigation you can set and update issue fields using the
**setIssue** script in a playbook task.

You initially define issue fields after the planning stage, with mapping
and classification for how the issues will be ingested from third-party
integrations into Cortex XSIAM.

> **Note**

- > The **setIssue** script includes all available fields; use the
  > scroll bar to see all the fields.

- > The `name` field has a limit of 600 characters. If there are more
  > than 600 characters, you can shorten the `name` field to under 600
  > characters and then include the full information in a long text
  > field such as the `description` field.

- > There are many ﬁelds already available as part of the Common Type
  > content pack. Before creating a new issue field, check if there is
  > an existing ﬁeld that matches your needs.

For more information, see [Update issue
fields](#UUIDaf219191200cbe7ea66a8d2683888253)

###### Playbook polling

When working with third-party products (such as detonation, scan,
search, and other third-party products) you may need to wait for a
process to finish on the remote host before continuing. In these cases,
the playbook should stop and wait for the process to complete on the
third-party product, and continue when it is done. Integrations or
automations may not be able to do this due to hardware limitations.

Generally, polling is used in the following scenarios:

- File detonation in a sandbox

- URL detonation

- Queries that take a long time to complete

To use polling, Cortex XSIAM comes out-of-the-box with the
**GenericPolling** playbook, which periodically polls the status of a
process being executed on a remote host, and when the host returns that
the process execution is done, the playbook finishes execution. For more
information about using this playbook, see [Generic
Polling](https://xsoar.pan.dev/docs/playbooks/generic-polling).

The **GenericPolling** playbook is used as a sub-playbook to block the
execution of the main playbook until the remote action is complete.
There are a number of playbooks that use the **GenericPolling** playbook
that come out-of-the-box or installed from a content pack, such as:

- [Contex Polling -
  Generic](https://xsoar.pan.dev/docs/reference/playbooks/context-polling---generic):
  Polls a context key to check if a specific value exists.

- [Field Polling -
  Generic](https://xsoar.pan.dev/docs/reference/playbooks/field-polling---generic):
  Polls a field to check if a specific value exists.

- [Scan Site -
  Nexpose](https://xsoar.pan.dev/docs/reference/playbooks/scan-site-nexpose):
  Scans according to asset IP addresses or host names from Rapid7
  Nexpose, and waits for the scan to finish by polling the scan status
  in pre-defined intervals.

> **Note**
>
> You need to use the **GenericPolling** playbook as a sub-playbook in a
> main playbook, such as **Detonate File - JoeSecurity**.
>
> The main playbook should follow this structure:

1.  > **Start Command**: The task contains a command that fetches the
    > initial state of the process and saves it to context. This command
    > starts the process that should be polled. For example:

- > Detonation: Submits a sample for analysis (detonated as part of the
  > analysis), using the `joe-analysis-submit-sample` command.

  > Scan: Starts a scan for specified asset IP addresses and host names
  > using the `nexpose-start-assets-scan` command.

  > Search: Searches in QRadar using AQL using the `qradar-searches`
  > command.

2.  > **Polling Command**: The task contains the **GenericPolling**
    > sub-playbook that polls for an answer. For example:

    - > Detonation: After the file is submitted to Joe Security, the
      > playbook polls for specific information for analysis, such as
      > ID, status, comments, errors, SHA-256 hash details.

    - > Scan: After the scan runs in Nexpose, using the playbook polls
      > for scan information such as the scan type, the number of assets
      > found, the scan ID, and other information.

    - > Search: The playbook runs the `qradar-get-search` to poll for
      > the search ID and status.

3.  > **Results Task**: Returns the results of the operation. The task
    > contains the results that were polled, which are added to context.
    > For example, after polling JoeSecurity, the results are added to
    > context.

> For information about the **GenericPolling** playbook inputs such as
> Ids, Interval, and dt, see [Playbook
> inputs](https://xsoar.pan.dev/docs/reference/playbooks/generic-polling#playbook-inputs).

This generic polling example uses the **Detonate File - JoeSecurity**
playbook from the **Joe Security** content pack.

The **Detonate File - JoeSecurity** playbook detonates one or more files
using the [Joe
Security](https://xsoar.pan.dev/docs/reference/integrations/joe-security)
integration and returns relevant reports to the War Room and file
reputations to the context data.

1.  If you have not done so, go to Marketplace and download the Joe
    Security content pack.

2.  Go to **Playbooks** and search for **Detonate File - JoeSecurity**.

3.  Open the **JoeSecurity Upload File** task. This task uses the
    `joe-analysis-submit-sample` command, which starts a new analysis of
    a file in Joe Security. This is the **Start** command.

4.  Open the **GenericPolling** task. This is the **Polling** command.

    - **Ids**: Returns a list of `Joe.Analysis.ID`'s to poll.

    - **PollingCommandName:** The `joe-analysis-info` command returns
      information for a specified analysis, such as status, MD5, SHA256,
      vendor.

    - **PollingCommandArgName:** The `webid` argument name of the
      polling command.

    - **dt**: The filter for polling. This is defined as
      `Joe.Analysis(val.Status!==’finished’).ID`.

    <!-- -->

    - `Joe.Analysis`: The object to return.

      `(val.Status !==‘finished’).ID` Gets the object that has a status
      other than 'finished', and then gets its ID field. The polling is
      done only when the result is `finished`. When finished, the `dt`
      filter returns an empty result, which triggers the playbook to
      stop running.

      You can change the `Status` to: `starting`, `running`, or
      `finished`.

      ![](media/rId2352.png){width="5.833333333333333in"
      height="6.819248687664042in"}

5.  Open the **JoeSecurity Get Info** task. The `joe-analysis-info`
    command returns details of the IDs that have finished polling. This
    is the **Results** task.

6.  Open the **Set Context** task. The context path to store the poll
    results is `Joe.Analysis`.

####### **GenericPolling** playbook limitations

The **GenericPolling** playbook has the following limitations.

- **Global context** is not supported.

<!-- -->

- Global context outputs enable receiving information from multiple
  integrated products when executing playbooks and commands.

<!-- -->

- It does not run from the **Playground**.

- It uses the **ScheduleGenericPolling** script, which must support a
  list argument.

<!-- -->

- ![](media/rId2356.png){width="5.833333333333333in"
  height="2.2262849956255466in"}

####### Troubleshoot playbook polling

The following are common generic polling issues and the recommended ways
to deal with them.

- The playbook is "stuck" on `Waiting for polling to complete`.

<!-- -->

- As generic polling schedules tasks are outside the context of the
  playbook (not visible in the playbook run), errors may appear only in
  the **Case War Room**. Go to the War Room of the case and check for
  errors or warnings related to GenericPolling tasks.

<!-- -->

- The GenericPolling task completes but the status has still not
  \"finished\".

<!-- -->

- If the timeout is reached, the playbook successfully finishes even if
  there are items that did not complete. Try increasing the timeout
  value for the GenericPolling task.

<!-- -->

- The integration returns an ID not found error when running from the
  GenericPolling sub-playbook, but when running manually, it finishes
  successfully.

<!-- -->

- Some products cannot handle consecutive requests to query an action
  status right after the request to perform the action. After you
  initiate the action, try adding a Sleep task before calling the
  GenericPolling sub-playbook.

##### Test your playbook

The debugger provides a test environment where you can make changes to
data and playbook logic and view the results in real-time to test and
troubleshoot playbooks. You can see exactly what is written to the
context at each step and which indicators are extracted.

To open a detached system playbook, a copy of a system playbook, or a
custom playbook in the debugger, select the playbook and click **Edit**.

To open an attached playbook in the debugger, select the playbook and
click **View** to access the debugger. While editing a playbook,
sub-playbooks can be opened directly in the debugger by choosing
**Open sub-playbook** in the task pane.

In some cases, you may have a playbook that includes two or more copies
of the same sub-playbook. When you set breakpoints, override inputs or
outputs, or skip tasks in sub-playbook A, the same changes apply to the
identical sub-playbook B. In addition, if you set a breakpoint, override
inputs or outputs, or skip tasks within a loop in a playbook, that
setting will be applied every time the loop executes.

Running the debugger involves the following actions.

###### Choose test data

The debugger uses test data to execute the playbook, so you can see what
your expected results would be. The following are options for test data.

> **Note**
>
> The debugger does not support using `parentIncidentFields`.

1.  **New Mock Issue:** By default, the debugger runs using an empty
    mock issue. An empty mock issue is useful to test simple
    functionality, such as a playbook that does simple tasks such as
    parsing inputs.

2.  **Playground:** You can load the contents of the Playground as test
    data, enabling you to use uploaded files and custom context data for
    testing purposes.

3.  **Existing Issue:** You can select an existing issue. For example,
    when debugging a phishing playbook, you might want to use an
    existing phishing issue that came from the mail listener
    integration. Using an existing issue in the debugger does not change
    the original issue. Click the **Debugger Panel** and in the
    **Test data** field, select an existing issue. The last fifty issues
    appear in the drop-down, as well as any issues you own or are a
    member of, or that you have participated in.

- > **Note**

  > Using an existing issue in the debugger does not affect the original
  > issue or change the original context data.

###### Set a breakpoint

At the breakpoint, you can override inputs and outputs to see how
changes affect playbook execution. In addition, conditional breakpoints
set conditions for the playbook to proceed. The playbook only pauses if
your condition is met, letting you manipulate data to see how different
scenarios impact how the playbook runs. For example, you can set a
conditional breakpoint to pause the playbook when a phishing issue
targets a member of a VIP asset list. If there are no VIPs in this
issue, the execution does not pause. If there is a VIP in the issue, you
can check that the member was properly identified by the playbook task.

Breakpoints do not apply to manual tasks, as a manual task will always
pause the playbook run unless you skip the manual task. When the
playbook reaches a breakpoint, no new tasks begin, but parallel tasks
that have already begun continue. Breakpoints can be set in both the
parent playbook and sub-playbooks.

1.  To set a breakpoint, go to a task and click on the breakpoint
    button. When a breakpoint is set, the breakpoint button changes to
    orange.

- ![](media/rId2364.png){width="5.666666666666667in"
  height="1.0833333333333333in"}

2.  After a breakpoint is reached, click the task to override inputs and
    outputs if needed.

3.  When you are finished with the task, run the debugger, and in the
    task, select an option for the playbook to continue.

- For an automated task, you have the options **Run automation now** or
  **Complete Manually**. If you choose **Complete Manually**, click on
  **Mark Completed** for the playbook to continue.

  For a task that is a sub-playbook, click **Run playbook now** for the
  playbook to continue.

  For a conditional task, choose which branch the playbook should follow
  and click **Mark Completed** for the playbook to continue. The default
  branch is **else**.

  When the playbook reaches a breakpoint, the task has an orange line at
  the top to indicate the breakpoint.

  ![](media/rId1557.png){width="5.833333333333333in"
  height="1.264258530183727in"}

  Breakpoint alerts are also displayed at the top of the playbook,
  enabling you to navigate between multiple breakpoints that have been
  reached in the playbook or sub-playbooks.

###### Start and stop the debugger

The debugger runs the playbook with the permissions of the logged in
user. If a user runs potentially harmful commands, they are logged to
the audit trail with the user's username. When the user sets
breakpoints, skips tasks, or overrides inputs or outputs, those changes
only apply to the individual user's session and do not permanently
change the playbook. Using an existing issue as test data does not
affect the original issue or change the original context data. When
tasks run, however, they execute the same as they would without the
debugger. For example, if you run the debugger and a task adds an item
to a list, that item will be in the real list, accessible across for all
users with permission to view that list.

Breakpoints pause playbook execution before a specific task. When the
playbook is paused, the Debugger Panel displays the current state of
context data, indicators, and task information.

To start the debugger, click **Run**. When you click **Stop**, the
debugger stops, and the context data is reset to the original issue
data. In the case of a new mock issue, the context data is cleared and
the context is empty. Any breakpoints, skips, or overrides you applied
are still available.

###### Override inputs and outputs

The debugger enables you to temporarily override inputs and outputs for
a playbook run and to view the results in real time. When you override
an input or output in the debugger, the change is saved only in the
debugger view and only for the user who made the change. If after
testing you decide to keep the temporary changes you made and apply them
permanently to the playbook for all users, you need to cancel the
override and edit the task. Tasks can be edited directly in the debugger
or outside of the debugger using the standard playbook editing options.

You can override task inputs or outputs before or during a playbook run
to troubleshoot tasks that fail or to try different input and outputs as
part of playbook development. If you override an input or output during
a playbook run, the override is applied to the run if the playbook has
not yet reached that task. If you edit (permanently change) inputs
during a playbook run, the changes only take effect the next time you
run the playbook. You cannot use filters or transformers for overrides.

1.  To override an input or output, open the task and hover over any
    existing input or output. Click **Override Input**.

- ![](media/rId2371.png){width="5.833333333333333in"
  height="1.337029746281715in"}

2.  Enter a new input or output that will be used only in the debugger.
    For output overrides, you can enter a value, an array of values, or
    JSON. For input overrides, you can only enter plain text.

3.  Click **OK** to save your changes.

- The playbook task card displays a label indicating that the task input
  or output has been overridden.

###### Skip tasks

For testing purposes, you may want to skip a task that for example
closes a port in a firewall, deletes an email, or sends a notification
to a manager. Or you might skip a task where the integration has not yet
been configured. By skipping a task and overriding the output, you can
provide the data necessary to complete the playbook run. When you skip a
conditional task, you can choose which branch runs after the skipped
task, enabling you to test different outcomes for multiple branches.

You might need to skip tasks within a playbook:

- To check if a particular task is causing an issue.

- To avoid performing tasks not relevant for your troubleshooting.

- To skip tasks with potentially harmful results such as blocking a user
  or opening a port in a firewall.

- To skip tasks for integrations that are not yet configured.

**How to skip a task**

1.  Click the 'skip' button for the task.

- When a task is set to skip, the 'skip' button will be orange.

  ![](media/rId1551.png){width="5.833333333333333in"
  height="1.286438101487314in"}

2.  If the output is required for the playbook to proceed, click the
    task and override inputs and outputs.

###### View context data, indicators, and task information

Within the debugger panel, you can view the context data during the
playbook run as well as the indicators as they are extracted by clicking
any completed task in the playbook while the debugger is running.

You can see the results of that task in the debugger panel.

![](media/rId2378.png){width="5.833333333333333in"
height="3.7082567804024498in"}

###### Troubleshoot playbook performance

You can analyze playbook metadata such as tasks input and output, the
amount of storage each task input/output uses, and the type of task.
This is useful when troubleshooting your custom playbook if your system
has slowed down and is using high CPU usage, memory, or storage (disk
space).

**Get data from XQL datasets**

You can leverage XQL for flexible and adjustable playbook and script
tracking to provide performance and execution data for debugging. The
following datasets are available for querying and dashboards:

- playbook_tasks: Data about task executions within playbooks.

- playbook_runs: Data about playbook runs and statuses.

- scripts_and_commands_metrics: Data about scripts and commands used in
  playbook tasks.

**Get playbook metadata using the CLI**

After an issue has been assigned to a playbook you can analyze it to see
its tasks inputs/outputs storage. You can filter the data according to
the KB used in each task input/output.

From the Cases & Issues \> Cases page, in the **Case War Room** tab the
following command in the CLI.

`!getInvPlaybookMetaData issueId=<issue ID> minSize=<size of the data you want to return in KB. Default is 10>`

To view the playbook metadata that is used in issue number 964, in the
CLI type
`!getInvPlaybookMetaData incidentid=”964” minSize=”0”!getInvPlaybookMetaData incidentid=”964” minSize=”0”.`

##### Manage playbook content

###### Manage playbook content with a remote repository

In Cortex XSIAM, you can develop and test your playbook content on
development machines before using it in a production environment using
the remote repository feature.

For more information about content management in Cortex XSIAM, see
[Cortex XSIAM development
tenant](#UUIDcd0108ce11b11a2c747b1c6b4ab07d62).

###### Save versions of your playbook in Cortex XSIAM

You can save versions of a playbook as you are developing it. When you
save a version of a playbook, add a meaningful comment so that you will
be able to recognize the changes you made in that version at a later
time. The version is saved with the name of the playbook, your commit
message, an indication of what the change was (modify, insert), the date
the playbook was saved, and the name of the author who last saved it. If
necessary, you can access the playbook's version history and revert your
playbook to a previous version.

1.  In a playbook, after making changes, click the list next to
    **Save Playbook** and then click
    **Save version for current Playbook**.

- ![](media/rId2385.png){width="5.833333333333333in"
  height="1.6059787839020123in"}

2.  Enter a description of the change that was made to the current
    version.

3.  Click **Update Playbook**.

4.  To access a version of a playbook:

    a.  Click the icon next to **New Playbook**. The tooltip displays
        **Version history for all Playbooks**.

    - ![](media/rId2388.png){width="5.305555555555555in"
      height="3.0277777777777777in"}

    b.  Search for the required playbook. The description that was
        entered when the version was saved should help you locate the
        version you now require.

    c.  Click **Restore** to restore the required version of the
        playbook.

##### Best practices

The following guidelines are best practices for building playbooks as
well as optimizing playbook design and performance. Whether you are just
starting or are creating advanced workflows, we recommend reviewing
these recommendations carefully so your playbooks have a clear logical
flow and run correctly and efficiently.

###### Best practices for building your playbook

Use clear task names and descriptions

Describe tasks clearly. Tasks should be clear to someone not familiar
with the playbook workflow. This applies to task names, task
descriptions, and the playbook description. When naming tasks, the
guideline should be that users can understand what the playbook does by
reading the task names, without having to open individual tasks to view
the details.

  -----------------------------------------------------------------------
  Clear                               Unclear
  ----------------------------------- -----------------------------------
  Task name:                          Task name: **IP Check**
  **Check if the IP is Private**      

  -----------------------------------------------------------------------

Define playbook inputs and outputs properly

- **Group related input fields**.

<!-- -->

- [Grouping inputs](#UUID9bca1fca99bf083446a9dfe10576bb10) organizes the
  input fields and provides clarity and context to understand which
  inputs are relevant to which playbook flow.

<!-- -->

- **Use Pascal case for input names**.

<!-- -->

- Use the PascalCase convention for inputs, keeping in mind that
  inherently capitalized terms should be kept in upper case. For
  example, the `Entity ID` input should be named `EntityID` and
  `MITRE Technique` should be `MITRETechnique`.

<!-- -->

- **Define outputs properly**.

<!-- -->

- When configuring playbook outputs, configure sub-keys as much as
  possible, do not limit configuration to only the root keys. For
  example, instead of outputting `File`, output `File.Name`,
  `File.Size`, etc. This helps when viewing the outputs of the playbook
  within another playbook.

Configure playbook task inputs correctly

- **Avoid using Cortex
  XSIAM Transform Language (DT) in the Get input field definition**.

<!-- -->

- If you need to use [DT](https://xsoar.pan.dev/docs/integrations/dt)
  for complex processing and you think a new filter or transformer would
  provide a better alternative to your DT solution, you can request the
  feature or contribute it. Consider using DT only if it can drastically
  simplify the playbook or improve performance.

Define playbook logic carefully

In each task, make sure appropriate logical operations are performed on
input data. For example:

- **Avoid race conditions**.

<!-- -->

- Be aware of potential race conditions. When you want to add multiple
  values to the same key, do not use multiple tasks that run `Set`,
  `SetAndHandleEmpty`, or any other script that sets data in context at
  the same time, because a race condition can cause your data to be
  overwritten by the same tasks. This is especially problematic when
  trying to append data. Instead, run the tasks one after the other or
  use scripts to append the data instead of setting a new value to the
  key.

<!-- -->

- **Determine where inputs are coming from**.

<!-- -->

- Verify whether the data you\'re getting is `As value` (simple value)
  or `From Previous Tasks` (from context).

<!-- -->

- **Filter your inputs correctly so the task runs efficiently**.

<!-- -->

- Tasks take their inputs from the context, not directly from the
  previous tasks (even if it says from previous tasks). For an example
  of a task not receiving the right context, see this bug (since fixed)
  in a playbook:

  ![](media/rId2396.png){width="5.833333333333333in"
  height="2.8072911198600177in"}

  The playbook begins by classifying the emails as internal or external.
  It then checks the reputation of external email addresses if any were
  found. That happens on the right side of the image. We expect that
  branch to run only if external addresses are found.

  ![](media/rId2399.png){width="5.833333333333333in"
  height="3.0114577865266843in"}

  However, we did not apply a filter to the last task that gets the
  reputation on the right side:

  This means that if both internal and external email addresses
  are found, we proceed with both branches (internal and external) of
  the playbook, and the task that gets the reputation runs without an
  applied filter, effectively taking all the emails we have in the
  inputs. The correct task input should have been:

  ![](media/rId2402.png){width="5.833333333333333in"
  height="1.4464763779527559in"}

<!-- -->

- **Select Ignore case for input names**.

<!-- -->

- Use `ignore-case` option where possible, especially when checking
  Boolean playbook inputs such as `True` which users may end up
  configuring as `true` with a lowercase t:

  ![](media/rId2405.png){width="5.833333333333333in"
  height="3.9022069116360454in"}

<!-- -->

- When working with two lists, if you need multiple items from list A,
  which are also in list B, use the `in` filter instead of the `equals`
  or `contains` filters.

+----------------------------------------------------+-----------------------------------+
| Correct Method                                     | Incorrect Method                  |
+====================================================+===================================+
| Get the IP addresses that `are in` the list of     | Get the IP addresses where the    |
| inputs.                                            | addresses `contain` the list.     |
|                                                    | This is incorrect because they    |
| ![](media/rId2408.png){width="4.347222222222222in" | don\'t contain the list, they     |
| height="1.9722222222222223in"}                     | contain individual items from it. |
+----------------------------------------------------+-----------------------------------+

- Differentiate between checking if `a specific element exists` versus
  checking if `an` element equals something. This is a common mistake
  that can lead to tests working in some situations, but not all.

+----------------------------------------------------+----------------------------------------------------+
| Correct Method                                     | Incorrect Method                                   |
+====================================================+====================================================+
| Check if `any object` where the NetworkType is     | Check if the NetworkType                           |
| External `exists`.                                 | `of the IP object is External`. This is incorrect  |
|                                                    | because the IP object may contain multiple IPs,    |
| ![](media/rId2411.png){width="5.833333333333333in" | some internal and some external.                   |
| height="1.9370220909886264in"}                     |                                                    |
|                                                    | ![](media/rId2414.png){width="5.833333333333333in" |
|                                                    | height="1.8525513998250218in"}                     |
+----------------------------------------------------+----------------------------------------------------+

- Run `one or more tasks` based on the `object types` versus running
  `either one task or the other` based on `the type of one object`.

+----------------------------------------------------+----------------------------------------------------+
| Correct Method                                     | Incorrect Method                                   |
+====================================================+====================================================+
| Check the existence of both object types and run   | Check if there is either an internal or an         |
| tasks for the types found.                         | external IP, and take only one path even if both   |
|                                                    | types exist.                                       |
| ![](media/rId2417.png){width="5.833333333333333in" |                                                    |
| height="2.8in"}                                    | ![](media/rId2420.png){width="5.833333333333333in" |
|                                                    | height="1.7864577865266842in"}                     |
+----------------------------------------------------+----------------------------------------------------+

Define playbook loops correctly

Use [playbook loops](#UUIDabee2878da723d088573af74ddd75ea4) only where
needed. Loops are needed when certain actions have to be performed on
specific pairs of data.

+-----------------------------------+----------------------------------------------------+
| Correct Method Example            | Incorrect Method Example                           |
+===================================+====================================================+
| Either use filters and            | A user has a playbook that creates relationships   |
| transformers or loop through each | for multiple indicator types. All indicator types  |
| separate indicator to verify      | and malware families are in their                  |
| they\'re creating the correct     | `${inputs.Domain}` and `${inputs.MFam}` playbook   |
| relationships.                    | inputs.                                            |
|                                   |                                                    |
|                                   | The user wrongly assumes that when creating the    |
|                                   | relationships, the correct malware families in     |
|                                   | `${inputs.MFam}` correspond to the correct domains |
|                                   | in \${inputs.Domain}.                              |
|                                   |                                                    |
|                                   | ![](media/rId2424.png){width="5.833333333333333in" |
|                                   | height="2.464583333333333in"}                      |
+-----------------------------------+----------------------------------------------------+

###### Best practices for optimizing playbook design and performance

In order to minimize your case response time and make sure the system
runs optimally, it\'s important to follow design and performance
guidelines.

Use latest playbook and script versions

Playbooks

When returning to work on a playbook after a break, verify you're
working on the latest version. Reattach the playbook if it's detached,
and update it to ensure you're not editing an older version and
introducing regressions. If you don't want to reattach your playbook, or
you're still working on your custom version, we recommend reviewing the
release notes to see what changes were made to the out-of-the-box
playbook and copying those changes to your version.

> **Note**
>
> If you reattach a detached playbook, any customizations you have made
> to the playbook will be overwritten when the playbook updates to the
> current version.

Scripts

Update scripts and integration commands in playbook tasks to their most
current version. Scripts that have updates or are deprecated are
designated by a yellow triangle.

![](media/rId1545.png){width="5.833333333333333in"
height="1.2705172790901138in"}

Break up large playbooks into sub-playbooks

If a playbook has more than thirty tasks, consider breaking the tasks
into multiple sub-playbooks. Sub-playbooks can be reused, managed easily
when upgrading, and they make it easier to follow the main playbook.

Sub-playbooks are playbooks that are used from within a parent playbook,
as building blocks. The parent playbook is the main playbook that runs
on the investigation, and each sub-playbook has a specific
goal/responsibility.

- Parent playbooks usually have a `closeInvestigation` task at the end
  because they are the main playbook for that issue.

- Parent playbooks usually contain inputs that are passed down to
  sub-playbooks. Certain `True`/`False` flags may come from the parent
  playbook inputs.

Remove unused playbook tasks

For production playbooks, remove playbook tasks that are not connected
to the playbook workflow.

Set the playbook to run in quiet mode

Run playbooks in quiet mode to reduce the issue number size and execute
playbooks faster.

For playbooks running in jobs, indicator enrichment should be done in
quiet mode.

Only extract indicators when needed

When indicator extraction is enabled for a playbook task, the task by
default tries to extract all indicator types from the task Results. (The
Results entry is the information printed to the War Room, not the
outputs of the task). Extracting all indicator types can slow down the
playbook, so it is important to only extract indicators as needed. For
example, for the **ParseEmailFilesV2** script which prints email
information to the War Room, extraction should be enabled in order to
extract email addresses, URLs, and other indicators. However, if your
task runs the Sleep script, there is no point in extracting indicators.

Set the **Indicator Extraction mode** to None in the playbook task
**Advanced** tab.

Use retries

Retries help ensure smoother playbook execution and more efficient
progress tracking.

Use retries when a task might temporarily fail but is expected to
succeed later. This helps handle issues like network glitches, service
downtime, or rate limits by retrying the task again after a short wait.

> **Note**
>
> Retries are not supported for data collection tasks that have errors
> sending emails (indicated by a server timeout). This is because
> retries only work on automation execution failures, not on email
> delivery issues.

Use polling

Use polling to monitor a process or condition over time, especially when
waiting for a specific outcome before proceeding such as waiting for an
asynchronous task to complete. It periodically checks if a required
condition is complete, ensuring your playbook moves forward only when
ready. Common uses include waiting for a job to finish or a system to
reach a certain state.

Minimize disk usage, CPU usage, and API calls

Consider the following:

- Do I need to do this action in multiple tasks?

- Can these tasks run in parallel instead of synchronously?

- Where applicable, am I setting realistic timeouts, search windows,
  intervals?

- Can I consolidate the API calls into one call? If not, can an
  integration enhancement solve this by accepting arrays as input
  instead of running multiple times for each input?

- Am I unnecessarily storing the same data twice? Do I have the data I
  need already stored?

- Where applicable, can I run this playbook without a loop?

- What extractions are running in my issue?

Get data from XQL datasets

You can leverage XQL for flexible and adjustable playbook and script
tracking to provide performance and execution data. The following
datasets are available for querying and dashboards:

- playbook_tasks: Data about task executions within playbooks.

- playbook_runs: Data about playbook runs and statuses.

- scripts_and_commands_metrics: Data about scripts and commands used in
  playbook tasks.

#### Create an automation rule

Automation rules allow users to automatically respond to events by
defining trigger conditions and desired actions to perform once the
condition is met.

> **Important**
>
> Automation rules apply to Medium and higher severity issues. They also
> apply to Low severity Analytic issues and Low severity ABIOC issues
> that are tagged with **Identity** or **Cloud**.
>
> Rules are evaluated in order, and only the first rule that matches the
> trigger conditions is executed.

The rules consist of three parts: WHEN, IF, and THEN.

- **WHEN**: Stands for the trigger type, for instance, issue, case, or
  audit log. **WHEN** is set to **Issue is created**.

- **IF**: Stands for the conditions that need to be met for the rule to
  run.

- **THEN**: The action that the user wants to perform: playbook or Quick
  action.

In the **Automation Rules** page, you can create or edit an automation
rule, use recommended automation rules, edit a playbook, and change the
order of priority. You can also delete or disable/enable an automation
rule. When you disable an automation rule, the automation does not run
for the selected condition.

> **Note**
>
> You can also define the conditions that trigger a specific playbook in
> the playbook editor. For more information, see [Task 2. Configure
> playbook settings](#UUID9bca1fca99bf083446a9dfe10576bb10)

Create or edit an automation rule

Create an automation rule for issues where conditions from the
automation rule are met, so that the automation, whether it is a Quick
Action or a playbook, automatically runs.

1.  Go Investigation & Response \> Automation \> Automation Rules.

2.  Click **Add Automation Rule** or right-click a rule, select
    **Edit rule**, or click the edit button.

3.  Define the rule name and conditions:

    1.  Enter a rule name and set the rule status.

    2.  Under **Rule Conditions**:

        - For **If**, click **+Add Condition** and from the **Issues**
          table, use the filter to set the criteria for the rule, and
          then click **Save**.

        <!-- -->

        - For example, filter the field **Severity**, and then select
          the value **Critical**. The **Issues** table returns all
          issues where the severity=critical.

        <!-- -->

        - For **Then**, click **+Add Automation** and from the
          **Select Automations** window, select the action you want to
          run.

        <!-- -->

        - You can search for the action or select a **Quick Actions** or
          a **Playbook** from the **Org Playbooks** or from the
          **Playbook Catalog**.

          Click ![](media/rId2443.png){width="0.25767497812773404in"
          height="0.20833333333333334in"} to view the description and
          the tasks of the playbook.

          For example, for the **IF** condition where severity=critical,
          select the Quick Action - Create Jira Ticket. The automation
          rule is triggered when a critical severity issue is detected,
          which then runs the selected automation, the Quick Action -
          Create Jira Ticket.

          For more information on Quick Actions, see [Quick
          Actions](#UUID569a367903e2a16643d3039ad7f7abde).

          For more information on Playbooks, see [Manage
          playbooks](#UUID9192fe7689366d4c76c39346f92cba60).

    3.  **Save** the automation rule.

In this example, there are a number of issues created
called **McAfee + Zscaler - Malware Downloaded And Dropped To Disk**.
These issues are a result of malware, which was detected by the agent. A
custom playbook runs these issues, where if action is detected by the
ePO, the playbook either quarantines the machine where the malware is
detected or closes the investigation if there is no action. We want to
create an automation rule to automatically run the playbook when an
issue is created.

1.  Create an automation rule
    called **McAfee + Zscaler - Malware Downloaded And Dropped To Disk**.

2.  Define the rule conditions.

3.  In the **Issues** section, filter for the
    **McAfee + Zscaler - Malware Downloaded And Dropped To Disk** issues.

- The next time an issue is created with the criteria, the playbook runs
  according to the automation rule.

  The case collects issues that automatically run the custom playbook.

4.  Select one of the issues to see that the playbook ran (Work Plan or
    Case War Room).

Add a recommended automation rule

You might want to add a recommended automation rule. These rules are
generic and recommended by your organization. These recommendations are
part of the **Core - Investigation and Response** content pack and are
designed for Ransomware, WildFire, etc. Before adding them to the
**Automation Rules** table, you can view the playbooks in more detail by
clicking on the link.

1.  Go to Investigation & Response \> Automation \> Automation Rules.

2.  Click **View Recommendations**.

3.  In the **Automation Rule Recommendations** table, view and select
    the required recommended automation rules to add to the
    **Automation Rules** table.

- You can view each playbook in detail in the Playbooks page.

4.  Click **Add Selected rules**.

5.  Verify the order of the automation rule and change the order (if
    required),

6.  Save the changes to the **Automation Rules** table.

After you create an automation rule, the rule is added to the
**Automation Rules** table. In the **Automation Rules** table, you can
do the following:

- Set the priority of the automation rules, so when an issue is created,
  the first rule takes priority, then the second, third, etc. Only the
  first matching rule is executed.

<!-- -->

- New rules created manually are added to the bottom of the table.

<!-- -->

- View details of the automation rules that have been created.

<!-- -->

- By default, you can see the condition, automation, and the creation
  dates and source. You can add columns and filters as required. To
  edit, disable, or delete an automation rule, right-click on the rule.

Scope-based access control for automation rules

Automation rules support SBAC (scope-based access control). The
following parameters are considered when editing a rule:

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to restrictive mode, you can edit an
  automation rule if you are scoped to all tags in the rule.

- If **Scope-Based Access Control (SBAC)** is enabled and
  **Endpoint Scoping Mode** is set to permissive mode, you can edit an
  automation rule if you are scoped to at least one tag listed in the
  rule.

- As a scoped user who has editing permissions to a rule, you can change
  the order among other rules that are locked.

- If a rule was added when set to restrictive mode, and then changed to
  permissive (or vice versa), you will only have view permissions.

#### Context data

Context data is a map (dictionary) that stores structured data related
to an issue, including issue fields and automations data. You can use
context data to pass data between playbook tasks, and create scripts
that map data into case and issue fields.

##### Issue context data

When an issue is generated, context data is captured from the issue
fields and from any automations, such as commands, playbooks,
correlation rules, and scripts. Context data includes keys (strings) and
values (numbers, maps, arrays, and strings).

To see context data for an issue, open the issue investigation panel by
clicking on the **Investigate** icon
![](media/rId2451.png){width="0.20833333333333334in"
height="0.20833333333333334in"}. Then, click on the
**Issue Context Data** icon
![](media/rId2454.png){width="0.20613954505686788in"
height="0.20833333333333334in"}.

Consider the following information when working with context data:

- When an issue is created, the issue field data is stored under the
  `issue` key in the context data. When an investigation is opened and
  commands are run, the data returned from those commands is stored
  outside of the main `issue` key.

- Issue context data is split into two tabs. The **Issue** tab contains
  the context data from the issue fields and the commands run on the
  issue. The **Case** tab contains the parent case fields and other case
  data. None of this data is added to the context data for the parent
  case unless you add it.

- You can add keys and values to the context data. This is useful when
  developing playbooks, and other automations. For more information, see
  [Add context data to an issue](#UUID8996dbb2c8fd4a1d9a77de6579278d02).

- When running automations on an issue, the issue can access context
  data from its parent case; however, it cannot access context data from
  other issues. If you want to use context data from other issues, add
  it to the parent case.

##### Case context data

Context data is written to issues and not to cases. Therefore, the case
context might be empty unless you previously added context data to the
case.

To see context data for a case, click on a case to open it in the case
investigation panel. Then, click on the **Case Context Data** icon
![](media/rId2458.png){width="0.2408847331583552in"
height="0.20833333333333334in"}.

Adding context data from issues to a parent case can help you with the
following tasks:

- **Remediation**: You can add context data from an issue, such as the
  issue status, actions, or ID, to its parent case\'s context data. This
  allows other playbooks to use the parent case context.

<!-- -->

- For example, if you have multiple issues in a case, you can add
  context data from each of the issues to the parent case. You can then
  use the case context data in playbooks, and avoid running duplicate
  actions on the issues.

<!-- -->

- **Case assignment**: You can see if an analyst has been assigned to
  the case or other issues.

- **Insights at the case level**: For automation engineers, you can set
  responses based on characteristics in the case.

For more information, see [Add context data to a
case](#UUID5cb05cc00041d6125260ac1bc1cf0b32).

##### Search context data

You can use Query to search within the context data JSON for specific
items and expand nested keys. Open the context data panel for an issue
or case, as explained in [Issue context
data](#UUID3cf89c8fc237f447235eca008b8174b3) or [Case context
data](#UUID1e8521fc4ca423845bdc9222a8226145), and type in the **Search**
field.

Example context:

    {
      "HelloWorld": {
        "Alerts": [
          {
            "name": "Example 1",
            "alert_status": "ACTIVE"
          },
          {
            "name": "Example 2",
            "alert_status": "CLOSED"
          },
          {
            "name": "Example 3",
            "alert_status": "ACTIVE"
          }
        ]
      }
    }

Search examples:

- `${c}` finds the value of the object c.

- `${HelloWorld.Alert(val.name == 'Example 1')}` shows the full object
  for the alert named \"Example 1\", as stored in the context data.

- `${HelloWorld.Alert(val.alert_status === "ACTIVE")}` shows the full
  object for all alerts in context with status \"ACTIVE\".

- `${HelloWorld.Alert(val.alert_status == 'ACTIVE').name}` fetches the
  HelloWorld.Alert.name of all alerts in context with status \"ACTIVE\".

##### Add context data to an issue

You can add keys and values to an issue\'s context data to be used in
playbooks or other automations.

To add context data to an issue, run the `Set` command in CLI, in a
script, or in a playbook task. The Set command enables you to set a
value under a specific key. For more information about the Set command,
see [Set](https://xsoar.pan.dev/docs/reference/scripts/set).

###### Use the CLI

Run the `!Set` command in the issue **War Room**.

1.  Identify an issue and click
    ![](media/rId2451.png){width="0.20833333333333334in"
    height="0.20833333333333334in"} to investigate the issue.

2.  In the issue investigation panel, select the **War Room** tab.

3.  Run the `!Set` command.

- Example
  The following example adds the key and value `hello:world` to the
  issue context data.

      !set key="hello" value="world"

###### Use a script

In the JSON file, add `Set` to the `demisto.executeCommand` key.

Example

The following example adds the key and value `hello:world` to the issue
context data.

    demisto.executeCommand("Set", {"key":"hello", "value":"world"})

###### Use a playbook

Use the `Set` script in a standard task.

Example

An issue\'s context data contains the following values:

    {  
       "Account":
        {
          "firstName": "Bob",
          "lastName": "Jones",
        }
    }

For an automation, you need to use the full name value. You can use the
`Set` script to add an new `fullName` value to the JSON:

![](media/rId2469.png){width="5.833333333333333in"
height="4.406891951006124in"}

Result:

    {  
       "Account":
        {
          "firstName": "Bob",
          "fullName": "Bob Jones"
          "lastName": "Jones",
        }
    }

##### Add context data to a case

You can add keys and values to a case\'s context data to be used in
playbooks or other automations. By default, context data is added to
cases only. To run automations on a case, add context data to the case
from its related issues.

To add context data to a case, run the `setParentIncidentContext`
command in the CLI, in a script, or in a playbook task.

###### Use the CLI

Run the `!setParentIncidentContext` command in the issue **War Room** or
the **Case War Room**.

> **Note**
>
> If you run the command in the issue **War Room**, the data is added to
> the following places:

- > The case context data.

- > The issue context data under the case tab.

> If you run the command in the **Case War Room**, the data is added to
> the case context data only.

**Run the command in the issue War Room**

1.  Identify an issue and click
    ![](media/rId2451.png){width="0.20833333333333334in"
    height="0.20833333333333334in"} to investigate the issue.

2.  In the issue investigation panel, select the **War Room** tab.

3.  Run the `!setParentIncidentContext` command.

- Example
  The following example adds the key and value `hello:world` to the case
  and issue context data.

      !setParentIncidentContext key="hello" value="world"

**Run the command in the case War Room**

1.  In the case investigation panel, select the **Case War Room** tab.

2.  Run the `!setParentIncidentContext` command.

- Example
  The following example adds the key and value `hello:world` to the case
  context data.

      !setParentIncidentContext key="hello" value="world"

###### Use a script

In any script that runs in an issue, the data is written to the issue
context.nIf you want to add the data to the case content from your
script, run the `setParentIncidentContext` using
the `demisto.executeCommand` key, as follows:

`demisto.executeCommand("setParentIncidentContext", {"key":"<key>", "value":"<value>"})`

Example

The following example creates a new key name `AuditID` with
a `90210` value to your script.

    demisto.executeCommand("setParentIncidentContext", {"key":"AuditID", "value":"90210"})

###### Use a playbook

When a playbook runs, the playbook data is written to the issue context
data. To write the data to the parent case context data, use the
`setParentIncidentContext` script in a standard task.

The following example adds the TicketID to the case context. To see a
full use case that includes this standard task, see [Use context data in
a playbook](#UUID050987befc55bed736718170a9a2e58c).

![](media/rId2482.png){width="5.833333333333333in"
height="5.893969816272966in"}

##### Delete context data from a case

Run the `!deleteParentIncidentContext` command to delete all context
data or a specific key in the **Case War Room** or issue **War Room**.

**Use the issue War Room**

1.  Identify an issue and click
    ![](media/rId2451.png){width="0.20833333333333334in"
    height="0.20833333333333334in"} to Investigate the issue.

2.  In the issue investigation panel, select the **War Room** tab.

3.  Run the `!deleteParentIncidentContext` command.

**Use the case War Room**

1.  In the case investigation panel, select the **Case War Room** tab.

2.  Run the `!deleteParentIncidentContext` command.

Example

The following example deletes the key and value `hello:world` from the
case or issue context.

    !deleteParentIncidentContext key="hello" value="world"

##### Use context data in a playbook

In Cortex XSIAM you can use context data (from an issue or case) in
playbooks, and you can use playbook tasks to update context data. You
can:

- Use the information stored in the issue context data as task inputs
  and outputs in a playbook.

  - To access data that is stored in the issue context data, use the
    keyword `issue`.

  <!-- -->

  - To access a the `status` value in the issue context data, use the
    following syntax:

        ${issue.status}

  <!-- -->

  - To access data that is stored in the parent case context data, use
    the keyword `parentIncidentContext`.

  <!-- -->

  - To access the `hostname` value in the case context data, use the
    following syntax:

        ${parentIncidentContext.hostname}

- Set a breakpoint in a playbook that reviews context data after a
  specific task.

<!-- -->

- This is available when using the debugger. As context data may be
  updated during a playbook run, setting a breakpoint enables you to
  pause the playbook execution, review the context data, and take action
  if necessary. Breakpoints can be useful when designing and
  troubleshooting playbooks. For more information, see [Test your
  playbook](#UUIDe8d7bd184fa0c0d595e939f9be0681b9).

<!-- -->

- Add a task that writes playbook data to the case context.

<!-- -->

- When you add data to the case context, you can use this data to run
  playbooks on any of the issues that are included in the case.

  To write playbook data to the case context, use the
  `setParentIncidentContext` script in a standard task. For more
  information, see [Add context data to a
  case](#UUID5cb05cc00041d6125260ac1bc1cf0b32).

  > **Caution**

  > Users with Trigger Playbook permissions on a given issue may still
  > be able to modify the parent case via commands and scripts, even
  > without full access to the case.

For more information about playbooks, see [Playbooks
overview](#UUID4d25f6a6678aed2733c9a5068333ba4c).

###### Context data in sub-playbooks

By default, the context data for sub-playbooks is stored in a separate
context key. Consider the following information:

- When a task in a main playbook accesses context data, it does not have
  direct access to sub-playbook data.

- When a task in a sub-playbook accesses context data, it does not have
  direct access to the main playbook data.

- If the sub-playbook has been configured to share globally, the
  sub-playbook context data is available to the main playbook and vice
  versa.

> **Note**
>
> Generic polling does not work if a playbook's context data is shared
> globally. For more information, see [Playbook
> polling](#UUID7350cc0d13e15a4b352bf34ba1b45057).

###### Use case: Use context data in a Jira ticketing system

In this use case, a Jira ticketing system is used to manage issues and
reduce duplicate tickets.

**Issue:** When an action is taken on an endpoint, some cases contain
multiple issues for the same endpoint. If each issue runs a playbook on
the same endpoint, duplicate tickets are created for each case.

**Solution:** This playbook checks existing endpoints and Case IDs and
decides whether to create a new ticket or to add the data to an existing
ticket, and therefore, reduces duplicate tickets in the case.

![](media/rId2495.png){width="5.833333333333333in"
height="5.944797681539807in"}

The playbook flow is described in the following steps:

1.  After checking that the Jira v3 integration is enabled, in this task
    the playbook adds the `EndpointFromAlerts` key to the case context
    by retrieving the `alert.hostname` and using the
    `setParentIncidentContext` script.

- ![](media/rId2498.png){width="5.833333333333333in"
  height="5.666666666666667in"}

2.  In this task, the playbook checks if there is an open ticket for the
    case by retrieving the `parentIncidentContext.TicketID`.

- ![](media/rId2501.png){width="5.833333333333333in"
  height="5.725085301837271in"}

3.  If there is no open ticket, a new ticket is created in Jira and the
    TicketID is added to the case context.

- ![](media/rId2482.png){width="5.833333333333333in"
  height="5.893969816272966in"}

4.  If there is an open ticket, this task checks whether there is an
    open ticket for the endpoint by comparing the `alert.hostname`
    (issue endpoint) to the `parentIncidentContent.EndpointFromAlerts`
    key.

- ![](media/rId2506.png){width="5.833333333333333in"
  height="6.0285903324584424in"}

5.  After retrieving the `alert.hostname` in the
    `parentIncidentContext.EndpointFromAlerts` context, if there is no
    open ticket for the endpoint, the playbook updates the Jira ticket
    for the case.

- In this example, you can see that the `EndpointFromAlerts` and
  `TicketID` has been added to the case context data.

  ![](media/rId2509.png){width="5.833333333333333in"
  height="1.4891426071741032in"}

#### Lists

Create and edit lists for use in playbooks and scripts.

A list is a data container for storing data and is mainly used in
playbooks and scripts but can be accessed anywhere the context button
appears (double-curly brackets). For example, in a playbook task, access
the data in a list via the context button under **Lists**, or by using
the path `${lists.<list_name>}`. Different types of data can be stored
in a list, for example, text, string, numbers, Markdown, HTML, CSS, and
JSON objects.  

> **Note**
>
> The maximum list size is 209,715 characters (approximately 200 KB).

##### Use cases

The following are use cases for lists: 

- **Defining HTML templates**: An HTML template can be defined as part
  of a communication task.

- **Configuring Automation Exclusion Policies**: Create lists of
  critical assets that should be excluded from automated remediation.
  For more information, see [Manage automation exclusion
  policies](#UUID94edb94b3675475d710406813aa77d03).

- **Organizing Network Security**: Use lists to keep track of internal
  networks and their corresponding IP addresses. Compare them to a set
  list to ensure only authorized connections are allowed through.

- **Store Data Objects**: For example, a list of URLs, which you can
  call as an input for scripts and playbooks.

- **Prioritizing Case Response**: Create lists to identify critical
  assets, such as important users or servers. This helps improve
  incident management by prioritizing the most important incidents.

##### Create a list

To create a Text, Markdown, HTML, CSS, or JSON list type:

1.  Go to Settings \> Configurations \> Object Setup \> Lists \> Add a
    List.

2.  Enter a name for the list.

3.  From the list, select the Content Type.

4.  Add content as required. For an example of a JSON list and how to
    use it, see [Use cases: JSON
    lists](#UUID919170edf21410dd27606650ef046bb3).

5.  To save, do one of the following:

    - Click Save.

    - Click Save Version to save your changes in Version history for all
      Lists. This allows you to revisit and restore previous versions. 

> **Note**
>
> If you want to edit a list from a content pack, you need to duplicate
> or detach a list. Detached lists do not receive updated content in
> subsequent Cortex XSIAM content releases. To retain an updated list,
> reattach it.

##### List commands

Use the following list commands in the CLI in the War Room and
Playground, scripts, and playbook tasks:

+-----------------------+-----------------------+-----------------------+
| Command               | Description           | Arguments             |
+=======================+=======================+=======================+
| **getList**           | Retrieves the         | **listName**: The     |
|                       | contents of the       | name of the list for  |
|                       | specified list.       | which to retrieve the |
|                       |                       | contents.             |
+-----------------------+-----------------------+-----------------------+
| **createList**        | Creates a list with   | - **listName**: The   |
|                       | the supplied data and |   name of the list to |
|                       | overwrites any        |   which to add items. |
|                       | existing list data..  |                       |
|                       |                       | - **listData**: The   |
|                       |                       |   data to add to the  |
|                       |                       |   new list and        |
|                       |                       |   overwrites any      |
|                       |                       |   existing list       |
|                       |                       |   data..              |
+-----------------------+-----------------------+-----------------------+
| **addToList**         | Appends the supplied  | - **listName:** The   |
|                       | items to the          |   name of the list to |
|                       | specified list. If    |   which to append     |
|                       | you add multiple      |   items.              |
|                       | items, make sure you  |                       |
|                       | use the same list     | - **listData**: The   |
|                       | separator that the    |   data to add to the  |
|                       | list currently uses,  |   specified list. The |
|                       | for example, a comma  |   data will be        |
|                       | or a semicolon.       |   appended to the     |
|                       |                       |   existing data in    |
|                       |                       |   the list.           |
+-----------------------+-----------------------+-----------------------+
| **setList**           | Adds the supplied     | - **listName**: The   |
|                       | data to the specified |   name of the list to |
|                       | list and overwrites   |   which to add items. |
|                       | existing list data.   |                       |
|                       |                       | - **listData**: The   |
|                       |                       |   data to add to the  |
|                       |                       |   specified list. The |
|                       |                       |   data overwrites the |
|                       |                       |   existing data in    |
|                       |                       |   the list.           |
+-----------------------+-----------------------+-----------------------+
| **removeFromList**    | Removes a single item | - **listName**: The   |
|                       | from the specified    |   name of the list    |
|                       | list.                 |   from which to       |
|                       |                       |   remove an item.     |
|                       |                       |                       |
|                       |                       | - **listData**: The   |
|                       |                       |   item to remove from |
|                       |                       |   the specified list. |
+-----------------------+-----------------------+-----------------------+

In this example, a manageOOOusers script uses the `getList`,
`createList`, and `setList` commands.

    register_module_line('ManageOOOusers', 'start', __line__())

    def _get_current_user():
        current_username = demisto.executeCommand("getUsers", {"current": True})
        if isError(current_username):
            demisto.debug(f"failed to get current username - {get_error(current_username)}")
            return
        else:
            return current_username[0]["Contents"][0]['username']

    def main():
        # get current time
        now = datetime.now()

        # args
        list_name = demisto.getArg("listname")
        username = demisto.getArg("username")

        option = demisto.getArg("option")
        days_off = now + timedelta(days=int(demisto.getArg("daysoff")))
        off_until = days_off.strftime("%Y-%m-%d")

        # update list name to start with 'OOO', so we can't overwrite other lists with this
        if not list_name.startswith("OOO"):
            list_name = f"OOO {list_name}"

        current_user = _get_current_user()
        if not current_user and not username:
            return_error('Failed to get current user. Please set the username argument in the script.')

        if not username:
            # Current user was found, running script on it.
            username = current_user
        else:
            # check if provided username is a valid user
            users = demisto.executeCommand("getUsers", {})
            if isError(users):
                return_error(f'Failed to get users: {str(get_error(users))}')
            users = users[0]['Contents']

            users = [x['username'] for x in users]
            if username not in users:
                return_error(message=f"{username} is not a valid user")

        # get the out of office list, check if the list exists, if not create it:
        ooo_list = demisto.executeCommand("getList", {"listName": list_name})[0]["Contents"]
        if isError(ooo_list):
            return_error(f'Failed to get users out of office: {str(get_error(ooo_list))}')

        if "Item not found" in ooo_list:
            demisto.results(demisto.executeCommand("createList", {"listName": list_name, "listData": []}))
            ooo_list = demisto.executeCommand("getList", {"listName": list_name})[0]["Contents"]

        # check status of the list, and add/remove the user from it.
        if not ooo_list:
            list_data = []
        else:
            list_data = json.loads(ooo_list)
        if option == "add":
            # check if user is already in the list, and remove, to allow updating
            list_data = [i for i in list_data if not (i['user'] == username)]
            list_data.append({"user": username,
                              "offuntil": off_until,
                              "addedby": current_user if current_user else 'DBot'})
        else:
            # remove the user from the list.
            list_data = [i for i in list_data if not (i['user'] == username)]

        set_list_res = demisto.executeCommand("setList", {"listName": list_name, "listData": json.dumps(list_data)})
        if isError(set_list_res):
            return_error(f'Failed to update the list {list_name}: {str(get_error(set_list_res))}')

        # welcome back, or see ya later!
        if option == "add":
            demisto.results(f"Vacation mode engaged until {off_until}, enjoy the time off {username}")
        else:
            demisto.results(f"Welcome back {username}, it's like you never left!")

    if __name__ in ('__builtin__', 'builtins', '__main__'):
        main()

    register_module_line('ManageOOOusers', 'end', __line__())

##### Use cases: JSON lists

List data can be stored in various structures, including JSON format.
When accessing a valid JSON file from within a playbook, it is
automatically parsed as a JSON object (list). Depending on how you store
the data, you may need to transform a list into an array. For example,
when using non-built-in commands in a script or looping over items in a
list, we recommend converting the list into an array. Working with JSON
files in playbooks typically involves the following:

- Extract the data from a JSON object

- Extract a subset of the data

- Filter extracted data

- Apply transformers to extracted data.

###### Extract data from a JSON object

Create a JSON list and use the **Set** automation to create a new
context key that can extract the data from the list.

1.  Create a List:

    a.  In the Name field, type `Test1`.

    b.  Select Settings \> Configurations \> Object Setup \> Lists \>
        Add a List.

    c.  In the **Content Type** field, select **JSON** and add the
        following content:

    - {    
              "domain": {
                  "name": "mwidomain",
                  "prod_mode": "prod",
                  "user": "weblogic",
                  "admin": {
                      "servername": "AdminServer",
                      "listenport": "8001"
                  },
                  "machines": [
                      {
                          "refname": "Machine1",
                          "name": "MWINODE01"
                      },
                      {
                          "refname": "Machine2",
                          "name": "MWINODE02"
                      }
                  ],
                  "clusters": [
                      {
                          "refname": "Cluster1",
                          "name": "App1Cluster",
                          "machine": "Box1"
                      },
                      {
                          "refname": "Cluster1",
                          "name": "App2Cluster",
                          "machine": "Box2"
                      }
                  ],
                  "servers": [
                      {
                          "name": "ms1",
                          "port": 9001,
                          "machine": "Box1",
                          "clusterrefname": "Cluster1"
                      },
                      {
                          "name": "ms2",
                          "port": 9002,
                          "machine": "Box2",
                          "clusterrefname": "Cluster2"
                      }
                  ]
              }
          }

    d.  **Save** the list.

2.  Create a playbook task with the **Set** automation:

    a.  Select Investigation & Response \> Automation \> Playbooks \>
        New Playbook.

    b.  Name the playbook, and click Save.

    c.  Click Create Task and provide a task name.

    d.  In the **Choose Script** field, select Set .

    - The **Set** script sets a value in context under the key entered.

    e.  In the **key** field, define a context key name for the data.
        For example, JSONData.

    - ![](media/rId2519.png){width="5.833333333333333in"
      height="4.4989577865266845in"}

    f.  In the **value** field, set the list you want to extract by
        clicking the curly brackets.

    g.  Click **Filters And Transformers**.

    h.  In the **Get** field, click the curly brackets, and in
        the **Select source for value** section, select the list you
        created in step 1: **Test1**.

    i.  In the **Fetch data** field, select an issue to test the data.

    j.  Click **Test**.

    - In this example, the test results have found the list data.

      ![](media/rId2522.png){width="5.833333333333333in"
      height="5.915492125984252in"}

    k.  When the test completes, click **Save**.

    l.  Save the task and playbook.

3.  Check all the data is stored in the context key you defined by
    testing the playbook using the debugger:

    a.  Click **Run**.

    b.  Open the **Debugger Panel**.

    - The key you defined, JSONData, holds the data in context from the
      JSON object.

      ![](media/rId2525.png){width="4.944444444444445in"
      height="11.11111111111111in"}

###### Extract a subset of the data

In a playbook, you can extract subsets of context data to analyze a
specific information set. This approach also applies when working with
lists, such as extracting a subset of data from a JSON object. In this
example, we extract server information from the list created above.

1.  In a playbook, create a task.

    a.  In the **Choose Script** field, select Set .

    b.  In the **key** field, define a context key name for the data;
        for example, JSONDataSubset.

    c.  In the **value** field, set the list you want to extract by
        clicking the curly brackets.

    d.  Click **Filters And Transformers**.

    e.  In the **Get** field, enter `lists.Test1.domain.servers`.

    f.  In the **Fetch data** field, select an issue to test the data.

    g.  Click **Test**.

    h.  When the test completes, click **Save**.

    i.  Save the task and the playbook.

2.  Check that all the data is stored in the context key you defined by
    testing the playbook using the debugger.

    a.  Click `Run` Debugger Panel.

    b.  The key you defined (JSONDataSubset) holds the subset of the
        data in context from the JSON object.

    - ![](media/rId2529.png){width="5.194444444444445in"
      height="3.9305555555555554in"}

###### Filter extracted data

You can filter the extracted data subset to analyze it on a more
granular level. In this example, we filter Box1 information from the
list created in Extract the data from a JSON Object above.

1.  Re-open the task you created above.

2.  Click the **value** field.

3.  Under **Filter**, click **Add Filter**.

4.  Set the condition you want to filter.

- In this example, retrieve the list of machines
  named `Box1` from `Test1` list by setting the
  filter `lists.Test1.domain.servers.machine Equals Box1`.

  ![](media/rId2533.png){width="5.833333333333333in"
  height="5.3432370953630794in"}

5.  Click **Test**.

6.  Check whether the data subset was accessed successfully by selecting
    the data source from an issue. You can see the results
    returned `machine: Box1`.

- ![](media/rId2536.png){width="5.833333333333333in"
  height="5.920542432195975in"}

###### Apply transformers to extracted data

In general, in a playbook task, you can transform (apply changes) to the
data extracted. This also applies to working with lists ,such as
transforming extracted data from a JSON object. In this example, we
extract the first element from the list created in the \'Extract Data
from a JSON Object\' section above and transform it to uppercase.

1.  Re-open the task, click the contents of the **value** field, and
    keep the current filters.

2.  In the **Apply transformers on the field**, click
    **Add transformer**.

3.  Add the following transformers to the extracted data:

    a.  Add the `Get index (General)` transformer to extract a specific
        machine element.

    - Set `index: 0` to extract the first element from the list.

    b.  Add the `To upper case (String`) transformer.

    - The `To upper case (String)` transformer does not work on lists,
      only on individual elements. Therefore,
      the `Get index (General)` transformer should be applied before
      adding the `To upper case (String)` transformer.

- ![](media/rId2540.png){width="5.833333333333333in"
  height="5.0738385826771655in"}

4.  In the **Fetch Data** field, select an issue to test and click
    **Test**.

##### Transform a list into an array

Create a transformer to split a list into an array, add or edit a task
in a playbook, or map an instance.

1.  Go to Investigation & Response \> Automation \> Playbooks and create
    or edit a playbook.

2.  Select **Create Task**.

3.  In the **Choose script** field, select the **Set** automation.

4.  In the **Key** field, enter the key name.

5.  In the **value** field, click **{}**

6.  Add a transformer.

    a.  Click **Filters And Transformers**.

    b.  In the **Get** field, click **{}**.

    c.  Expand the **Lists** node and select a list to transform.

    d.  In **Apply transformers on the field**, click
        **Add transformer**.

    e.  Search for and select **Split**.

    f.  (Optional) In the **delimiter** field, type the delimiter used
        to separate the items in the string (default is \",\").

    g.  Click **Save**.

7.  Save the task and playbook.

For an example of using a transformer in a list, see [Apply transformers
to extracted data](#X2995b4968ed99123c5e6c8ea3c95a8d96d1dd1d).

#### Jobs

Schedule playbooks to run automatically by defining a job based on
events or specific times. For instance, process indicators automatically
upon ingestion and then add them to your SIEM.

##### Manage jobs

A job is an automated playbook task or set of playbook tasks that are
scheduled to run at predefined intervals or under specific conditions.
Jobs can be used for data enrichment, periodic reporting, threat
intelligence gathering, or any repetitive operational tasks that need to
be performed regularly without manual intervention. There are two types
of jobs:

- Time triggered jobs that run at specific times: For example, you can
  schedule a time triggered job that runs nightly and removes expired
  indicators.

- Jobs triggered by a delta or change in a feed: For example, you can
  define an event triggered job to run a playbook when a specified TIM
  feed finishes a fetch operation for new indicators.

> **Note**

- > Only Account Admins and Instance Administrator roles can create jobs
  > and view/edit job runs.

- > If the owner of a job has been removed from Cortex XSIAM, the job
  > will fail to run. In this case, you must change the owner to a
  > current user.

On the **Jobs** page, you can:

+-----------------------------------+------------------------------------------------------+
| Action                            | Details                                              |
+===================================+======================================================+
| Create a new job                  | Click **+ New Job**.                                 |
+-----------------------------------+------------------------------------------------------+
| Edit an existing job              | In the table, select a job and click **Edit**.       |
+-----------------------------------+------------------------------------------------------+
| Perform additional job management | In the table, select a job and click one of the      |
|                                   | following:                                           |
|                                   |                                                      |
|                                   | - **Run now**                                        |
|                                   |                                                      |
|                                   | - **Disable**                                        |
|                                   |                                                      |
|                                   | - **Enable**                                         |
|                                   |                                                      |
|                                   | - **Pause**                                          |
|                                   |                                                      |
|                                   | - **Resume**                                         |
|                                   |                                                      |
|                                   | - **Abort**                                          |
|                                   |                                                      |
|                                   | - **Delete**                                         |
+-----------------------------------+------------------------------------------------------+
| View job status                   | The chart panel at the top of the **Jobs** page      |
|                                   | shows various status buttons. Click one of the       |
|                                   | following buttons to filter the list of jobs for     |
|                                   | that status:                                         |
|                                   |                                                      |
|                                   | - **Running**                                        |
|                                   |                                                      |
|                                   | - **Waiting**                                        |
|                                   |                                                      |
|                                   | - **Error**                                          |
|                                   |                                                      |
|                                   | - **Disabled**                                       |
|                                   |                                                      |
|                                   | - **Time Triggered**                                 |
|                                   |                                                      |
|                                   | - **Event Triggered**                                |
|                                   |                                                      |
|                                   | You can hide this panel by clicking                  |
|                                   | **Hide Chart Panel**.                                |
+-----------------------------------+------------------------------------------------------+
| Search for a specific job         | Enter a search query in the filter field. You can    |
|                                   | also save a filter.                                  |
+-----------------------------------+------------------------------------------------------+
| View job details in the table     | By default, the displayed table columns are:         |
|                                   |                                                      |
|                                   | - **Name**                                           |
|                                   |                                                      |
|                                   | - **Job Status**                                     |
|                                   |                                                      |
|                                   | - **Last Run**                                       |
|                                   |                                                      |
|                                   | - **Next Run**                                       |
|                                   |                                                      |
|                                   | - **Description**                                    |
|                                   |                                                      |
|                                   | - **Playbook**                                       |
|                                   |                                                      |
|                                   | Click                                                |
|                                   | ![](media/rId2547.png){width="0.23648622047244094in" |
|                                   | height="0.20833333333333334in"} to change the        |
|                                   | displayed columns. You can also select to show:      |
|                                   |                                                      |
|                                   | - **Owner**                                          |
|                                   |                                                      |
|                                   | - **ID**                                             |
|                                   |                                                      |
|                                   | - **Trigger**                                        |
|                                   |                                                      |
|                                   | - **Job Schedule**: This column shows a human        |
|                                   |   readable description of a cron schedule for a job. |
|                                   |                                                      |
|                                   | - **Attachments**                                    |
+-----------------------------------+------------------------------------------------------+

##### Create a time triggered job

Time triggered jobs run at predetermined times. You can schedule the job
to run at a recurring time or one time at a specific date and time.

1.  Select Investigation & Response \> Automation \> Jobs \> New Job.

2.  Select **Time triggered**.

3.  If you want the job to repeat at regular intervals, select
    **Recurring** and select the desired interval.

- You can choose to run the job every X number of days, on specific days
  of the week, at a specific time and also choose a start date and an
  expiration date.

  You can configure the recurring job using a cron expression. To do so,
  after selecting the **Recurring** checkbox, click
  **Switch to Cron view** and enter the expression. For help defining
  the cron expression, click **Show cron examples** after switching to
  cron view.

  > **Note**

  > To view a human readable description of a cron schedule for an
  > existing job, click
  > ![](media/rId2547.png){width="0.23648622047244094in"
  > height="0.20833333333333334in"} and select **Job Schedule** from the
  > available columns.

4.  If you do not want the job to repeat, **Select date and time** for
    the job to run.

5.  In the **BASIC INFORMATION**, section, add relevant time triggered
    job parameters from the following:

  -----------------------------------------------------------------------
  Name                                Description
  ----------------------------------- -----------------------------------
  Name                                Enter a meaningful name for the
                                      job.

  Playbook                            Determine which playbook to run
                                      when this job is triggered.

  Description                         Enter a meaningful description of
                                      the job.
  -----------------------------------------------------------------------

6.  In the **QUEUE HANDLING** section, select one of the following
    response options to use if the job is triggered while a previous run
    of the job is active:

    - Don't trigger a new job run

    - Cancel the previous job run and trigger a new job run

    - Trigger a new job run and execute concurrently with the previous
      run

- > **Important**

  > We recommend to avoid triggering a job while a previous run of the
  > job is active by configuring the playbook a job triggers to close
  > the investigation before running a new instance of the job.

7.  Select **Create new job**.

##### Create a job triggered by a delta in a feed

Jobs triggered by a delta in a feed (event triggered jobs) run when a
feed completes an operation and there is a change in the content. For
the job to trigger, there must be a delta between the incoming feed and
the previous one. You can define a job to trigger a playbook when the
specified feed or feeds finish a fetch operation that includes a
modification to the feed. The modification can be a new indicator, a
modified indicator, or a removed indicator. For example, you may want to
update your firewall every time a URL is added, modified, or removed
from the Office 365 feed. You can configure a job that triggers the
firewall update playbook to run whenever a modification is made to the
feed.

> **Note**
>
> A job triggered by a delta in a feed runs only if there is a change in
> the feed, and does not run on a feed's initial fetch. For the initial
> fetch, you can run the playbook manually and then set up an event
> triggered job for subsequent fetches.
>
> If you want to trigger a job after a feed completes a fetch operation
> and the feed does not change frequently, you can select the
> **Reset last seen** option in the feed integration instance. The next
> time the feed fetches indicators, it will process them as new
> indicators in the system.

1.  Select Investigation & Response \> Automation \> Jobs \> New Job.

2.  Select **Triggered by delta in feed**.

3.  In the **Trigger** section, select one of the following:

    - **Any feed**: The playbook runs when a modification is made to any
      feed.

    - **Specific feeds**: Select the feed instances that will trigger
      the playbook to run when a modification is made to them.

4.  In the **BASIC INFORMATION** section:

    - Add a meaningful name for the job.

    - Select the playbook you want to run when the conditions for the
      job are met.

5.  **Create new job**.

#### Engines

Install an engine in your remote network, enabling effortless
communication with Cortex XSIAM. Easily configure and manage the engine
to fit your specific needs, and explore how to leverage it for seamless
integrations.

##### What is an engine?

An engine is a proxy server application that is installed on a remote
machine and enables communication between the remote machine and the
Cortex XSIAM tenant. You can run playbooks, scripts, commands, and
integrations on the remote machine, and the results are returned to the
tenant.

While the Cortex XSIAM tenant includes a user interface that allows
security analysts to create and manage playbooks, investigate issues,
and perform other tasks, the engine operates behind the scenes to
execute these playbooks and automate security actions. The separation
between the user interface and the engine allows for the scalable and
efficient execution of security automation and orchestration.

You can install multiple engines on the same machine (Shell installation
only), which is useful in a dev-prod environment where you do not want
to have numerous engines in different environments and to manage those
machines.

> **Note**
>
> You cannot share a multiple-engine installation with a
> single-engine installation.

**Engine architecture**

![](media/rId2556.png){width="5.833333333333333in"
height="3.5510411198600176in"}

Within the network, you need to allow the engine to access the Cortex
XSIAM's IP address and listening port (by default, TCP 443). The engine
always initiates the communication to Cortex XSIAM.

**Engine use cases**

An engine can be used for the following purposes:

- **Engine proxy**

<!-- -->

- Cortex XSIAM engines enable you to access internal or external
  services that are otherwise blocked by a firewall or a proxy. For
  example, if a firewall blocks external communication and you want to
  run the Rasterize integration, you need to install an engine to access
  the Internet.

<!-- -->

- **Engine load-balancing**

<!-- -->

- Engines can be part of a load-balancing group, which enables the
  distribution of the command execution load. The load-balancing group
  uses an algorithm to efficiently share the workload for integrations
  that the group is assigned to, thereby speeding up execution time. In
  general, heavy workloads are caused by playbooks that run multiple
  commands.

  ![](media/rId2559.png){width="5.555555555555555in"
  height="2.4444444444444446in"}

  > **Note**

  > When you add an engine to a load-balancing group, you cannot use
  > that engine separately. The engine does not appear in the engines
  > menu when configuring an integration instance, but you can choose
  > the load-balancing group.

##### Engine requirements

You can install engines on all Linux environments. Docker/Podman needs
to be installed before installing an engine. If you are using the shell
installer for an engine, Docker/Podman is installed automatically.

> **Note**
>
> The Cron package is required to install engines on a Linux machine.

**Engine hardware requirements**

If your hard drive is partitioned, we recommend a minimum of 50 GB for
the `/var` partition.

  -----------------------------------------------------------------------
  Component               Dev Environment Minimum Production Minimum
  ----------------------- ----------------------- -----------------------
  CPU                     8 CPU cores             16 CPU cores

  Memory                  16 GB RAM               32 GB RAM

  Storage                 100 GB                  100 GB
  -----------------------------------------------------------------------

**Operating system requirements**

You can deploy a Cortex XSIAM engine on the following operating systems:

+-----------------------------------+-----------------------------------+
| Operating System                  | Supported Versions                |
+===================================+===================================+
| Ubuntu                            | 18.04, 20.04, 22.04               |
+-----------------------------------+-----------------------------------+
| RHEL                              | 8.x, 9.x                          |
|                                   |                                   |
|                                   | Includes all minor versions.      |
+-----------------------------------+-----------------------------------+
| Oracle Linux                      | 7.x, 8.9, 9.3, 9.4                |
+-----------------------------------+-----------------------------------+
| Amazon Linux                      | 2, Amazon Linux 2023              |
+-----------------------------------+-----------------------------------+
| Rocky Linux                       | 9.5                               |
+-----------------------------------+-----------------------------------+

> **Note**
>
> CentOS 8.x reached End of Life (EOL) on December 31, 2021, and is no
> longer supported as an operating system.
>
> CentOS 7.x reached End of Life (EOL) on June 30, 2024, and is no
> longer supported as an operating system.

**Engine required URLs**

You need to allow the following in the URLs for Cortex XSIAM engines to
operate properly. The URLs are needed to pull container images from
public Docker registries.

The endpoint URL
is: `wss://api-<tenant domain>.xdr.<region>.paloaltonetworks.com/xsoar/d1ws`.
For example,
`wss://api-my-tenant.xdr.us.paloaltonetworks.com/xsoar/d1ws`

+-----------------+--------------------------------------------+----------------------+-----------------+
| FUNCTION        | SERVICE                                    | PORT                 | DIRECTION       |
+=================+============================================+======================+=================+
| Integrations    |                                            | Integration-specific | Outbound        |
|                 |                                            | ports                |                 |
+-----------------+--------------------------------------------+----------------------+-----------------+
| Engine          | HTTPS                                      | 443 (configurable)   | Outbound        |
| connectivity    |                                            |                      |                 |
+-----------------+--------------------------------------------+----------------------+-----------------+
| Docker          | - https://registry-1.docker.io             | 443                  | Outbound        |
|                 |                                            |                      |                 |
|                 | - https://registry.fedoraproject.org       |                      |                 |
|                 |                                            |                      |                 |
|                 | - https://registry.access.redhat.com       |                      |                 |
|                 |                                            |                      |                 |
|                 | - https://docker.io                        |                      |                 |
|                 |                                            |                      |                 |
|                 | - https://registry.docker.io               |                      |                 |
|                 |                                            |                      |                 |
|                 | - https://auth.docker.io                   |                      |                 |
|                 |                                            |                      |                 |
|                 | <!-- -->                                   |                      |                 |
|                 |                                            |                      |                 |
|                 | - This URL may change at Docker's          |                      |                 |
|                 |   discretion.                              |                      |                 |
|                 |                                            |                      |                 |
|                 | <!-- -->                                   |                      |                 |
|                 |                                            |                      |                 |
|                 | - https://production.cloudflare.docker.com |                      |                 |
|                 |                                            |                      |                 |
|                 | <!-- -->                                   |                      |                 |
|                 |                                            |                      |                 |
|                 | - This URL may change at Docker's          |                      |                 |
|                 |   discretion.                              |                      |                 |
+-----------------+--------------------------------------------+----------------------+-----------------+

##### Install an engine

When you install the engine, the `d1.conf` is installed on the engine
machine, which contains engine properties such as proxy, log level, and
log files. If Docker/Podman is already installed, the
`python.engine.docker` and `powershell.engine.docker` keys are set to
`true`. If Docker or Podman is not available when the engine is
installed, the key is set to `false`. If so, you need to set the key to
`true` after installing Docker and Podman. Verify that
`python.engine.docker` and `powershell.engine.docker` configuration keys
are present in the `d1.conf` file.

> **Note**
>
> If you are using DEB, RPM, or Zip installation, install Docker or
> Podman.
>
> Natively running Python or PowerShell integrations/scripts on Windows
> or Linux is not supported on Cortex XSIAM engines.

###### Installation types

Cortex XSIAM supports the following file types for installation on the
engine machine:

- **Shell:** For all Linux deployments, including Ubuntu and SUSE.
  Automatically installs Docker/Podman, downloads Docker/Podman images,
  enables remote engine upgrade, and allows installation of multiple
  engines on the same machine.

<!-- -->

- The installation file is selected for you. Shell installation supports
  the purge flag, which by default is false. To uninstall an engine, run
  the installer with the purge flag enabled.

  > **Note**

  > When upgrading an engine that was installed using the Shell
  > installation, you can use the **Upgrade Engine** feature in the
  > **Engines** page. For Amazon Linux 2 type engines, you need to
  > upgrade these engine types using a zip-type engine and not use the
  > **Upgrade Engine** feature.

  > If you use the shell installer, Docker/Podman is automatically
  > installed. We recommend using Linux and not Windows to be able to
  > use the shell installer, which installs all dependencies.

<!-- -->

- **DEB:** For Ubuntu operating systems.

- **RPM:** RHEL operating systems.

<!-- -->

- > **Note**

  > Use DEB and RPM installation when the shell installation is not
  > available. You need to manually install
  > [Docker](#UUIDc2a4633cc8904adf2a1322b040573124) or
  > [Podman](#UUIDe52020e8425c72ad475a16b5073ca96c) and any
  > dependencies.

<!-- -->

- **Zip:** Used for Amazon Linux 2 machines.

- **Configuration:** Configuration file for download. When you install
  one of the other options, this configuration file (`d1.conf` ) is
  installed on the engine machine.

> **Important**
>
> For DEB/RPM engines, Python (including 3.x) and the containerization
> platform (Docker/Podman) must be installed and configured. For Docker
> or Podman to work correctly on an engine, [IPv4
> forwarding](https://docs.docker.com/network/bridge/#enable-forwarding-from-docker-containers-to-the-outside-world)
> must be enabled.

###### How to install an engine

1.  Create an engine.

    a.  Select Settings \> Configurations \> Data Broker \> Engines \>
        Create New Engine.

    b.  In the **Engine Name** field, add a meaningful name for the
        engine.

    c.  Select one of the installer types from the list.

    d.  (*Optional*) (*Shell only*) Select the checkbox to enable
        multiple engines to run on the same machine.

    - If you have an existing engine, and you did not select the
      checkbox, and now you want to install another engine on the same
      machine, you need to delete the existing engine.

    e.  (*Optional*) Add any required configuration in JSON format.

    f.  Click **OK** to create the engine.

2.  For shell installation, do the following:

- > **Tip**

  > For Linux systems, we recommend using the shell installer. If using
  > Amazon Linux 2, use the zip installer (see step
  > [4](#N1716185281356)).

  a.  Move the `.sh` file to the engine machine using a tool such as SSH
      or PuTTY.

  b.  On the engine machine, grant execution permission by running the
      following command:

  - `chmod +x /<engine-file-path>`

  c.  Install the engine by typing one of the following commands:

  - With tools: `sudo <engine-file-path>`

    Without tools: `sudo <engine-file-path> -- -tools=false`

    > **Note**

    > If you receive a `permissions denied` error, it is likely that you
    > do not have permission to access the `/tmp` directory.

    > If the installer fails to start due to a permissions issue, even
    > if running as root, add one of the following two arguments when
    > running the installer:

    - > `--target <path>` - Extracts the installer files into the
      > specified custom path.

    - > `--keep` - Extracts the installer files into the current working
      > directory (without cleaning at the end).

    > If using installer options such as `-- -tools=false`, the option
    > should come after the `--target` or `--keep` arguments. For
    > example:

    > `sudo ./d1-installer.sh --target /some/temp/dir -- -tools=false`

    > If you set a custom path when you run the installer, you must also
    > set a custom path for upgrading your engine or the upgrade will
    > fail. For more information, see
    > [/document/preview/1199417#UUID-3a9e655c-6f7e-2566-d416-29991d7d1d3b](/document/preview/1199417#UUID-3a9e655c-6f7e-2566-d416-29991d7d1d3b).

3.  For RPM/DEB installation, do the following:

    a.  Move the file to the required machine using a tool such as SSH
        or PuTTY.

    b.  Type one of the following installation commands:

  -------------------------------------------------------------------------------
  Machine Type                        Install Command
  ----------------------------------- -------------------------------------------
  RHEL (RPM)                          `sudo rpm -Uvh d1-2.5_15418-1.x86_64.rpm`

  Ubuntu (DEB)                        `sudo dpkg --install d1_xxx_amd64.deb`
  -------------------------------------------------------------------------------

c.  Start the engine by running one of the following commands:

  -----------------------------------------------------------------------
  Machine Type                        Start Command
  ----------------------------------- -----------------------------------
  RHEL (RPM)                          `sudo systemctl start d1`

  Ubuntu (DEB)                        `sudo service d1 restart`
  -----------------------------------------------------------------------

4.  For Zip installation on Amazon Linux 2, run the following commands:

    a.  Create the engine folder.

    - `mkdir /usr/local/demisto`

    b.  Unzip the engine files to the folder created in the previous
        step.

    - `unzip ./d1.zip -d /usr/local/demisto`

    c.  Allow the process to bind to low-numbered ports.

    - `setcap CAP_NET_BIND_SERVICE=+eip /usr/local/demisto/d1_linux_amd64`

    d.  Change the owner of `/usr/local/demisto` to the demisto user.

    - `chown -R demisto:demisto /usr/local/demisto`

    e.  In `/etc/systemd/system` edit the `d1.service` file as follows
        (adjust the directory and the name of the binary file if
        needed).

    -  [Unit]
          Description=Demisto Engine Service
          After=network.target
          [Service]
          Type=simple
          User=demisto
          WorkingDirectory=/usr/local/demisto
          ExecStart=/usr/local/demisto/d1_linux_amd64
          EnvironmentFile=/etc/environment
          Restart=always
          [Install]
          WantedBy=multi-user.target

    f.  Run the following commands:

    - `chown root:root /etc/systemd/system/d1.service`

      `chmod 644 /etc/systemd/system/d1.service`

    g.  Run the engine process.

    - `systemctl start d1`

    h.  Verify that the engine is running.

    - `systemctl status d1`

5.  Verify that the engine you created is connected.

    a.  Select Settings \> Configurations \> Data Broker \> Engines.

    b.  Locate your engine on the **Engines** page and check that it is
        connected.

6.  When the engine is connected, you can add the engine to a
    load-balancing group by clicking **Load-Balancing Group** on the
    Engines page.

- If you want to add the engine to a new group, click
  **Add to new group** from the list.

  When the engine is in the load-balancing group, it cannot be used as
  an individual engine and does not appear when configuring an engine
  from the list.

7.  (Optional) After installing the engine, you may want to set up a
    proxy, set up Docker hardening, configure the number of workers for
    the engine, or perform other related engine configurations. For more
    information, see [Configure
    Engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb). You can also
    configure an integration instance to run on the engine you created.

###### Docker

Docker is a software framework for building, running, and managing
containers.

> **Note**
>
> This section is relevant when installing an engine.

Cortex XSIAM maintains a repository of Docker images, available in the
Docker Hub under the [Cortex](https://hub.docker.com/u/demisto/)
organization.

Each Python/PowerShell script or integration has a specific Docker image
listed in the YAML file. When the script or integration runs, if the
specified Docker image is not available locally, it is downloaded from
the Docker Hub or the Cortex Container Registry. The script or
integration then runs inside the Docker container. For more information
on Docker, see the [Docker documentation](https://docs.docker.com/) and
[Using Docker](https://xsoar.pan.dev/docs/integrations/docker).

> **Note**
>
> Docker images can be
> [downloaded](https://xsoar.pan.dev/docs/reference/articles/download-packs-offline)
> together with their relevant content packs for offline installation.

####### Install Docker

Docker is required for engines to run Python/Powershell scripts and
integrations in a controlled environment.

If you use the Shell installer to install an engine, Docker is
automatically installed. If using DEB and RPM installations, install
Docker or Podman before installing an engine. The engine uses Docker to
run Python scripts, PowerShell scripts, and integrations in a controlled
environment. By packaging libraries and dependencies together, the
environment remains the same, and scripts and integrations are not
affected by different server configurations.

Cortex XSIAM supports the latest Docker Engine release from Docker and
the following corresponding supported Linux distributions:

- 5.3.15 and later

- 5.4.2 and later

- 5.5 and later

These Linux distributions include their own Docker Engine package. In
addition, older versions of Docker Engine released within the last 12
months are supported unless there is a known compatibility issue with a
specific Docker Engine version. In case of a compatibility issue, Cortex
XSIAM will publish an advisory notifying customers to upgrade their
Docker Engine version.

You can use a version that is not supported. However, when encountering
an issue that requires Customer Support involvement, you may be asked to
upgrade to a supported version before assistance can be provided.

######## Docker installation by operating system

If you need to install Docker before installing an engine, use the
following procedures:

- [Red Hat](#UUID9d586cab0fd83bcc382e5a92aa8a05c0)

- [Ubuntu](https://docs.docker.com/engine/install/ubuntu/)

- [Amazon
  Linux](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html#install_docker)

- [Oracle
  Linux](https://docs.oracle.com/en/operating-systems/oracle-linux/docker/)

> **Note**
>
> For Red Hat\'s Docker distribution, you need Mirantis Container
> Runtime (formerly Docker Engine - Enterprise) to run specific
> Docker-dependent integrations and scripts. For more information, see
> [Install Docker distribution for Red Hat on an engine
> server](#UUID9d586cab0fd83bcc382e5a92aa8a05c0).
>
> To use the Mirantis Container Runtime (formerly Docker Engine -
> Enterprise) follow the [deployment
> guide](https://docs.mirantis.com/welcome/mcr) for your operating
> system distribution.

######## Verify Docker user and permissions

Verify Docker user

If you installed an engine before installing Docker, verify the
`demisto` operating system user is part of the Docker operating system
group.

1.  Run `id demisto` verify. For example:

- id demisto
      uid=997(demisto) gid=997(demisto) groups=997(demisto),998(docker)

  If needed, add the demisto user to the operating system group:

      sudo groupadd docker
      sudo usermod -aG docker demisto

  Remove these keys from the engine configuration file.

      python.executable
      python.executable.no.docker

Verify user permissions

To verify that the operating system user (demisto) has the necessary
permissions and can run Docker containers, run the following command
from the OS command line.

`sudo -u demisto docker run --rm -it demisto/python:1.3-alpine python --version`

If everything is configured properly you will receive the following
output. `Python 2.7.14`.

######## Install Docker distribution for Red Hat on an engine server

Red Hat maintains its own package of Docker, which is the version used
in OpenShift Container Platform environments, and is available in the
RHEL Extras repository.

> **Note**
>
> If running RHEL v8 or higher, the engine installs
> [Podman](#UUID64ae8cd3b40b67caa92b8b259c856431) packages and
> configures the operating system to enable Podman in rootless mode.

For more information about the different packages available to install
on Red Hat, see the [Red Hat Knowledge Base
Article](https://access.redhat.com/solutions/3092401) (requires a Red
Hat subscription to access).

1.  Install [Red Hat's Docker
    package](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html-single/getting_started_with_containers/index#using_the_docker_command_and_service).

2.  Run the following commands.

- `systemctl enable docker.service`

  `systemctl restart docker.service`

3.  Change ownership of the Docker daemon socket so members of the
    `dockerroot` user group have access.

    a.  Edit or create the file `/etc/docker/daemon.json`.

    b.  Enable OS group `dockerroot` access to Docker by adding the
        following entry to the
        `/etc/docker/daemon.json: "group": "dockerroot"`file. For
        example:

    - `{ "group": "dockerroot" }`

    c.  Restart the Docker service by running the following command.

    - `systemctl restart docker.service`

    d.  [Install the engine](#UUID65eabcb0fcddc32e7dc5f216e8f66604)

    e.  After the engine is installed, run the following command to add
        the `demisto` os user to the `dockerroot` os group (Red Hat uses
        dockerroot group instead of docker).

    - `usermod -aG dockerroot demisto`

    f.  Restart the engine.

4.  Set the required SELinux permissions.

- The Cortex XSIAM engine uses the `/var/lib/demisto/temp` directory
  (with subdirs) to copy files and receive files from running Docker
  containers. By default, when SELinux is in **enforcing** mode
  directories under `/var/lib/` it cannot be accessed by Docker
  containers.

  a.  To allow containers access to the `/var/lib/demisto/temp`
      directory, you need to set the correct SELinux policy type, by
      typing the following command.

  - `chcon -Rt svirt_sandbox_file_t /var/lib/demisto/temp`

  b.  ( *Optional*) Verify that the directory has the `container_file_t`
      SELinux type attached by running the following command.

  - `ls -d -Z /var/lib/demisto/temp`

  c.  Configure label confinement to allow Python and PowerShell
      containers to access other script folders.

  - In the d1.conf file, set the following parameters:

  -----------------------------------------------------------------------------------------------
                          Key                          Value
  ----------------------- ---------------------------- ------------------------------------------
  For Python containers   python.pass.extra.keys       \--security-opt=label=level:s0:c100,c200

  For PowerShell          powershell.pass.extra.keys   \--security-opt=label=level:s0:c100,c200
  containers                                           
  -----------------------------------------------------------------------------------------------

d.  Open any issue and in the issue War Room CLI, run the
    `/reset_containers` command.

######## Docker image security

The project that contains the source Dockerfiles used to build the
images and the accompanying files is fully open source and [available
for review](https://github.com/demisto/dockerfiles). Cortex XSIAM uses
the secure Docker Hub registry for its [Docker
images](https://hub.docker.com/u/demisto). However, in an Engine
environment, you can also use the [PANW
registry](/document/preview/1076037#UUID-4e9bb025-5de8-f83f-befc-b2e46a4a2dee)
. You can view the Docker trust information for each image at the [image
info
branch](https://github.com/demisto/dockerfiles-info/blob/master/README.md).

![](media/rId2585.png){width="5.833333333333333in"
height="2.1986417322834644in"}

We automatically update our open-source Docker images and their
accompanying dependencies (OS and Python). Examples of automatic updates
can be viewed on
[GitHub](https://github.com/demisto/dockerfiles/pull/700).

We maintain Docker image information, which includes information on
Python packages, OS packages, and image metadata for all our Docker
images. [Data image
information](https://github.com/demisto/dockerfiles-info/blob/master/README.md)
is updated nightly.

All of our images are continuously scanned using Prisma Cloud for known
and newly published vulnerabilities, in two scenarios:

- Every new image, and every new version of an image, are scanned before
  publishing to our public registries, as part of our CI/CD process.

- All existing images are continuously scanned to check whether new
  vulnerabilities have been published and now exist in those images.

We evaluate all critical/high findings and actively work to prevent and
mitigate security vulnerabilities.

Cortex XSIAM ensures container images are fully patched and do not
contain unnecessary packages. Patches and dependencies are applied
automatically via our open-source Docker file build project.

######### Response Prioritization

We remediate any critical and high level vulnerabilities, irrespective
of who found them. Issues may be discovered by external researchers,
found during internal testing, encountered by customers or reported by
other organizations and vendors.

Any vulnerability with a possible exploitation against our images would
be responded to with utmost urgency. If we conclude that there is a risk
for our customers we will issue an advisory with recommended actions and
mitigations. Advisories are published at:
<https://security.paloaltonetworks.com/>.

In each version release (every 3 months,) we publish a new version of
our content, which will use the latest and secure versions of our
images.

######### Troubleshooting

- Purge old and unused images periodically.

- If you scanned the Docker images locally, and found some critical
  CVE's - Make sure you use the latest version of the pack, as it should
  have the latest version of the image. In addition, purge the old and
  unused images with vulnerabilities.

######## Docker FAQs

- **Does Cortex XSIAM use COPY or ADD for building images?**

<!-- -->

- Cortex XSIAM uses COPY for building images. The COPY instruction
  copies files from the local host machine to the container file system.
  Cortex XSIAM does not use the ADD instruction, which could potentially
  retrieve files from remote URLs and perform operations such as
  unpacking, introducing potential security vulnerabilities.

<!-- -->

- **Should the **`--restart flag`** be used?**

<!-- -->

- The \--restart flag should not be used. Cortex XSIAM manages the
  lifecycle of Docker images and restarts images as needed.

<!-- -->

- **Can we restrict containers from acquiring additional privileges by setting the no-new-privileges option?**

<!-- -->

- Cortex XSIAM does not support the no-new-privileges option. Some
  integrations and scripts may need to change privileges when running as
  a non-root user (such as Ping).

<!-- -->

- **Can we apply a daemon-wide custom seccomp profile?**

<!-- -->

- The [default seccomp
  profile](https://docs.docker.com/engine/security/seccomp/) from Docker
  is strongly recommended. The default seccomp profile provides
  protection as well as wide application compatibility. While you can
  apply a custom seccomp profile, Cortex XSIAM cannot guarantee that it
  won\'t block system calls used by an integration or script. If you
  apply a custom seccomp profile, you need to verify and test the
  profile with any integrations or scripts you plan to use.

<!-- -->

- **Can we use TLS authentication for docker daemon configuration?**

<!-- -->

- TLS authentication is not used, because Cortex XSIAM does not use
  Docker remote connections. All communication is done via the local
  Docker IPC socket.

<!-- -->

- **How do we set the logging level to** `info`?

<!-- -->

- Set the log level in the [Docker daemon configuration
  file](https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file).

<!-- -->

- **Can we restrict Linux kernel capabilities within containers?**

<!-- -->

- The default Docker settings (recommended) include 14 kernel
  capabilities and exclude 23 kernel capabilities. Refer to Docker's
  [full list of runtime privileges and Linux
  capabilities](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities).

  You can further exclude capabilities via advanced configuration, but
  will first need to verify that you are not using a script that
  requires the capability. For example, Ping requires `NET_RAW`
  capability.

<!-- -->

- **Is the Docker health check option implemented at runtime?**

<!-- -->

- The Cortex XSIAM tenant monitors the health of the containers and
  restarts/terminates containers as needed. The Docker health check
  option is not needed.

<!-- -->

- **Can we enable live restore?**

<!-- -->

- Live restore is not used. Cortex XSIAM uses ephemeral Docker
  containers. Every running container is stateless by design.

<!-- -->

- **Can we restrict network traffic between containers?**

<!-- -->

- Cortex XSIAM does not disable inter-container communication by
  default, as there are use cases where this might be needed. For
  example, a script communicating with a long running integration which
  listens on a port, may require inter-container communication. If
  inter-container communication is not required, it can be disabled by
  modifying the [Docker daemon
  configuration.](https://docs.docker.com/engine/reference/commandline/dockerd/)

<!-- -->

- **Can we enable user namespace remapping?**

<!-- -->

- Cortex XSIAM does not support user namespace remapping.

<!-- -->

- **How do we configure auditing for Docker files and directories?**

<!-- -->

- Auditing is an operating system configuration, and can be enabled in
  the operating system settings. Cortex XSIAM does not change the audit
  settings of the operating system.

<!-- -->

- **Can we disable the userland proxy?**

<!-- -->

- If the kernel supports hairpin NAT, you can disable docker userland
  proxy settings by modifying the [Docker daemon
  configuration](https://docs.docker.com/engine/reference/commandline/dockerd/).

<!-- -->

- **Does Cortex XSIAM support the AppArmor profile?**

<!-- -->

- Cortex XSIAM supports the default AppArmor profile (only relevant for
  Ubuntu with AppArmor enabled).

<!-- -->

- **Does Cortex XSIAM support the SELinux profile?**

<!-- -->

- Cortex XSIAM supports the default SELinux profile (only relevant for
  RedHat with SELinux enabled).

<!-- -->

- **How does Cortex XSIAM handle secrets management?**

<!-- -->

- For Docker swarm services, a secret is a blob of data, such as
  password, SSH private keys, SSL certificates, or other piece of data
  that should not be transmitted over a network or stored unencrypted in
  a Docker file or in your application's source code. Cortex XSIAM
  manages integration credentials internally. It also supports using an
  [external credentials
  service](https://xsoar.pan.dev/docs/reference/articles/managing-credentials)
  such as CyberArk.

######## Troubleshoot Docker issues

The following provides troubleshooting solutions for Docker networking
and performance issues.

Troubleshoot Docker networking issues

In Cortex XSIAM, integrations and scripts run either on the tenant, or
on an engine.

If you have Docker networking issues when using an engine, you need to
modify the [d1.conf file](#X7f07aca93bb8acfa46d16c3d93af3ce57d94f5c).

1.  On the machine where the Engine is installed, open the `d1.conf`
    file.

2.  Add the following to the `d1.conf` file:

- {
          "LogLevel": "info",
          "LogFile": "/var/log/demisto/d1.log",
          "EngineURLs": [
          "wss://1234.demisto.live/d1ws"
          ],
                          "BindAddress": ":443",
          "EngineID": "XYZ",
          "ServerPublic": "ABC"
          "ArtifactsFolder": "",
          "TempFolder": "",
          "python.pass.extra.keys": "--network=host"
          }

3.  Save the file.

4.  Restart the engine using `systemctl restart d1` or
    `service d1 restart`.

Troubleshoot Docker performance issues

This information is intended to help resolve the following Docker
performance issues.

- Containers are getting stuck.

- The Docker process consumes a lot of resources.

- Time synchronization issues between the container and the operating
  system.

**Cause**

The installed Docker package and its dependencies are not up to date.

**Workaround**

1.  Update the package manager cache.

  -----------------------------------------------------------------------
  Linux Distribution                  Command
  ----------------------------------- -----------------------------------
  Debian                              `apt-get update`

  -----------------------------------------------------------------------

2.  *(Optional)* Check for a newer version of the Docker package.

  -----------------------------------------------------------------------
  Linux Distribution                  Command
  ----------------------------------- -----------------------------------
  Debian                              `apt-cache policy docker`

  -----------------------------------------------------------------------

3.  Update the Docker package.

  -----------------------------------------------------------------------
  Linux Distribution                  Command
  ----------------------------------- -----------------------------------
  Debian                              `apt-get update docker`

  -----------------------------------------------------------------------

######## Configure Docker pull rate limit

Docker enforces a [pull rate
limit](https://www.docker.com/blog/scaling-docker-to-serve-millions-more-developers-network-egress/)
on public images. The limit is based on an IP address or as a logged-in
Docker hub user. The default limit (100 pulls per 6 hours) is usually
high enough for Cortex XSIAM\'s use of Docker images, but the rate limit
may be reached if using a single IP address for a large organization
(behind a NAT). If the rate limit is reached, the following error
message is issued:

`Error response from daemon: toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit.`

To increase the limit:

1.  Sign up a free user [in the Docker
    hub](https://hub.docker.com/signup/).

- The pull limit is higher for a registered user (200 pulls per 6
  hours).

2.  Authenticate the user on the engine machine by running the following
    command.

- `sudo -u demisto docker login`

3.  (*Optional*) Instead of manually logging in to Docker to pull
    images, you can edit the [Docker config
    file](https://docs.docker.com/engine/reference/commandline/login/)
    to use credentials from the file or from a credential store.

######## Change the Docker installation folder

The `/var/lib/docker/` folder is the default Docker folder for Ubuntu,
Fedora, and Deblan in a standard engine installation.

To change the Docker folder:

1.  Stop the Docker daemon.

- `sudo service docker stop`

2.  Create a file called `daemon.json` under the `/etc/docker` directory
    with the following content:

- {
              "data-root": "<path to your Docker folder>"
        }

3.  Copy the current data directory to the new one.

- `sudo rsync -aP /var/lib/docker/ <path to your Docker folder>`

4.  Rename the old docker directory.

- `sudo mv /var/lib/docker /var/lib/docker.bkp`

5.  After confirming that the change was successful, you can remove the
    backup file.

- `sudo rm -rf /var/lib/docker.bkp`

6.  Start the Docker daemon.

- `sudo service docker start`

####### Docker hardening guide

The following describes the engine settings we recommend for securely
running Docker containers.

When editing the configuration file, you can limit container resources,
open file descriptors, limit available CPU, and more. For example, add
the following keys to the configuration file:

`{"docker.run.internal.asuser": true,"limit.docker.cpu": true,"limit.docker.memory": true,"python.pass.extra.keys": "--pids-limit=256##--ulimit=nofile=1024:8192"}`

> **Tip**
>
> We recommend reviewing *Docker network hardening* below before
> changing any parameters in the configuration file.
>
> To securely run Docker containers, we recommend using the latest
> Docker version.

You can *Check Docker Hardening Configurations* to verify that the
Docker container has been hardened according to the settings we
recommend.

> **Note**
>
> The settings below can also be applied to
> [Podman](#UUID64ae8cd3b40b67caa92b8b259c856431), with the exception of
> limiting available memory, limiting available CPU, and limiting PIDS.

Docker network hardening

Docker creates its networking stack that enables containers to
communicate with other networking endpoints. You can use iptables rules
to restrict which networking sources the containers communicate with. By
default, Docker uses a networking configuration that allows unrestricted
communication for containers, so that containers can communicate with
all IP addresses.

- **Block network access to the host machine**

<!-- -->

- Integrations and scripts running within containers do not usually
  require access to the host network. For added security, you can block
  network access from containers to services running on the engine
  machine.

  For example, to limit all source IPs from containers that use the IP
  ranges 172.16.0.0/12, run
  `sudo iptables -I INPUT -s 172.16.0.0/12 -d 10.18.18.246 -j DROP`.
  This also ensures that new Docker networks that use addresses in the
  IP address range of 172.16.0.0/12 are blocked from access to the host
  private IP. The default IP range used by Docker is 172.16.0.0/12. If
  you configured a different range in Docker\'s `daemon.json` config
  file, use the configured range. Alternatively, you can limit specific
  interfaces by using the interface name, such as `docker0`, as a
  source.

  1.  Add the following iptables rule for each private IP on the tenant
      machine:

  - `sudo iptables -I INPUT -s <IP address range> -d <host private ip address> -j DROP`

  2.  (*Optional*) To view a list of all private IP addresses on the
      host machine, run `sudo ifconfig -a`

<!-- -->

- **Assign a Docker network for a Docker image**

<!-- -->

- If your engine is installed on a cloud provider such as AWS or GCP, it
  is best practice to block containers from accessing the cloud
  provider's instance metadata service. The metadata service is accessed
  via IP address `169.254.169.254`. For more information about the
  metadata service and the data exposed, see the AWS and GCP
  documentation

  There are cases where you might need to provide access to the metadata
  service. For example, access is required when using an AWS integration
  that authenticates via the available role from the instance metadata
  service. You can create a separate Docker network, without the blocked
  iptable rule, to be used by the AWS integration's Docker container.
  For most AWS integrations, the relevant Docker image is:
  `demisto/boto3py3`

  1.  Create a new Docker network by running the following command:

  - `sudo docker network create -d bridge -o com.docker.network.bridge.name=docker-metadata aws-metadata`

  2.  Edit the engine configuration file either by editing the `d1.conf`
      file, or If you installed via Shell, you can edit the
      configuration in the UI as well as editing the file directly. For
      details, see [Configure
      engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

  3.  Add the following key.

  - `"python.pass.extra.keys.demisto/boto3py3": "--network=aws-metadata"`

  4.  Save the changes.

  5.  Restart the demisto service on the engine machine.

  - `sudo systemctl start d1`

    (Ubuntu) `sudo service d1 restart`

  6.  Verify the configuration of your new Docker network:

  - `sudo docker network inspect aws-metadata`

<!-- -->

- **Block internal network access**

<!-- -->

- In some cases, you might need to block specific integrations from
  accessing internal network resources and allow the integrations to
  access only external IP addresses. We recommend this setting for the
  **Rasterize** integration when used to Rasterize untrusted URLs or
  HTML content, such as those obtained via external emails. With
  internal network access blocked, a rendered page in the Rasterize
  integration cannot perform an SSRF or DNS rebind attack to access
  internal network resources.

  1.  Create a new Docker network by running the following command:

  - `sudo docker network create -d bridge -o com.docker.network.bridge.name=docker-external external`

  2.  Block network access to the host machine for the new Docker
      network:

  - `iptables -I INPUT -i docker-external -d <host private ip> -j DROP`

  3.  Block network access to cloud provider instance metadata:

  - `sudo iptables -I DOCKER-USER -i docker-external -d 169.254.169.254/32 -j DROP`

  4.  Block internal network access:

  - `sudo iptables -I DOCKER-USER -i docker-external -d 10.0.0.0/8 -j DROP`

    `sudo iptables -I DOCKER-USER -i docker-external -d 172.16.0.0/12 -j DROP`

    `sudo iptables -I DOCKER-USER -i docker-external -d 192.168.0.0/16 -j DROP`

  5.  Edit the engine configuration file either by editing the `d1.conf`
      file, or If you installed via Shell, you can edit the
      configuration in the UI as well as editing the file directly. For
      details, see [Configure
      engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

  6.  Add the following key to run integrations that use the
      `demisto/chromium` Docker image with the Docker network
      `external`.

  - `"python.pass.extra.keys.demisto/chromium": "--network=external"`

  7.  Save the changes.

  8.  Restart the demisto service on the engine machine.

  - `sudo systemctl start d1`

    (Ubuntu) `sudo service d1 restart`

  9.  Verify the configuration of your new Docker network:

  - `sudo docker network inspect external`

<!-- -->

- **Persist iptables rules**

<!-- -->

- By default, iptables rules are not persistent after a reboot. To
  ensure your changes are persistent, save the iptables rules by
  following the recommended configuration for your Linux operating
  system:

  - [Ubuntu](https://help.ubuntu.com/community/IptablesHowTo)

  - [Red Hat and related operating system
    flavors](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/security_guide/sec-setting_and_controlling_ip_sets_using_iptables)

Configure Docker images

You can apply more specific fine tuned settings to Docker images,
according to the Docker image name or the Docker image name including
the image tag. To apply settings to a Docker image name, add the
advanced configuration key to the engine configuration file. If you
apply Docker image specific settings, they will be used instead of the
general `python.pass.extra.keys` setting. This overrides the general
memory and CPU settings, as needed.

1.  Edit the engine configuration file either by editing the `d1.conf`
    file, or If you installed via Shell, you can edit the configuration
    in the UI as well as editing the file directly. For details, see
    [Configure engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

2.  Add the following key to apply settings to a Docker image name.

- `"python.pass.extra.keys.<image_name>"`

  For example, `"python.pass.extra.keys.demisto/dl"`.

  - To apply settings to a Docker image name, including the image tag,
    use `"python.pass.extra.keys.<image_name>": "<image_tag>"`.

  <!-- -->

  - For example, `"python.pass.extra.keys.demisto/dl": "1.4"`.

  <!-- -->

  - To set the Docker images `demisto/dl` (all tags) to use a higher max
    memory value of 2g and to remain with the recommended PIDs and
    ulimit, add the following to the configuration
    file:`"python.pass.extra.keys.demisto/dl": "--memory=2g##--ulimit=no- file=1024:8192##--pids-limit=256"`

3.  Save the changes.

4.  Restart the demisto service on the engine machine.

- `sudo systemctl start d1`

  (Ubuntu) `sudo service d1 restart`

Run Docker with non-root internal users

For additional security isolation, we recommend to run Docker containers
as non-root internal users. This follows the principle of least
privilege.

1.  Edit the engine configuration file either by editing the `d1.conf`
    file, or If you installed via Shell, you can edit the configuration
    in the UI as well as editing the file directly. For details, see
    [Configure engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

2.  Add the following key:

- `"docker.run.internal.asuser": true`

3.  For containers that do not support non-root internal users, add the
    following key:

- `"docker.run.internal.asuser.ignore" : "A comma separated list of container names. The engine matches the container names according to the prefixes of the key values>"`

  For example,
  `"docker.run.internal.asuser.ignore"="demisto/python3:","demisto/python:"`

  The engine matches the key values for the following containers:

      demisto/python:1.3-alpine
      demisto/python:2.7.16.373
      demisto/python3:3.7.3.928
      demisto/python3:3.7.4.977

  The `:` character should be used to limit the match to the full name
  of the container. For example, using the `:` character does not find
  `demisto/python-ubuntu:2.7.16.373`.

4.  Save the changes.

5.  Restart the demisto service on the engine machine.

- `sudo systemctl start d1`

  (Ubuntu) `sudo service d1 restart`

Configure the memory limit support without swap limit capabilities

When a container exceeds the specified amount of memory, the container
starts to swap. Not all Linux distributions have the swap limit support
enabled by default.

- Red Hat distributions usually have swap limit support enabled by
  default.

- Ubuntu distributions usually have swap limit support disabled by
  default.

To protect the host from a container using too many system resources
(either because of a software bug or a DoS attack), limit the resources
available for each container. In the engine configuration file, some of
these settings are set using the advanced parameter:
`python.pass.extra.keys`. This key receives as a parameter full
`docker run` options, separated with the `##` string.

**How to check if your system supports swap limit capabilities**

1.  On the engine machine, run the following command:

- `sudo docker run --rm -it --memory=1g demisto/python:1.3-alpine true`

2.  If `swap limit capabilities` is enabled, [configure the memory
    limitation](/document/preview/886729#UUID-474921ff-0ac9-43bb-567d-4e4cd0b2358f_sidebar-idm456992794144643393717133447)
    . (To test the memory, see step 5 of [configure the memory
    limitation](/document/preview/886729#UUID-474921ff-0ac9-43bb-567d-4e4cd0b2358f_sidebar-idm456992794144643393717133447).)

3.  If you see the following message in the output (the message may vary
    between Docker versions):

- `WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.`

  You have 2 options:

  - Configure `swap limit capabilities` by following the [Docker
    documentation](https://docs.docker.com/config/containers/resource_constraints/).

  - See [How to configure the memory limit support without swap limit
    capabilities](#X2d9904c5755c1b0aeee1fb99c017f6b30076945).

  If you see the `WARNING: No swap limit support` you can configure
  memory support without swap limit capabilities.

**How to configure the memory limit support without swap limit
capabilities**

1.  Edit the engine configuration file either by editing the `d1.conf`
    file, or If you installed via Shell, you can edit the configuration
    in the UI as well as editing the file directly. For details, see
    [Configure engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

2.  Add the following key to disable swap memory enforcement:

- `"python.pass.extra.keys": "--memory=1g##--memory-swap=-1"`

  If you have the `python.pass.extra.keys` already set up with a value,
  add the value after the `##` separator.

3.  Save the changes.

4.  Restart the demisto service on the engine machine.

- `sudo systemctl start d1`

  (Ubuntu) `sudo service d1 restart`

Configure the memory limitation

We recommend limiting available memory for each container to 1 GB.

If `swap limit capabilities` is enabled (see
**How to check if your system supports swap limit capabilities** above),
in Cortex XSIAM configure the memory limitation using the following
advanced parameters.

1.  Edit the engine configuration file either by editing the `d1.conf`
    file, or If you installed via Shell, you can edit the configuration
    in the UI as well as editing the file directly. For details, see
    [Configure engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

2.  Add the following keys.

- `"limit.docker.memory": true, "docker.memory.limit": "1g"`

  > **Note**

  > If you do not want to apply Docker memory limitations, you should
  > explicitly set the advanced parameter: `limit.docker.memory` to
  > `false`.

3.  Save the changes.

4.  Restart the demisto service on the engine machine.

- `sudo systemctl start d1`

  (Ubuntu) `sudo service d1 restart`

5.  Test the memory limit.

    a.  Go to Investigation & Response \> Automation \> Scripts \> New
        Script.

    b.  In the **Script Name** file, type `TestMemory`.

    c.  Add the following script:

    - from multiprocessing import Process
          import os


          def big_string(size):
              sys.stdin = os.fdopen(0, "r")
              s = 'a' * 1024
              while len(s) < size:
                  s = s * 2
              print('completed creating string of length: {}'.format(len(s)))


          size = 1 * 1024 * 1024 * 1024
          p = Process(target=big_string, args=(size, ))
          p.start()
          p.join()
          if p.exitcode != 0:
              return_error("Return code from sub process indicates failure: {}".format(p.exitcode))
          else:
              print("Success allocating memory of size: {}".format(size))

    d.  In the **SCRIPT SETTINGS** section, select the script to run on
        the **Single engine** and select the engine where you want to
        run the script.

    e.  Save the script.

    f.  To test the memory limit, type `!TestMemory`. The command
        returns an error when it fails to allocate 1 GB of memory.

Configure the CPU, PIDs, and open file descriptors limit

Set the advanced parameters to configure the CPU limit, PIDs limit, and
the open file descriptor limit.

1.  Edit the engine configuration file either by editing the `d1.conf`
    file, or If you installed via Shell, you can edit the configuration
    in the UI as well as editing the file directly. For details, see
    [Configure engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb).

2.  Add the following keys:

  ---------------------------------------------------------------------------------------------------
  Parameter                           Key
  ----------------------------------- ---------------------------------------------------------------
  Available CPU limit                 `"limit.docker.cpu": true, "docker.cpu.limit": "<CPU Limit>"`
                                      We recommend to limit each container to 1 CPU. (For example,
                                      `1.0`. Default is 1.0).

  PIDs limit                          `"python.pass.extra.keys": "--pids-limit=256"`

  Open file descriptors limit         `"python.pass.extra.keys": "--ulimit=nofile=1024:8192"`
  ---------------------------------------------------------------------------------------------------

3.  Save the changes.

4.  Restart the demisto service on the engine machine.

- `sudo systemctl start d1`

  (Ubuntu) `sudo service d1 restart`

Check Docker hardening configurations

Check your Docker hardening configurations on an engine by running the
`!DockerHardeningCheck` command in the Case/Issue War Room CLI. The
results show the following:

- Non-root User

- Memory

- File descriptors

- CPUs

- PIDs

Before running the command, ensure that your engine is up and running.

1.  Update the `DockerHardeningCheck` script to run on the engine.

    a.  Go to Investigation & Response \> Automation \> Scripts \>
        DockerHardeningCheck \> Settings.

    b.  In the **Run on** field select **Single engine** and from the
        list, select the engine you want to run the script.

    c.  Save the script.

2.  Verify the Docker container has been hardened according to
    recommended settings. In the Case/Issue War Room CLI, run the
    `!DockerHardeningCheck` command.

###### Podman

[Podman](https://podman.io/) is a daemonless container engine for
developing, managing, and running [OCI
Containers](https://opencontainers.org/) on Linux systems. Containers
can either be run as root or in rootless mode.

If you use the Shell installer to install an engine, Cortex XSIAM
automatically detects the container management type based on the
operating system. For example, if your operating system is running RHEL
v8 and higher, Cortex XSIAM installs Podman packages and configures the
operating system to enable Podman in rootless mode.

> **Note**
>
> When upgrading an engine, the engine keeps the previously used
> container management type (regardless of distribution version).

If using PowerShell integrations, you may need to configure the default
SELinux policy as Podman can affect processes that `mmap` to
`/dev/zero`.

**Docker hardening guidelines**

Docker hardening guidelines can be applied to Podman, except Limit
Available Memory, Limit Available CPU, and Limit PIDS.

####### Change the container storage directory

By default, Podman uses the `$HOME/.local/share/containers/storage`
directory. To use a different directory for container storage, edit the
[Podman config
file](https://github.com/containers/podman/blob/main/vendor/github.com/containers/storage/storage.conf#L33)
located at `/home/demisto/.config/containers/storage.conf`. If the
Podman config file does not exist, you need to create it and change the
ownership.

The new storage directory needs to be owned by the **demisto **user,
otherwise, they will be denied access to it.

> **Warning**
>
> Do not use NAS storage or a temporary (tmpfs) directory for
> the `graphroot` setting. The `graphroot` needs to be a local,
> non-temporary directory for Podman to work. For more information, see
> <https://en.wikipedia.org/wiki/Network-attached_storage>.
>
> **Tip**
>
> We recommend reserving 150 GB for container storage, either in the
> /home partition or a different storage directory that you have set
> using the `graphroot` key.

1.  If the Podman config file does not exist:

    1.  Create the Podman config file.

    - `sudo mkdir -p /home/demisto/.config/containers`

      `cp /etc/containers/storage.conf /home/demisto/.config/containers`

    2.  Change the ownership of the Podman config file.

    - `sudo chown -R demisto:demisto /home/demisto`

2.  To set a different directory for container storage, change the key:
    `graphroot` in the `storage.conf` file. For example:

- `graphroot = "/var/lib/containers/cortex-storage"`

3.  Some additional changes are required in the storage.conf file.
    Comment out the `runroot` setting by adding a `#` (hash) before it.
    For example:

- `#runroot = "/run/containers/storage"`

  > **Note**

  > Alternatively, the `runroot` setting may be set to some temporary
  > directory that is accessible by the user demisto. If you choose to
  > set the `runroot`, it must be a directory that is mounted as tmpfs
  > (temporary filesystem), unlike the graphroot.

4.  Under \[storage.options.overlay\], uncomment the following line
    (remove the \# from the start):

- `mount_program = "/usr/bin/fuse-overlayfs"`

5.  If the engine has already been installed, apply your changes to any
    existing containers:

- `sudo -u demisto podman system migrate`

6.  Verify the change (once the engine is installed):

- `sudo -u demisto podman info | grep graph`

####### Install Podman

When installing a new engine on RHEL 8 or later, the shell installer
configures Podman automatically. There are some cases, however, where
you might need to install Podman manually:

- When using an installation method other than the shell installer
  (e.g., an RPM package) on RHEL 8 or later.

- When the shell installer did not successfully install Podman.

- When you want to migrate from Docker to Podman for an existing Cortex
  XSIAM engine.

> **Note**

- > This procedure is intended for RHEL 8 or later. It may not work for
  > other operating system types.

- > Do not use [NAS
  > storage](https://en.wikipedia.org/wiki/Network-attached_storage) for
  > the \$HOME directory. The directory needs to be a local directory
  > for Podman to work.

1.  For RHEL 8, install Podman by typing the following commands:

    - `sudo yum -y install slirp4netns fuse-overlayfs`

    - `sudo yum -y module install container-tools`

- For RHEL 9 or later, install Podman by typing the following command:

  - `sudo yum -y install slirp4netns fuse-overlayfs podman`

2.  Run the following commands:

    - `sudo touch /etc/subuid /etc/subgid`

    - `sudo mkdir -p /home/demisto`

    - `sudo chown demisto:demisto /home/demisto`

3.  Configure the `unqualified-search-registries` used by Podman.

- Podman by default uses the fedoraproject.org, redhat.com, and
  docker.io unqualified search registries. SinceCortex XSIAM images use
  only the docker.io registry, you can speed up download times for
  container images by setting `unqualified-search-registries` to just
  docker.io.

  a.  Create or edit the
      `/home/demisto/.config/containers/registries.conf` config file.

  b.  In the file, set `unqualified-search-registries = ["docker.io"]`

  - > **Note**

    > If you edit the file with the `root` user, make sure to set the
    > `demisto` user as file owner by running
    > `chown demisto:demisto /home/demisto/.config/containers/registries.conf`

4.  Change the `subuids` and `subgids` by running the following command:

- `sudo usermod --add-subuids 200000-265535 --add-subgids 200000-265535 demisto`

5.  Migrate existing containers to Podman:

- `sudo sh -c "cd /; runuser -u demisto -- podman system migrate"`

6.  Set the `net.ipv4.ping-group-range`, by typing the following
    commands:

    - `sudo sh -c "echo 'net.ipv4.ping_group_range=0 2000000' > /etc/sysctl.d/demisto-ping.conf"`

    - `sudo sysctl -w "net.ipv4.ping_group_range=0 2000000"`

7.  As root user, edit the following `config` file:

- `/usr/local/demisto/d1.conf`

8.  Change the `"container.engine.type": "docker"` to `“podman"`.

- If this line does not exist, add the following line to the file:

  `"container.engine.type": "podman"`

      "Server": {
                      "HttpsPort": "443",
                      "ProxyMode": true
              },
              "container": {
                                      "engine": {
                                              "type": "podman"
                                      }
              },
              "db": {
                      "index": {
                              "entry": {
                                      "disable": true

9.  If the engine is running, restart the service.

- `sudo systemctl restart d1`

  > **Note**

  > If the **Allow running multiple engines on the same machine** option
  > is selected, run the command:

  > `sudo systemctl restart d1_<Engine _name>`

####### Migrate From Docker to Podman

Although Podman is set up automatically in an engine installation, it is
possible to migrate from Docker to Podman in an existing engine. Follow
the [Podman installation
instructions](#UUIDe52020e8425c72ad475a16b5073ca96c) to migrate.

####### Troubleshoot Podman

######## dbus-daemon process leak

Podman version 3.4.1 and lower has a [known
issue](https://github.com/containers/podman/issues/9727) that
dbus-daemon processes may leak when running in an environment containing
the dbus-x11 OS package. The issue occurs when the dbus-x11 OS package
is installed, for example, when installing an X11 desktop environment
like GNOME desktop on the host machine. If you experience this issue,
you see a large number of dbus-daemon processes owned by the demisto OS
user. To check if you are affected by the issue, run the following
command:

`ps -fe | grep demisto | grep dbus-daemon`

To fix this issue:

1.  Remove the dbus-x11 OS package and dependent packages by running the
    following command:

- `sudo yum remove dbus-x11`

2.  After removal you can kill the leaked dbus-daemon processes by
    running the following OS command:

- `pgrep -u demisto dbus-daemon | xargs sudo kill`

######## Invalid argument error

When Podman fails to run with an "Invalid argument" error, such as:

    ERRO[0000] running `/usr/bin/newuidmap 15936 0 1029 1 1 165536 65536 65537 200000 65536`: newuidmap: write to uid_map failed: Invalid argument
    Error: cannot set up namespace using "/usr/bin/newuidmap": exit status 1

This can be caused by duplicate lines for Cortex XSIAM
in `/etc/subuid` and `/etc/subgid`.

To fix this issue:

1.  Check if the `/etc/subuid` file contains multiple lines that start
    with the Cortex XSIAM username (usually demisto). For example:

- alice:100000:65536
      demisto:165536:65536
      demisto:200000:65536
      splunk:331072:65536

2.  If this is the case, edit the file as root, and remove the extra
    line(s) for Cortex XSIAM. The line you should keep is the one that
    ends with 200000:65536. Continuing with the above example, here is
    the end result:

- alice:100000:65536
      demisto:200000:65536
      splunk:331072:65536

3.  Repeat the above steps for the `/etc/subgid` file.

######## Verify Podman installation

When encountering errors in Cortex XSIAM that are Podman related, such
as:

- `failed to run "docker ps". stderr: [], err: [Timeout. Process killed (1400)`

- `Timeout while waiting for pong response [error 'Read timed out (15s)`

- `Error: error joining network namespace of container 06b8aec6eabe2e735128e3a72cb06c8ae2d97ade60a56ab555034442ea4e2a84: error retrieving network namespace at /tmp/podman-run-989/netns/cni-86dca01c-bd84-1aaf-85fb-72b659a8e42a: unknown FS magic on "/tmp/podman-run-993/netns/cni-86dca01c-bd84-1aaf-85fb-72b659a8e42a": 58465342`

1.  Verify that Podman is running properly with the `demisto` OS user by
    performing the following steps:

    - Change the OS user to `demisto` by running the following command:

    <!-- -->

    - `sudo su - -s /bin/bash demisto`

    <!-- -->

    - Check that your system complies with the minimum requirements, and
      view general system information such as host architecture, CPU,
      OS, registries, container storage path, etc., by running the
      following command:

    <!-- -->

    - `podman info`

    <!-- -->

    - Check all active running containers, container names, and IDs by
      running the following command:

    <!-- -->

    - `podman ps`

    <!-- -->

    - Check that Podman can run a container by running the following
      command:

    <!-- -->

    - `podman run --rm -t demisto/python3:3.10.4.29342 echo "podman is working"`

- If any of the Podman commands are not working, try running with the
  `--log-level=debug` to receive additional details as to why it is
  failing. For example:

  `podman --log-level=debug ps`

  `podman --log-level=debug ps podman --log-level=debug run --rm -t demisto/python3:3.10.4.29342 echo "podman is working"`

2.  Reset the Podman Data Directories.

- If the Podman commands in step [1](#N1669201349474) are failing, you
  should clean the Podman working directories. Sometimes Podman\'s data
  directories get corrupted (for example, as a result of insufficient
  disk space).

  > **Note**

  > This step removes all Podman images, including any custom images you
  > may have created.

  a.  Stop the engine by running the following command:

  - `sudo systemctl stop d1`

  b.  Ensure that all Podman containers of the `demisto` user are
      stopped by running the following command:

  - `ps -fe | grep demisto | grep 'podman run'`

    If required, kill the running containers.

  c.  Delete the following directories (assuming the `demisto` OS
      user\'s home directory is at: /home/demisto)

      - `sudo rm -rf /home/demisto/.cache/containers/`

      - `sudo rm -rf /home/demisto/.local/share/containers/`

      - `sudo rm -rf /tmp/podman-run-$(id -u demisto)`

      - `sudo rm -rf /tmp/containers-user-$(id -u demisto)`

      - `sudo rm -rf /tmp/tmp/run-$(id -u demisto)`

  - > **Note**

    > `$(id -u demisto)` is used to get the `demisto` user ID, which is
    > part of the directory name. For example, `/tmp/podman-run-993`

    > Not all the directories above may be present.

  d.  Start the engine by running the following command:

  - `sudo systemctl start d1`

  e.  Verify that Podman is working properly with the `demisto` OS user
      by following step [1](#N1669201349474).

######## Unused containers are taking up resources

In some cases, if the Podman process crashes or is killed abruptly, it
can leave containers on disk. You might see errors such as
`error allocating lock for new container: allocation failed; exceeded num_lock`
when the maximum number of locks used to manage containers is exhausted
due to the unused containers that remain.

1.  Change to the demisto operating system user
    `sudo su - -s /bin/bash demisto`.

2.  Run `podman ps -a -f status=exited` to check for unused containers.

3.  Clean up the unused containers `podman container cleanup --rm -a`.

- > **Note**

  > When you run`podman container cleanup --rm -a`, you might see a
  > message such as
  > `running or paused containers cannot be moved without force`. The
  > message can be safely ignored, as it only pertains to current
  > running containers, which are not removed.

4.  After cleanup, verify there are no remaining unused containers
    `podman ps -a -f status=exited`.

######## Keyring quota exceeded error

`Script failed to run: Docker code runner got container error: [Docker code script is in inconsistent state, ... error: [exit status 126] stderr: [Error: OCI runtime error: crun: create keyring ...: Disk quota exceeded]`

By default, Podman creates a `keyring` that is used by each container.
The limit per user on the machine might be low, and Podman can reach the
limit when running more containers than the `keyring` limit. To check
the `keyring` usage, run the `sudo cat /proc/key-users` operating system
command.

The command returns the usage for each UID (to retrieve the demisto user
UID, run `id demisto` ). The fourth column shows the number of keys used
out of the total number available. For more information about keys, see
[Kernel Key Retention
Service](https://www.kernel.org/doc/Documentation/security/keys.txt).

You can either increase the limit of max keyrings (increasing to 1000 is
safe and reasonable) per user, as specified by your Linux vendor
documentation or you can disable keyring creation by Podman. We
recommend disabling keyring creation unless keyrings are used by Podman
in other applications on the machine. To disable keyring creation by
Podman, modify the `containers.conf` file and add the option
`keyring = false` under the`"[containers]"` section. For more
information, see the [Containers Engine Configuration
File](https://github.com/containers/common/blob/main/docs/containers.conf.5.md).

######## error \"exit status 125\" and output \"Error: chown \... operation not permitted \"

If the container storage directory is not owned AND exclusively used by
the demisto user, scripts will fail to run. See the Podman section for
more information about assigning ownership of the storage directory.

######## Report a support case for installation issues

If the procedure set out in the Verify Podman installation section above
does not solve the Podman issue and you require assistance from Support,
do the following:

1.  Include the following files as part of the support case:

    - `/etc/containers/storage.conf`

    - `/home/demisto/.config/containers/storage.conf`

    <!-- -->

    - If the file does not exist, indicate that there is no such file.

    <!-- -->

    - `/home/demisto/.config/containers/registries.conf`

    <!-- -->

    - If the file does not exist, indicate that there is no such file.

2.  Include the output of the following commands as the `demisto` user.

- > **Note**

  > To change to the `demisto` OS user, run the following command:

  > `sudo su - -s /bin/bash demisto`

  - `podman info`

  - `podman images`

  - `podman --log-level=debug ps`

  - `podman --log-level=debug run --rm -t demisto/python3:3.10.4.29342 echo "podman is working"`

######## Permission issues with directories under the /run path

When installing a Cortex XSIAM engine on a RHEL system (version 8 or
later), or when running an integration on such an engine, you get a
permission error for a path under `/run` (for example
`/run/user/0` or `/run/libpod`).

1.  In RHEL 9 only: Make sure the `container-tools` meta-package is
    installed by running:

- `yum -y install container-tools`

2.  Run the following commands:

    - `cp /etc/containers/storage.conf /home/demisto/.config/containers/storage.conf`

    - `chown demisto:demisto /home/demisto/.config/containers/storage.conf`

    - `chmod 600 /home/demisto/.config/containers/storage.conf`

3.  Edit `/home/demisto/.config/containers/storage.conf`.

    - Under `[storage]`, change `runroot` to some temporary directory
      that is accessible by user `demisto`.

    <!-- -->

    - For example: `runroot = "/tmp/podman-run-xsiam"`

      > **Important**

      > The `runroot` must be located under the `tmpfs` file system
      > type. This is required to clean Podman\'s run state on reboot
      > and for performance reasons.

    <!-- -->

    - Also under `[storage]`, change `graphroot` (where container images
      are stored) to any location that is owned and accessible by user
      `demisto`. We recommend using this standard path:

    <!-- -->

    - `graphroot = "/home/demisto/.local/share/containers/storage"`

      > **Caution**

      > Unlike the `runroot`, the `graphroot` must NOT be located under
      > the `tmpfs` file system type. Using `tmpfs` for the `graphroot`
      > might corrupt container images, causing command executions to
      > fail. It also degrades performance by forcing Podman to
      > needlessly re-pull images.

    <!-- -->

    - Under `[storage.options.overlay]`, uncomment the following line
      (remove the \# from the start):

    <!-- -->

    - `mount_program = "/usr/bin/fuse-overlayfs"`

4.  Save the file and run the following.

- > **Note**

  > You must switch to user`demisto` before running the \"system
  > migrate\" (running it as root will have no effect).

  - `su - demisto`

  - `podman system migrate`

5.  Also as user `demisto`, run the following to ensure the path changes
    were applied:

- `podman info | grep Root`

  You should see the correct runRoot and graphRoot settings.

6.  As user `demisto`, verify the issue is resolved by running:

- `podman run hello-world`

7.  If the issue persists, purge Podman\'s database by running the
    following:

- > **Note**

  > The \"system migrate\" must be done by the user demisto.

  - `rm -rf /home/demisto/.local/share/containers/*`

  - `podman system migrate`

##### Manage engines

You can manage your engines and load-balancing groups by going to
Settings \> Configurations \> Data Broker \> Engines.

You can view engine names, hosts, status, connection, and other engine
information.

You can do the following:

+-----------------------------------+--------------------------------------------------+
| Option                            | Description                                      |
+===================================+==================================================+
| Load-Balancing Group              | It is useful to create separate load-balancing   |
|                                   | groups. For example:                             |
|                                   |                                                  |
|                                   | - Use separate load-balancing groups for         |
|                                   |   different integrations and instances. Create   |
|                                   |   Load-Balancing groups for certain tasks, which |
|                                   |   can help segregate the infrastructure of       |
|                                   |   critical integrations.                         |
|                                   |                                                  |
|                                   | - Managed Security Service Providers may want to |
|                                   |   split internal engines and SaaS product        |
|                                   |   engines.                                       |
|                                   |                                                  |
|                                   | - If you have multiple AWS accounts that are not |
|                                   |   connected and do not want a single point of    |
|                                   |   failure for AWS integrations that use STS.     |
|                                   |                                                  |
|                                   | You can do the following:                        |
|                                   |                                                  |
|                                   | - Add/remove engines to a load-balancing group   |
|                                   |                                                  |
|                                   | <!-- -->                                         |
|                                   |                                                  |
|                                   | - You can only add the engine to the             |
|                                   |   load-balancing group after you have connected  |
|                                   |   the engine.                                    |
|                                   |                                                  |
|                                   |   If you want to remove the last engine from a   |
|                                   |   specific load-balancing group, if one or more  |
|                                   |   integration instances use that engine, you     |
|                                   |   will get an error. Before moving the engine,   |
|                                   |   you need to assign **Run **on to a different   |
|                                   |   engine or no engine for each of the            |
|                                   |   integration instance settings.                 |
|                                   |                                                  |
|                                   | <!-- -->                                         |
|                                   |                                                  |
|                                   | - Create load-balancing groups                   |
|                                   |                                                  |
|                                   | <!-- -->                                         |
|                                   |                                                  |
|                                   | - When selecting Load-Balancing Group \> Add to  |
|                                   |   new group, you can create multiple             |
|                                   |   load-balancing groups and decide which engines |
|                                   |   are part of each group.                        |
|                                   |                                                  |
|                                   |   Users can move an engine from one group to     |
|                                   |   another. A group will be deleted when the last |
|                                   |   engine is removed from it.                     |
|                                   |                                                  |
|                                   |   Each engine can only belong to one group.      |
+-----------------------------------+--------------------------------------------------+
| Upgrade Engine                    | Relevant for Shell installation only. If you     |
|                                   | didn\'t install an engine using the Shell        |
|                                   | installation, you will need to remove the engine |
|                                   | and do a fresh installation. For more            |
|                                   | information, see [Upgrade an                     |
|                                   | engine](#UUIDce00d52d102466985178ffec6274101e).  |
+-----------------------------------+--------------------------------------------------+
| Get Logs                          | Logs are located in `/var/log/demisto`. For      |
|                                   | multiple engines, logs are located in            |
|                                   | `/var/log/demisto/<name of the engine>`. For     |
|                                   | example, `var/log/demisto.d1_e1`.                |
+-----------------------------------+--------------------------------------------------+
| Edit Configuration                | Relevant for Shell installation only. Enables    |
|                                   | you to edit the `d1.conf` file without having to |
|                                   | access the file on your remote machine. For more |
|                                   | information, see [Configure                      |
|                                   | engines](#UUIDea7bc684741f4281cb5dab7fed8d5acb). |
+-----------------------------------+--------------------------------------------------+
| Download Configuration            | Download the `d1.conf` file to view the          |
|                                   | attribute values.                                |
+-----------------------------------+--------------------------------------------------+
| Delete Engine                     | Deletes an engine from Cortex XSIAM. To remove   |
|                                   | the engine from your remote machine, see [Remove |
|                                   | an                                               |
|                                   | engine](#UUID684ba8c2356c7aac4ad165530f38d673).  |
+-----------------------------------+--------------------------------------------------+

##### Upgrade an engine

Whenever there is a Cortex XSIAM major version change or a change in
tenant-engine protocol version, your engines require an upgrade. On the
**Engines** page, the **Status** column shows those engines that require
upgrades. You can upgrade an engine by doing the following:

- If you installed the engine using the Shell installer, you can upgrade
  the engine on the **Engines** page.

- If you didn\'t install the engine using the Shell installer, you need
  to remove the engine and do a fresh install.

###### Upgrade an engine (shell installations)

You can upgrade the engine on the **Engines** page if you have installed
the engine using the shell installer. The engine must be connected
during the upgrade.

**Customize upgrade variables**

Before upgrading, we recommend you review the upgrade variables and
verify if any need to be set in the `/usr/local/demisto/upgrade.conf`
file on the engine. For environments with multiple engines, the file is
located at `/usr/local/demisto/<engine-name>/upgrade.conf`. In some
cases, usually related to a web proxy server or a custom directory, if
you do not configure the `upgrade.conf` file, the upgrade will fail.

The option to set custom upgrade variables is only available for shell
installation.

> **Note**
>
> The `upgrade.conf` file is available on the engine after it has been
> upgraded to Cortex XSIAM 3.1. Any custom variables you add to the file
> are applied when you upgrade from Cortex XSIAM 3.1 to Cortex XSIAM 3.2
> or later.

  ---------------------------------------------------------------------------------------------------------------------------
  Variable                            Description                                                     Default
  ----------------------------------- --------------------------------------------------------------- -----------------------
  https_proxy                         The URL of a web proxy server to use when connecting with the   Not set
                                      server. The variable name is case sensitive. Other common proxy 
                                      variables, such as `http_proxy` or `HTTPS_PROXY` are ignored.   
                                      Use `https_proxy` even if your proxy address begins with        
                                      `http://`.                                                      

  SERVER_URLS                         The URL to connect to for hash validation. Set this variable if Public tenant URL
                                      your tenant\'s address has changed. Use your tenant\'s API      
                                      address, with the `api-` prefix added, instead of the UI        
                                      address. For                                                    
                                      example: `SERVER_URLS="api-example.us.paloaltonetworks.com"`.   
                                      Include only the IP/hostname and, optionally, a port. Do not    
                                      include `https://` or any path at the end.                      

  TRUST_ANY_CERTIFICATE               Determines whether the connection\'s SSL certificate must be    -k
                                      trusted. This variable must be empty `""` to require            
                                      certificate trust. When set to `-k`, trusts any certificate. We 
                                      recommend enabling this setting. Verify first that the engine   
                                      host has the required CA root certificate, especially if using  
                                      a proxy.                                                        

  XSOAR_ENGINE_AUTO_UPGRADE_TMP_DIR   Specifies a directory to use for extracting upgrade files and   By default, a random
                                      executing the upgrade. For example,                             directory under the
                                      `XSOAR_ENGINE_AUTO_UPGRADE_TMP_DIR="/root/tmp/engine1"` For     `/tmp` folder is used.
                                      environments with multiple engines, each engine must use a      
                                      different temporary directory. This variable must be set if you 
                                      used the `--target` option in the shell installer.              
  ---------------------------------------------------------------------------------------------------------------------------

**Test upgrade connectivity**

1.  Test the upgrade connectivity by creating a mock `d1_upgrade.sh`
    file :

- cd /usr/local/demisto
      echo test > d1_upgrade.sh

  After you create the file, the upgrade cron job removes the file
  within one minute.

2.  Check the upgrade log file `/var/log/demisto/demisto_install.log`
    for connection-related errors. For hosts with multiple engines, the
    log file can be found at `/tmp/<engine name>/demisto_install.log`.

3.  If the test is successful, the following message appears at the end
    of the log file, with a recent timestamp:
    `Validation HTTPS request returned: false`.

4.  If you find errors in the log, you may need to change the variables
    in the `upgrade.conf` file or to change your network configuration.

**How to upgrade**

1.  On the **Engines** page, select the checkbox for the engine that
    requires an upgrade.

2.  Click **Upgrade Engine**.

- When the upgrade finishes, the version appears in the **Cortex
  XSIAM Version** column. The upgrade procedure can take several
  minutes.

###### Upgrade an engine (non-shell installations)

If you didn\'t use the Shell installer, you need to remove the engine
and do a fresh install.

1.  On the **Engines** page, locate the engine that requires an update.

2.  In the Download link, click the relevant Download files.

3.  On the remote machine, do the following:

    - Remove the existing engine. For more information, see [Remove an
      engine](#UUID684ba8c2356c7aac4ad165530f38d673).

    - Install the engine you downloaded in step 2. For more information,
      see [Install an engine](#UUID65eabcb0fcddc32e7dc5f216e8f66604).

- When the upgrade finishes, the version appears in the **Cortex
  XSIAM Version** column. The upgrade procedure can take several
  minutes.

###### Related information

[Troubleshoot engines](#UUID8c3d8a1ac8287e7bd06d04aba766b975).

##### Remove an engine

You can remove an engine when it is no longer needed.

1.  Run one of the following commands according to your operating
    system:

+-----------------------------------+--------------------------------------+
| Installation                      | Command                              |
+===================================+======================================+
| RPM                               | Get the full package:                |
|                                   | `rpm -qa | grep -i ^d1_*`            |
|                                   |                                      |
|                                   | Remove the package:                  |
|                                   | `rpm -evv d1_ <package name>`        |
+-----------------------------------+--------------------------------------+
| DEB                               | Get the full package:                |
|                                   | `dpkg-query -W -f='${Package}' d1_*` |
|                                   |                                      |
|                                   | Remove the package:                  |
|                                   | `dpkg --purge <package name>`        |
+-----------------------------------+--------------------------------------+
| SH                                | Remove an Engine:                    |
|                                   | `sudo <engine-file-path> -- -purge`  |
+-----------------------------------+--------------------------------------+

##### Configure engines

When installing an engine, a `d1.conf` file is installed on your
machine. Some configurations can only be done by editing the d1.conf
file. If you install via Shell, you can edit the configuration in the UI
as well as edit the file directly.

A use case for modifying the engine configuration is if you want to
generate engine logs for a specific log level.

**Edit the** `d1.conf` **file**

1.  On the machine on which you installed the engine, navigate to the
    `d1.conf` file:

+-----------------------------------+-------------------------------------------+
| Installation Type                 | Location                                  |
+===================================+===========================================+
| RPM, DEB, Shell                   | `/usr/local/demisto`                      |
|                                   |                                           |
|                                   | If using multiple engines, the location   |
|                                   | is                                        |
|                                   | `/usr/local/demisto/name of the engine>`. |
|                                   | For example, `/usr/local/demisto/d1_e1`   |
+-----------------------------------+-------------------------------------------+
| ZIP                               | Same folder as the binary.                |
+-----------------------------------+-------------------------------------------+

2.  Modify the file as required. See
    [#UUIDea7bc684741f4281cb5dab7fed8d5acb_bridgeheadidm4521254625646433940221975904](#X58724c051293db14141d1f2e6c54c8c2e30f01c)

- You can also [Configure the engine to use a web
  proxy](#UUIDfe6f3327bbaae062cc183ded63edd180).

**Modify the configuration in Cortex XSIAM (Shell installations only)**

Ensure that the data is in JSON format. The properties that you specify
override the values defined in the `d1.conf` file.

1.  From the engines table, select the engine for which you want to
    modify the configuration.

2.  Click **Edit Configuration**.

3.  In the **JSON formatted configuration** dialog box, modify the
    properties as required. For more information, see
    [#UUIDea7bc684741f4281cb5dab7fed8d5acb_bridgeheadidm4521254625646433940221975904](#X58724c051293db14141d1f2e6c54c8c2e30f01c).

- ![](media/rId2648.png){width="5.833333333333333in"
  height="3.91589457567804in"}

**Common properties when editing an engine configuration**

The following table describes the common properties when editing an
engine configuration using the `d1.conf` file (located by default at
`/usr/local/demisto/`) or in the **JSON formatted configuration **dialog
box in Cortex XSIAM.

+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| Property                            | Type            | Values                                         | Edit                                                  |
+=====================================+=================+================================================+=======================================================+
| `http_proxy`                        | String          | The IP address of the HTTP proxy through which | The engine `d1.conf` file.                            |
|                                     |                 | the engine communicates.                       |                                                       |
|                                     |                 |                                                |                                                       |
|                                     |                 | For example, see [Configure the engine to use  |                                                       |
|                                     |                 | a web                                          |                                                       |
|                                     |                 | proxy](#UUIDfe6f3327bbaae062cc183ded63edd180). |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `https_proxy`                       | String          | The IP address of the HTTP/s proxy through     | The engine `d1.conf` file.                            |
|                                     |                 | which the engine communicates.                 |                                                       |
|                                     |                 |                                                |                                                       |
|                                     |                 | For example, see [Configure the engine to use  |                                                       |
|                                     |                 | a web                                          |                                                       |
|                                     |                 | proxy](#UUIDfe6f3327bbaae062cc183ded63edd180). |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `LogLevel`                          | String          | - `debug`                                      | The engine `d1.conf` file or in the JSON formatted    |
|                                     |                 |                                                | configuration dialog box.                             |
|                                     |                 | - `info`                                       |                                                       |
|                                     |                 |                                                |                                                       |
|                                     |                 | - `warning`                                    |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `log.rolling.maxfilesize`           | String          | The maximum size in MB to retain log files.    | The engine `d1.conf` file.                            |
|                                     |                 | Default is 20 MB.                              |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `log.rolling.backups`               | String          | The maximum number of log files to retain.     | The engine `d1.conf` file.                            |
|                                     |                 | Default is 3.                                  |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `log.rolling.maxage`                | String          | The maximum number of days to retain old log   | The engine `d1.conf` file.                            |
|                                     |                 | files based on the time stamp encoded in the   |                                                       |
|                                     |                 | file name. Default is 0 (not to retain old log |                                                       |
|                                     |                 | files based on age).                           |                                                       |
|                                     |                 |                                                |                                                       |
|                                     |                 | > **Note**                                     |                                                       |
|                                     |                 | >                                              |                                                       |
|                                     |                 | > A day is defined as 24 hours and may not     |                                                       |
|                                     |                 | > exactly correspond to calendar days due to   |                                                       |
|                                     |                 | > daylight savings, leap seconds, etc.         |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `BindAddress`                       | String          | The port on which the engine listens for agent | The engine `d1.conf` file.                            |
|                                     |                 | connection requests and communication task     |                                                       |
|                                     |                 | responses.                                     |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `EngineURLs`                        | String array    | An array of tenant addresses to which the      | The engine `d1.conf` file.                            |
|                                     |                 | engine tries to connect. If you change the     |                                                       |
|                                     |                 | tenant URL, you need to update this parameter. | > **Note**                                            |
|                                     |                 |                                                | >                                                     |
|                                     |                 |                                                | > In addition, to support engine upgrades from the    |
|                                     |                 |                                                | > UI, edit the `/usr/local/demisto/upgrade.conf` file |
|                                     |                 |                                                | > on the engine to include the `SERVER_URLS` setting  |
|                                     |                 |                                                | > with the new tenant\'s address. Include only the    |
|                                     |                 |                                                | > host, without https:// or any additional path at    |
|                                     |                 |                                                | > the end of the host name. For example:              |
|                                     |                 |                                                | > `SERVER_URLS="api-example.us.paloaltonetworks.com"` |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `LogFile`                           | String          | Path to the `d1.log` file. If you change the   | The engine `d1.conf` file.                            |
|                                     |                 | name or location of the `d1.log` file, you     |                                                       |
|                                     |                 | need to update this parameter.                 |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+
| `engine.handshake.max.retries.slow` | String          | The maximum time in minutes the engine will    | The engine `d1.conf` file.                            |
|                                     |                 | try to reconnect after losing communication.   |                                                       |
|                                     |                 | Default is 600 (10 hours).                     |                                                       |
|                                     |                 |                                                |                                                       |
|                                     |                 | > **Note**                                     |                                                       |
|                                     |                 | >                                              |                                                       |
|                                     |                 | > If the engine loses communication for longer |                                                       |
|                                     |                 | > than this time, it will disconnect and you   |                                                       |
|                                     |                 | > need to restart the service.                 |                                                       |
+-------------------------------------+-----------------+------------------------------------------------+-------------------------------------------------------+

###### Configure the engine to use a web proxy

Proxy settings can be configured in an engine by adding them as an
engine configuration.

> **Note**
>
> You need to [configure
> Docker](https://docs.docker.com/config/daemon/systemd/#httphttps-proxy)
> to use a proxy. When using a BlueCoat proxy, ensure you encode the
> values correctly.

1.  On the machine on which you installed the engine, navigate to the
    `d1.conf` file and add the following keys.

+-----------------------+---------------------------------------------+-----------------------+
| Key                   | Value                                       | Description           |
+=======================+=============================================+=======================+
| `http_proxy`          | `http://<user:password@proxy-server:port#>` | Environment uses HTTP |
|                       |                                             | proxy. Special        |
|                       | For example                                 | characters must be    |
|                       | `http://user:password@proxy-server:3128`    | escaped.              |
+-----------------------+---------------------------------------------+-----------------------+
| `https_proxy`         | `https://user:password@proxy-server:port#`  | Environment uses      |
|                       |                                             | HTTPS proxy. Special  |
|                       | For example,                                | characters must be    |
|                       | `https://user:password@proxy-server:3128`   | escaped.              |
+-----------------------+---------------------------------------------+-----------------------+
| `no_proxy`            | `http://<user:password@proxy-server:port#>` | For specific          |
|                       |                                             | addresses, a proxy    |
|                       | For example                                 | bypass will be        |
|                       | `http://user:password@proxy-server:3128`    | applied. Special      |
|                       |                                             | characters must be    |
|                       |                                             | escaped.              |
+-----------------------+---------------------------------------------+-----------------------+

2.  If the environment variables are not set, or you wish to use
    different settings than those specified in the environment
    variables, set the configuration with your specific proxy details in
    the `d1.conf` file. For example:

- {"http_proxy": "http://proxy.host.local:8080",
      "https_proxy": "https://proxy.host.local:8443"
      "no_proxy": "https://proxy.host.local:8020"}

3.  Save the file.

4.  On the machine where you installed the engine, navigate to the
    `upgrade.conf` file and edit the file to set `https_proxy` to your
    proxy address. For example,
    `https_proxy="https://proxy.host.local:8443"`.

- > **Note**

  > In an environment with a single engine, go to
  > `/usr/local/demisto/upgrade.conf`. In an environment with multiple
  > engines, go to`/usr/local/demisto/<engine-name>/upgrade.conf`,
  > replacing \<engine-name\> with the name of the engine.

  > Note that the key is in the `upgrade.conf` file and must be
  > `https_proxy`, even if your proxy address starts with `http://`.

5.  Save the file.

###### Configure the engine to call the server without using a proxy

In some cases, due to specific environment architecture, you may need to
configure the engine to use a proxy when working with integrations, but
not use a proxy when calling the Cortex XSIAM tenant.

1.  On the computer where you have installed the engine, go to the
    directory for `d1.conf` file.

- For RPM, DEB, Shell go to `/usr/local/demisto`.

2.  Add the following configuration:

  -----------------------------------------------------------------------
  Key                                 Value
  ----------------------------------- -----------------------------------
  `engine.to.server.proxy`            `false` (default is `true`)

  -----------------------------------------------------------------------

####### Use NGINX as a reverse proxy

NGINX can act as a reverse proxy that sits between internal applications
and external clients, forwarding client requests to the appropriate
application. Using NGINX as a reverse proxy in front of the engine
enables you to provide network segmentation where the proxy can be put
on a public subnet (DMZ) while the engine can be on a private subnet,
only accepting traffic from the proxy. Additionally, NGINX provides a
number of advanced load balancing and acceleration features that you can
utilize.

If you want to use an engine (d1) through the reverse proxy, you need to
modify `EngineURLs` in the `d1.conf` file to point to the host and port
the NGINX server is listening on. In addition to supporting engine
upgrades from the UI, edit the `/usr/local/demisto/upgrade.conf` file to
add the `SERVER_URLS` setting. `SERVER_URLS` should be set to the
proxy's network address (host and port). For example:
`SERVER_URLS="10.0.0.30:1234"`. For SERVER_URLS, include only the
IP/hostname and, optionally, a port. Do not include https:// or any path
at the end.

Install NGINX

You can install NGINX on the Red Hat/Amazon (yum) and Ubuntu Linux
distributions. For full instructions and available distributions, see
[NGINX
documentation](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#).

1.  On the engine, run one of the following commands according to your
    Linux system:

    - **RedHat/Amazon:** `sudo yum install nginx`

    - **Ubuntu:** `sudo apt-get install nginx`

2.  (*Optional*) Verify the NGINX installation by running the following
    command:

- `sudo nginx -v`

Generate a certificate for NGINX

You should not use self-signed certificates for production systems. It
is recommended to use a properly signed certificate for production
systems. These instructions are intended only for non-production setups.

1.  To use OpenSSL to generate a self-signed certificate, on the engine
    machine, run the following command:

- `sudo openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout /etc/nginx/cert.key -out /etc/nginx/cert.crt`

2.  When prompted, complete the on-screen instructions to complete the
    required fields.

Configure NGINX

1.  Open the following NGINX configuration file with your preferred
    editor:

- `/etc/nginx/conf.d/demisto.conf`

2.  Use the following configuration template:

- Replace `DEMISTO_ENGINE` with the appropriate hostname.

      # Replace DEMISTO_ENGINE with the appropriate hostname. If needed, change port 443 to the port on which the engine is listening.

      upstream demisto {
          server DEMISTO_ENGINE:443;
      }

      # Uncomment to redirect http to https (optional)
      # server {
      #     listen 80;
      #     return 301 https://$host$request_uri;
      # }

      server {
         # Change the port if you want NGINX to listen on a different port
          listen 443;
          
          ssl_certificate           /etc/nginx/cert.crt;
          ssl_certificate_key       /etc/nginx/cert.key;

          ssl on;
          ssl_session_cache  builtin:1000  shared:SSL:10m;
          ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;
          ssl_ciphers HIGH:!aNULL:!eNULL:!EXPORT:!CAMELLIA:!DES:!MD5:!PSK:!RC4;
          ssl_prefer_server_ciphers on;

          access_log            /var/log/nginx/demisto.access.log;

          location / {

            proxy_set_header        Host $host;
            proxy_set_header        X-Real-IP $remote_addr;
            proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header        X-Forwarded-Proto $scheme;

            proxy_pass          https://demisto;
            proxy_read_timeout  90;
          }

          location ~ ^/(websocket|d1ws|d2ws) {
              proxy_pass https://demisto;
              proxy_http_version 1.1;
              proxy_set_header Upgrade $http_upgrade;
              proxy_set_header Connection "upgrade";
              proxy_set_header Host $host;
              proxy_set_header Origin "";
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $scheme;
          }
      }

  > **Note**

  > For multi-tenant deployments, replace
  > `location ~ ^/(websocket|d1ws|d2ws) {` with
  > `location ~ ^/(acc_\S+/)?(websocket|d1ws|d2ws)`

3.  Restart the NGINX server by typing the following command:

- `sudo service nginx restart`

4.  Verify you can access the engine by browsing to the NGINX server
    host.

###### Configure an engine to use custom certificates

You can replace the default self-signed certificate for the engine with
your own certificate.

1.  Find the two files created by the engine. The default location is
    `/usr/local/demisto`.

- `d1.key.pem`

  `d1.cert.pem`

2.  Replace the contents of these files with your own certificates.

3.  Change file owner to demisto:

- `chown -R demisto:demisto d1.key.pem`

  `chown -R demisto:demisto d1.cert.pem`

4.  Set the file permissions:

- `chmod 600 d1.key.pem`

  `chmod 644 d1.cert.pem`

##### Use an engine in an integration

When you create an integration instance, you can select whether to fetch
issues and run commands executed for the integration using the engine or
a load-balancing group of engines. After you add the engine or
load-balancing group to an integration instance, you can run commands
using the engine or load-balancing group by specifying the `using`
argument in the Issues War Room.

Before configuring an integration to run using multiple engines in a
load-balancing group, we recommend that you test the integration using a
single engine in the load-balancing group.

> **Note**
>
> Long-running integrations should not run on load-balancing groups.

**Command Example**

`!url url="www.cnn.com" using=urlscan.io_instance_1`

##### Run a script using an engine

You can run a script on an engine or load-balancing group to distribute
the workload and improve performance.

1.  Go to Investigation & Response \> Automation \> Scripts.

2.  Select the script and click **Settings**.

3.  From the **BASIC** section, in the **Run on** field, select either a
    single engine or a load-balancing group.

- The option to select an engine or load-balancing group only appears if
  at least one engine or load-balancing group is connected.

4.  From the list, select the name of the engine or load-balancing
    group.

5.  Click **Save**.

##### Troubleshoot engines

When troubleshooting engines, access the logs from Settings \>
Configurations \> Engines and select the engine from which you want to
download the logs.

> **Note**
>
> Ensure that pop-ups are not blocked by your browser.

**Debug engines**

The **d1.log** field appears whenever an engine is running. The
**d1.log** field contains information necessary for your customer
success team to debug any engine-related issue. The field displays any
error, as well as noting whether the engine is connected.

![](media/rId2663.png){width="2.25in" height="0.75in"}

Troubleshoot engine installation

> **Note**
>
> If the installer fails to start due to a permissions issue, even if
> running as root, add one of the following two arguments when running
> the installer:

- > `--target <path>` - Extracts the installer files into the specified
  > custom path.

- > `--keep` - Extracts the installer files into the current working
  > directory (without cleaning at the end).

> If using installer options such as `-- -tools=false`, the option
> should come after the `--target` or `--keep` arguments. For example:
>
> `sudo ./d1-installer.sh --target /some/temp/dir -- -tools=false`
>
> If you set a custom path when you run the installer, you must also set
> a custom path for upgrading your engine or the upgrade will fail. For
> more information, see [Upgrade an
> engine](#UUIDce00d52d102466985178ffec6274101e).

After installing the engine, check that the engine is connected to the
Cortex XSIAM tenant and that it is running.

1.  Go to Settings \> Configurations \> Data Broker \> Engines and
    verify that the engine is connected.

2.  If the engine is not connected, run the following command on the
    engine server to check if the engine service is running.

- `sudo systemctl status d1`

  > **Note**

  > If the **Allow running multiple engines on the same machine** option
  > is selected, run the command:

  > `sudo systemctl status d1_<Engine _name>`

3.  Access the d1 log on the engine server.

- `sudo tail -f /var/log/demisto/d1.log`

  - If the engine service is not running, and there's nothing relevant
    in the log, run `journalctl` on the engine server to understand why
    the installation failed.

  - If the engine service is running, review the errors to see if the
    engine is failing to connect or if there are other issues (ignore
    all errors related to `\d2ws`, because this is not the same as
    `d1ws`.) Most often, the server address is incorrect and you will
    see an error like this:

  <!-- -->

  - `error Cannot connect to [wss://<mainServerIP/HostName>/d1ws]: wss://<mainServerIP/HostName>/d1ws: dial tcp: lookup localhost: no such host. . Waiting 3 seconds. Will try until…`

    In this case, navigate to `/usr/local/demisto/d1.conf` and change
    the `EngineURLs` parameter to an address the engine can reach. Check
    the addresses at the beginning of the *upgrade_engine.sh* file. If
    the addresses are not correct, set the correct addresses in the
    `/usr/local/demisto/upgrade.conf` file, as a comma-separated list.

    The configurations that might affect the `upgrade_engine.sh` script
    are the following variables are located at the beginning of the
    script:

    - `SERVER_URLS`

    - `TRUST_ANY_CERT`

    If you make a change to the baseURLs configuration, you must apply
    the change in `/usr/local/demisto/d1.conf` AND in
    `/usr/local/demisto/upgrade.conf` under the SERVER_URLS var. For
    SERVER_URLS, specify only the IP/hostname and, optionally, a port.
    Do not include`https://` or any path at the end.

    If you make a change in the
    `engine.connection.trust_any_certificate` configuration, you must
    apply the change in `/usr/local/demisto/upgrade.conf` as follows:

    - If the `engine.connection.trust_any_certificate` configuration was
      set to true (trust any certificate), set the TRUST_ANY_CERT
      variable to -k.

    - If the `engine.connection.trust_any_certificate` configuration was
      set to false, the TRUST_ANY_CERT variable should be blank ("").

    > **Note**

    > Any changes made to variables in the `upgrade_engine.sh` file are
    > reset after each upgrade. We recommend instead using the
    > `upgrade.conf` file to set variables.

  > **Note**

  > You can ignore the following error:
  > `Cannot create folder '/var/lib/demisto'`

4.  To check the connectivity from the engine to the Cortex XSIAM
    tenant, see *Troubleshoot engine connectivity* below.

5.  If the installation issue remains, open a support case with logs
    from the engine.

    a.  On the engine server, in `/usr/local/demisto/d1.conf`, set
        \"LogLevel\": \"debug".

    b.  Restart the d1 service and let it run for a few minutes.

    - `sudo systemctl restart d1`

      > **Note**

      > If the **Allow running multiple engines on the same machine**
      > option is selected, run the command:

      > `sudo systemctl status d1_<Engine _name>`

    c.  Capture a`journalctl`:

    - `journalctl --since "1 day ago" > engineTroubleshootingJournalctl.log`

    d.  On the engine server, tar up the log, conf,`journalctl`, and
        install log on the engine.

    - `tar -cvzf engineLogs.tar.gz /var/log/demisto /usr/local/demisto/d1.conf /tmp/demisto_install.log engineTroubleshootingJournalctl.log`

Troubleshoot engine upgrades

During an upgrade, the upgrade file is sent to the engine server. A cron
job running on the engine server checks if that file exists. The most
common upgrade error is that the job is not running, so the new
installer does not run.

> **Note**
>
> If the installer fails to start due to a permissions issue, even if
> running as root, add one of the following two arguments when running
> the installer:

- > `--target <path>` - Extracts the installer files into the specified
  > custom path.

- > `--keep` - Extracts the installer files into the current working
  > directory (without cleaning at the end).

> If using installer options such as `-- -tools=false`, the option
> should come after the `--target` or `--keep` arguments. For example:
>
> `sudo ./d1-installer.sh --target /some/temp/dir -- -tools=false`

1.  SSH to the machine.

2.  Check the d1 service status on the engine server. It is possible
    that it stopped or doesn\'t exist.

- `sudo systemctl status d1`

  > **Note**

  > If the **Allow running multiple engines on the same machine** option
  > is selected, run the command:

  > `sudo systemctl status d1_<Engine _name>`

3.  Access the installer log on the engine server and review the error.

- `sudo vi /tmp/demisto_install.log`

4.  Rerun the installer on the engine using one of the following
    options. You can open a second window and run `watch df -h`. If the
    problem seems to be disk space, you should resolve the disk space
    issue and then rerun the installer.

5.  Do one of the following:

    - Download the installer from the user interface and copy it to the
      engine.

    <!-- -->

    - Add the following commands:

      `sudo chmod +x installer.sh`

      `sudo ./installer.sh -- -y`

    <!-- -->

    - Verify that `/usr/local/demisto/d1_upgrade.sh` exists.

      1.  Run the following commands:

      - `sudo chmod +x /usr/local/demisto/d1_upgrade.sh`

        `sudo /usr/local/demisto/d1_upgrade.sh`

      2.  If `d1_upgrade.sh` doesn\'t exist, check if
          `/usr/local/demisto/archived_d1_upgrade.sh` exists and that it
          was created at the time of the attempted upgrade.

      3.  If the file exists and was created at the time of the
          attempted upgrade, run the following commands on the engine
          server:

      - `sudo chmod +x /usr/local/demisto/archived_d1_upgrade.sh`

        `sudo /usr/local/demisto/archived_d1_upgrade.sh`

Troubleshoot engine connectivity

The following provides instructions for troubleshooting connectivity
issues from the engine to the endpoint.

1.  Follow the instructions in [network
    troubleshooting](https://xsoar.pan.dev/docs/reference/articles/troubleshooting-guide#host-based-networking).

2.  Ensure that the engine can reach the endpoint by running the
    following command on the server engine.

- `sudo curl -kvv <endpointURL>`

3.  If the engine could not reach the endpoint, try the IP with curl
    instruction adding the http(s)//, or try using ping.

- If this works, add the IP to the /etc/hosts file with the hostname and
  try to reach the endpoint again by running the following command on
  the engine server

  `sudo curl -kvv <endpointURL>`

  If this still fails, then this is an issue of connectivity between the
  engine and endpoint and you need to resolve this with your networking
  team.

4.  After connectivity has been confirmed via curl:

    - Try connecting within Docker without passing host networking.

    <!-- -->

    - `docker run -it --rm demisto/netutils:1.0.0.6138 curl -kvv <endpointURL>`

      If this succeeds but the integration still fails, it could be an
      integration credentials issue. In that case, open a [support
      case](https://support.paloaltonetworks.com/support).

    <!-- -->

    - If, without passing the host networking fails, run the following:

    <!-- -->

    - `docker run -it --rm --network=host demisto/netutils:1.0.0.6138 curl -kvv <endpointURL>`

      If this succeeds, add
      `"python.pass.extra.keys": "--network=host" to /usr/local/demisto/d1.conf`and
      retest the integration.

      If you see a Docker or SELinux issue, see [Troubleshoot Docker
      networking issues](#X8fa59abcfc418db9c069d3eb4ca1f6d2312fb36) .

5.  If the installation issue remains, open a support case with logs
    from the engine.

    a.  On the engine server, in `/usr/local/demisto/d1.conf`, set
        \"LogLevel\": \"debug".

    b.  Restart the d1 service and let it run for a few minutes.

    - `sudo systemctl restart d1`

      > **Note**

      > If the **Allow running multiple engines on the same machine**
      > option is selected, run the command:

      > `sudo systemctl status d1_<Engine _name>`

    c.  Capture a journalctl:

    - `journalctl --since "1 day ago" > engineTroubleshootingJournalctl.log`

    d.  On the engine server, tar up the logs, conf, journalctl, and
        install log on the engine.

    - `tar -cvzf engineLogs.tar.gz /var/log/demisto /usr/local/demisto/d1.conf /tmp/demisto_install.log engineTroubleshootingJournalctl.log`

Engine 443 error

This error might occur when a connection is established between an
engine and the Cortex XSIAM tenant, because, by default, Linux does not
allow processes to listen on low-level ports.

**Error Message**

`listen tcp :443: bind: permission denied`

**Solution**

- In the `d1.conf` file, change the port number to a higher one, for
  example, 8443.

- Run this command:
  `sudo setcap CAP_NET_BIND_SERVICE=+eip /path/to/binary`. After running
  this command the server should be able to bind to low-numbered ports.

Bad handshake error

This error can occur in the engine logs relating to a bad handshake on
the engine trying to connect to a Cortex XSIAM tenant.

**Error Message**

`Cannot connect to [wss:/xxx]: [wss://xxx|wss://xxx/]: websocket: bad handshake`

**Solution**

Verify that time is synchronized on the engine to a reliable NTP source.
When timing is off on the engine, this can cause a failure during the
SSL/TLS handshake process. When time is resynced, connectivity from the
engine to the parent server should be restored.

##### Troubleshoot integrations running on engines

The following are common errors that occur when integrations are running
on an engine.

Troubleshoot engine import error or invalid syntax error

When running an integration on an engine, the most common errors are:

- `Broken Pipe`

- `"ImportError: No module named...`

- `Invalid syntax`

- `Script failed to run: exec: “python”: executable file not found in $PATH (2603)`

These errors could indicate that the engine is not using Docker.

1.  Use SSH to access the engine server.

2.  Make sure Docker is healthy.

    a.  Ensure that Docker is installed and is running.

    - `sudo systemctl status docker`

      If the Docker status is not good, restart your Docker.

      `sudo systemctl restart docker`

    b.  Ensure Docker can run a container.

    - `sudo docker run hello-world`

      If this fails, reinstall your Docker.

3.  Access the d1.conf file on the engine server.

- `sudo vi /usr/local/demisto/d1.conf`

4.  Add the `"python.engine.docker": true` configuration to the d1.conf
    file and remove any other configurations related to python and
    Docker, such as `“python.executable.no.docker”`.

5.  Restart the system on the engine server.

- `sudo systemctl restart d1`

  > **Note**

  > If the **Allow running multiple engines on the same machine** option
  > is selected, run the command:

  > `sudo systemctl restart d1_<Engine _name>`

6.  Retest the integration from the user interface. This may take a few
    minutes because it may need to pull the relevant Docker image.

Troubleshoot permission denied

A common error message you may see when running integrations on engines
is something like:
`Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.35/images/json?t.`

1.  Determine if you are using a Docker group or Dockerroot group by
    running one of the following on the server engine:

    - `ls -la /var/run/docker.sock`

    <!-- -->

    - The output from this command will show what user/group is running
      docker.sock. For example:

          srw-rw----. 1 root docker 0 Apr 12 20:32 /var/run/docker.sock

      shows that it's a Docker group and not Dockerroot.

    <!-- -->

    - `cat /etc/group | grep docker`

    <!-- -->

    - This command shows if you are running Docker or Dockerroot.

- > **Note**

  > Docker CE installations typically run Docker, while Docker EE
  > installations typically run dockerroot.

2.  To fix a Docker user, run the following commands on the server
    engine:

    a.  `sudo groupadd docker`

    b.  `sudo usermod -aG docker demisto`

    c.  `sudo systemctl restart docker`

    d.  `sudo systemctl restart d1`

    - > **Note**

      > If the **Allow running multiple engines on the same machine**
      > option is selected, run the command:

      > `sudo systemctl restart d1_<Engine _name>`

3.  To fix a `dockerroot` user, run the following commands on the server
    engine:

    a.  `sudo groupadd dockerroot`

    b.  Set the dockerroot group in `/etc/docker/daemon.json`. For
        example: { \"group\": \"dockerroot\" }.

    c.  `sudo usermod -aG dockerroot demisto`

    d.  `sudo chcon -Rt svirt_sandbox_file_t /var/lib/demisto/temp`

    e.  `sudo systemctl restart docker`

    f.  `sudo systemctl restart d1`

    - > **Note**

      > If the **Allow running multiple engines on the same machine**
      > option is selected, run the command:

      > `sudo systemctl restart d1_<Engine _name>`

### Response actions

To assist you with your investigation, Cortex XSIAM provides response
actions for investigating and remediating endpoints. For example, if you
detect a compromised endpoint you can isolate it from your network. This
action prevents the endpoint from communicating with other internal or
external devices, and thereby reducing an attacker's mobility on your
network.

For response actions that rely on the Cortex XDR agent, the following
table describes the supported platforms and minimum agent version. A
dash (---) indicates that the setting is not supported.

+-----------------------------------------------+-----------------+-----------------+-----------------+
| Module                                        | Windows         | Mac             | Linux           |
+===============================================+=================+=================+=================+
| **Initiate a Live Terminal Session**          | ✓               | ✓               | ✓               |
|                                               |                 |                 |                 |
| Initiates a remote connection to an endpoint, | Agent 6.1 and   | Agent 7.0 and   | Agent 7.0 and   |
| enabling you to investigate and respond to    | later           | later           | later           |
| security events. Using `Live Terminal` you    |                 |                 |                 |
| can manage files in the file system, manage   |                 |                 |                 |
| active processes, and run operating system or |                 |                 |                 |
| Python commands.                              |                 |                 |                 |
+-----------------------------------------------+-----------------+-----------------+-----------------+
| **Isolate an Endpoint**                       | ✓               | ✓               | ✓               |
|                                               |                 |                 |                 |
| Halts all network access on the endpoint      | Agent 6.0 and   | Agent 7.3 and   | Agent 7.7 and   |
| except for traffic to Cortex XSIAM. This      | later           | later on macOS  | later           |
| prevents a compromised endpoint from          |                 | 10.15.4 and     |                 |
| communicating with other internal or external |                 | later           |                 |
| devices.                                      |                 |                 |                 |
+-----------------------------------------------+-----------------+-----------------+-----------------+
| **Run Scripts on an Endpoint**                | ✓               | ✓               | ✓               |
|                                               |                 |                 |                 |
| Allows executing Python 3.7 scripts on your   | Agent 7.1 and   | Agent 7.1 and   | Agent 7.1 and   |
| endpoints directly from Cortex XSIAM,         | later           | later           | later           |
| including out-of-the-box scripts or your own  |                 |                 |                 |
| Python scripts and code snippets.             |                 |                 |                 |
+-----------------------------------------------+-----------------+-----------------+-----------------+
| **Remediate Changes from Malicious Activity** | ✓               | ---             | ---             |
|                                               |                 |                 |                 |
| Investigates suspicious causality process     | Agent 7.2 and   |                 |                 |
| chains and cases on your endpoints, and       | later           |                 |                 |
| provides suggested actions for remediating    |                 |                 |                 |
| processes, files and registry keys on your    |                 |                 |                 |
| endpoint that were changed as a result of     |                 |                 |                 |
| malicious activity.                           |                 |                 |                 |
+-----------------------------------------------+-----------------+-----------------+-----------------+
| **Search and Destroy Malicious Files**        | ✓               | ✓               | ---             |
|                                               |                 |                 |                 |
| Searches for the presence of known and        | Agent 7.2 and   | Agent 7.3 and   |                 |
| suspected malicious files on endpoints, and   | later           | later on macOS  |                 |
| destroys the file on endpoints where it       |                 | 10.15.4 and     |                 |
| exists.                                       |                 | later           |                 |
+-----------------------------------------------+-----------------+-----------------+-----------------+

> **Caution**
>
> Response actions are not supported for Android endpoints.

#### Initiate a Live Terminal session

To investigate and respond to security events on endpoints, you can use
the Live Terminal to initiate a remote connection to an endpoint. The
remote connection is facilitated by the Cortex XDR agent by using a
remote procedure call. With the Live Terminal you can manage remote
endpoints, and perform investigation and response actions on endpoints.
Actions include:

- Navigating and managing files in the file system.

- Managing active processes.

- Running operating system commands and Python commands.

- Downloading files of up to 200 MB and uploading files of up to 40 MB.

Live Terminal is supported for endpoints that meet the following
requirements:

+-----------------------------------+----------------------------------------------------------------------------------------------------------+
| Operating System                  | Requirements                                                                                             |
+===================================+==========================================================================================================+
| Windows                           | - Traps 6.1 or a later release.                                                                          |
|                                   |                                                                                                          |
|                                   | - Windows 7 SP1 or a later release.                                                                      |
|                                   |                                                                                                          |
|                                   | - Windows update patch for [WinCRT (KB                                                                   |
|                                   |   2999226)](https://support.microsoft.com/en-us/help/2999226/update-for-universal-c-runtime-in-windows). |
|                                   |   To verify the Hotfixes that are installed on the endpoint, run the `systeminfo` command from a command |
|                                   |   prompt.                                                                                                |
|                                   |                                                                                                          |
|                                   | - Endpoint activity reported within the last 90 minutes (as identified by the **Last Seen** time stamp   |
|                                   |   in the endpoint details).                                                                              |
+-----------------------------------+----------------------------------------------------------------------------------------------------------+
| Mac                               | - Cortex XDR agent 7.0 or a later release.                                                               |
|                                   |                                                                                                          |
|                                   | - macOS 10.12 or a later release.                                                                        |
|                                   |                                                                                                          |
|                                   | - Endpoint activity reported within the last 90 minutes (as identified by the **Last Seen** time stamp   |
|                                   |   in the endpoint details).                                                                              |
+-----------------------------------+----------------------------------------------------------------------------------------------------------+
| Linux                             | - Cortex XDR agent 7.0 or a later release.                                                               |
|                                   |                                                                                                          |
|                                   | - Any Linux supported version as listed in *Where Can I Install the Cortex XDR Agent?* in the Palo Alto  |
|                                   |   Networks Compatibility Matrix.                                                                         |
|                                   |                                                                                                          |
|                                   | - Endpoint activity reported within the last 90 minutes (as identified by the **Last Seen** time stamp   |
|                                   |   in the endpoint details).                                                                              |
+-----------------------------------+----------------------------------------------------------------------------------------------------------+

> **Note**
>
> You can run PowerShell 5.0 or a later release on Live Terminal of
> Windows.

##### Initiate a Live Terminal session

1.  You can initiate a Live Terminal session from Inventory \> Endpoints
    \> All Endpoints page. Right-click an endpoint and select Security
    Operations \> Initiate Live Terminal. It might take the Cortex XDR
    agent a few minutes to facilitate the connection.

- You can also initiate a Live Terminal as a response action to a
  security event. If the endpoint is inactive or does not meet the
  requirements, the option is disabled.

2.  Use the Live Terminal to investigate and take action on the
    endpoint.

- > **Tip**

  > You can fine-tune the Live Terminal session visibility on the
  > endpoint by adjusting the **User Interface** options in your Agent
  > Settings Profile.

3.  When you are finished, **Disconnect** the Live Terminal session.

- After you terminate the Live Terminal session, you can save a session
  report that logs all actions from the Live Terminal session. The
  report is available for download as a text file report when you close
  the live terminal session.

  The following example displays a sample session report:

      Live Terminal Session Summary
      Initiated by user username@paloaltonetworks.com on target TrapsClient1 at Jun 27th 2019 14:17:45

      Jun 27th 2019 13:56:13  Live Terminal session has started   [success]
      Jun 27th 2019 14:00:45  Kill process calc.exe (4920)    [success]
      Jun 27th 2019 14:11:46  Live Terminal session end request   [success]
      Jun 27th 2019 14:11:47  Live Terminal session has ended [success]


      No artifacts marked as interesting

##### Manage processes from a Live Terminal session

From the **Live Terminal** you can monitor processes running on the
endpoint. The **Task Manager** displays the task attributes, owner, and
resources used. If you discover an anomalous process while investigating
the cause of a security event, you can take immediate action to
terminate the process or the whole process tree, and block processes
from running.

1.  From the Live Terminal session, open the **Task Manager** to
    navigate the active processes on the endpoint.

- You can toggle between a sorted list of processes and the default
  process tree view
  (![](media/rId2682.png){width="0.20833333333333334in"
  height="0.20833333333333334in"}). You can also export the list of
  processes and process details to a comma-separated values file. If the
  process is known as malware, the row displays a red indicator and
  identifies the file using a malware attribute.

2.  Right-click the process to take the following actions:

    - **Terminate process:** Terminate the process or the entire process
      tree.

    - **Suspend process:** To stop an attack while investigating the
      cause, you can suspend a process or process tree without killing
      it entirely.

    - **Resume process:** Resume a suspended process.

    - **Open in VirusTotal:** VirusTotal aggregates known malware from
      antivirus products and online scan engines. You can scan a file
      using the VirusTotal scan service to check for false positives or
      verify suspected malware.

    - **Get WildFire verdict:** WildFire evaluates the file hash
      signature to compare it against known threats.

    - **Get file hash:** Obtain the SHA256 hash value of the process.

    - **Download Binary:** Download the file binary to your local host
      for further investigation and analysis. You can download files up
      to 200MB in size.

    - **Mark as Interesting:** Add an **Interesting** tag to a process
      so that you can easily locate the process in the session report.

    - **Remove from Interesting:** If no threats are found, you can
      remove the **Interesting** tag.

    - **Copy Value:** Copy the cell value to your clipboard.

3.  To end the Live Terminal session, select **Disconnect**.

- Choose whether to save the session report including files and tasks
  marked as interesting. Administrator actions are not saved to the
  endpoint.

##### Manage files from a Live Terminal session

The **File Explorer** enables you to navigate the file system on the
remote endpoint and take the following actions:

- Create, move, delete, or download files, folders, and drives,
  including connected external drives and devices such as USB drives and
  CD-ROM.

<!-- -->

- > **Note**

  > Network drives are not supported.

<!-- -->

- View file attributes, creation and last modified dates, and the file
  owner.

- Investigate files for malicious content.

**How to manage files from a Live Terminal**

1.  From the Live Terminal session, open the **File Explorer**.

2.  Double click to navigate through each file directory. To locate a
    specific file, you can search for any filename rows on the screen
    from the search bar.

3.  From the top right hand menu you can take the following actions:

    - Create a new directory

    - Export the table as a CSV file.

4.  Right click a file or folder to see the available actions,
    including:

    - Rename files and folders.

    - Move and delete files and folders.

    - Download a file.

    - **Open in VirusTotal:** VirusTotal aggregates known malware from
      antivirus products and online scan engines. You can scan a file
      using the VirusTotal scan service to check for false positives or
      verify suspected malware.

    - **Get WildFire verdict:** WildFire evaluates the file hash
      signature to compare it against known threats.

    - **Get file hash:** Obtain the SHA256 hash value of the file.

    - **Download Binary:** Download the file binary to your local host
      for further investigation and analysis. You can download files up
      to 200MB in size.

    - **Mark as Interesting:** Add an **Interesting** tag to a file or
      directory so that you can easily locate the file in the session
      report.

    - **Remove from Interesting:** If no threats are found, you can
      remove the **Interesting** tag.

    - **Copy Value:** Copy the cell value to your clipboard.

5.  Select **Disconnect** to end the live terminal session.

- Choose whether to save the live terminal session report including
  files and tasks marked as interesting. Administrator actions are not
  saved to the endpoint.

##### Run operating system commands from a Live Terminal session

The Live Terminal provides a command line interface for running
operating system commands on a remote endpoint. Each command runs
independently and is not persistent.

> **Note**
>
> On Windows endpoints, you cannot run GUI-based cmd commands like
> `winver` or `appwiz.cpl`.

**How to run operating system commands**

1.  From the Live Terminal session, select **Command Line**.

2.  Type your command on the command line and press **Shift** +
    **Enter** to execute the command.

- For example, you can manage files or launch batch files. You can enter
  or paste the commands into the command line interface, or you can
  upload a script.

  To chain multiple commands together use `&&`, as shown in the
  following example:

      cd c:\windows\temp\ && <command1> && <command2>

3.  To end the Live Terminal session, select **Disconnect**.

- Choose whether to save the session report including files and tasks
  marked as interesting. Administrator actions are not saved to the
  endpoint.

##### Run Python commands and scripts from a Live Terminal session

The Live Terminal provides a Python command line interface for running
Python commands and scripts. The Python command interpreter uses Unix
command syntax and supports Python 3 with standard Python libraries.

1.  From the Live Terminal session, select **Python** to start the
    python command interpreter on the remote endpoint.

2.  Run Python commands or scripts as required.

- You can enter or paste the commands into the command line interface,
  or you can upload a script.

3.  When you are finished, **Disconnect** the Live Terminal session.

- Choose whether to save the live terminal session report including
  files and tasks marked as interesting. Administrator actions are not
  saved to the endpoint.

##### Disable Live Terminal sessions

If you want to prevent Cortex XSIAM from initiating Live Terminal remote
sessions on an endpoint that is running the Cortex XDR agent, you can
disable this capability during agent installation or through Cortex
XSIAM [Endpoint Administration](#UUIDbcc5060e05a2c7874bf28a53796739c6).
Disabling script execution is irreversible. If you later want to
re-enable this capability on the endpoint, you must re-install the
Cortex XDR agent.

> **Note**
>
> Disabling Live Terminal does not take effect on sessions that are in
> progress.

#### Isolate an endpoint

When you isolate an endpoint, you halt all network access on the
endpoint except for traffic to Cortex XSIAM. This can prevent a
compromised endpoint from communicating with other endpoints, thereby
reducing an attacker's mobility on your network. After the agent
receives the instruction to isolate the endpoint and carries out the
action, Cortex XSIAM shows an **Isolated** status. To ensure an endpoint
remains in isolation, agent upgrades are not available for isolated
endpoints.

When isolated, the endpoint will still allow:

- DHCP and HTTPS outgoing traffic for root user

- DNS traffic

> **Note**
>
> IP-based file storage protocol traffic will also be blocked. This
> might affect endpoint functionality if the endpoint uses such mounts.

Network isolation is supported for endpoints that meet the following
requirements:

+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| Operating System                  | Prerequisites                                                                                                                               |
+===================================+=============================================================================================================================================+
| Windows                           | - Agent 6.0 or later.                                                                                                                       |
|                                   |                                                                                                                                             |
|                                   | - (*VDI*) Network isolation allow list in the agent settings profile is configured to ensure VDI sessions remain uninterrupted. For more    |
|                                   |   information, see                                                                                                                          |
|                                   |   [/document/preview/868498#UUID-416260cf-dda6-2267-9eaa-b66a68471cb6](/document/preview/868498#UUID-416260cf-dda6-2267-9eaa-b66a68471cb6). |
+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| Mac                               | - Agent 7.3 or later.                                                                                                                       |
|                                   |                                                                                                                                             |
|                                   | - MacOS 10.15.4 or later.                                                                                                                   |
|                                   |                                                                                                                                             |
|                                   | - Cortex XSIAM Network extension is enabled on the endpoint.                                                                                |
|                                   |                                                                                                                                             |
|                                   | Network isolation on Mac endpoints does not terminate active connections that were initiated before the agent was installed on the          |
|                                   | endpoint.                                                                                                                                   |
+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| Linux                             | - iptables and ip6tables.                                                                                                                   |
|                                   |                                                                                                                                             |
|                                   | - Agent 7.7 or later.                                                                                                                       |
|                                   |                                                                                                                                             |
|                                   | - Linux kernel with the following enabled:                                                                                                  |
|                                   |                                                                                                                                             |
|                                   |   - CONFIG_NETFILTER                                                                                                                        |
|                                   |                                                                                                                                             |
|                                   |   - CONFIG_IP_NF_IPTABLES                                                                                                                   |
|                                   |                                                                                                                                             |
|                                   |   - CONFIG_IP_NF_MATCH_OWNER                                                                                                                |
|                                   |                                                                                                                                             |
|                                   | - Network isolation allow list configured in the agent settings profile.                                                                    |
|                                   |                                                                                                                                             |
|                                   | Network isolation on Linux endpoints is based on the defined IP addresses and ports.                                                        |
+-----------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+

**How to isolate an endpoint**

1.  Go to Investigation & Response \> Response \> Action Center \> New
    Action and select **Isolate**.

- You can also initiate the action (for one or more endpoints) from the
  **Isolation** page of the **Action Center** or from Endpoints \>
  Endpoint Management \> Endpoint Administration.

2.  Enter a **Comment** to provide additional background or other
    information that explains why you isolated the endpoint.

- After you isolate an endpoint, Cortex XSIAM displays the
  **Isolation Comment** under Action Center \> Isolation. If needed, you
  can edit the comment from the right-click pivot menu.

3.  Click **Next**.

4.  Select the target endpoint that you want to isolate from your
    network.

- > **Tip**

  > If needed, **Filter** the list of endpoints.

5.  Click **Next**.

6.  Review the action summary and click **Done** when finished.

- In the next heartbeat, the agent will receive the isolation request
  from Cortex XSIAM.

7.  To track the status of an isolation action, go to Action Center \>
    Currently Applied Actions \> Endpoint Isolation.

- If after initiating an isolation action, you can cancel the action by
  right-clicking the action and selecting Cancel for pending endpoint.
  You can cancel the isolation action only if the endpoint is still in
  `Pending` status and has not been isolated yet.

8.  After you remediate the endpoint, cancel endpoint isolation to
    resume normal communication.

- You can cancel isolation from Actions Center \> Isolation or from
  Endpoints \> Endpoint Management \> Endpoint Administration. From
  either place right-click the endpoint and select Endpoint Control \>
  Cancel Endpoint Isolation.

> **Note**
>
> If file system operations become unresponsive during isolation, such
> as being unable to list folder content, unmount the mounted network
> shares.

#### Pause endpoint protection

As of * agent 7.7 and above*, you can pause the agent protection
capabilities on one or more endpoints while maintaining connectivity
with Cortex XSIAM. By only pausing the protection and retaining
connectivity, the agent will run with all the profiles disabled, but
continue to send data and take actions from the server. When you are
ready, you can resume the endpoint protection.

> **Note**
>
> Pausing your endpoint protection modules leaves your machines exposed
> to risks.

**How to pause endpoint protection modules**

1.  Go to Inventory \> Endpoints \> All Endpoints.

2.  In the **All Endpoints** page, select the endpoints on which you
    want to pause protection, right-click and select Endpoint Control \>
    Pause Endpoint Protection.

3.  Verify the endpoints, add an optional comment that appears in the
    Management Audit log, and **Pause** the protection.

- Paused endpoints display a pause icon in the **Endpoint Name** field,
  and one of the following the action statuses in
  **Manual Protection Pause** field:

  - Protection Active

  - Pending Pause

  - Protection Paused

  - Pending Activation

4.  When you are ready to resume protection, select the paused
    endpoints, right-click and select Endpoint Control \> Resume
    Endpoint Protection and **Resume** protection on the listed
    endpoints.

- The **All Endpoint** table fields are updated accordingly.

5.  Track your pause and resume endpoint protection actions.

- Go to Investigation & Response \> Response \> Action Center and locate
  **Action Type** **Pause Endpoint Protection** or
  **Resume Endpoint Protection**.

#### Remediate changes from malicious activity

When investigating cases and causality chains you might need to restore
and revert changes made to your endpoints as result of a malicious
activity. To avoid manually searching for the affected files and
registry keys on your endpoints, you can request remediation
suggestions.

> **Prerequisite**
>
> To initiate remediation suggestions, you must have the following
> system requirements:

- > An App Administrator, Privileged Responder, or Privileged Security
  > Admin role permissions which include the remediation permissions.

- > EDR data collection enabled.

- > Agent version 7.2 or above on Windows endpoints.

**How to initiate remediation suggestions**

1.  You can initiate a remediation suggestions analysis from the
    following places:

    - In the **Cases** view, click the more options icon in the cases
      panel and select **Remediation Suggestions**.

    <!-- -->

    - > **Note**

      > Endpoints that are part of the **Case** view and do not meet the
      > required criteria are excluded from the remediation analysis.

    <!-- -->

    - In the **Causality View**:

      - Right-click any process node involved in the causality chain and
        select **Remediation Suggestion**.

      - Select Actions \> Remediation Suggestions.

- Analysis can take a few minutes. You can minimize the analysis pop-up
  if desired while navigating to other pages.

2.  Review the remediation suggestion summary and details.

- Field descriptions

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Original Event Description        | Summary of the initial event that |
|                                   | triggered the malicious causality |
|                                   | chain.                            |
+-----------------------------------+-----------------------------------+
| Original Event Timestamp          | Timestamp of the initial event    |
|                                   | that triggered the malicious      |
|                                   | causality chain.                  |
+-----------------------------------+-----------------------------------+
| Endpoint Name                     | Hostname of the endpoint.         |
+-----------------------------------+-----------------------------------+
| IP Address                        | IP address associated with the    |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+
| Endpoint Status                   | Connectivity status of the        |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+
| Domain                            | Domain or workgroup to which the  |
|                                   | endpoint belongs, if applicable.  |
+-----------------------------------+-----------------------------------+
| Endpoint ID                       | Unique ID assigned by Cortex      |
|                                   | XSIAM that identifies the         |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+
| Suggested Remediation             | Action suggested by the           |
|                                   | remediation scan for you to apply |
|                                   | to the causality chain process:   |
|                                   |                                   |
|                                   | - Delete File.                    |
|                                   |                                   |
|                                   | - Restore File.                   |
|                                   |                                   |
|                                   | - Rename File.                    |
|                                   |                                   |
|                                   | - Delete Registry Value.          |
|                                   |                                   |
|                                   | - Restore Registry Value.         |
|                                   |                                   |
|                                   | - Terminate Process               |
|                                   |                                   |
|                                   | <!-- -->                          |
|                                   |                                   |
|                                   | - Available when selecting        |
|                                   |   **Remediation Suggestions** for |
|                                   |   a node in the Causality View.   |
|                                   |                                   |
|                                   | <!-- -->                          |
|                                   |                                   |
|                                   | - Terminate Causality             |
|                                   |                                   |
|                                   | <!-- -->                          |
|                                   |                                   |
|                                   | - Terminate the entire causality  |
|                                   |   chain of processes that have    |
|                                   |   been executed under the process |
|                                   |   tree of the listed Causality    |
|                                   |   Group Owner (GCO) process name. |
|                                   |                                   |
|                                   | <!-- -->                          |
|                                   |                                   |
|                                   | - Manual Remediation              |
|                                   |                                   |
|                                   | <!-- -->                          |
|                                   |                                   |
|                                   | - Requires you to take manual     |
|                                   |   action to revert or restore.    |
+-----------------------------------+-----------------------------------+
| Suggested Remediation Description | Summary of the remediation        |
|                                   | suggestion to apply to the file   |
|                                   | or registry.                      |
+-----------------------------------+-----------------------------------+
| Remediation Status                | Status of the applied             |
|                                   | remediation.                      |
+-----------------------------------+-----------------------------------+
| Remediation Date                  | Displays the timestamp of when    |
|                                   | all of the endpoint artifacts     |
|                                   | were remediated. If missing a     |
|                                   | successful remediation, the field |
|                                   | will not display the timestamp.   |
+-----------------------------------+-----------------------------------+

3.  Select one or more rows, right-click and select **Remediate**.

4.  Track your remediation process.

- Go to Investigation & Response \> Response \> Action Center \> All
  Actions and locate your remediation process in the **Action Type**
  field. Right-click **Additional data** to open the
  **Detailed Results** window.

#### Run agent scripts on an endpoint

For enhanced endpoint remediation and endpoint management, you can run
Python 3.7 scripts on your endpoints directly from Cortex XSIAM. For
commonly used actions, Cortex XSIAM provides out-of-the-box scripts. You
can also write and upload your own Python scripts and code snippets into
Cortex XSIAM for custom actions. Cortex XSIAM enables you to manage,
run, and track the script execution on the endpoints, and store and
display the execution results per endpoint.

> **Prerequisites**
>
> To run scripts on an endpoint, you must have the following system
> requirements:

- > Endpoints running the Agent v7.1 and later. Since the agent uses its
  > built-in capabilities and many available Python modules to execute
  > the scripts, no additional setup is required on the endpoint.

- > Role in the hub with the following permissions to run and configure
  > scripts:

  - > **Run Standard scripts**

  - > **Run High-risk scripts**

  - > **Script configuration** (required to upload a new script, run a
    > snippet, and edit an existing script)

  - > **Scripts **(required to view the **Scripts Library** and the
    > script execution results)

<!-- -->

- > **Note**

  > Running snippets requires both **Run High-risk scripts** and
  > **Script configuration** permissions. Additionally, all scripts are
  > executed as System User on the endpoint.

Manage scripts in the Scripts Library

Your scripts are available in the Action Center \> Scripts Library,
including out-of-the-box scripts and custom scripts. From the
**Scripts Library**, you can view the script code and metadata, and
perform the following actions from the right-click pivot menu:

- **Download script:** Download the Python code file locally.

- **View/Download definitions file:** View or download the script
  metadata.

- **Run:** Run the selected script. Cortex XSIAM redirects you to the
  **Action Center** where the details of this script are populated in
  the new action fields.

- **Edit:** Edit the script code or metadata. This option is not
  available for the out-of-the-box scripts.

The following table describes the default and optional fields that you
can view in the **Scripts Library**. The fields are in alphabetical
order.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Compatible OS                     | Operating systems with which the  |
|                                   | script is compatible.             |
+-----------------------------------+-----------------------------------+
| Created By                        | User who created the script. For  |
|                                   | out-of-the-box scripts, the user  |
|                                   | name is Palo Alto Networks.       |
+-----------------------------------+-----------------------------------+
| Description                       | Script description is an optional |
|                                   | field that can be completed when  |
|                                   | creating, uploading, or editing a |
|                                   | script.                           |
+-----------------------------------+-----------------------------------+
| Id                                | Unique ID assigned by Cortex      |
|                                   | XSIAM to identify the script.     |
+-----------------------------------+-----------------------------------+
| Modification Date                 | Date and time in which the script |
|                                   | or its attributes were last       |
|                                   | edited.                           |
+-----------------------------------+-----------------------------------+
| Name                              | Script name is a mandatory field  |
|                                   | that can be completed when        |
|                                   | creating, uploading, or editing a |
|                                   | script.                           |
+-----------------------------------+-----------------------------------+
| Outcome                           | - **High-risk:** Scripts that may |
|                                   |   potentially harm the endpoint.  |
|                                   |                                   |
|                                   | - **Standard:** Scripts that do   |
|                                   |   not have a harmful impact on    |
|                                   |   the endpoint.                   |
+-----------------------------------+-----------------------------------+
| Script FileSHA256                 | SHA256 of the code file.          |
+-----------------------------------+-----------------------------------+

Out-of-the-box scripts

Palo Alto Networks provides out-of-the-box scripts. You can view the
scripts, download the script code and metadata, and duplicate the
scripts, however you cannot edit the code or definitions of
out-of-the-box scripts.

The following table lists the out-of-the-box scripts provided by Palo
Alto Networks, in alphabetical order. New scripts are continuously
uploaded into Cortex XSIAM through content updates, and are labeled
**New** for a period of three days.

+-----------------------------------+-----------------------------------+
| Script name                       | Description                       |
+===================================+===================================+
| delete_file                       | Delete a file on the endpoint     |
|                                   | according to the full path.       |
+-----------------------------------+-----------------------------------+
| file_exists                       | Search for a specific file on the |
|                                   | endpoint according to the full    |
|                                   | path.                             |
+-----------------------------------+-----------------------------------+
| get_process_list                  | List CPU and memory for all       |
|                                   | processes running on the          |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+
| list_directories                  | List all directories under a      |
|                                   | specific path on the endpoint.    |
|                                   | You can limit the number of       |
|                                   | levels you want to list.          |
+-----------------------------------+-----------------------------------+
| process_kill_cpu                  | Set a minimum CPU value and kill  |
|                                   | all process on the endpoint that  |
|                                   | are using higher CPU.             |
+-----------------------------------+-----------------------------------+
| process_kill_mem                  | Set a minimum RAM usage in bytes  |
|                                   | and kill all process on the       |
|                                   | endpoint that are using higher    |
|                                   | private memory.                   |
+-----------------------------------+-----------------------------------+
| process_kill_name                 | Kill all processes by a given     |
|                                   | name.                             |
+-----------------------------------+-----------------------------------+
| \*registry_delete                 | Delete a Registry key or value on |
|                                   | the endpoint.                     |
| (Windows)                         |                                   |
+-----------------------------------+-----------------------------------+
| \*registry_get                    | Retrieve a Registry value from    |
|                                   | the endpoint.                     |
| (Windows)                         |                                   |
+-----------------------------------+-----------------------------------+
| \*registry_set                    | Set a Registry value from the     |
|                                   | endpoint.                         |
| (Windows)                         |                                   |
+-----------------------------------+-----------------------------------+

> **Note**
>
> \*Since all scripts are running under System context, you cannot
> perform any registry operations on user-specific hives
> (HKEY_CURRENT_USER of a specific user).

Upload your scripts

You can write and upload scripts to the **Scripts Library**.

1.  Go to Action Center \> Agent Script Library and select New Script.

- Drag your script file into the window, or browse and select it. During
  upload, Cortex XSIAM parses the script to ensure you are using only
  supported Python modules. Click **supported modules** to view the
  supported modules list. If your script is using unsupported Python
  modules, or if your script is not using proper indentation, you will
  be required to fix it. You can use the editor to update your script
  directly in Cortex XSIAM.

2.  Add metadata to your script.

- You can enter the field definitions manually, or upload a definitions
  file to automatically enter the definitions. The definitions file must
  use exact script manifest format. To view the manifest format and
  create your own, see [Create a script
  manifest](#X4a57d50c2bb2ac7a1a1daa141a6d044d11beec2).

  Complete the following fields:

  - **General:** Specify the general script definitions including name
    and description, risk categorization, supported operating systems,
    and timeout in seconds.

  - **Input:** Set the starting execution point of your script code. To
    execute the script line by line, select **Just run**. Alternatively,
    to set a specific function in the code as the entry point, select
    **Run by entry point**. Select the function from the list, and
    specify for each function parameter its type.

  <!-- -->

  - ![](media/rId2698.png){width="5.833333333333333in"
    height="2.1656244531933506in"}

  <!-- -->

  - **Output:** If your script returns an output, specify the output
    type. Cortex XSIAM displays this information in the script results
    table.

    - **Single parameter:** If the script returns a single parameter,
      select the output type from the list and the output will be
      displayed as is. To detect the type automatically, select
      **Auto Detect**.

    - **Dictionary:** If the script returns multiple values, select
      **Dictionary**. By default, Cortex XSIAM displays the dictionary
      value as is in the script results table.

    <!-- -->

    - To improve the display of the script results table and enable
      filtering, you can assign user-friendly names and types to your
      dictionary keys.

  <!-- -->

  - ![](media/rId2701.png){width="5.833333333333333in"
    height="1.5677077865266842in"}

    To retrieve files from the endpoint, add the `files_to_get` key to
    the dictionary. This key includes an array of paths from which files
    will be retrieved from the endpoint.

3.  When you are finished, create the new script. The script is uploaded
    to the **Scripts Library**.

Create a script manifest

You can create a script manifest to automatically enter file definitions
for a script. For more information see Step 2 in [Upload your
scripts](#X7f261d7e28a51482c446e2161789d7506f46dd0).

The script manifest file that you upload into Cortex XSIAM has to be a
single-line textual file, in the exact format explained below. If your
file is structured differently, the manifest validation will fail and
you will be required to fix the file.

This is an example of the manifest file structure and content.

In this example, we are showing each parameter in a new line. However,
when you create your file, you must remove any `\n` or `\t` characters.

    {
    "name":"script name",
    "description":"script description",
    "outcome":"High Risk|Standard",
    "platform":"Windows,macOS,Linux",
    "timeout":600,
    "entry_point":"entry_point_name",
    "entry_point_definition":{
            "input_params":[
                {"name":"registry_hkey","type":"string"},
                {"name":"registry_key_path","type":"number"},
                {"name":"registry_value","type":"number"}],
            "output_params":{"type":"JSON","value":[
                {"name":"output_auto_detect","friendly_name":"name1","type":"auto_detect"},
                {"name":"output_boolean","friendly_name":"name2","type":"boolean"},
                {"name":"output_number","friendly_name":"name3","type":"number},
                {"name":"output_string","friendly_name":"name4","type":"string"},
                {"name":"output_ip","friendly_name":"name5","type":"ip"}]
        }
    }

> **Note**
>
> Always use lowercase for variable names.

**How to create a script manifest**

1.  Type the script name and description.

- You can use letters and digits. Avoid the use of special characters.

2.  Categorize the script.

- If a script is potentially harmful, set it as `High— Risk` to limit
  the user roles that can run it. Otherwise, set it as `Standard.`

3.  Assign the platform.

- Enter the name of the operating system this script supports. The
  options are Windows, macOS, and Linux. If you need to define more than
  one, use a comma as a separator.

4.  Set the script timeout.

- Enter the number of seconds after which Cortex XSIAM agent halts the
  script execution on the endpoint.

5.  Configure the script input and output.

- To **Run by entry point**, you must specify the entry point name, and
  all input and output definitions.

  The available parameter types are:

  - `auto_detect`

  - `boolean`

  - `number`

  - `string`

  - `ip`

  - `number_list`

  - `string_list`

  - `ip_list`

  To set the script to **Just run**, leave both the `Entry_point` and
  `Entry_point_definitions` empty:

      {
      "name":"script name",
      "description":"script description",
      "outcome":"High Risk|Standard",
      "platform":"Windows,macOS,Linux",
      "timeout":600,
      "entry_point":"",
      "entry_point_definition":{}
      }

Track script execution

When you run a script, you can see the script execution in the
**Action Center** and track the script execution status. The **Status**
indicates the action\'s progress, which includes the general action
status and the breakdown by endpoints included in the action. The
following table lists the possible status of a script execution action
for each endpoint, in alphabetical order:

+-----------------------------------+-----------------------------------+
| Status                            | Description                       |
+===================================+===================================+
| Aborted                           | The script execution action was   |
|                                   | aborted after it was already in   |
|                                   | progress on the endpoint.         |
+-----------------------------------+-----------------------------------+
| Canceled                          | The script execution action was   |
|                                   | canceled before the agent pulled  |
|                                   | the request from the server.      |
+-----------------------------------+-----------------------------------+
| Completed Successfully            | The script was executed           |
|                                   | successfully on the endpoint with |
|                                   | no exceptions.                    |
+-----------------------------------+-----------------------------------+
| Expired                           | The script execution actions      |
|                                   | expire after four days. After an  |
|                                   | action expires, the status of any |
|                                   | remaining pending actions on      |
|                                   | endpoints changes to **Expired**  |
|                                   | and these endpoints will not      |
|                                   | receive the action.               |
+-----------------------------------+-----------------------------------+
| Failed                            | A script can fail due to these    |
|                                   | reasons:                          |
|                                   |                                   |
|                                   | - The agent failed to execute the |
|                                   |   script.                         |
|                                   |                                   |
|                                   | - Exceptions occurred during the  |
|                                   |   script execution.               |
+-----------------------------------+-----------------------------------+
| In Progress                       | The agent pulled the script       |
|                                   | execution request.                |
+-----------------------------------+-----------------------------------+
| Pending                           | The agent has not yet pulled the  |
|                                   | script execution request from the |
|                                   | server.                           |
+-----------------------------------+-----------------------------------+
| Pending Abort                     | The agent is in the process of    |
|                                   | executing the script, and has not |
|                                   | pulled the abort request from the |
|                                   | server yet.                       |
+-----------------------------------+-----------------------------------+
| Timeout                           | The script execution reached its  |
|                                   | configured time out and the agent |
|                                   | stopped the execution on the      |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+

**Open script in Interactive Mode**

You can use **Interactive Mode** to dynamically track the script
execution progress on all target endpoints and view the results as they
are being received in real-time. Additionally, you can start executing
more scripts on the same scope of target endpoints.

To initiate **Interactive Mode** for a script that is already running,
in the **Action Center**, right-click the execution action of the
relevant script and select **Open in interactive mode**.

Cancel or abort script execution

You can cancel or abort a script execution action for **Pending** and
**In Progress** actions:

- When the script execution action is **Pending**, the agent has not yet
  pulled the request from the Cortex XSIAM server. When you cancel a
  pending action, the server pulls back the request and updates the
  action status to **Canceled**. To cancel the action for all pending
  endpoints, go to the Action Center, right-click the action and
  **Cancel for pending endpoints**. Alternatively, to cancel a pending
  action for specific endpoints, go to Action Center \> Additional data
  \> Detailed Results, right-click the endpoint(s) and
  **Cancel pending action**.

- When the script execution action is **In Progress**, the agent has
  begun running the script on the endpoint. When you abort an action
  that is in progress, the agent halts the script execution on the
  endpoint and updates the action status to **Aborted**. To abort the
  action for all **In Progress** endpoints and cancel the action for any
  **Pending** endpoints, go to the **Action Center**, right-click the
  action and **Abort and cancel execution**. Alternatively, to abort an
  in progress action for specific endpoints, go to Action Center \>
  Additional data \> Detailed Results, right-click the endpoints and
  **Abort for endpoint in progress**.

View script execution results

Cortex XSIAM logs all script execution actions, including the script
results and the parameters specified when running the script. To view
full details about the run, including returned values, right-click the
script and select **Additional data**.

The script results are divided into the upper bar and the main view. The
upper bar displays the script meta-data including the script name and
entry point, the script execution action status, the parameter values
used in this run and the target endpoints scope. You can also download
the exact code used in this run as a `py` file.

The main view displays the script execution results as follows:

- **Main results view:** Displays a table listing all target endpoints
  and their details.

<!-- -->

- In addition to the endpoint details (name, IP, domain, etc), the
  following table describes the default and additional optional fields
  that you can view per endpoint. The fields are in alphabetical order.

  --------------------------------------------------------------------------------------------
  Field                               Description
  ----------------------------------- --------------------------------------------------------
  \*`Returned values`                 If your script returned values, the values are also
                                      listed in the additional data table according to your
                                      script output definitions.

  Execution timestamp                 Date and time the agent started the script execution on
                                      the endpoint. If the execution has not started yet, this
                                      field is empty.

  Failed files                        Number of files the agent failed to retrieve from the
                                      endpoint.

  Retention date                      Date after which the retrieved file will no longer be
                                      available for download. The value is 90 days from the
                                      execution date.

  Retrieved files                     Number of files that were successfully retrieved from
                                      the endpoint.

  Status                              See the list of statuses and their descriptions in
                                      [Track script
                                      execution](#Xe0446fedbd34d7838cd8d4fc758912d8be4d59d).

  Standard output                     The returned `stdout`
  --------------------------------------------------------------------------------------------

- For each endpoint, you can right-click to download the script
  `stdout`, download retrieved files, and view returned exceptions. You
  can also **Export to file** to download the detailed results table in
  `TSV` format.

<!-- -->

- **Aggregated results:** A visualization of the script results. Cortex
  XSIAM automatically aggregates only results that have a small variety
  of values. To see how many of the script results were aggregated
  successfully, see the counts on the toggle (for example, aggregated
  results 4/5). You can filter the results to adjust the endpoints
  considered in the aggregation. You can also generate a PDF report of
  the aggregated results view.

Rerun a script

You can select a script execution action in the **Action Center** and
rerun it. When you rerun a script, the same parameter values, target
endpoints, and defined timeout are used, as defined in the previous run.
However, you can make changes to the script before rerunning it. In
addition, if the target endpoints in the original run were defined using
a filter, the filter will be recalculated when you rerun the script.

Cortex XSIAM uses the current version of the script. If the script has
been deleted or the supported operating system definition has been
modified the since the previous run, you will not be able to rerun the
script.

1.  From the **Action Center**, right-click the script you want to rerun
    and select **Rerun**.

- You are redirected to the final summary stage of the script execution
  action.

2.  Run the script.

- To run the script with the same parameters and on the same target
  endpoints as the previous run, click **Done**. To change any of the
  previous run definitions, navigate through the wizard and make the
  necessary changes. Then, click **Done**. The script execution action
  is added to the **Action Center**.

Troubleshoot script execution

To understand why a script returned **Failed** execution status, you can
take the following actions:

1.  **Check script exceptions:** If the script generated exceptions, you
    can view them to learn why the script execution failed. From the
    **Action Center**, right-click the **Failed** script and select
    **Additional data**. In the **Script Results** table, right-click an
    endpoint for which the script execution failed and select
    **View exceptions**. The agent executes scripts on Windows endpoints
    as a SYSTEM user, and on Mac and Linux endpoints as a root user.
    These context differences could cause differences in behavior, for
    instance when using environment variables.

2.  **Validate custom scripts:** If a custom script that you uploaded
    failed, and the reason the script failed is still unclear from the
    exceptions or if the script did not generate any exceptions, try to
    identify whether it failed due to an error in Cortex XSIAM or an
    error in the script. To identify the error source, execute the
    script without the agent on the same endpoint with regular Python
    3.7 installation. If the script execution is unsuccessful, you
    should fix your script. Otherwise, if the script was executed
    successfully with no errors, contact Customer Support.

Disable script execution

If you want to prevent Cortex XSIAM from running scripts on an agent,
you can disable this capability during agent installation, or through
Endpoint Administration. Disabling script execution is irreversible. If
you want to re-enable this capability on the endpoint, you must
reinstall the agent. For more information, see the Cortex XDR Agent
Administrator's Guide.

> **Note**
>
> Disabling Script Execution does not take effect on scripts that are in
> progress.

#### Search and destroy malicious files

To take immediate action on known and suspected malicious files, you can
search and destroy the files. After identifying the presence of a
malicious file, you can immediately destroy the file from any or all
endpoints on which the file exists.

The agent builds a local database on the endpoint with a list of all the
files, including their path, hash, and additional metadata. Depending on
the number of files and the disk size of each endpoint, it can take a
few days for Cortex XSIAM to complete the initial endpoint scan and
populate the files database. You cannot search an endpoint until the
initial scan is complete and all file hashes are calculated.

After the initial scan is complete, the agent retains a snapshot of the
endpoint files inventory. The agent maintains the files database by
initiating periodic scans and closely monitoring all actions performed
on the files.

You can search for specific files according to the file hash, the file
full path, or a partial path using regex parameters from the
**Action Center** or the **Query Builder**. When you find the file, you
can select it in the search results and destroy the file by hash or by
path. If you already know the path or hash, you can also destroy a file
from the **Action Center** without performing a search. When you destroy
a file by hash, all the file instances on the endpoint are removed.

You can validate a hash against VirusTotal and WildFire to provide
additional context before initializing the File Destroy action.

> **Note**
>
> The Cortex XSIAM agent does not include the following information in
> the local files inventory:

- > Information about files that existed on the endpoint and were
  > deleted before the Cortex XSIAM agent was installed.

- > Information about files where the file size exceeds the maximum file
  > size for hash calculations that are pre-configured in Cortex XSIAM .

- > If the Agent Settings Profile on the endpoint is configured to
  > monitor common file types only, then the local files inventory
  > includes information about these file types only. You cannot search
  > or destroy file types that are not included in the list of common
  > file types.

> **Prerequisite**
>
> The following are prerequisites to enable Cortex XSIAM to search and
> destroy files on your endpoints:

- > Supported platforms:

  - > **Windows:** Cortex XDR agent version 7.2 or a later. If you plan
    > to enable Search and Destroy on VDI sessions, you must perform the
    > initial scan on the Golden Image.

  - > **Mac:** Cortex XDR agent version 7.3 or a later release running
    > on macOS version 10.15.4 or later.

  - > **Linux:** Not supported.

- > Setup and permissions:

  - > Ensure File Search and Destroy is enabled for your Cortex XDR
    > agent.

  - > Ensure your Cortex XSIAM role has File search and Destroy files
    > permissions.

##### Search a file

You can search for files on the endpoint by file hash or file path. The
search returns all instances of this file on the endpoint. You can then
immediately destroy all of the file instances on the endpoint, or upload
the file to Cortex XSIAM for further investigation.

You can search for a file using the **Query Builder**, or use the
**Action Center** wizard as described in the following workflow.

1.  From the **Action Center** select New Action \> File Search.

2.  Configure the search method:

    - To search by hash, enter the file SHA256 value. When you search by
      hash, you can also search for deleted instances of this file on
      the endpoint.

    - To search by path, enter the specific path for the file on the
      endpoint or specify the path using wildcards. When you provide a
      partial path or partial file name using \*, the search will return
      all the results that match the partial expression. Note the
      following limitations:

      - The file path must begin with a drive name, for example: `c:\`.

      - You must specify the exact path folder hierarchy, for example
        `c:\users\user\file.exe`. You must specify the exact path folder
        hierarchy also when you replace folder names with wildcards, by
        using a wildcard for each folder in the hierarchy. For example,
        `c:\*\*\file.exe`.

- Click **Next**.

3.  Select the target endpoints on which you want to search for the
    file. Cortex XSIAM displays only endpoints eligible for file search.
    Click **Next**.

4.  Review the summary and initiate the search.

- Cortex XSIAM displays the summary of the file search action. If you
  need to change your settings, go **Back**. If all the details are
  correct, click **Run**. The File search action is added to the
  **Action Center**.

5.  Review the search results.

- In the **Action Center**, you can monitor the action progress in
  real-time and view the search results for all target endpoints. For a
  detailed view of the results, right-click the action and select
  **Additional data**. Cortex XSIAM displays the search criteria,
  timestamp, and real-time status of the action on the target endpoints.
  You can:

  - **View results by file (default view):** Cortex XSIAM displays the
    first 100 instances of the file from every endpoint. Each search
    result includes details about the endpoint (such as endpoint status,
    name, IP address, and operating system) and details about the file
    instance (such as full file name and path, hash values, and creation
    and modification dates).

  - **View the results by endpoint:** For each endpoint in the search
    results, Cortex XSIAM displays details about the endpoint (such as
    endpoint status, name, IP address, and operating system), the search
    action status, and details about the file (whether it exists on the
    endpoint or not, how many instances of the file exist on the
    endpoint, and the last time the action was updated).

  If not all endpoints in the query scope are connected or the search
  has not completed, the search action remains in **Pending** status.

6.  (Optional) Destroy a file.

- After you located the malicious file instances on all your endpoints,
  proceed to destroy all the file instances on the endpoint. From the
  search results **Additional data**, right-click the file to
  immediately **Destroy by path**, **Destroy by hash**, or **Get file**
  to upload it to Cortex XSIAM for further examination.

##### Destroy a file

When you know a file is malicious, you can destroy all of its instances
on your endpoints, directly from Cortex XSIAM. You can destroy a file
immediately from the File search action result, or initiate a new action
from the **Action Center**. When you destroy a file, the Cortex XSIAM
agent deletes all the file instances on the endpoint. To destroy a file
from the file search results, see [Search a
file](#X5cb150a94e084002794f4d5eea5b58ab2e91ac9).

1.  From the **Action Center** select New Action \> Destroy File.

2.  To destroy by hash, provide the SHA256 of the file. To destroy by
    path, specify the exact file path and file name. Click **Next**.

3.  Select the target endpoints from which you want to remove the file.
    Cortex XSIAM displays only endpoints eligible for file destroy. When
    you're done, click **Next**.

4.  Review the summary and initiate the action.

- Cortex XSIAM displays the summary of the file destroy action. If you
  need to change your settings, go **Back**. If all the details are
  correct, click **Run**. The File destroy action is added to the
  **Action Center**.

#### Manage external dynamic lists

An External Dynamic List (EDL) is a hosted text file. In Cortex XSIAM,
you can configure an EDL to share a list of Cortex XSIAM indicators with
other products in your network, such as a firewall. For example, your
Palo Alto Networks firewall can add IP addresses and domain data from
the EDL to block or allow lists.

Cortex XSIAM hosts the following external dynamic lists that you can
configure and manage:

- IP Addresses EDL

- Domain Names EDL

> **Note**

- > To configure an EDL, you must have a role that includes EDL
  > permissions, such as Instance Admin or Account Admin.

- > Configuring custom certificates or private API Keys in the EDL
  > integration instance is supported only on engines, not on the Cortex
  > XSIAM server.

- > For EDL integrations on the server, you must set a username and
  > password. For long-running integrations running on an engine, we
  > strongly recommend setting a username and password, but it is not
  > required. You can set credentials for all EDL integrations or for a
  > specific integration instance.

<!-- -->

- > If you set a username and password in an EDL integration instance,
  > only those credentials are accepted, and the username and password
  > you set in the Cortex XSIAM doesn\'t work.

You can set up Cortex XSIAM to export internal data to an EDL using an
EDL integration installed either on the Cortex XSIAM tenant or on an
engine.

> **Note**
>
> The legacy external dynamic list PAN-OS integration is deprecated.
> Configure the EDL integration by clicking the
> **Automation & Feed Integration** link.

##### Access EDL Data on the Cortex XSIAM tenant

If the EDL integration runs on the Cortex XSIAM tenant, you must set a
username and password to allow external access to the data.

1.  Go to Settings \> Configurations \> Integrations \> External Dynamic
    List Integration.

2.  Enter a username and password for all EDL integration instances. If
    you do not enter credentials here, you must set them for each
    integration instance.

3.  In the **External Dynamic List - Generic Integration** section,
    click the **Automation & Feed Integration** link.

4.  Add an instance of the **Generic Export Indicators Service**.

5.  (Optional) If you want credentials specific to this integration
    instance, enter a **Username** and **Password** .

- > **Note**

  > If the EDL integration runs on the Cortex XSIAM server, you do not
  > need to enter a **Listen Port** in the instance settings. The system
  > auto-selects an unused port for the EDL integration when the
  > instance is saved. If you enter a value for **Listen Port**, it will
  > be overwritten by the port auto-selected by the system

6.  Enter an indicator query.

- The query updates the EDL list. To view expected results, run
  `!findIndicators query=<your query>` from the Cortex XSIAM CLI. Field
  names in your query must match the machine name for each field.

7.  Enter the maximum list size.

8.  Run the following curl command to access and test the External
    Dynamic
    List: `https://ext-<cortex-xsiam-address>/xsoar/instance/execute/<instance-name>`

- curl -v -u user:pass https://ext-mytenant.paloaltonetworks.com/xsoar/instance/execute/edl_instance_01\?q\=type:ip

  > **Important**

  > The EDL URL must always be prefixed by `ext-`.

9.  Save your changes.

##### Access EDL Data on an Engine

Provide access to internal data via an engine using an endpoint port. We
strongly recommend setting a username and password for additional
security.

1.  Click the **Automation & Feed Integration** link.

2.  For the **Generic Export Indicators Service**, click
    **Add instance** and enter:

    - **Listen Port:** The service to access the EDL runs on this port
      from within Cortex XSIAM. You need a unique port for each long
      running integration instance (do not use the same port for
      multiple instances).

    - (Optional) **Username** and **Password:** The username and
      password for the EDL.

    - **Run on single engine:** Select the engine from a drop-down.

3.  Enter an indicator query.

- The query updates the EDL list. To view expected results, run
  `!findIndicators query=<your query>` from the Cortex XSIAM CLI. Field
  names in your query must match the machine name for each field.

4.  Enter the maximum list size.

5.  Run the following curl command to access and test the External
    Dynamic List with the engine
    URL: `http://<engine-address>:<integration listen port>/`

- curl -v -u user:pass http://<engine_address>:<listen_port>/?n=50

6.  Save your changes.

#### Collect a memory image

> **Note**
>
> This functionality has the following license requirements:

- > Forensics add-on license.

Certain forensic artifacts exist only in the computer's memory, such as
volatile data created by running processes. The **Memory Collection**
option enables Cortex XSIAM to capture the memory of a Windows endpoint.
After the memory image has been captured from the Cortex XSIAM endpoint,
the image is available to download. Use the image to perform a full
analysis using industry-standard tools.

**How to collect a memory image**

1.  From the **Action Center** select New Action \> Memory Collection.

2.  Select the target Windows endpoint from which you want to collect
    the memory image (only one endpoint at a time). Click **Next**.

3.  Review the summary and initiate the action.

- A summary of the memory collection action is displayed. If you need to
  change your settings, click **Back**. If all the details are correct,
  click **Done**. The **Memory Collection** action is added to the
  **Action Center**.

4.  Review the collection results.

- In the **Action Center**, you can monitor the action progress in
  real-time and view the status for the target endpoint. For a detailed
  view of the results, right-click the action and select
  **Additional data**. Cortex XSIAM displays the action, timestamp, and
  real-time status of the action on the target endpoint.

5.  Download the file of the image.

- In the **Detailed Results - Memory Collection** screen, right-click
  the action and select **Download files**.

  The file is downloaded to the local computer.

### Forensics

> **Note**
>
> Requires the Forensics add-on

#### Forensic investigations

Investigations are comprised of one or more data collections from
endpoints within an environment. Grouping the collections within a
single location enables you to focus on the endpoints relevant to your
investigation. When searching for data, you can select two types of
collections:

- **Hunt** collections enable you to search for a specific activity
  across a large number of hosts. A hunt collection provides more
  details about where something occurred. Examples of this type of
  collection are, finding which endpoints ran a piece of malware, which
  users accessed a particular file, or which endpoints were accessed by
  a specific user.

- **Triage** collections enable you to collect detailed information
  about specific activities that occurred on an endpoint. The triage
  functionality is configurable and supports the collection of all
  currently supported forensic artifacts, user-defined file paths, a
  full file listing for all of the connected drives, full event logs,
  and registry hives. The amount of data collected during a triage can
  be large, so triages are limited to ten or fewer endpoints per
  collection.

##### Manage an investigation

Forensic investigations streamlines your case response, data collection,
threat hunting and analysis of your endpoint. By using the Forensic
Investigation, you can find the source and scope of the attack and to
determine what, if any, data was accessed. It provides a single location
for grouping, tracking, and analyzing all forensic data collections.

Forensic Investigations enables you to do the following:

- View any alerts triggered during data ingested as part of the
  investigation.

- Tag relevant evidence for inclusion for the
  **Investigation Timeline**.

- Export collected data for long-term retention.

- Set user permissions that can be assigned to investigations allowing
  you to restrict access to the Investigation page including the
  **Investigation Timeline** and collection details.

The **Forensic Investigation** fields shows information relating to the
investigation.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Investigation                     | Name of the investigation.        |
+-----------------------------------+-----------------------------------+
| Status                            | Present status of the             |
|                                   | investigation:                    |
|                                   |                                   |
|                                   | - Open                            |
|                                   |                                   |
|                                   | - Close pending: After selecting  |
|                                   |   close, the investigation status |
|                                   |   changes to close pending. It    |
|                                   |   takes 24 hours until officially |
|                                   |   removed from the investigations |
|                                   |   repository. This gives the      |
|                                   |   users a chance to revert back   |
|                                   |   if necessary.                   |
+-----------------------------------+-----------------------------------+
| Evidence collections              | Number of completed collections   |
|                                   | from the total collections.       |
+-----------------------------------+-----------------------------------+
| New alerts                        | Total count of alerts for the     |
|                                   | collection where the              |
|                                   | **Resolution Status**=**New**.    |
+-----------------------------------+-----------------------------------+
| Total alerts                      | Total number of alerts for data   |
|                                   | collected in the investigation    |
|                                   |                                   |
|                                   | You can click the link to open    |
|                                   | the investigation on the          |
|                                   | **Alerts** tab.                   |
+-----------------------------------+-----------------------------------+
| Created                           | Timestamp of when the             |
|                                   | investigation was created.        |
+-----------------------------------+-----------------------------------+

###### Create a new investigation

Create a forensics investigation that includes all the relevant
forensics data. This includes adding collections (hunts and triages),
exporting the data collections, managing alerts and evaluating key
assets & artifacts.

1.  Select Investigation & Response \> Forensics.

2.  Click **New Investigation**.

3.  In the **Create New Investigation** wizard, enter a name and
    description (optional) for the investigation.

4.  In the **Permissions** table, select the users to whom you want to
    grant access to the investigation data.

- > **Note**

  > To set up user permissions, you must have Scope-Based Access Control
  > (SBAC) enabled.

  Refer to [User permissions](#UUIDa4bfe3f1bfa4dc0c428132682982e2e3) for
  detailed information on permissions.

5.  Click **Save** to save the investigation in the
    **Forensic Investigations** table or click
    **Save & Start A Collection** to start the process of adding
    collections.

6.  In the **New Collection** widget, select
    [**Triage**](#UUID31199e382d5f9b6ad2f9f5d8e129ee37) or
    [**Hunt**](#UUIDe76de1da8109a6b3e1eaa2568db1b4d0).

7.  The investigation is saved to the **Forensic Investigations** table.

8.  Click **UTC Timezone** to configure the timezone and timestamp
    format. Refer to
    [/document/preview/860300#UUID-78b34243-f149-fd64-a2d8-b92f26a9ec0e](/document/preview/860300#UUID-78b34243-f149-fd64-a2d8-b92f26a9ec0e)
    for information on setting up your timezone.

###### Edit an investigation

From the list of active investigations, you can edit the name,
description or update the user permissions for the investigation.

1.  From the **Forensic Investigations** table, right-click one of the
    investigations and select **Edit**.

2.  In the **Edit Investigation** widget, you can update the
    **Investigation Name**, **Description**, and **Permissions**. For
    more information, refer to [User
    permissions](#UUIDa4bfe3f1bfa4dc0c428132682982e2e3).

###### Close an investigation

From the list of ongoing investigations, you can close an investigation.
You might want to close an investigation if resolved, or if you want to
cancel the investigation.

> **Note**
>
> When you close an investigation, Palo Alto Networks has a grace period
> of 24 hours before deleting any collections associated with the
> investigation. During this timeframe, you have the option to cancel
> the close investigation action.

1.  From the **Forensic Investigations** table, right-click an
    investigation and select **Close**.

2.  In the **Close Investigation** widget, you can view all evidence
    collections exported for the investigation.

3.  In the **Forensic Investigation** table, the status of the
    investigation changes to **Close Pending**, and the timestamp
    displays the time the investigation expires and the investigation
    data is deleted.

4.  Right-click an investigation pending closure to display the
    following options::

    - **Edit**: Update the investigation name, description, or adjust
      user permissions.

    - **Open**: Cancel the close request.

    - **Permanently delete**: Delete the investigation and all
      associated data immediately. This action can\'t be canceled.

###### User permissions

By default, investigation permissions utilize the role-based access
control (RBAC) settings configured in the system. Users must have a role
with the Forensic permissions set to **View** in order to view forensic
investigations. In order to create investigations or collections, a user
must have a role where the Forensics permissions is set to
**View/Edit**. Without either role, a user cannot interact with the
forensics interface.

If Scope-Based Access Control (SBAC) is enabled on your system, from the
**Permissions** table, you can select the users from which to assign
permissions to the investigation.

Users with account administrator or instance administrator roles have
access to investigations and can\'t be cleared from the **Permissions**
table. They can view and edit all Investigations, including
adding/removing users, creating/deleting collections, closing the
Investigation. This prevents investigation lockout in the event of a
user leaving before the Investigation is complete.

> **Note**
>
> Even if a user does not have access to view an investigation via the
> **Forensics Investigations** page, they can still query the results of
> the collections using an XQL query.

The **Permissions** fields describe the following information:

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  User Name                           Name of the user as logged in the
                                      Settings \> Configurations \>
                                      Access Management \> Users.

  Email                               The user\'s email as logged in the
                                      Settings \> Configurations \>
                                      Access Management \> Users.

  User Type                           Indicates whether the user was
                                      defined in Cortex XSIAM using
                                      the CSP (Customer Support
                                      Portal), SSO (single sign-on) using
                                      your organization's IdP, or
                                      both CSP/SSO.

  Role                                Name of the role assigned
                                      specifically to the user that is
                                      not inherited from somewhere else,
                                      such as a User Group. When
                                      the user does not have any Cortex
                                      XSIAM access permissions that are
                                      assigned specifically to them, the
                                      field displays No-Role.

  Permissions                         Options are None, View, View/Edit
  -----------------------------------------------------------------------

##### Data collection

The data collection section includes information related to each
collection type.

###### Hunting

Hunting enables investigators to search for specific data across a large
number of hosts. Hunt collections provide more details about where
something occurred. Hunting examples include finding which endpoints
executed a piece of malware, which users accessed a particular file, or
which endpoints were accessed by a specific user.

####### Create a hunt

Select hunt collections when you want to search for a specific activity
across a large number of hosts. Hunt Collections gather more details
about where something occurred. For example, use a hunt to find which
endpoints executed a piece of malware, which users accessed a particular
file, or which endpoints a specific user authenticated to.

When adding a new hunt collection, you can select from various artifact
types for Windows and macOS.

1.  In the **New Hunt Collection** wizard, in the
    **Hunt Collection Name**, enter a name that will be easy to find in
    the collections table.

2.  Select the **Platform**, Windows or macOS.

3.  Select one of the time range options:

    - **One Time Collection**: Run the hunt collection only once.

    - **Repeat Collection Every**: Run the hunt collection every x hours
      set.

    - **Schedule**: Range of days during the week and time frame.

4.  In **Description** , enter information that is relevant to the
    collection you are creating.

5.  In **Maximum Concurrent Endpoints**, enter the maximum number of
    endpoints that will run the searches at the same time within the
    time range specified. The default is 200 endpoints.

6.  In the **Configuration** page, refer to Configuration for hunt
    collection section for information of each of the artifacts.

> **Note**
>
> You can save hunts in an incomplete state and edit them later. After a
> hunt has run, you cannot edit it. Instead, you can duplicate to create
> a new hunt with the same configuration in order to edit.

######## Configuration for hunt collection

> **Note**
>
> When search fields are specified, the results of the search are
> limited based upon those filters. If more than one entry in a search
> filter field, the search returns entries that match any of the
> provided entries. For example: A **File Search** with two specified
> paths (\"C:\\Test\\\*\" and \"C:\\Windows\\\*\") will return results
> from both the Test folder and the Windows folder.
>
> If you specify multiple search fields, the search returns entries that
> match all the selected criteria. For example: A **File Search** with
> one path (\"C:\\Test\") and one size filter (\"\>= 100MB\") will only
> return results from the Test folder that are greater-than or equal to
> 100 megabytes.
>
> Not all artifacts within an artifact category support the same search
> fields. If an artifact does not support one of the specified fields
> then that filter will not be applied to the search results. For
> example: For Windows, **Process Execution** search with the search
> field for User Name=\"jsmith\", all results from the CidSizeMRU,
> LastVisitedPidlMRU, and UserAssist artifacts will be filtered by that
> user name. Results from the Amcache, Prefetch, and Shimcache artifacts
> will not be filtered by that user name because those artifacts do not
> have a User Name field.

In a hunt collection, you can create a search query adding any of the
following artifacts.

+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| Category              | Default Timeout | Artifacts collected from           | Supported Filters                                                          |
|                       |                 | endpoint(s)                        |                                                                            |
+=======================+=================+====================================+============================================================================+
| **Archive History**   | 60 minutes      | - (Windows)                        | - **File Name**: regular expression (case-insensitive)                     |
| (Windows only)        |                 |   **7-Zip Folder History**: A      |                                                                            |
|                       |                 |   registry key containing a list   | <!-- -->                                                                   |
|                       |                 |   of archive files accessed using  |                                                                            |
|                       |                 |   7-Zip.                           | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **WinRAR ArcHistory**: | <!-- -->                                                                   |
|                       |                 |   A registry key containing a list |                                                                            |
|                       |                 |   of archive files accessed using  | - **File Path**: path (wildcards ? \* \*\* supported)                      |
|                       |                 |   WinRAR.                          |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: C:Windows\\Temp\\\*\*\\\*.exe                                   |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Browser History**   | 60 minutes      | - (Windows, macOS) Chrome          | - **URL**: goog\*.\\.com                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows, macOS) Chromium-Based  | - **History File Path**: path (wildcards ? \* \*\* supported)              |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows, macOS) Firefox         | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) Edge-Anaheim           | - Example:                                                                 |
|                       |                 |                                    |   C:\\Users\\\*\\AppData\\Local\\BraveSoftware\\Brave-Browser\\\*\\History |
|                       |                 | - (Windows) Edge-Spartan           |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) Internet Explorer      |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) Quarantine               |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) Safari                   |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Command History**   | 60 minutes      | - (Windows) **PSReadline**: A      | - **Search Regex**: regular expression (case-insensitive)                  |
|                       |                 |   record of commands typed into a  |                                                                            |
|                       |                 |   PowerShell terminal by user. The | <!-- -->                                                                   |
|                       |                 |   history file is only enabled by  |                                                                            |
|                       |                 |   default, starting with           | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |   Powershell 5 on Windows 10 or    |                                                                            |
|                       |                 |   newer.                           |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Shell History**:       |                                                                            |
|                       |                 |   Commands recorded to             |                                                                            |
|                       |                 |   the history files for Bash and   |                                                                            |
|                       |                 |   Zsh shells.                      |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Deleted Files**     | 180 minutes     | - (Windows) **Recycle Bin**:       | - **File Name**: regular expression (case-insensitive)                     |
| (Windows only)        |                 |   Folder used by Windows as        |                                                                            |
|                       |                 |   temporary storage for deleted    | <!-- -->                                                                   |
|                       |                 |   files prior to permanent         |                                                                            |
|                       |                 |   deletion.                        | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **File Path**: path (wildcards ? \* \*\* supported)                      |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: C:Windows\\Temp\\\*\*\\\*.exe                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **User Search**: User SID or User Name selector.                         |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: ACME\\jsmith                                                    |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **File Access**       | 60 minutes      | - (Windows) **Jumplists**: A       | - **Target File Name**: regular expression (case-insensitive)              |
|                       |                 |   feature of the Windows Task bar  |                                                                            |
|                       |                 |   that provides shortcuts to users | <!-- -->                                                                   |
|                       |                 |   for recently accessed files or   |                                                                            |
|                       |                 |   applications.                    | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **OpenSavePidlMRU**: A | <!-- -->                                                                   |
|                       |                 |   registry key containing a list   |                                                                            |
|                       |                 |   of recently opened and saved     | - **Target File Path**: path (wildcards ? \* \*\* supported)               |
|                       |                 |   files for a user's account.      |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 | - (Windows) **Recent Files**:      |                                                                            |
|                       |                 |   Contents of the shortcut (.lnk)  | - Example: C:Windows\\Temp\\\*\*\\\*.exe                                   |
|                       |                 |   files found in a user\'s Recent  |                                                                            |
|                       |                 |   folder. These files represent    | <!-- -->                                                                   |
|                       |                 |   files recently accessed for a    |                                                                            |
|                       |                 |   user account.                    | - **User Search**: User SID or User Name selector.                         |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **ShellBags**:         | <!-- -->                                                                   |
|                       |                 |   Registry keys that record user   |                                                                            |
|                       |                 |   layout preferences for each      | - Example: ACME\\jsmith                                                    |
|                       |                 |   folder with which the user       |                                                                            |
|                       |                 |   interacts.                       |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **TypedPaths**: A      |                                                                            |
|                       |                 |   registry key containing a list   |                                                                            |
|                       |                 |   of paths that the user typed     |                                                                            |
|                       |                 |   into the Windows Explorer path   |                                                                            |
|                       |                 |   bar.                             |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Recent Documents**:    |                                                                            |
|                       |                 |   Plist files located within a     |                                                                            |
|                       |                 |   user\'s Library directory that   |                                                                            |
|                       |                 |   contain a list of documents      |                                                                            |
|                       |                 |   accessed by that user.           |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **File Search**       | 180 minutes     | - (Windows, macOS)                 | - **File Path**: path (wildcards ? \* \*\* supported)                      |
|                       |                 |   **File Search**: Search for a    |                                                                            |
|                       |                 |   file across endpoints by         | <!-- -->                                                                   |
|                       |                 |   specifying a file path that can  |                                                                            |
|                       |                 |   include wildcards, and then      | - Example: C:Windows\\Temp\\\*\*\\\*.exe                                   |
|                       |                 |   filter those results based on    |                                                                            |
|                       |                 |   the file size, the file name     | <!-- -->                                                                   |
|                       |                 |   (supports regular expressions),  |                                                                            |
|                       |                 |   or file hash (MD5, SHA1, or      | - **File Name**: regular expression (case-insensitive)                     |
|                       |                 |   SHA256).                         |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **File Hash**: Supports MD5, SHA1, and SHA256.                           |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example:                                                                 |
|                       |                 |                                    |   f9d9b9ded9a67aa3cfdbd5002f3b524b265c4086c188e1be7c936ab25627bf01         |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **Size**                                                                 |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: \>= 100 MB                                                      |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Log Search**        | 180 minutes     | - (Windows) **Event Log**: A       | - **Event Log Channel**: Does not support wildcards.                       |
|                       |                 |   component of Microsoft Windows,  |                                                                            |
|                       |                 |   where the user can view record   | <!-- -->                                                                   |
|                       |                 |   of events that occurred within a |                                                                            |
|                       |                 |   system or process.               | - Example: Security                                                        |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Apple Unified Logs**:  | <!-- -->                                                                   |
|                       |                 |   Predicate is a custom filter     |                                                                            |
|                       |                 |   component for Apple Unified      | - **Event ID**:                                                            |
|                       |                 |   Logs.                            |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: 4624                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **Providers**: Does not support wildcards.                               |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: Security                                                        |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **Message**: regular expression (case-insensitive)                       |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **Predicate**: Custom filter component for Apple Unified Logs.           |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: eventType=logEvent AND eventMessage Contains abc                |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Network Data**      | 60 minutes      | - (Windows) **ARP Cache**: A cache | - **IP Address**: IPv4 or IPv6 addresses.                                  |
|                       |                 |   of Address Resolution Protocol   |                                                                            |
|                       |                 |   (ARP) records for resolved MAC   | <!-- -->                                                                   |
|                       |                 |   and IP addresses.                |                                                                            |
|                       |                 |                                    | - Example: 10.0.0.5                                                        |
|                       |                 | - (Windows) **DNS Cache**: A cache |                                                                            |
|                       |                 |   of Domain Name System (DNS)      | <!-- -->                                                                   |
|                       |                 |   records for resolved domains and |                                                                            |
|                       |                 |   IP addresses.                    | - **Domain**: regular expression (case-insensitive)                        |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows.macOS) **Hosts File**:  | <!-- -->                                                                   |
|                       |                 |   Listing of entries from the      |                                                                            |
|                       |                 |   etc/hosts file.                  | - Example: goo.\*\\.com                                                    |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Recent Places**: A     | <!-- -->                                                                   |
|                       |                 |   plist file located within a      |                                                                            |
|                       |                 |   user\'s Library directory that   | - **Path**: path (wildcards ? \* \*\* supported)                           |
|                       |                 |   contains a list of recently      |                                                                            |
|                       |                 |   accessed servers and hosts.      | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: /Volumes/VMware\*                                               |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **User Search**: User SID or User Name selector.                         |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: ACME\\jsmith                                                    |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Persistence**       | 60 minutes      | - (Windows) **Drivers**: Windows   | - **Registry Path**: path (wildcards ? \* \*\* supported)                  |
|                       |                 |   device drivers installed on each |                                                                            |
|                       |                 |   endpoint.                        | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows)                        | - Example:                                                                 |
|                       |                 |   **Registry Persistence**: A      |   HKEY_USERS\\\*\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\\*    |
|                       |                 |   collection of registry keys that |                                                                            |
|                       |                 |   can be used for malware          | <!-- -->                                                                   |
|                       |                 |   persistence.                     |                                                                            |
|                       |                 |                                    | - **Executable Path**: path (wildcards ? \* \*\* supported)                |
|                       |                 | - (Windows) **Scheduled Tasks**:   |                                                                            |
|                       |                 |   Tasks used to execute Windows    | <!-- -->                                                                   |
|                       |                 |   programs or scripts at specified |                                                                            |
|                       |                 |   intervals.                       | - Example: C:Windows\\Temp\\\*\*\\test.exe                                 |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **Services**: Windows  | <!-- -->                                                                   |
|                       |                 |   applications that run in the     |                                                                            |
|                       |                 |   background and do not require    | - **User Search**: User SID or User Name selector.                         |
|                       |                 |   user interaction.                |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 | - (Windows) **Shim Databases**:    |                                                                            |
|                       |                 |   Databases used by the            | - Example: ACME\\jsmith                                                    |
|                       |                 |   Application Compatibility        |                                                                            |
|                       |                 |   Infrastructure to apply shims to | <!-- -->                                                                   |
|                       |                 |   executables for backwards        |                                                                            |
|                       |                 |   compatibility. These databases   | - **SHA256**: Supports SHA256 hashes.                                      |
|                       |                 |   can be used to inject malicious  |                                                                            |
|                       |                 |   code into legitimate processes   | <!-- -->                                                                   |
|                       |                 |   and maintain persistence on an   |                                                                            |
|                       |                 |   endpoint.                        | - Example:                                                                 |
|                       |                 |                                    |   f9d9b9ded9a67aa3cfdbd5002f3b524b265c4086c188e1be7c936ab25627bf01         |
|                       |                 | - (Windows) **Startup Folder**:    |                                                                            |
|                       |                 |   Contents of the                  | <!-- -->                                                                   |
|                       |                 |   shortcut .lnk files found in the |                                                                            |
|                       |                 |   Startup folder for both the      | - **Command**: regular expression (case-insensitive)                       |
|                       |                 |   system and users. The folders    |                                                                            |
|                       |                 |   are used to automatically launch | <!-- -->                                                                   |
|                       |                 |   applications during system       |                                                                            |
|                       |                 |   startup or user logon processes. | - Example: /bin/sh /private/etc/periodic/weekly/.\*                        |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **WMI Persistence**:   |                                                                            |
|                       |                 |   List of WMI EventConsumers and   |                                                                            |
|                       |                 |   any EventFilters that are bound  |                                                                            |
|                       |                 |   to them using a                  |                                                                            |
|                       |                 |   FilterToConsumerBinding. WMI     |                                                                            |
|                       |                 |   EventConsumers can be used as a  |                                                                            |
|                       |                 |   method of fileless malware       |                                                                            |
|                       |                 |   persistence.                     |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Cron**: A system       |                                                                            |
|                       |                 |   utility that executes programs   |                                                                            |
|                       |                 |   or scripts at specified          |                                                                            |
|                       |                 |   intervals.                       |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Launchd**: Listing of  |                                                                            |
|                       |                 |   applications and daemons         |                                                                            |
|                       |                 |   configured to launch using the   |                                                                            |
|                       |                 |   launchd process.                 |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Login Items**: Plist   |                                                                            |
|                       |                 |   files containing applications,   |                                                                            |
|                       |                 |   files, or folders configured to  |                                                                            |
|                       |                 |   launch during user login.        |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Process Execution** | 60 minutes      | - (Windows) **Amcache**: A         | - **Executable File Name**: regular expression (case-insensitive)          |
|                       |                 |   registry hive used by the        |                                                                            |
|                       |                 |   Application Compatibility        | <!-- -->                                                                   |
|                       |                 |   Infrastructure to cache the      |                                                                            |
|                       |                 |   details of executed or installed | - Example: \[0-9A-F\]{8}\\.exe                                             |
|                       |                 |   programs.                        |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **Background Activity Monitor**: | - **Executable Path**: path (wildcards ? \* \*\* supported)                |
|                       |                 |   Per-user registry keys created   |                                                                            |
|                       |                 |   by Background Activity Monitor   | <!-- -->                                                                   |
|                       |                 |   (BAM) service to store the full  |                                                                            |
|                       |                 |   paths of executable files and a  | - Example: C:Windows\\Temp\\\*\*\\test.exe                                 |
|                       |                 |   timestamp, indicating when they  |                                                                            |
|                       |                 |   were last executed.              | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **CidSizeMRU**: A      | - **User Search**: User SID or User Name selector.                         |
|                       |                 |   registry key containing a list   |                                                                            |
|                       |                 |   of recently launched             | <!-- -->                                                                   |
|                       |                 |   applications.                    |                                                                            |
|                       |                 |                                    | - Example: ACME\\jsmith                                                    |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **LastVisitedPidlMRU**: A        | <!-- -->                                                                   |
|                       |                 |   registry key containing a list   |                                                                            |
|                       |                 |   of the applications and folder   | - **SHA256**: Supports SHA256 hashes.                                      |
|                       |                 |   paths associated with recently   |                                                                            |
|                       |                 |   opened files found in the user's | <!-- -->                                                                   |
|                       |                 |   OpenSavePidMRU key.              |                                                                            |
|                       |                 |                                    | - Example:                                                                 |
|                       |                 | - (Windows) **Prefetch**: A type   |   f9d9b9ded9a67aa3cfdbd5002f3b524b265c4086c188e1be7c936ab25627bf01         |
|                       |                 |   of file created to optimize      |                                                                            |
|                       |                 |   application startup in Windows.  |                                                                            |
|                       |                 |   These files contains a run count |                                                                            |
|                       |                 |   for each application, between    |                                                                            |
|                       |                 |   one and eight timestamps of the  |                                                                            |
|                       |                 |   most recent executions, and a    |                                                                            |
|                       |                 |   record of all of the files       |                                                                            |
|                       |                 |   opened for a set duration after  |                                                                            |
|                       |                 |   the application was started.     |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **Recentfilecache**: A |                                                                            |
|                       |                 |   cache created by the Application |                                                                            |
|                       |                 |   Compatibility Infrastructure to  |                                                                            |
|                       |                 |   store the details of executed or |                                                                            |
|                       |                 |   installed programs (Windows 7    |                                                                            |
|                       |                 |   only).                           |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **Shimcache**: A       |                                                                            |
|                       |                 |   registry key used by the         |                                                                            |
|                       |                 |   Application Compatibility        |                                                                            |
|                       |                 |   Infrastructure to cache details  |                                                                            |
|                       |                 |   about local executables.         |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **UserAssist**: A      |                                                                            |
|                       |                 |   registry value that records a    |                                                                            |
|                       |                 |   count for each application that  |                                                                            |
|                       |                 |   a user launches via the Windows  |                                                                            |
|                       |                 |   UI.                              |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **Windows Activities**: A        |                                                                            |
|                       |                 |   database containing user         |                                                                            |
|                       |                 |   activity for a particular        |                                                                            |
|                       |                 |   Microsoft user account,          |                                                                            |
|                       |                 |   potentially across multiple      |                                                                            |
|                       |                 |   devices. This is also called the |                                                                            |
|                       |                 |   Windows Timeline.                |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **CoreAnalytics**: A     |                                                                            |
|                       |                 |   diagnostic log that contains     |                                                                            |
|                       |                 |   details of files executed on the |                                                                            |
|                       |                 |   system.                          |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (macOS) **Recent Applications**: |                                                                            |
|                       |                 |   A plist file located within a    |                                                                            |
|                       |                 |   user\'s Library directory that   |                                                                            |
|                       |                 |   contains a list of applications  |                                                                            |
|                       |                 |   opened by that user.             |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Registry Search**   | 180 minutes     | - (Windows) **Registry Search**:   | - **Path**: path (wildcards ? \* \*\* supported)                           |
| (Windows only)        |                 |   Registry listings collected      |                                                                            |
|                       |                 |   during Forensic investigation.   | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example:                                                                 |
|                       |                 |                                    |   HKEY_USERS\\\*\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\\*    |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - **Data**: regular expression (case-insensitive)                          |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 |                                    | - Example: \[0-9A-F\]{8}\\.exe                                             |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **Remote Access**     | 60 minutes      | - (Windows)                        | - **IP Address**: IPv4 or IPv6 addresses                                   |
| (Windows only)        |                 |   **AnyDesk Connection Logs**:     |                                                                            |
|                       |                 |   Records of activity found in the | <!-- -->                                                                   |
|                       |                 |   AnyDesk connection logs.         |                                                                            |
|                       |                 |                                    | - Example: 10.0.0.5                                                        |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **AnyDesk Trace Logs**: Records  | <!-- -->                                                                   |
|                       |                 |   of activity found in the AnyDesk |                                                                            |
|                       |                 |   trace logs.                      | - **User Search**: User SID or User Name selector.                         |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **LogMein**: Records   | <!-- -->                                                                   |
|                       |                 |   of activity found in the LogMeIn |                                                                            |
|                       |                 |   event logs.                      | - Example: ACME\\jsmith                                                    |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows) **TeamViewer**:        |                                                                            |
|                       |                 |   Records of incoming TeamViewer   |                                                                            |
|                       |                 |   connections found in the         |                                                                            |
|                       |                 |   Connections_incoming.txt file.   |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **User Access Logging**: A       |                                                                            |
|                       |                 |   Windows Server feature that      |                                                                            |
|                       |                 |   records details about client     |                                                                            |
|                       |                 |   access to the server. Only found |                                                                            |
|                       |                 |   on Windows Server 2012 and       |                                                                            |
|                       |                 |   newer.                           |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **System Statistics** | 60 - 120        | - (Windows)                        | - **Application**: path (wildcards ? \* \*\* supported)                    |
| (Windows only)        | minutes         |   **Application Resource Usage**:  |                                                                            |
|                       |                 |   A table in the System Resource   | <!-- -->                                                                   |
|                       |                 |   Usage database that stores       |                                                                            |
|                       |                 |   statistics pertaining to         | - Example: C:Windows\\Temp\\\*\*\\test.exe                                 |
|                       |                 |   resource usage by running        |                                                                            |
|                       |                 |   applications.                    | <!-- -->                                                                   |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows)                        | - **User Search**: User SID or User Name selector.                         |
|                       |                 |   **Network Connectivity Usage**:  |                                                                            |
|                       |                 |   A table in the System Resource   | <!-- -->                                                                   |
|                       |                 |   Usage database that stores       |                                                                            |
|                       |                 |   statistics pertaining to network | - Example: ACME\\jsmith                                                    |
|                       |                 |   connections, containing the      |                                                                            |
|                       |                 |   start time and duration of the   |                                                                            |
|                       |                 |   connections for each network     |                                                                            |
|                       |                 |   interface.                       |                                                                            |
|                       |                 |                                    |                                                                            |
|                       |                 | - (Windows)                        |                                                                            |
|                       |                 |   **Network Data Usage**: A table  |                                                                            |
|                       |                 |   in the System Resource Usage     |                                                                            |
|                       |                 |   database that stores statistics  |                                                                            |
|                       |                 |   pertaining to network data usage |                                                                            |
|                       |                 |   for running applications.        |                                                                            |
|                       |                 |   Includes application path,       |                                                                            |
|                       |                 |   network interface, bytes sent,   |                                                                            |
|                       |                 |   and bytes received.              |                                                                            |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+
| **User Searches**     | 60 minutes      | - (Windows) **WordWheelQuery**:    | - **User Search**: User SID or User Name selector.                         |
|                       |                 |   Registry key containing a list   |                                                                            |
|                       |                 |   of terms that a user searched    | <!-- -->                                                                   |
|                       |                 |   for in Windows Explorer.         |                                                                            |
|                       |                 |                                    | - Example: PANW\\jsmith                                                    |
|                       |                 | - (macOS)                          |                                                                            |
|                       |                 |   **Spotlights Shortcuts**: A      | <!-- -->                                                                   |
|                       |                 |   plist file that contains the     |                                                                            |
|                       |                 |   Spotlight search terms entered   | - **Search Regex**: regular expression (case-insensitive)                  |
|                       |                 |   by each user and the items that  |                                                                            |
|                       |                 |   they selected from the search    | <!-- -->                                                                   |
|                       |                 |   results.                         |                                                                            |
|                       |                 |                                    | - Example: \[0-9A-F\]{8}\\.exe                                             |
+-----------------------+-----------------+------------------------------------+----------------------------------------------------------------------------+

####### Hunt results

The hunt results page consolidates information collected by the Cortex
XDR agent enabling you to investigate and take action on your endpoints.

######## Review process execution search results

The **Process Execution** table displays a normalized table containing
an overview of all of the different process execution artifacts
collected from the endpoints. Investigate the following detailed fields:

> **Note**
>
> The grouping button
> (![](media/rId2733.png){width="0.11458333333333333in"
> height="0.20833333333333334in"}) shows the number of affected
> endpoints grouped by executable name. This enables you to perform
> hunting via frequency analysis (referred to as stacking) and provides
> a birds eye view of potential malware files that require further
> analysis.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Context                           | Contextual details relating to    |
|                                   | the executed process such as      |
|                                   | files opened, command line        |
|                                   | arguments, or process run count.  |
+-----------------------------------+-----------------------------------+
| Executable Name                   | Name of the executable.           |
+-----------------------------------+-----------------------------------+
| Executable Path                   | Path of the executable.           |
+-----------------------------------+-----------------------------------+
| Hostname                          | Name of the host on which the     |
|                                   | process resided.                  |
+-----------------------------------+-----------------------------------+
| MDS                               | MDS value of the executable file, |
|                                   | if available on the file system.  |
+-----------------------------------+-----------------------------------+
| SHA1                              | SHA1 value of the executable      |
|                                   | file, if available on the file    |
|                                   | system.                           |
+-----------------------------------+-----------------------------------+
| SHA256                            | SHA256 value of the executable    |
|                                   | file, if available on the file    |
|                                   | system.                           |
+-----------------------------------+-----------------------------------+
| Timestamp                         | Timestamp associated with the     |
|                                   | executable file or process        |
|                                   | execution.                        |
+-----------------------------------+-----------------------------------+
| Type                              | Type of process artifact.         |
+-----------------------------------+-----------------------------------+
| User                              | User name associated with the     |
|                                   | execution artifact.               |
+-----------------------------------+-----------------------------------+
| Verdict                           | WildFire verdict for the          |
|                                   | following process execution       |
|                                   | artifacts.                        |
|                                   |                                   |
|                                   | - Prefetch                        |
|                                   |                                   |
|                                   | - Recentfilecache                 |
|                                   |                                   |
|                                   | - Shimcache                       |
|                                   |                                   |
|                                   | - UserAssist                      |
|                                   |                                   |
|                                   | If there is a WildFire verdict,   |
|                                   | the relevant **Verdict** is       |
|                                   | displayed.                        |
|                                   |                                   |
|                                   | - Unknown                         |
|                                   |                                   |
|                                   | - Benign                          |
|                                   |                                   |
|                                   | - Malware                         |
|                                   |                                   |
|                                   | - Grayware                        |
|                                   |                                   |
|                                   | Also, a link to the WildFire      |
|                                   | analysis report is available for  |
|                                   | review.                           |
+-----------------------------------+-----------------------------------+

######## Review file access

The **File Access** table displays a normalized table containing an
overview of all of the different file access artifacts collected from
the endpoints. Investigate the following detailed fields:

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  Hostname                            Name of the host on where the file
                                      access artifact resided.

  Path                                Path of the accessed file or
                                      folder.

  Timestamp                           Timestamp associated with the
                                      accessed file or folder.

  Type                                Type of file access artifact.

  User                                User name of who accessed the file
                                      or folder, if available.
  -----------------------------------------------------------------------

######## Review persistence search results

The **Persistence** table displays a normalized table containing an
overview of all of the application persistence artifacts collected from
the endpoints. Investigate the following detailed fields:

> **Note**
>
> The grouping button
> (![](media/rId2733.png){width="0.11458333333333333in"
> height="0.20833333333333334in"}) shows the number of affected
> endpoints grouped by file path. This enables you to perform hunting
> via frequency analysis (referred to as stacking) and provides a birds
> eye view of potential malware files that require further analysis.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Command                           | Command to be executed.           |
+-----------------------------------+-----------------------------------+
| Endpoint ID                       | Unique identifier of the endpoint |
|                                   | on which the persistence          |
|                                   | mechanism resides.                |
+-----------------------------------+-----------------------------------+
| File Path                         | Path of a secondary executable    |
|                                   | (often a dll) associated with     |
|                                   | this persistence mechanism.       |
+-----------------------------------+-----------------------------------+
| File SHA256                       | SHA256 value of the file.         |
+-----------------------------------+-----------------------------------+
| Hostname                          | Name of the host on which the     |
|                                   | persistence mechanism resides.    |
+-----------------------------------+-----------------------------------+
| Image Path                        | Path of the executable associated |
|                                   | with this persistence mechanism.  |
+-----------------------------------+-----------------------------------+
| Name                              | Name associated with persistence  |
|                                   | mechanism, if available.          |
+-----------------------------------+-----------------------------------+
| Registry Path                     | Path of the registry value.       |
+-----------------------------------+-----------------------------------+
| Timestamp                         | Timestamp associated with the     |
|                                   | persistence mechanism.            |
+-----------------------------------+-----------------------------------+
| Type                              | Type of persistence mechanism.    |
+-----------------------------------+-----------------------------------+
| User                              | User account associated with      |
|                                   | persistence mechanism.            |
+-----------------------------------+-----------------------------------+
| User SID                          | User account associated with      |
|                                   | persistence mechanism.            |
+-----------------------------------+-----------------------------------+
| Verdict                           | WildFire verdict for the          |
|                                   | following persistence artifacts.  |
|                                   |                                   |
|                                   | - Drivers                         |
|                                   |                                   |
|                                   | - Registry                        |
|                                   |                                   |
|                                   | - Scheduled Tasks                 |
|                                   |                                   |
|                                   | - Services                        |
|                                   |                                   |
|                                   | - Startup Folder                  |
|                                   |                                   |
|                                   | If there is a WildFire verdict,   |
|                                   | the relevant **Verdict** is       |
|                                   | displayed.                        |
|                                   |                                   |
|                                   | - Unknown                         |
|                                   |                                   |
|                                   | - Benign                          |
|                                   |                                   |
|                                   | - Malware                         |
|                                   |                                   |
|                                   | - Grayware                        |
|                                   |                                   |
|                                   | Also, a link to the WildFire      |
|                                   | analysis report is available for  |
|                                   | review.                           |
+-----------------------------------+-----------------------------------+

######## Review network data search results

The **Network** table displays an overview of the different types of
network artifacts collected on the endpoints. Investigate the following
detailed fields:

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  Hostname                            Name of the host on which the
                                      network activity occurred.

  Interface                           Type of network interface.

  IP Address                          IP address associated with network
                                      activity.

  Resolution                          Network data type associated with
                                      the IP address.

  Type                                Type of network artifact.
  -----------------------------------------------------------------------

######## Review remote access search results

The **Remote Access** table displays a normalized table containing an
overview of all of the remote access artifacts collected from the
endpoints. Investigate the following detailed fields:

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  Connection ID                       Unique Identifier associated with
                                      the particular remote access
                                      connection found in this row.

  Connection Type                     Type of remote access connection.

  Duration                            Duration of remote access
                                      connection.

  Endpoint ID                         A unique ID assigned by Cortex XDR
                                      that identifies the endpoint.

  Hostname                            Name of the host on which the
                                      remote access occurred.

  Message                             Description of activity related to
                                      this remote access collection.

  Source Host                         Origination host of remote access
                                      connection.

  Timestamp                           Date and time of the remote access
                                      activity.

  Type                                Type of remote access artifact.

  User                                User account associated with remote
                                      access connection.
  -----------------------------------------------------------------------

######## Review archive history search results

The **Archive History** table displays an overview of the different
types of archive processes that were executed on an endpoint.
Investigate the following detailed fields:

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Hostname                          | Name of the host on which the     |
|                                   | archive history was found.        |
+-----------------------------------+-----------------------------------+
| Timestamp                         | Timestamp associated with archive |
|                                   | history file.                     |
+-----------------------------------+-----------------------------------+
| Type                              | Type of archive history artifact. |
|                                   |                                   |
|                                   | - 7-Zip Folder History            |
|                                   |                                   |
|                                   | - WinRAR ArcHistory               |
+-----------------------------------+-----------------------------------+
| Path                              | Path of archive history file.     |
+-----------------------------------+-----------------------------------+
| User                              | User account associated with      |
|                                   | archive history file.             |
+-----------------------------------+-----------------------------------+

####### Hunt status

Hunts consist of searches across multiple endpoints and those searches
can take time to return results from all of the targeted endpoints. To
view the status of all of the searches contained within a hunt, go to
Investigation & Response \> Forensics. From the investigations table,
click the investigation link. From the **Collections** tab, select
**Hunt** and from the **Status** column of the hunt, click **Actions**.
This launches a new browser tab displaying the **Actions** table. Within
the **Actions** table, you can scroll or use the filters to see the
status of any search within a hunt across any of the targeted endpoints.

Using this information, you can identify the successful and failed
searches and take the necessary action.

+-----------------------------------+--------------------------------------+
| Field                             | Description                          |
+===================================+======================================+
| Endpoint name                     | Agent hostname.                      |
+-----------------------------------+--------------------------------------+
| Endpoint ID                       | Agent unique ID.                     |
+-----------------------------------+--------------------------------------+
| Action ID                         | A unique identifier for the agent    |
|                                   | action.                              |
+-----------------------------------+--------------------------------------+
| Name                              | Name of search.                      |
+-----------------------------------+--------------------------------------+
| Status                            | Shows one of the following statuses  |
|                                   | of the search:                       |
|                                   |                                      |
|                                   | - Pending                            |
|                                   |                                      |
|                                   | - In progress                        |
|                                   |                                      |
|                                   | - Completed successfully             |
|                                   |                                      |
|                                   | - Failed                             |
|                                   |                                      |
|                                   | - Timeout                            |
+-----------------------------------+--------------------------------------+
| Artifact category                 | Name of category for the search.     |
|                                   |                                      |
|                                   | Example: `Process execution`         |
+-----------------------------------+--------------------------------------+
| Artifact                          | Artifact targeted by this search.    |
|                                   |                                      |
|                                   | Example: `Amcache`                   |
+-----------------------------------+--------------------------------------+
| Results                           | Number of results received for the   |
|                                   | search.                              |
+-----------------------------------+--------------------------------------+
| Last updated                      | Latest time results were received    |
|                                   | for this action.                     |
+-----------------------------------+--------------------------------------+
| Parameters                        | The string that describes the search |
|                                   | parameters.                          |
|                                   |                                      |
|                                   | Example:                             |
|                                   | `C:\Users\* File Name Regex: *\.exe` |
+-----------------------------------+--------------------------------------+
| Creation time                     | Timestamp when the search was        |
|                                   | created.                             |
+-----------------------------------+--------------------------------------+

###### Triage

Triage enables you to do a in-depth analysis of a specific endpoint to
fully understand the activities that occurred on that endpoint. The
triage functionality is configurable and supports the collection of all
currently supported forensic artifacts, user-defined file paths, a full
file listing for all of the connected drives, full event logs, and
registry hives. The amount of data collected during a triage can be
large, so triages are limited to ten or fewer endpoints per collection.

####### Create a triage

Use triage collections when a certain activity, group of activities, or
the actions of a specific user on that endpoint have been identified,
and additional information is required. The triage functionality
collects detailed system information, including a full file listing for
all of the connected drives, full event logs, and registry hives, to
provide you with a complete, holistic picture of an endpoint.

Triage supports data collection from both online and offline hosts, on
both Windows and macOS platforms.

1.  In the **Triage Collection Name** field, enter a name that will be
    easy to find in the collections table.

2.  Select the **Platform** either Windows or macOS.

3.  In the **Description** field, enter information that is relevant to
    the collection you are creating .

4.  For **Triage Type**, you can select **Offline** or **Online** or
    both.

5.  Select **Offline** to upload archives containing forensic data
    collected by the Offline Collector. After the archive has been
    uploaded, the data is extracted and ingested into the Forensics
    tables on the tenant. Import Offline Triage supports uploading
    packages created on both the Windows and macOS platforms.

6.  Click **Save Collection and Exit** or click **Next** to continue.

7.  In the configuration page, select the options from the
    **Artifacts**, **Volatiles** and **File Collection** list.

- You can click **Add Custom** to add your own file to the File
  Collections.

8.  You can select a preset from **Select Presets (Windows/macOS)** to
    copy the options of artifacts, volatiles and file collections from
    another collection.

- You can also click **Save new preset** to save the options of the
  current collection for prospective triage collections to use.

9.  Click **Save Collection and Exit** or click **Next** to continue.

####### Upload an offline triage package

The Forensics Triage feature enables you to create a custom, standalone
executable package that collects all of the forensic artifacts in the
configuration.

Use the **Upload Offline Triage** to upload archives containing forensic
data collected by the offline collector. After the archive has been
uploaded, the data is extracted and ingested into the forensics table on
the tenant. **Upload Offline Triage** supports uploading packages
created on both the Windows and macOS platforms..

1.  In Cortex XSIAM, select Investigation & Response \> Forensics.

2.  Click the link of the relevant investigation.

3.  When in the **Collections** page, search for or select the triage
    and click the menu options button
    (![](media/rId2748.png){width="0.1425437445319335in"
    height="0.20833333333333334in"}) to select
    **Upload Offline Package**.

4.  Drag and drop or use the **browse** link to search for the file.
    More than one offline triage package can be uploaded at a time.

- > **Note**

  > Do not upload memory images captured by the Offline Triage
  > Collector. These images are collected for analysis using third-party
  > tools and are not intended for upload.

5.  Click **Done**.

####### Offline triage collection

The Forensics add-on provides a triage collection option for endpoints
with no network connection or no Cortex XDR agent currently installed.

Note that the procedure is different for Windows and macOS.

######## Windows

1.  Select Investigation & Response \> Forensics.

2.  Click the investigation link and from the **Collections** tab, find
    the triage and click the menu options button
    (![](media/rId2748.png){width="0.1425437445319335in"
    height="0.20833333333333334in"})/ Depending on the system type of
    the endpoint, select **Download 32-bit Collector** or
    **Download 64-bit Collector** .

3.  Copy the downloaded file to a destination of which is accessible
    from the targeted endpoint.

4.  From the endpoint, open the folder containing the offline triage
    collector and right-click on the executable file
    **cortex-xdr-payload.exe** and select `Run as administrator`.

- The `cortex-xdr-payload.exe` opens a command window that displays the
  status of each artifact collection.

  After the collection is completed, a zip file with the hostname and a
  timestamp in the file name is created in the same directory as the
  executable.

5.  From the the **Collections** page, select the triage and click the
    menu options button
    (![](media/rId2748.png){width="0.1425437445319335in"
    height="0.20833333333333334in"}) and select
    **Upload Offline Package**.

6.  In the **Import Offline Triage** dialog, browse for or drag and drop
    the zip file and click **Done**.

- The triage file is ingested and the results are available for review.

  > **Note**

  > Security software running on the endpoint (including the Cortex
  > agent) can interfere or block the execution of the offline triage
  > collector. Disable any security software on the endpoint while the
  > collector is running or whitelist the collector in your security
  > software before running the offline triage collector.

######## macOS

1.  Select Investigation & Response \> Forensics.

2.  Click the investigation link and from the **Collections** tab, find
    the triage and click the menu options button
    (![](media/rId2748.png){width="0.1425437445319335in"
    height="0.20833333333333334in"}) and select **Download Collector**.

3.  Open the folder containing the zip file and run the command
    `xattr -c &lt;triage_configuration_name&gt;.zip`, to remove any
    extended attributes that macOS might have applied to the file.

4.  Copy the downloaded zip file to a destination of which is accessible
    from the targeted endpoint.

5.  From the endpoint, open the folder containing the offline triage
    collector and run the **cortex-xdr-payload.exe** file or from a
    command line, enter: `sudo cortex-xdr-payload`.

- After the collection is completed, a zip file with the hostname and a
  timestamp in the file name is created in the same directory as the
  executable.

6.  From the the **Collections** page, select the triage and click the
    menu options button
    (![](media/rId2748.png){width="0.1425437445319335in"
    height="0.20833333333333334in"}) and select
    **Upload Offline Package**.

7.  In the **Import Offline Triage** dialog, browse for or drag and drop
    the zip file and click **Done**.

- The triage file is ingested and the results are available for review.

  > **Note**

  > Security software running on the endpoint (including the Cortex
  > agent) can interfere or block the execution of the offline triage
  > collector. Disable any security software on the endpoint while the
  > collector is running or whitelist the collector in your security
  > software before running the offline triage collector.

####### Triage results

The Triage collection results page displays an overview of the different
types of triage collections that were initiated on an endpoint.

The triage results page is divided by the following tabs:

- **Alerts**: Refer to
  [Alerts](/document/preview/1159310#UUID-85658ca7-db59-1eae-4647-094b080003e1)
  for descriptions of the fields.

- **Artifacts**: Display all of the artifact categories collected. You
  can select the item to add to a timeline.

- **Host Timeline**: Displays a list of normalized, per-host timelines
  that include multiple forensic artifacts in a single table.

####### Triage status

You can drill down to the **Actions** table from the status link of the
triage to view the search the status of all the artifacts for the
triage.

+-----------------------------------+----------------------------------------+
| Field                             | Description                            |
+===================================+========================================+
| Endpoint name                     | Agent hostname.                        |
+-----------------------------------+----------------------------------------+
| Endpoint ID                       | Agent unique ID.                       |
+-----------------------------------+----------------------------------------+
| Action ID                         | Unique identifier for this agent       |
|                                   | action.                                |
+-----------------------------------+----------------------------------------+
| Type                              | Type of collection.                    |
|                                   |                                        |
|                                   | Example:                               |
|                                   | `Amcache, File Collection, Event Logs` |
+-----------------------------------+----------------------------------------+
| Path                              | Path for files, registry path for      |
|                                   | registry artifacts.                    |
+-----------------------------------+----------------------------------------+
| Status                            | Displays one of the following statuses |
|                                   | of the search:                         |
|                                   |                                        |
|                                   | - Pending: agent action sent           |
|                                   |                                        |
|                                   | - In progress: SAM not sent            |
|                                   |                                        |
|                                   | - Results received: received SAM       |
|                                   |   results                              |
|                                   |                                        |
|                                   | - Timeout: SAM timed out               |
|                                   |                                        |
|                                   | - Ingesting: Ingestion started         |
|                                   |                                        |
|                                   | - Uploaded: data received, but not     |
|                                   |   parsed                               |
|                                   |                                        |
|                                   | - Ingested: ingestion completed        |
|                                   |                                        |
|                                   | - Partially ingested: ingested with    |
|                                   |   errors                               |
|                                   |                                        |
|                                   | - Failed: ingestion failed             |
+-----------------------------------+----------------------------------------+
| Details                           | Shows the detailed output from the     |
|                                   | ingestion script.                      |
|                                   |                                        |
|                                   | Example: `Ingested X of Y records`     |
+-----------------------------------+----------------------------------------+
| Collected                         | Time the data was collected.           |
+-----------------------------------+----------------------------------------+
| Download expiration               | Time when bucket data (raw files) is   |
|                                   | to be deleted.                         |
+-----------------------------------+----------------------------------------+
| Preset                            | Name of the triage configuration.      |
+-----------------------------------+----------------------------------------+
| Collection Type                   | Collection type.                       |
+-----------------------------------+----------------------------------------+
| Triage ID                         | Unique ID associated with this triage  |
|                                   | data.                                  |
+-----------------------------------+----------------------------------------+

##### Analysis and documentation

Forensic investigations include additional data for analysis and
documentation purposes.

- Alerts

- Forensics Timeline

- Key Assets & Artifacts

###### Review alerts

The alerts table displays all the collections within the investigation
that has identified suspicious or malicious activity within the
forensics data sets.

Refer to
[Alerts](/document/preview/1159310#UUID-85658ca7-db59-1eae-4647-094b080003e1)
for the descriptions of the table fields.

The following actions are available for a selected alert.

- Change status

- Change severity

- Investigate causality chain

- Run playbook

- Manage alerts

###### Investigation timeline

The Timeline page enables you to view the list of forensic artifacts
that were tagged. The tags display details of the forensic data
collected from the endpoints.

The **Timeline** table displays the following fields:

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Hostname                          | Name of the host machine.         |
+-----------------------------------+-----------------------------------+
| Timestamp                         | Timestamp associated with the     |
|                                   | artifact.                         |
+-----------------------------------+-----------------------------------+
| Type                              | Forensic artifact of which a tag  |
|                                   | was added.                        |
+-----------------------------------+-----------------------------------+
| Description                       | Name of the timestamp field.      |
+-----------------------------------+-----------------------------------+
| Tags                              | There are three default tags to   |
|                                   | choose from.                      |
|                                   |                                   |
|                                   | - legitimate                      |
|                                   |                                   |
|                                   | - malicious                       |
|                                   |                                   |
|                                   | - suspicious                      |
|                                   |                                   |
|                                   | You can also create your own      |
|                                   | tags.                             |
+-----------------------------------+-----------------------------------+
| User                              | User account associated with the  |
|                                   | forensic artifact.                |
+-----------------------------------+-----------------------------------+
| Data                              | Data summary for the tagged item. |
+-----------------------------------+-----------------------------------+
| Mitre Att&ck Tactic               | Displays the type of MITRE ATT&CK |
|                                   | tactic of the tagged item.        |
+-----------------------------------+-----------------------------------+
| Mitre Att&ck Technique            | Displays the type of MITRE ATT&CK |
|                                   | technique of the tagged item.     |
+-----------------------------------+-----------------------------------+
| Notes                             | Displays notes entered by the     |
|                                   | user.                             |
+-----------------------------------+-----------------------------------+

1.  Edit a timeline entry:

- You can edit a tag of an artifact in the **Timeline** table.

  a.  Locate the relevant item to update the tag.

  b.  Right-click and select **Edit timeline entry**.

  c.  In **Edit timeline entry**, update the information as required and
      then click **Save** to update the changes.

2.  Clear a timeline entry:

- You can remove a tag from the artifact in the **Timeline** table.

  a.  Locate the relevant item to remove the tag.

  b.  Right-click and select **Clear timeline entry**. The tag is
      removed from the artifact and the row is removed from the
      **Timeline** table.

###### Key assets & artifacts

Key assets & artifacts are automatically created based on the tagged
data from the investigation timeline of the investigation and dividing
them among the categories:

- **Data Access**: Displays all the items that have been tagged in the
  File Access tables.

The following table for **Endpoints** displays the endpoints that have
at least one or more items tagged:

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Endpoint Name                     | Name of the endpoint.             |
+-----------------------------------+-----------------------------------+
| Endpoint Type                     | Displays the endpoint type:       |
|                                   |                                   |
|                                   | - Mobile                          |
|                                   |                                   |
|                                   | - Server                          |
|                                   |                                   |
|                                   | - Workstation                     |
|                                   |                                   |
|                                   | - Kubernetes Node                 |
+-----------------------------------+-----------------------------------+
| Endpoint Status                   | Displays the status of the        |
|                                   | endpoint:                         |
|                                   |                                   |
|                                   | - Connected                       |
|                                   |                                   |
|                                   | - Connected Lost                  |
|                                   |                                   |
|                                   | - Deleted                         |
|                                   |                                   |
|                                   | - Disconnected                    |
|                                   |                                   |
|                                   | - Uninstalled                     |
|                                   |                                   |
|                                   | - VDI Pending Login               |
|                                   |                                   |
|                                   | - Forensics Offline               |
|                                   |                                   |
|                                   | - Partial Registration            |
+-----------------------------------+-----------------------------------+
| Earliest Activity                 | Timestamp of the earliest tagged  |
|                                   | item in the incident timeline for |
|                                   | the endpoint.                     |
+-----------------------------------+-----------------------------------+
| Latest Activity                   | Timestamp of the last tagged item |
|                                   | in the incident timeline for the  |
|                                   | endpoint.                         |
+-----------------------------------+-----------------------------------+
| IP Address                        | List of associated IP addresses.  |
+-----------------------------------+-----------------------------------+
| IPv6 Address                      | List of associated IPv6           |
|                                   | addresses.                        |
+-----------------------------------+-----------------------------------+
| First Seen                        | Timestamp of first seen.          |
+-----------------------------------+-----------------------------------+
| Last Seen                         | Timestamp of last seen.           |
+-----------------------------------+-----------------------------------+
| Endpoint Isolated                 | Displays the status of endpoint   |
|                                   | isolation:                        |
|                                   |                                   |
|                                   | - Pending Isolation Cancellation  |
|                                   |                                   |
|                                   | - Pending Isolation               |
|                                   |                                   |
|                                   | - Isolated                        |
|                                   |                                   |
|                                   | - Not Isolated                    |
+-----------------------------------+-----------------------------------+
| Isolation Date                    | Isolation date of the endpoint.   |
+-----------------------------------+-----------------------------------+

The following table for **Malware** shows all the items that have been
tagged in the Process Execution or Persistence tables.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| File Name                         | Name of the artifact collected    |
|                                   | from the endpoint.                |
+-----------------------------------+-----------------------------------+
| Path                              | Executable path.                  |
+-----------------------------------+-----------------------------------+
| Tags                              | Assigned tags of the artifact.    |
+-----------------------------------+-----------------------------------+
| SHA256                            | SHA256 value of the executable    |
|                                   | file.                             |
+-----------------------------------+-----------------------------------+
| Verdicts                          | WildFire verdicts.                |
+-----------------------------------+-----------------------------------+
| User                              | User name of the person who ran   |
|                                   | the process.                      |
+-----------------------------------+-----------------------------------+
| Mitre ATT&CK Tactic               | Tactic selected during tagging.   |
+-----------------------------------+-----------------------------------+
| Mitre ATT&CK Technique            | Technique selected during         |
|                                   | tagging.                          |
+-----------------------------------+-----------------------------------+
| Platform                          | Operating system of the endpoint: |
|                                   |                                   |
|                                   | - Windows                         |
|                                   |                                   |
|                                   | - macOS                           |
|                                   |                                   |
|                                   | - Linux                           |
|                                   |                                   |
|                                   | - Android                         |
+-----------------------------------+-----------------------------------+
| Created                           | Creation timestamp of the file    |
|                                   | accessed.                         |
+-----------------------------------+-----------------------------------+
| Accessed                          | Accessed timestamp of the file    |
|                                   | accessed.                         |
+-----------------------------------+-----------------------------------+
| Modified                          | Modified timestamp of the file    |
|                                   | accessed.                         |
+-----------------------------------+-----------------------------------+

The following table for**Users** displays any artifact data with a
non-null user field that has been tagged.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Username                          | Username of the person who ran    |
|                                   | the process.                      |
+-----------------------------------+-----------------------------------+
| Domain                            | Domain of the user\'s computer.   |
+-----------------------------------+-----------------------------------+
| ID                                | Indicates the operating system:   |
|                                   |                                   |
|                                   | - UID for macOS and Linux         |
|                                   |                                   |
|                                   | - SID for Windows                 |
+-----------------------------------+-----------------------------------+
| Earliest Activity                 | Timestamp of earliest tagged item |
|                                   | in Incident Timeline for the      |
|                                   | user.                             |
+-----------------------------------+-----------------------------------+
| Latest Activity                   | Timestamp of last tagged item in  |
|                                   | Incident Timeline for the user.   |
+-----------------------------------+-----------------------------------+

The following table for **Network Indicators** displays the event logs
with the IP addresses that have been tagged.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Indicator                         | Data field that was tagged.       |
+-----------------------------------+-----------------------------------+
| Type                              | - IP Address                      |
|                                   |                                   |
|                                   | - Hostname                        |
|                                   |                                   |
|                                   | - URL                             |
+-----------------------------------+-----------------------------------+
| Country                           | Geolocation data for IP           |
|                                   | addresses.                        |
+-----------------------------------+-----------------------------------+
| Flag                              | Flag of geolocated country.       |
+-----------------------------------+-----------------------------------+
| Organization                      | Organization associated with IP   |
|                                   | address.                          |
+-----------------------------------+-----------------------------------+

The following table for **Data Access** displays all the items that have
been tagged in the File Access tables.

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  Path                                Path of the accessed file.

  User                                User name of person who accessed
                                      the file.

  Created                             Creation timestamp of the file
                                      accessed.

  Accessed                            Accessed timestamp of the file
                                      accessed.

  Modified                            Modified timestamp of the file
                                      accessed.

  Size                                Size of the file.
  -----------------------------------------------------------------------

##### Export

You can export the data collection for long-term retention or offline
analysis.

From the collections page, choose a search item from a hunt collection
or the endpoint from a triage collection and click the export icon
(![](media/rId2772.png){width="0.20833333333333334in"
height="0.20833333333333334in"}). For export of all items, select the
**Export All** option from the **Exports** button at the top of the
**Collections** page.

> **Note**
>
> You can export a collection more than once.

To view the status of the export, click the **Exports** button.

The **Investigation Exports** table displays the status of the requested
exports for the selected collection. The compressed export data expires
from the bucket after 30 days.

+-----------------------------------+-----------------------------------+
| Field                             | Description                       |
+===================================+===================================+
| Collection name                   | Displays the name of the triage   |
|                                   | or hunt. For triage, the endpoint |
|                                   | name of the triaged host is       |
|                                   | displayed.                        |
+-----------------------------------+-----------------------------------+
| Exported                          | Displays the time when the        |
|                                   | exported package was created      |
|                                   | (compressed).                     |
+-----------------------------------+-----------------------------------+
| Exported by                       | Displays the name of the user who |
|                                   | requested the export.             |
+-----------------------------------+-----------------------------------+
| Export expiration                 | Displays the timestamp of when    |
|                                   | the bucket data (compressed data) |
|                                   | will be deleted.                  |
|                                   |                                   |
|                                   | The timestamp changes to red      |
|                                   | after the timestamp and the last  |
|                                   | column shows *Expired*.           |
+-----------------------------------+-----------------------------------+
| Status                            | Indicates how many tables from    |
|                                   | the collections have been         |
|                                   | successfully exported to a        |
|                                   | bucket.                           |
+-----------------------------------+-----------------------------------+
| Download button                   | Enables you to download the the   |
|                                   | compressed (zip) export of the    |
|                                   | collection.                       |
+-----------------------------------+-----------------------------------+
| Bin icon                          | Enables you to delete the         |
|                                   | compressed export file.           |
+-----------------------------------+-----------------------------------+

### Notebooks

Cortex XSIAM Notebooks enable you to analyze and visualize the extensive
data collected by Cortex XSIAM. Using Jupyter tools, you can build
machine learning models to visualize clusters, identify anomalies, and
then feed your findings back into the Cortex XSIAM environment to
generate security insights.

You can write Python code, run all or parts of it, and create
visualizations of the data sanitation that show the results of the
algorithms you ran.

- Create customized analytics and bring your own machine learning models
  into Cortex XSIAM.

- Utilize existing public resources.

- Visualize analytics using existing libraries and applications.

- Document, automate, and reuse hunting processes.

- Use the existing data manipulation and visualization tools to identify
  patterns, anomalies, and trends in the data.

- Automate the custom investigation process and make it available as
  part of a case with actions like creating issues and adding a comment
  to a case.

> **Prerequisite**
>
> Cortex XSIAM Notebooks usage requires the following.

- > Cortex XSIAM Enterprise or Cortex XSIAM Premium.

- > Apps and XQL RBAC permissions.

  - > To use Notebooks, you must have the **View/Edit** permissions
    > in Settings \> Configurations \> Access Management \> Roles \>
    > Apps \> Jupyter.

  - > To configure Notebooks, you must have the **View/Edit**
    > permissions in Settings \> Configurations \> Access Management \>
    > Roles \> Configurations \> Apps.

  - > To work in Notebooks, you must have the Application Service
    > Account role.

  <!-- -->

  - > When you create a Notebooks instance, the API key is assigned the
    > App Service Account role by default. You can change the API key or
    > the role to match your activities.

- > A daily minimum of 1000 compute units. After activation, 1000 units
  > are deducted every day at 00:00 UTC.

<!-- -->

- > XQL and BQ queries performed in Cortex XSIAM Notebooks are
  > calculated similarly to Compute Unit usage of XQL queries
  > originating from public APIs.

Every notebook you create is preconfigured with Cortex SDK access that
enables you to query the data using Cortex Query Language.

> **Note**

- > You can only add one instance of Notebooks.

- > Cortex XSIAM Notebooks has access to approved sites on the internet
  > when embedded in Cortex XSIAM.

- > The Notebooks instance includes restart options.

Create a Notebook inside Cortex XSIAM.

1.  Select Settings \> Configurations \> Integrations \> Apps.

2.  Click the menu to the right of **Notebooks** and
    **+Create Instance**.

3.  Specify an **Instance Name** and **Add Instance**.

- Cortex XSIAM displays a notification that the instance is being
  prepared, which may take time. When completed, the instance is
  available in the navigation menu under **Apps**.

To edit the Notebooks instance, from Settings \> Configurations \>
Integrations \> Apps, hover over the instance and select the edit icon.
You can change the name of the instance, create a new API key, or select
an API key from the list.

Installing or uninstalling some plug-ins and packages require the
Notebooks server to refresh the web page. For these actions, go to File
\> Shut Down and then refresh the page.

To start working in your Notebooks instance, select it in the navigation
menu under **Apps**.

#### Manage datasets in Notebooks

Create, edit, and delete datasets directly in Notebooks and use them in
rules.

You can create datasets in BigQuery through Notebooks using custom
Cortex XSIAM APIs. You can then bring the insights and the data enriched
through machine learning into Cortex XSIAM to use them inside rules. For
example, you can run a query in Cortex XSIAM that searches a case and
correlates it to a sensitive users list you\'ve created in Notebooks to
trigger an issue.

To use the Cortex XSIAM APIs inside Notebooks, in Investigation &
Response \> Notebooks, import them from the Cortex SDK.

    from cortex.dataset import define_dataset, create_dataset_from_dataframe, delete_dataset, get_created_datasets. 
    from cortex.xql import start_query, get_query_results.

The datasets you create are available for querying in the
**Query Builder**, can be used in defining rules, can be viewed under
**Dataset Management**, and can be selected for access when creating a
user role. The creation and deletion of datasets is also recorded in the
**Management Audit Logs**.

To change the schema of a dataset created using the Notebooks API,
delete the dataset and create a new dataset with the schema you want.

You can use all the Google BigQuery functions to update the data in a
dataset created using the Notebooks API.

The functions that are available for creating and editing datasets in
Notebooks are listed below.

Define dataset

Creates an XQL dataset based on an existing BQ table.

    define_dataset(table_name: str, client: Optional[Client] = None)

+-----------------------------------+-----------------------------------+
| Arguments                         | - table_name: Existing BQ table   |
|                                   |   name created by the user.       |
|                                   |                                   |
|                                   | - client: Cortex http client.     |
+-----------------------------------+-----------------------------------+
| Required licenses                 | Cortex XSIAM Enterprise, Cortex   |
|                                   | XSIAM Premium                     |
+-----------------------------------+-----------------------------------+

Create dataset from dataframe

Creates an XQL dataset and the table at the same time, where you supply
the data and the schema of the table in the API.

    create_dataset_from_dataframe(
        table_name: str,
        dataframe: DataFrame,
        schema: Optional[Sequence[Union[SchemaField, Mapping[str, Any]]]] = None,
        client: Optional[Client] = None,
        bq_client: Optional[BqClient] = None,
    )

+-----------------------------------+-----------------------------------------------------------------------------------------+
| Arguments                         | - table_name: Dataset name.                                                             |
|                                   |                                                                                         |
|                                   | - schema: Schema of the table - a list of dicts or SchemaField objects defining the     |
|                                   |   structure of the table.                                                               |
|                                   |                                                                                         |
|                                   | <!-- -->                                                                                |
|                                   |                                                                                         |
|                                   | - for example,                                                                          |
|                                   |                                                                                         |
|                                   |                           schema = [                                                    |
|                                   |                               SchemaField("project_name", "STRING"),                    |
|                                   |                               SchemaField("project_id", "INT64"),                       |
|                                   |                               SchemaField("users", "STRING", mode="REPEATED"),          |
|                                   |                               SchemaField("assets", "RECORD", mode="REPEATED", fields=[ |
|                                   |                                   SchemaField("ip", "STRING"),                          |
|                                   |                                   SchemaField("created_time", "TIMESTAMP")              |
|                                   |                               ])                                                        |
|                                   |                           ]                                                             |
|                                   |                                                                                         |
|                                   | <!-- -->                                                                                |
|                                   |                                                                                         |
|                                   | - client: Cortex http client.                                                           |
|                                   |                                                                                         |
|                                   | - bq_client: Cortex BigQuery client.                                                    |
+-----------------------------------+-----------------------------------------------------------------------------------------+
| Required licenses                 | Cortex XSIAM Enterprise, Cortex XSIAM Enterprise Plus, Cortex XSIAM Premium             |
+-----------------------------------+-----------------------------------------------------------------------------------------+

> **Note**
>
> If a schema is not provided, the function detects the schema
> automatically.

Get created datasets

Retrieves a list of all XQL datasets generated using the Cortex SDK.

    get_created_datasets(client: Optional[Client] = None)

  ----------------------------------- -----------------------------------
  Arguments                           client: Cortex http client.

  Required licenses                   Cortex XSIAM Enterprise, Cortex
                                      XSIAM Enterprise Plus
  ----------------------------------- -----------------------------------

Delete dataset

Deletes the XQL dataset that was created by the Cortex SDK.

> **Note**

- > Using this function, you can only delete datasets created using the
  > Notebooks APIs .

- > When you delete a dataset, the rules that use the dataset return an
  > error.

<!-- -->

    delete_dataset(dataset_name: str, delete_underlying_bq_table: Optional[bool] = False, client: Optional[Client] = None)

+-----------------------------------+-----------------------------------+
| Arguments                         | - dataset_name: Name of the       |
|                                   |   dataset to be deleted.          |
|                                   |                                   |
|                                   | - delete_underlying_bq_table:     |
|                                   |   When True, deletes the BQ table |
|                                   |   related to the dataset. Default |
|                                   |   value is False.                 |
|                                   |                                   |
|                                   | - client: Cortex http client.     |
+-----------------------------------+-----------------------------------+
| Required licenses                 | Cortex XSIAM Enterprise, Cortex   |
|                                   | XSIAM Enterprise Plus             |
+-----------------------------------+-----------------------------------+

#### Notebooks scheduler

Ensure automatic data enrichment by scheduling Notebook jobs to run at
set intervals or one time only.

1.  In Investigation & Response \> Notebooks, click the calendar button
    on the top.

2.  In the **Create Job** page, fill in the name, the input file, the
    format of the output.

3.  Determine the schedule for the job or run it once.

The results of the scheduled job are reflected in the related rules as
soon as the job runs.

### Build XQL queries

To support investigation and analysis, you can search your data by
creating queries in the Query Builder. You can create queries with
the Cortex Query Language (XQL) or by using the Query Builder templates.

#### About the Query Builder

The Query Builder aids in the detection of threats by allowing you to
search for indicators of compromise and suspicious patterns within data
sources. It assists in expanding case investigations by identifying
related events and entities, such as activities associated with specific
user accounts or network lateral movement. In addition, the Query
Builder enables data analytics on suspected threats, helping
organizations analyze large volumes of data to identify trends,
anomalies, and correlations that may indicate potential security issues.
The Query Builder also provides an interactive and visually intuitive
way for you to search assets and findings by their relationship types
and map them out in real-time.

To support investigation and analysis, you can search all of the data
ingested by Cortex XSIAM by creating queries in the Query Builder. You
can create queries that investigate leads, expose the root cause of an
issue, perform damage assessment, and hunt for threats from your data
sources.

Cortex XSIAM provides different options in the Query Builder for
creating queries:

- XQL (Build your own queries)

<!-- -->

- You can use the Cortex Query Language (XQL) to build complex and
  flexible queries that search specific datasets or presets, or the
  entire Cortex Data Model (XDM). With XQL Search, you create queries
  based on stages, functions, and operators. To help you build your
  queries, Cortex XSIAM provides tools in the interface that provide
  suggestions as you type, or you can look up predefined queries, common
  stages and examples. For more information, see [How to build XQL
  queries](#UUID125805d7e53750e71a87cb4c4140fa73).

  > **Note**

  > Schema changes to datasets may not be reflected in the autocomplete
  > suggestions and deﬁnitions as you type in real time the XQL query,
  > and can appear with a slight delay.

  > **Tip**

  > When creating XQL queries, you can:

  - > Use the up and down arrow keys to navigate through the
    > auto-suggestion commands and definitions.

  - > Select an auto-suggestion command by pressing either the **Enter**
    > or **Tab** key.

  - > Press **Shift**+**Enter** to add a new line, and easily ignore the
    > auto-suggestion output.

  - > Close the auto-suggestion output by pressing the **Esc** key.

<!-- -->

- Query Builder templates (No XQL knowledge required)

<!-- -->

- You can use the Query Builder templates to access your data without
  prior XQL knowledge. The templates include predefined filtering fields
  and key fieldsets, and can include any field from the XDM schema.

  As the templates are also based on XQL, you can also translate your
  template queries into XQL. With this flexibility, you can enrich the
  basic queries created by templates for more detailed investigation, or
  use the templates as a starting point for creating complex queries
  with full XQL functionality. For more information, see
  [/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834](/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834).

<!-- -->

- Graph Search to build queries to search assets, findings, and their
  contextual data. For more information, see [How to build Graph Search
  queries?](#UUIDb33e2aff7fda7b7becb9ff81ba480cd1).

> **Tip**
>
> If you prefer to use the Query Builder in **Legacy mode**, switch the
> toggle in the header. In Legacy mode, the Query Builder searches
> predefined datasets only. To search the full XDM Data Model, switch to
> **New mode** or select **XQL Search**.

#### How to build XQL queries

The Cortex Query Language (XQL) enables you to query data ingested into
Cortex XSIAM for rigorous endpoint and network event analysis. To help
you create an eﬀective XQL query with the proper syntax, the query ﬁeld
in the user interface provides suggestions and deﬁnitions as you type.

XQL forms queries in stages. Each stage performs a specific query
operation and is separated by a pipe character (\|). Queries require a
dataset, or data source, to run against. You can either query the Cortex
Data Model (XDM) or you can query specific datasets. In a dataset query,
unless otherwise specified, the query runs against the
`xdr_data` dataset, which contains all log information that Cortex XSIAM
collects from all Cortex product agents, including EDR data, and PAN
NGFW data. In XDM queries, you must specify the dataset mapped to the
XDM that you want to run your query against.

> **Important**
>
> Forensic datasets are not inlcuded by default in XQL query results,
> unless the dataset query is explicitly defined to use a forensic
> dataset.

##### Which datasets are mapped to XDM?

The Cortex Query Language (XQL) supports a single Cortex Data Model
(XDM), which is a normalized data structure. Datasets are mapped to the
XDM in 3 different ways:

1.  Automatic default mappings, including the following:

    - The `xdr_data` dataset is automatically mapped to the XDM with
      some data mapping exceptions.

    - Next-Generation Firewall (NGFW) network log data are mapped to the
      XDM from the following datasets:

      - `panw_ngfw_traffic_raw`

      - `panw_ngfw_threat_raw`

      - `panw_ngfw_url_raw`

      - `panw_ngfw_filedata_raw`

      - `panw_ngfw_globalprotect_raw`

      - `panw_ngfw_hipmatch_raw`

2.  Out-of-the-box mappings of the datasets as part of the Data Model
    Rules via the Marketplace. For more information, see [Cortex
    Marketplace](#UUIDbd7bb72a06838e5b74c7b3b159596497).

3.  You can create your own mappings by creating your own Data Model
    Rules. For more information, see [Create Data Model
    Rules](#UUIDae88d6b87191f2aff1599fbe27eb41fe).

For more information on the XDM Schema, specifically the fields,
fieldsets, fields designated as ENUMS (CONST), and aliases, see the
[Cortex XSIAM Data Model
Schema](https://docs-cortex.paloaltonetworks.com/r/Cortex-XSIAM/Cortex-Data-Model-Schema-Guide/Introduction).

##### XDM query syntax

The basic syntax structure for querying the Cortex Data Model (XDM) is:

    datamodel
        | <STAGE> ...
        | <STAGE> ...
        | <STAGE> ...

In a query using the `datamodel` command, unless specific datasets are
specified, a query will run against all mapped datasets, which contain
log information ingested by Cortex XSIAM. You can also install
Marketplace Content Packs, or map an ingested dataset into the XDM, to
query additional datasets.

In XDM queries that specify datasets, use either of the following
syntax:

    datamodel dataset in (<dataset_name>,...) …

or

    datamodel dataset = <dataset_name> …

Adding a wildcard suffix (\*) is supported in the `<dataset_name>`,
which matches all datasets that are mapped to the data model and begin
with the specified text. For example, `datamodel dataset = xdr*` or
`datamodel dataset in (xdr*)`.

When querying the XDM, fields that are not mapped to the XDM are
accessible by `<dataset>.<field>`. They can be used at any stage of a
`datamodel` query.

When creating XDM queries, auto-suggestions are available, according to
the existing XDM fields.

##### Dataset query syntax

In a dataset query, unless otherwise specified, the query runs against
the `xdr_data` dataset, which contains all log information that Cortex
XSIAM collects from all Cortex product agents, including EDR data, and
PAN NGFW data. In a dataset query, if you are running your query against
a dataset that has been set as default, there is no need to specify a
dataset. Otherwise, specify a dataset in your query. The Dataset Queries
lists the available datasets, depending on system configuration.

> **Note**

- > Users with different dataset permissions can receive different
  > results for the same XQL query.

- > An administrator or a user with a predefined user role can create
  > and view queries built with an unknown dataset that currently does
  > not exist in Cortex XSIAM. All other users can only create and view
  > queries built with an existing dataset.

- > When you have more than one dataset or lookup, you can change your
  > default dataset by navigating to Settings \> Configurations \> Data
  > Management \> Dataset Management, right-click on the appropriate
  > dataset, and select **Set as default**. For more information about
  > setting default datasets, see
  > [/document/preview/952274#UUID-ae82030e-2493-a33b-9a9e-a9834e993e93](/document/preview/952274#UUID-ae82030e-2493-a33b-9a9e-a9834e993e93).

The basic syntax structure for querying datasets that are not mapped to
the XDM is:

    dataset = <dataset name> 
        | <stage1> ...
        | <stage2> ... 
        | <stage3> ...

or

    dataset in (<dataset name>)
        | <stage1> ...
        | <stage2> ...
        | <stage3> ...

You can specify a dataset using one of the following formats, which is
based on the data retention offerings available in Cortex XSIAM.

- Hot Storage queries use the format `dataset = <dataset name>`. This is
  the default option.

<!-- -->

- dataset = xdr_data

<!-- -->

- Cold Storage queries use the format `cold_dataset = <dataset name>`.

<!-- -->

- cold_dataset = xdr_data

  > **Note**

  > You can build a query that investigates data in both a cold dataset
  > and a hot dataset in the same query. In addition, as the hot storage
  > dataset format is the default option and represents the fully
  > searchable storage, this format is used throughout this guide for
  > investigation and threat hunting. For more information on hot and
  > cold storage, see
  > [/document/preview/952274#UUID-ae82030e-2493-a33b-9a9e-a9834e993e93](/document/preview/952274#UUID-ae82030e-2493-a33b-9a9e-a9834e993e93).

When using the hot storage default format, this returns every `xdr_data`
record contained in your Cortex XSIAM instance over the time range that
you provide to the Query Builder user interface. This can be a large
amount of data, which may take a long time to retrieve. You can use a
`limit` stage to specify how many records you want to retrieve.

There is no practical limit to the number of stages that you can
specify. See [Stages](#UUID877336c467ba7af1a4331269479e3e8e) for
information on all the supported stages.

In the `xdr_data` dataset, every user ﬁeld included in the raw data for
network, authentication, and login events has an equivalent normalized
user ﬁeld associated with it that displays the user information in the
following standardized format:

`<company domain>\<username>`

For example, the `login_data` ﬁeld has the
`login_data_dst_normalized_user` ﬁeld to display the content in the
standardized format. To ensure the most accurate results, we recommend
that you use these `normalized_user` ﬁelds when building your queries.

##### Additional components

XQL queries can contain different components, such as functions and
stages, depending on the type of query you want to build. For a complete
list of the syntax options available with example queries, see
[Stages](#UUID877336c467ba7af1a4331269479e3e8e) and
[Functions](#UUIDe74efd8b8558b7a11ca8525d6b6a30b2).

##### Get started with XQL queries

Before you begin running XQL queries, consider the following
information:

- Use the interface to help you build queries

<!-- -->

- Cortex XSIAM offers features in the XQL search interface to help you
  build queries. For more information, see [Useful XQL user interface
  features](#UUIDbb726d45b210ab19bb423d3db545b858).

<!-- -->

- Mitigate long-running queries

<!-- -->

- Querying the XDM enables searching of Cortex XSIAM\'s extensive data.
  We recommend that you use filters to streamline your queries. For more
  information, see [XQL Query best
  practices](#UUIDdd21d96bea0bbaad472c6edd7f13392e).

<!-- -->

- Understand query defaults and limitations

<!-- -->

- Before you run a query, review this list to better understand query
  behavior and results. For more information, see [Expected results when
  querying fields](#UUIDd7cc9384a8e5611f2bbe36dc6f725f00).

<!-- -->

- Translate Splunk queries to XQL

<!-- -->

- If you have existing Splunk queries, you can translate them to XQL.
  For more information, see [Translate to
  XQL](#UUIDdba75cce040d194c73378d1c87dc8628).

> **Tip**
>
> If you are new to creating queries, you can also try our simple search
> templates, which can help you get started in understanding how queries
> work. See
> [/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834](/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834).

##### Useful XQL user interface features

The user interface contains several useful features for querying data,
and for viewing results:

- **XQL query**: The XQL query field is where you define the parameters
  of your query. To help you create an effective XQL query, the search
  field provides suggestions and definitions as you type.

<!-- -->

- > **Note**

  > Schema changes to datasets may not be reflected in the autocomplete
  > suggestions and deﬁnitions as you type in real time the XQL query
  > and can appear with a slight delay.

  > **Tip**

  > When creating XQL queries, you can:

  - > Use the up and down arrow keys to navigate through the
    > auto-suggestion command suggestions and definitions.

  - > Select an auto-suggestion command by pressing either the **Enter**
    > or **Tab** key.

  - > Press **Shift**+**Enter** to add a new line, and easily ignore the
    > auto-suggestion output.

  - > Close the auto-suggestion output by pressing the **Esc** key.

<!-- -->

- **Translate to XQL**: Converts your existing Splunk queries to the XQL
  syntax. When you enable Translate to XQL , both an **SPL query** field
  and an **XQL query** field are displayed. You can easily add a Splunk
  query, which is converted automatically into XQL in the **XQL query**
  ﬁeld. This option is disabled by default.

- **Query Results**: After you create and run an XQL query, you can
  view, filter, and visualize your **Query Results**.

- **XQL Helper**: Describes common stage commands and provides examples
  that you can use to build a query.

- **Query Library**: Contains common, predefined queries that you can
  use or modify to your liking. In addition, there is a personal query
  library for saving and managing your own queries so that you can share
  with others, and queries can be shared with you. For more information,
  see [Manage your personal query
  library](#UUID9eadb61fac4a89b3f3165d6bbc06ef1b).

- **Schema**: Contains schema information for every field found in the
  result set. This information includes the field name, data type,
  descriptive text (if available), and the dataset that contains the
  field.

  - For dataset queries, it contains the list of all the fields of all
    the datasets that were involved in the query.

  - For data model queries, it contains the list of all the data model
    fields.

##### XQL Query best practices

Cortex XSIAM includes built-in mechanisms for mitigating long-running
queries, such as default limits for the maximum number of allowed
issues, and for the maximum number of returned rows. Only specified
mapped datasets are searched when querying by the Cortex Data Model
(XDM) to use system resources and time more efficiently. The following
suggestions can help you to streamline your queries:

- Add a smaller limit to queries by using a `limit` stage.

<!-- -->

- To help reduce the Cortex Query Language (XQL) response time, the
  default results for an XDM query or an XQL dataset query is limited to
  1000, when no limit is explicitly stated in the query. This applies to
  basic queries with no stages except the `fields` stage. This default
  limit does not apply to widgets, Correlation Rules, public APIs, saved
  queries, or scheduled queries, where the limit is a maximum of
  1,000,000 results. Queries based on legacy templates are limited to
  10,000 results. Adding a smaller limit can greatly reduce the response
  time.

      datamodel dataset = microsoft_windows_raw 
      | fields *host* 
      | limit 100

<!-- -->

- Use a small time frame for queries by specifying the specific date and
  time in the **Timeframe**, such as selecting **Relative time** and
  defining **Last 30 Minutes**, instead of picking the nearest larger
  option available or defining an extended time period.

- Use filters that exclude data, along with other possible filters.

- Select the specific fields that you would like to see in the query
  results.

##### Expected results when querying fields

The following are returned when querying fields:

- If specific fields are stated in the
  [fields](#UUIDa22fb161beb7d67c6d9bc8c52d66f3bd) stage, those exact
  fields will be returned. 

- If no fields are stated in the query, the `xdm_core` fieldset will be
  returned.

- Unmapped fields are treated as NULL. An unmapped field is an `xdm`
  field that hasn\'t been mapped from the relevant datasets using a Data
  Model Rule.

- By default, the `_time` system field will be added to all data model
  queries. Yet, the `_time` system field will not be added to queries
  that contain the `comp` stage.

- For dataset queries, all current system fields will be returned, even
  if they are not stated in the query.

- For UNION between XDM and dataset, each part of the UNION will return
  its own fields.

- Each new column in the result set created by the
  [alter](#UUID29adfeb71cc64bb046509f7b4089e1b5) stage will be added as
  the last column. You can specify a different column order by modifying
  the field order in the [fields](#UUIDa22fb161beb7d67c6d9bc8c52d66f3bd)
  stage of the query.

- Each new column in the result set created by the
  [/document/preview/892018#UUID-bab9ca82-561c-c7a9-8a37-f9c42a06e8f3](/document/preview/892018#UUID-bab9ca82-561c-c7a9-8a37-f9c42a06e8f3)
  stage will be added as the last column. Other fields that are not in
  the `group by / calculated` column will be removed from the result
  set, including the core fields and `_time` system field.

- When no limit is explicitly stated in a `datamodel` query, a maximum
  of 1000 results are returned (default). When this limit is applied to
  results using the [limit](#UUIDa42977faddf5d14f266e03147a8b4cf3)
  stage, it will be indicated in the user interface.

##### Create XQL query

Review the following topics:

- [How to build XQL queries](#UUID125805d7e53750e71a87cb4c4140fa73)

Build Cortex Query Language (XQL) queries to analyze raw log data stored
in Cortex XSIAM. You can query the Cortex Data Model (XDM) or datasets
using specific syntax.

How to create a XDM query

1.  From Cortex XSIAM, select Investigation & Response \> Search \>
    Query Builder.

2.  Click **XQL**.

3.  *(Optional)* Change the default time period against which to run
    your query from the time picker at the top right of the window. You
    can select the required time period from any of the following
    options available:

    - Preset time ranges easily available to select from, such as
      **24 hours** and **30 days**.

    - Recently used selections from your previous queries.

    - **Relative time**: Define the time frame as the last \<number\>
      minutes, days, or hours by setting the number.

    - **Calendar**: Create a customized time period by selecting the
      date range from the calendar and the specific **Start Time** and
      **End Time**.

- > **Note**

  - > Whenever the time period is changed in the query window, the
    > `config timeframe` is automatically set to the time period
    > defined, but this won\'t be visible as part of the query. Only if
    > you manually type in the `config timeframe` will this be seen in
    > the query.

  - > These time picker options are available in XQL queries when using
    > the Query Builder, XQL Widgets, and when defining XQL Widgets in
    > Reports and Dashboards.

4.  *(Optional)* To translate Splunk queries to XQL queries, enable
    **Translate to XQL**. If you choose to use this feature, enter your
    Splunk query in the **Splunk** field, click the arrow icon to
    convert to XQL, and then go to
    [#UUID5f5b967337c3cb75a413d47e8b461681_N1669623521916](#Xb3f9aeb8c32cc199d334d4945dd6349f40021ed).

5.  Create your query by typing in the query field. Relevant commands,
    their definitions, and operators are suggested as you type.

- > **Tip**

  > When creating XQL queries, you can:

  - > Use the up and down arrow keys to navigate through the
    > auto-suggestion command suggestions and definitions.

  - > Select an auto-suggestion command by pressing either the **Enter**
    > or **Tab** key.

  - > Press **Shift**+**Enter** to add a new line, and easily ignore the
    > auto-suggestion output.

  - > Close the auto-suggestion output by pressing the **Esc** key.

  a.  Specify the datasets to run your query against by typing either
      `datamodel dataset = <dataset name>...` or
      `datamodel dataset in (<dataset name>,...)...`. For example:

  - datamodel dataset in (amazon_aws_raw)

    > **Note**

    > While `datamodel dataset=*` is supported in the query, we
    > recommend that you specify specific datasets for quicker and more
    > efficient results.

  b.  Press Enter, and then type the pipe character (`|`). Select a
      stage, and complete the stage syntax using the suggested options.

  c.  Continue adding stages until your query is complete. For example:

  - datamodel dataset in (amazon_aws_raw)
            | filter xdm.source.ipv4 = "10.9.165.1"
            | fields xdm.source.ipv4, xdm.source.port
            | limit 100  

6.  Choose when to run your query:

    - Run the query immediately.

    - Run the query by the specified date and time, or on a specific
      date, by selecting the calendar icon
      (![](media/rId2810.png){width="0.30302930883639545in"
      height="0.20833333333333334in"}).

7.  *(Optional)* The Save As options save your query for future use:

    - Correlation Rule: When compatible, saves the query as a
      Correlation Rule. For more information, see [What\'s a correlation
      rule?](#UUIDaa8a139a1b00c4c5d40d7c25de20b762).

    - Query to Library: Saves the query to your personal query library.
      For more information, see [Manage your personal query
      library](#UUID9eadb61fac4a89b3f3165d6bbc06ef1b).

    - Widget to Library: For more information, see
      <urn:resource:component:1159521>.

> **Tip**
>
> While the query is running, you can navigate away from the page. A
> notification is sent when the query has finished. You can also
> **Cancel** the query or run a new query, where you have the option to
> **Run only new query (cancel previous)** or **Run both queries**.

How to create a dataset query

1.  From Cortex XSIAM, select Investigation & Response \> Search \>
    Query Builder.

2.  Click **XQL**.

3.  *(Optional)* Change the default time period against which to run
    your query from the time picker at the top right of the window. You
    can select the required **Timeframe** from any of the following
    options available:

    - Preset time ranges easily available to select from, such as
      **24 hours** and **30 days**.

    - Recently used selections from your previous queries.

    - **Relative time**: Define the time frame as the last \<number\>
      minutes, days, or hours by setting the number.

    - **Calendar**: Create a customized time period by selecting the
      date range from the calendar and the specific **Start Time** and
      **End Time**.

- > **Note**

  - > Whenever the time period is changed in the query window, the
    > `config timeframe` is automatically set to the time period
    > defined, but this won\'t be visible as part of the query. Only if
    > you manually type in the `config timeframe` will this be seen in
    > the query.

  - > These time picker options are available in XQL queries when using
    > the Query Builder, XQL Widgets, and when defining XQL Widgets in
    > Reports and Dashboards.

4.  *(Optional)* To translate Splunk queries to XQL queries, enable
    **Translate to XQL**. If you choose to use this feature, enter your
    Splunk query in the **Splunk** field, click the arrow icon
    (![](media/rId2815.png){width="0.3020833333333333in"
    height="0.20833333333333334in"}) to convert to XQL, and then go to
    [#UUID5f5b967337c3cb75a413d47e8b461681_stepidm151669624932174](#Xbae59d30f3ba27fa706bd5689848133f8412c1e).

5.  Create your query by typing in the query field. Relevant commands,
    their definitions, and operators are suggested as you type.

- > **Tip**

  > When creating XQL queries, you can:

  - > Use the up and down arrow keys to navigate through the
    > auto-suggestion command suggestions and definitions.

  - > Select an auto-suggestion command by pressing either the **Enter**
    > or **Tab** key.

  - > Press **Shift**+**Enter** to add a new line, and easily ignore the
    > auto-suggestion output.

  - > Close the auto-suggestion output by pressing the **Esc** key.

  a.  (Optional) Specify a dataset.

  - You only need to specify a dataset if you are running your query
    against a dataset that you have not set as default. Otherwise, the
    query runs against the `xdr_data` dataset. For more information, see
    [How to build XQL queries](#UUID125805d7e53750e71a87cb4c4140fa73).

        dataset = xdr_data

  b.  Press **Enter**, and then type the pipe character (`|`). Select a
      command, and complete the command using the suggested options.

  c.  Continue adding stages until your query is complete.

  - dataset = xdr_data 
        | filter agent_os_type = ENUM.AGENT_OS_MAC
        | limit 250  

6.  Choose when to run your query:

    - Run the query immediately.

    - Run the query by the specified date and time, or on a specific
      date, by selecting the calendar icon
      (![](media/rId2810.png){width="0.30302930883639545in"
      height="0.20833333333333334in"}).

7.  *(Optional)* The Save As options save your query for future use:

    - BIOC Rule: When compatible, saves the query as a BIOC rule. The
      XQL query must contain a filter for the **event_type** field.

    - Correlation Rule: When compatible, saves the query as a
      Correlation Rule. For more information, see [What\'s a correlation
      rule?](#UUIDaa8a139a1b00c4c5d40d7c25de20b762).

    - Query to Library: Saves the query to your personal query library.
      For more information, see [Manage your personal query
      library](#UUID9eadb61fac4a89b3f3165d6bbc06ef1b).

    - Widget to Library: For more information, see
      <urn:resource:component:1159521>.

> **Tip**
>
> While the query is running, you can navigate away from the page. A
> notification is sent when the query has finished. You can also
> **Cancel** the query or run a new query, where you have the option to
> **Run only new query (cancel previous)** or **Run both queries**.

##### Review XQL query results

Review the following topics:

- [How to build XQL queries](#UUID125805d7e53750e71a87cb4c4140fa73)

- [Create XQL query](#UUID5f5b967337c3cb75a413d47e8b461681)

The results of a Cortex Query Language (XQL) query are displayed in a
tab called **Query Results**.

> **Note**
>
> It\'s also possible to graph the results displayed. For more
> information, see [Graph query
> results](#UUID66d5f7c34cf5b98b79e931ea76c83b11).

###### Understanding the options available to investigate results

Use the following options in the **Query Results** tab to investigate
your query results:

+-----------------------------------+---------------------------------------------------------+
| Option                            | Use                                                     |
+===================================+=========================================================+
| Table tab                         | Displays results in rows and columns according to the   |
|                                   | entity ﬁelds. Columns can be filtered, using their      |
|                                   | filter icons.                                           |
|                                   |                                                         |
|                                   | More options (kebab icon                                |
|                                   | ![](media/rId2824.png){width="0.14583333333333334in"    |
|                                   | height="0.20833333333333334in"}) displays table layout  |
|                                   | options, which are divided into different sections:     |
|                                   |                                                         |
|                                   | - In the **Appearance** section, you can                |
|                                   |   **Show line breaks** for any text field in the        |
|                                   |   **Query Results**. By default, the text in these      |
|                                   |   fields are wrapped unless the **Show line breaks**    |
|                                   |   option is selected. In addition, you can change the   |
|                                   |   way rows and columns are displayed.                   |
|                                   |                                                         |
|                                   | - In the **Log Format** section, you can change the way |
|                                   |   that logs are displayed:                              |
|                                   |                                                         |
|                                   |   - **RAW**: Raw format of the entity in the database.  |
|                                   |                                                         |
|                                   |   - **JSON**: Condensed JSON format with key value      |
|                                   |     distinctions. NULL values are not displayed.        |
|                                   |                                                         |
|                                   |   - **TREE**: Dynamic view of the JSON hierarchy with   |
|                                   |     the option to collapse and expand the different     |
|                                   |     hierarchies.                                        |
|                                   |                                                         |
|                                   | - In the **Search column** section, you can find a      |
|                                   |   specific column; enable or disable display of columns |
|                                   |   using the checkboxes.                                 |
|                                   |                                                         |
|                                   | Show and hide rows according to a specific field in a   |
|                                   | specific event: select a cell, right-click it, and then |
|                                   | select either Show rows with ... or Hide rows with ...  |
+-----------------------------------+---------------------------------------------------------+
| Graph tab                         | Use the **Chart Editor** to visualize the query         |
|                                   | results.                                                |
+-----------------------------------+---------------------------------------------------------+
| Advanced tab                      | Displays results in a table format which aggregates the |
|                                   | entity ﬁelds into one column. You can change the        |
|                                   | layout, decide whether to **Show line breaks** for any  |
|                                   | text field in the results table, and change the log     |
|                                   | format from the                                         |
|                                   | ![](media/rId2824.png){width="0.14583333333333334in"    |
|                                   | height="0.20833333333333334in"} menu.                   |
|                                   |                                                         |
|                                   | Select **Show more** to pivot an **Expanded View** of   |
|                                   | the event results that include NULL values. You can     |
|                                   | toggle between the **JSON** and **Tree** views, search, |
|                                   | and **Copy to clipboard**.                              |
+-----------------------------------+---------------------------------------------------------+
| Export to File                    | Exports the results to a TSV (tab-separated values)     |
|                                   | ﬁle.                                                    |
|                                   |                                                         |
|                                   | - More options                                          |
|                                   |   (![](media/rId2824.png){width="0.14583333333333334in" |
|                                   |   height="0.20833333333333334in"}) works in a similar   |
|                                   |   way to how it works on the **Table** tab.             |
|                                   |                                                         |
|                                   | - **Show more** in the bottom left corner of each row   |
|                                   |   opens the **Expanded View** of the event results that |
|                                   |   also include NULL values. Here, you can toggle        |
|                                   |   between the **JSON** and **Tree** views, search, and  |
|                                   |   **Copy to clipboard**.                                |
|                                   |                                                         |
|                                   | - **Log format** options change the way that logs are   |
|                                   |   displayed:                                            |
|                                   |                                                         |
|                                   |   - RAW: Raw format of the entity in the database.      |
|                                   |                                                         |
|                                   |   - JSON: Condensed JSON format with key value          |
|                                   |     distinctions. NULL values are not displayed.        |
|                                   |                                                         |
|                                   |   - TREE: Dynamic view of the JSON hierarchy with the   |
|                                   |     option to collapse and expand the diﬀerent          |
|                                   |     hierarchies.                                        |
+-----------------------------------+---------------------------------------------------------+
| Refresh                           | Refreshes the query results.                            |
+-----------------------------------+---------------------------------------------------------+
| Free text search                  | Searches the query results for text that you specify in |
|                                   | the free text search. Click the **Free text search**    |
|                                   | icon to reveal or hide the free text search field.      |
+-----------------------------------+---------------------------------------------------------+
| Filter                            | Enables you to ﬁlter a particular ﬁeld in the interface |
|                                   | that is displayed to specify your ﬁlter criteria.       |
|                                   |                                                         |
|                                   | For integer, boolean, and timestamp (such as `_time`)   |
|                                   | ﬁelds, we recommend that you use the **Filter** instead |
|                                   | of the **Free text** search, in order to retrieve the   |
|                                   | most accurate query results.                            |
+-----------------------------------+---------------------------------------------------------+
| Fields menu                       | Filters query results. To quickly set a ﬁlter, Cortex   |
|                                   | XSIAM displays the top ten results from which you can   |
|                                   | choose to build your ﬁlter. This option is only         |
|                                   | available in the **Table** and **Advanced** tabs,       |
|                                   |                                                         |
|                                   | From within the Fields menu, click on any ﬁeld          |
|                                   | (excluding JSON and array ﬁelds) to see a histogram of  |
|                                   | all the values found in the result set for that ﬁeld.   |
|                                   | This histogram includes:                                |
|                                   |                                                         |
|                                   | - A count of the total number of times a value was      |
|                                   |   found in the result set.                              |
|                                   |                                                         |
|                                   | - The value\'s frequency as a percentage of the total   |
|                                   |   number of values found for the ﬁeld.                  |
|                                   |                                                         |
|                                   | - A bar chart showing the value\'s frequency.           |
|                                   |                                                         |
|                                   | > **Note**                                              |
|                                   | >                                                       |
|                                   | > In order for Cortex XSIAM to provide a histogram for  |
|                                   | > a ﬁeld, the ﬁeld must not contain an array or a JSON  |
|                                   | > object.                                               |
+-----------------------------------+---------------------------------------------------------+

###### Available options for saving results

The Save As options save your query for future use:

- BIOC Rule: When compatible, saves the query as a BIOC rule. The XQL
  query must contain a filter for the **event_type** field.

- Correlation Rule: When compatible, saves the query as a Correlation
  Rule. For more information, see [What\'s a correlation
  rule?](#UUIDaa8a139a1b00c4c5d40d7c25de20b762).

- Query to Library: Saves the query to your personal query library. For
  more information, see [personal query
  library](#UUID9eadb61fac4a89b3f3165d6bbc06ef1b).

- Widget to Library: For more information, see
  <urn:resource:component:1159521>.

###### Investigating results in the Causality View or Timeline View

You can continue investigating the query results in the Causality View
or Timeline by right-clicking the event and selecting the desired view.
This option is available for the following types of events:

- Process (except for those with an event sub-type of termination)

- Network

- File

- Registry

- Injection

- Load image

- System calls

- Event logs for Windows

- System authentication logs for Linux

For network stories, you can pivot to the Causality View only. For cloud
Cortex XSIAM events and Cloud Audit Logs, you can only pivot to the
Cloud Causality View, while software-as-a-service (SaaS) related issues
for audit stories, such as Office 365 audit logs and normalized logs,
you can only pivot to the SaaS Causality View.

###### Add file path to Malware Profile allowed list

Add a file path to your existing Malware Profile allowed list by
right-clicking a \<path\> field, such as **target_process_path**, and
select **Add \<path type\> to malware profile allow list**.

##### Translate to XQL

To help you easily convert your existing Splunk queries to the Cortex
Query Language (XQL) syntax, Cortex XSIAM includes a toggle called
**Translate to XQL** in the query ﬁeld in the user interface. When
building your XQL query and this option is selected, both a
**SPL query** field and **XQL query** field are displayed, so you can
easily add a Splunk query, which is converted to XQL in the XQL query
field. This option is disabled by default, so only the **XQL query**
field is displayed.

> **Important**
>
> This feature is still in a Beta state and you will find that not all
> Splunk queries can be converted to XQL. This feature will be improved
> upon in the upcoming releases to support greater Splunk query
> translations to XQL.

Supported functions in Splunk

The following table details the supported functions in Splunk that can
be converted to XQL in Cortex XSIAM with an example of a Splunk query
and the resulting XQL query. In each of these examples, the `xdr_data`
dataset is used.

+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Splunk Function/Stage       | Splunk Query Example                                                                                                                                       | Resulting XQL Query Example                                                                                                                                                                                                          |
+=============================+============================================================================================================================================================+======================================================================================================================================================================================================================================+
| `avg`                       | `index=xdr_data | stats avg(dst_association_strength)`                                                                                                     | `dataset in (xdr_data) | comp avg(dst_association_strength)`                                                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `bin`                       | `index = xdr_data | bin _time span=5m`                                                                                                                     | `dataset in (xdr_data) | bin _time span=5m`                                                                                                                                                                                          |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `coalesce`                  | `index= xdr_data | eval product_or_vendor_not_null=coalesce(_product, _vendor )`                                                                           | `dataset in (xdr_data) | alter product_or_vendor_not_null = coalesce(_product, _vendor)`                                                                                                                                             |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `count`                     | `index=xdr_data | stats count(_product) BY _time`                                                                                                          | `dataset in (xdr_data) | comp count(_product) by _time`                                                                                                                                                                              |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `ctime`                     | `index=xdr_data | convert ctime(field) as field`                                                                                                           | `dataset in (xdr_data) | alter field = format_timestamp("%m/%d/%Y %H:%M:%S", to_timestamp(field))`                                                                                                                                   |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `earliest`                  | `index = xdr_data earliest=24d`                                                                                                                            | `dataset in (xdr_data) | filter _time >= to_timestamp(add(to_epoch(current_time()),2073600000))`                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `eval`                      | `index=xdr_data | eval field = "test"`                                                                                                                     | `dataset in (xdr_data) | alter field = "test"`                                                                                                                                                                                       |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `fillnull`                  | `index=xdr_data | fillnull value = "missing ipv6" agent_ip_addresses_v6`                                                                                   | `dataset in (xdr_data) | replacenull agent_ip_addresses_v6 = "missing ipv6"`                                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `floor`                     | `index=xdr_data | eval floor_test = floor(1.9)`                                                                                                            | `dataset in (xdr_data) | alter floor_test = floor(1.9)`                                                                                                                                                                              |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `iplocation`                | `index=xdr_data | inputlookup append=true my_lookup.csv`                                                                                                   | `dataset in (xdr_data) | union (dataset=my_lookup | limit 1000000000)`                                                                                                                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `iplocation`                | `index = xdr_data | inputlookup agent_ip_addresses`                                                                                                        | `dataset in (xdr_data) | iploc agent_ip_addresses loc_continent AS Continent, loc_country AS Country, loc_region AS Region, loc_city AS City, loc_latlon AS lon`                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `isnotnull`                 | `index=xdr_data | eval x = isnotnull(agent_hostname)`                                                                                                      | `dataset in (xdr_data)\n | alter x = if(agent_hostname != null, true, false)`                                                                                                                                                        |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `isnull`                    | `index=xdr_data | eval x = isnull(agent_hostname)`                                                                                                         | `dataset in (xdr_data)\n | alter x = if(agent_hostname = null, true, false)`                                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `json_extract`              | `index= xdr_data | eval London=json_extract(dfe_labels,"dfe_labels{0}")`                                                                                   | `dataset in (xdr_data) | alter London = dfe_labels -> dfe_labels[0]{}`                                                                                                                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `join`                      | `join agent_hostname [index = xdr_data]`                                                                                                                   | `join type=left conflict_strategy=right (dataset in (xdr_data)) as inner agent_hostname = inner.agent_hostname`                                                                                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `latest`                    | `index = xdr_data latest=-24d`                                                                                                                             | `dataset in (xdr_data) |filter _time <= to_timestamp(add(to_epoch(date_floor(current_time(),"d")),-2073600000))`                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `len`                       | `index = xdr_data | where uri != null | eval length = len(agent_ip_address)`                                                                               | `dataset in (xdr_data) | filter agent_ip_addresses != null | alter agent_ip_address_length = len(agent_ip_addresses)`                                                                                                                |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `ltrim(<str>,<trim_chars>)` | `index=xdr_data | eval trimed_agent=ltrim("agent_hostname", "agent_")`                                                                                     | `dataset in (xdr_data) | alter trimed_agent = ltrim("agent_hostname", "agent_")`                                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `lower`                     | `index = xdr_data | eval field = lower("TEST")`                                                                                                            | `dataset in (xdr_data) | alter field = lowercase("TEST")`                                                                                                                                                                            |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `max`                       | `index =xdr_data | stats max(action_file_size) by _product`                                                                                                | `dataset in (xdr_data) | comp max(action_file_size) by _product`                                                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `md5`                       | `index=xdr_data | eval md5_test = md5("test")`                                                                                                             | `dataset in (xdr_data) | alter md5_test = md5("test")`                                                                                                                                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `median`                    | `index = xdr_data | stats median(actor_process_file_size) by _time`                                                                                        | `dataset in (xdr_data) | comp median(actor_process_file_size) by _time`                                                                                                                                                              |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `min`                       | `index =xdr_data | stats min(action_file_size) by _product`                                                                                                | `dataset in (xdr_data) | comp min(action_file_size) by _product`                                                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvcount`                   | `index = xdr_data | where http_data != null | eval http_data_array_length = mvcount(http_data)`                                                            | `dataset in (xdr_data) | filter http_data != null | alter http_data_array_length = array_length(http_data)`                                                                                                                          |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvdedup`                   | `index = xdr_data | eval s=mvdedup(action_app_id_transitions)`                                                                                             | `dataset in (xdr_data) | alter s = arraydistinct(action_app_id_transitions)`                                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvexpand`                  | `index = xdr_data | mvexpand dfe_labels limit = 100`                                                                                                       | `dataset in (xdr_data) | arrayexpand dfe_labels limit 100`                                                                                                                                                                           |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvfilter`                  | `index = xdr_data | eval x = mvfilter(isnull(dfe_labels))`                                                                                                 | `dataset in (xdr_data) | alter x = arrayfilter(dfe_labels, if("@element" = null, true, false) = true)`                                                                                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvindex`                   | `index=xdr_data | eval field = mvindex(action_app_id_transitions, 0)`                                                                                      | `dataset in (xdr_data) | alter field = arrayindex(action_app_id_transitions, 0)`                                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `mvjoin`                    | `index=xdr_data | eval n=mvjoin(action_app_id_transitions, ";")`                                                                                           | `dataset in (xdr_data) | alter n = arraystring(action_app_id_transitions, ";")`                                                                                                                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `pow`                       | `index=xdr_data | eval pow_test = pow(2, 3)`                                                                                                               | `dataset in (xdr_data) | alter pow_test = pow(2, 3)`                                                                                                                                                                                 |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `relative_time(X,Y)`        | - `index ="xdr_data" | where _time > relative_time(now(),"-7d@d")`                                                                                         | - `dataset in (xdr_data) | filter _time > to_timestamp(add(to_epoch(date_floor(current_time(),"d")),-604800000))`                                                                                                                    |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index ="xdr_data" | where _time > relative_time(now(),"+7d@d")`                                                                                         | - `dataset in (xdr_data)| filter _time > to_timestamp(add(to_epoch(date_floor(current_time(),"d")),604800000))`                                                                                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `replace`                   | `index= xdr_data | eval description = replace(agent_hostname,"\("."NEW")`                                                                                  | `dataset in (xdr_data) | alter description = replace(agent_hostname, concat("\(", "NEW"))`                                                                                                                                           |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `rex`                       | `index=xdr_data action_local_ip!="0.0.0.0" | rex field=action_local_ip "(?<src_ip>\d+\.\d+\.\d+\.48)" | where src_ip != "" | table action_local_ip src_ip` | `dataset in (xdr_data) |filter (action_local_ip != "0.0.0.0" AND action_local_ip != null) | alter src_ip = arrayindex(regextract(action_local_ip, "(\d+\.\d+\.\d+\.48)"), 0) | filter src_ip != "" | fields action_local_ip, src_ip` |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `round`                     | `index=xdr_data | eval round_num = round(3.5)`                                                                                                             | `dataset in (xdr_data) | alter round_num = round(3.5)`                                                                                                                                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `rtrim`                     | `index=xdr_data | eval trimed_hostname=rtrim("agent_hostname", "hostname")`                                                                                | `dataset in (xdr_data) | alter trimed_hostname = rtrim("agent_hostname", "hostname")`                                                                                                                                                |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `search`                    | `index = xdr_data | eval ip="192.0.2.56" | search ip="192.0.2.0/24"`                                                                                       | `dataset in (xdr_data) | alter ip = "192.0.2.56" | filter incidr(ip,"192.0.2.0/24") = true`                                                                                                                                          |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `sha256`                    | `index = xdr_data | eval sha256_test = sha256("test")`                                                                                                     | `dataset in (xdr_data) | alter sha256_test = sha256("test")`                                                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `sort (ascending order)`    | `index = xdr_data | sort action_file_size`                                                                                                                 | `dataset in (xdr_data) | sort asc action_file_size | limit 10000`                                                                                                                                                                    |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `sort (descending order)`   | `index = xdr_data | sort -action_file_size`                                                                                                                | `dataset in (xdr_data) | sort desc action_file_size | limit 10000`                                                                                                                                                                   |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `spath`                     | `index = xdr_data | spath output=myfield input=action_network_http path=headers.User-Agent`                                                                | `dataset in (xdr_data) | alter myfield = json_extract(action_network_http ,"$.headers.User-Agent")`                                                                                                                                  |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `split`                     | `index = xdr_data | where mac != null | eval split_mac_address = split(mac, ":")`                                                                          | `dataset in (xdr_data)\n | filter mac != null\n | alter split_mac_address = split(mac, ":")`                                                                                                                                         |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `stats`                     | `index=xdr_data | stats count(event_type) by _time`                                                                                                        | `dataset in (xdr_data) | comp count(event_type) by _time`                                                                                                                                                                            |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `stats dc`                  | `index = xdr_data | stats dc(_product) BY _time`                                                                                                           | `dataset in (xdr_data) | comp count_distinct(_product) by _time`                                                                                                                                                                     |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `strcat`                    | `index=xdr_data | strcat story_id "/" http_req_before_method comboIP`                                                                                      | `dataset in (xdr_data) | alter comboIP=concat(if(story_id!=null,story_id,""),"/",if(http_req_before_method!=null,http_req_before_method,""))`                                                                                        |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `sum`                       | `index=xdr_data | where action_file_size != null | stats sum(action_file_size) by _time`                                                                   | `dataset in (xdr_data) | filter action_file_size != null | comp sum(action_file_size) by _time`                                                                                                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `table`                     | `index = xdr_data | table _time, agent_hostname, agent_ip_addresses, _product`                                                                             | `dataset in (xdr_data) | fields _time, agent_hostname, agent_ip_addresses, _product`                                                                                                                                                 |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `tonumber`                  | `index=xdr_data | eval tonumber_test = tonumber("90210")`                                                                                                  | `dataset in (xdr_data) | alter tonumber_test = to_number("90210")`                                                                                                                                                                   |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `top`                       | The following Splunk functions can be translated to XQL:                                                                                                   | - `limit`                                                                                                                                                                                                                            |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `limit`                                                                                                                                                  | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `dataset in (xdr_data) | filter action_app_id_risk > 0 | top 20 action_app_id_risk top_count as count, top_percent as percent`                                                                                                     |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index = xdr_data | where action_app_id_risk > 0 | top limit=20 action_app_id_risk`                                                                      | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `countfield`                                                                                                                                                                                                                       |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `countfield`                                                                                                                                             | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `dataset in (xdr_data) |top 10 agent_hostname by _time top_count as count_agent_hostname, top_percent as percent`                                                                                                                  |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index = xdr_data | top countfield=count_agent_hostname agent_hostname by _time`                                                                         | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `showcount`                                                                                                                                                                                                                        |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `showcount`                                                                                                                                              | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `dataset in (xdr_data) | filter action_app_id_risk > 0 | top 3 action_app_id_risk top_count as count, top_percent as percent`                                                                                                      |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index = xdr_data | where action_app_id_risk > 0 | top 3 showcount=t action_app_id_risk`                                                                 | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `showperc`                                                                                                                                                                                                                         |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `showperc`                                                                                                                                               | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `dataset in (xdr_data) | filter action_app_id_risk > 0 | top 3 action_app_id_risk top_count as count, top_percent as percent`                                                                                                      |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index = xdr_data | where action_app_id_risk > 0 | top 3 showperc=t action_app_id_risk`                                                                  | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `percentfield`                                                                                                                                                                                                                     |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `percentfield`                                                                                                                                           | <!-- -->                                                                                                                                                                                                                             |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | <!-- -->                                                                                                                                                   | - `dataset in (xdr_data) | top 10 agent_hostname by _time top_count as count, top_percent as agent_hostname_percentage`                                                                                                              |
|                             |                                                                                                                                                            |                                                                                                                                                                                                                                      |
|                             | - `index = xdr_data | top percentfield=agent_hostname_percentage agent_hostname by _time`                                                                  |                                                                                                                                                                                                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `upper`                     | `index=xdr_data | eval field = upper("test")`                                                                                                              | `dataset in (xdr_data) | alter field = uppercase("test")`                                                                                                                                                                            |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `var`                       | `index=xdr_data | stats var (event_type) by _time`                                                                                                         | `dataset in (xdr_data) | comp var(event_type) by _time`                                                                                                                                                                              |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

How to translate a Splunk query to XQL syntax

1.  Select Investigation & Response \> Search \> Query Builder \> XQL.

2.  Toggle to **Translate to XQL**, where both a **SPL query** field and
    **XQL query** field are displayed.

3.  Add your Splunk query to the **SPL query** field.

4.  Click the arrow (![](media/rId2815.png){width="0.3020833333333333in"
    height="0.20833333333333334in"}).

- The **XQL query** field displays the equivalent Splunk query using the
  XQL syntax.

  You can now decide what to do with this query based on the
  instructions explained in [Create XQL
  query](#UUID5f5b967337c3cb75a413d47e8b461681).

##### Graph query results

To help you better understand your Cortex Query Language (XQL) query
results and share your insights with others, Cortex XSIAM enables you to
generate graphs and outputs of your query data directly from query
results page.

1.  Select Investigation & Response \> Search \> Query Builder \> XQL.

2.  Run an XQL query.

- Enter the following query:

      dataset = xdr_data 
      | fields action_total_upload, _time 
      | limit 10

  The query returns the `action_total_upload`, a number field, and
  `_time`, a string field, for up to 10 results.

3.  In the **Query Results** section, to graph the results either:

- Use Chart Editor
  Navigate to Query Results \> Chart Editor
  (![](media/rId2842.png){width="0.2604166666666667in"
  height="0.20833333333333334in"}) to manually build and view the graph
  using the selected graph parameters:

  - **Main**

    - **Graph Type**: Type of graphs and output options available:
      **Area**, **Bubble**, **Column**, **Funnel**, **Gauge**, **Line**,
      **Map**, **Pie**, **Scatter**, **Single Value**, or
      **Word Cloud**.

    <!-- -->

    - > **Note**

      > To display the result of as a time duration, choose the graph
      > type **Single Value** and enable **Show as Time**. You can then
      > select the **Time Unit** (millisecond, second, minute, or hour)
      > and the **Display format**.

    <!-- -->

    - **Subtype** and **Layout**: Depending on the selected type of
      graph, choose from the available display options.

    - **Header**: Title your graph.

    - **Show Callouts**: Display numeric values on the graph.

  - **Data**

    - **X-axis**: Select a field with a string value.

    - **Y-axis**: Select a field with a numeric value.

    - (Optional) **Series**: For an area, bubble, column, line, map, or
      scatter chart, you can specify a field (column) to group chart
      results based on y-axis values. This option is only displayed when
      one of the supported graph types are selected, and a single y-axis
      value is selected.

  - Depending on the selected type of graph, customize the **Color**,
    **Font**, and **Legend**.

  Use XQL query
  Enter the visualization parameters in the XQL query section.

  You can express any chart preferences in XQL. This is helpful when you
  want to save your chart preferences in a query and generate a chart
  every time that you run it. To define the parameters, either:

  - Define the following query:

  <!-- -->

  - dataset = xdr_data 
        | view graph type = column header = "Test 1" xaxis = _time yaxis = action_total_upload series = _vendor

  <!-- -->

  - Select **ADD TO QUERY** to insert your chart preferences into the
    query itself.

4.  (*Optional*) Create a custom widget.

- To easily track your query results, you can create custom widgets
  based on the query results. The custom widgets you create can be used
  in your custom dashboards and reports. For more information, see
  <urn:resource:component:1159521>.

  Select **Save to Widget Library** to pivot to the Widget Library and
  generate a custom widget based on the query results.

#### Query Builder templates

You can use the Query Builder templates to create effective queries
without using the Cortex Query Language (XQL).

From the Query Builder, you can select the following templates:

- **Basic**: Search by IP address, host name, user name, and domain.

- **Free text**: Search for a free text string.

- **Identity**: Search by user name and type.

- **Endpoint**: Search by host name, files, and processes.

- **Network IP**: Search by IP address and connection status.

- **Cloud**: Search by cloud provider and zone.

The templates are configured to run on specific datasets, but it\'s
possible to run them on all datasets. The templates run on the following
datasets by default:

- **Basic**, **Identity**, **Endpoint**, and **Network** templates:
  `xdr_data`

- **Cloud** template: `cloud_audit_logs`

The templates are set up with predefined filtering fields and fieldsets
that are specific to the template type. For example, a query built with
the **Endpoint** template includes fields from `fieldset.xdm_endpoint`.
You can specify values for the default fields and add any other required
fields to refine and adapt your search. The Query Builder templates
support any filtering fields from the Cortex Data Model (XDM) schema.

> **Tip**
>
> To get started with queries, you can run an empty template query with
> no values specified. The query results will include all of the fields
> in the template specific fieldset. Based on the query results, you can
> run subsequent queries to narrow down your search.

##### Get started with Query Builder templates

Before you start running queries with Query Builder templates, consider
the following information:

- **Learn about the templates:** Although the templates don't require
  XQL knowledge, they do require knowledge of operators and other
  factors. Understanding how the templates work will help you to build
  effective queries. For more information, see
  [/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5](/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5).

- **Look up field and alias descriptions:** The templates are based on
  the fields and aliases in the Cortex Data Model (XDM). If you want
  more information about a field or alias, see the [Cortex XSIAM Data
  Model Schema
  Guide](https://docs-cortex.paloaltonetworks.com/r/Cortex-XSIAM/Cortex-Data-Model-Schema-Guide/Introduction).

- **Try out our examples:** To help you feel confident with Query
  Builder templates, start by following our step-by-step examples and
  tailor them for your environment. For more information, see [Query
  Builder template examples](#UUID916e794a9c9e407bd4864e77f4402a76).

##### Considerations for using Query Builder templates

The following sections provide information and considerations for using
Query Builder templates.

###### General considerations

The following general considerations apply to Query Builder templates:

- The templates run on the following datasets by default:

  - **Basic**, **Identity**, **Endpoint**, and **Network** templates:
    `xdr_data`

  - **Cloud** template: `cloud_audit_logs`

<!-- -->

- It is also possible to run the templates on all datasets.

<!-- -->

- The query uses an AND operator between the filtering fields.

- Separate multiple values with pipes and do not add spaces between the
  value and the pipe.

- Some of the filtering fields are aliases and therefore search all
  fields that are associated with the alias.

- Fields with dropdown options support ENUMs and free text values.

- In IP address fields, you can also specify subnets.

- The asterisk (`*`) wildcard is supported, except in subnet values.

- You cannot remove the predefined fields, but you can leave them blank.

- When filtering integer and float fields, you can only specify two
  operators from the four available options.

###### = (equal to) and != (not equal to) operators

Filtering fields support the `=` (equal to) and `!=` (not equal to)
operators, and you can specify both operators for the same field. The
following conditions apply to these operators:

- If you specify multiple values for a field with the `=` operator, the
  OR operator is applied. For example, `User Name = aaa|bbb` searches
  for instances of user name equal to aaa OR bbb.

- If you specify multiple values for a field with the `!=` operator, the
  AND operator is applied. For example, `User Name != aaa|bbb` searches
  for instances of user name not equal to aaa AND bbb.

- If you specify both operators (`=` and `!=`) for the same field, the
  AND operator is applied. For example,
  `COUNTRY = Empty values AND COUNTRY != USA`.

###### \>= (greater than and equal) and \<= (less than and equal) operators

Filtering fields support the `>=` (greater than and equal) and `<=`
(less than and equal) operators, and you can specify both operators for
the same field. The following conditions apply to these operators:

- Cortex XSIAM supports using these operators for integer and float
  fields.

- Empty values are not supported with these operators.

###### Include and exclude empty values

You can use the **Empty values** field to include or exclude fields with
empty values and strings. In the search results, some fields might
return empty values. This occurs if no data is mapped to a field. The
following conditions apply to the **Empty values** field:

- If you specify **=** and select **Empty values**, the query includes
  fields with empty values with an OR operator.

<!-- -->

- For example, `_vendor = aaa OR _vendor = Empty values` searches the
  `_vendor` field for any instances of aaa or empty values.

<!-- -->

- If you specify **!=** and select **Empty values**, the query excludes
  fields with empty values with an AND operator.

<!-- -->

- For example, `_vendor != aaa AND _vendor != Empty values` searches the
  `_vendor` field for values that are not equal to aaa AND do not
  contain empty values.

<!-- -->

- If you specify **!=** and select **Empty values** for an alias, you
  might not receive any results. The query searches all of the fields
  associated with the alias for non-empty values. If any of the
  associated fields contain empty values, no results are returned.

<!-- -->

- For example, `User Name != aaa AND User Name != Empty values` searches
  the User Name alias fields for values that are not equal to aaa AND
  empty values. If the query finds either aaa or empty values in any of
  the alias fields, no results are returned.

##### Create a query from a template

You can use the Query Builder templates to create effective queries
without using the Cortex Query Language (XQL).

Review the following topics:

- [/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834](/document/preview/918018#UUID-e34405b6-a092-2267-2b05-b2e6af734834)

- [Get started with Query Builder
  templates](#UUID6bf5ced752af891dac5a10a43eb93dc9)

- [/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5](/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5)

**How to create a query from a Query Builder template**

1.  Select Investigation & Response \> Search \> Query Builder.

2.  In the Query Builder, select the template that you want to use.

- If you want to use the Free Text Search template, see [Run a free text
  query](#UUID550352451d3f46199906fd9c62aa3d0b).

3.  (Optional) Change the **Run on** option (upper-right corner) that
    controls the datasets configured to run with the template. The
    templates are automatically configured to run on default datasets or
    you can choose to run them on all datasets. The templates run on the
    following datasets by default:

    - **Basic**, **Identity**, **Endpoint**, and **Network** templates:
      `xdr_data`

    - **Cloud** template: `cloud_audit_logs`

4.  Enter values for any of the predefined fields and specify whether to
    include **Empty values** in the query.

- Guidelines
  - The query uses an AND operator between the filtering fields.

  - Separate multiple values with pipes and do not add spaces between
    the value and the pipe.

  - Some of the filtering fields are aliases and therefore search all
    fields that are associated with the alias.

  - You can run an empty template with no values specified. The query
    results will show data from all of the fields in the template
    specific fieldset.

  For more information about using the filtering fields, operators, and
  including **Empty values**, see
  [/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5](/document/preview/922571#UUID-bbfb8b34-3bc0-8015-0244-26914b98f0d5).

5.  (Optional) Click **Add Field** and select the additional filtering
    fields or aliases to include in the query.\"

- > **Note**

  - > Field names and aliases are listed without their prefix, for
    > example **xdm.SOURCE.USER.USERNAME** is listed as
    > **SOURCE.USER.USERNAME** and **XDM_ALIAS.ipv4** is listed as
    > **ipv4**.

  - > Fields that are already included in the query template are shown
    > as grayed out.

  - > In the Identity and Network templates, `xdm.event.outcome` shows
    > as grayed out. In these templates, the **ACTION STATUS** and
    > **CONNECTION STATUS** fields are linked to the `xdm.event.outcome`
    > enum. Therefore, you can\'t duplicate this field in a query.

6.  Click **TIME** and select a time frame for the query.

7.  Click **Run** to start the query, or click **Schedule** to run the
    query at a specific time.

- You can also click **Continue in XQL** to open the XQL Query Builder
  showing the defined XQL fields. In XQL you have the flexibility to add
  additional stages and functions that are not available in the Query
  Builder templates.

8.  Review the **Results**.

- The search is limited to 1,000 results. In the **Fields** column, you
  can see all of the fields that were included in the query in the
  following order: (1) **\_time**, (2) the filtering fields that you
  defined, and (3) the fields from the template specific fieldset.

  > **Note**

  > This order might change if you include a filtering field that is
  > listed in the fieldset. In that case, the field is taken out of the
  > fieldset and ordered at the top of the list with the other filtering
  > fields.

  The query is also saved in the Query Center. In the Query Center, you
  can identify your query by filtering the **Created By** column and
  looking in the **Query Description** column. Queries created from a
  template are prefixed with the template name.

Example

- The following query searches for instances of IP 3.3.3.3 with a source
  host name equal to host1 or host2. IP is an alias field; therefore,
  the query searches all fields associated with the alias.

<!-- -->

- IP ADDRESS = 3.3.3.3, SOURCE.HOST.OS = host1|host2

<!-- -->

- The following query searches for the event outcome success with an
  event duration value that is not equal to null:

<!-- -->

- EVENT.OUTCOME = XDM_CONST.OUTCOME_SUCCESS, EVENT.DURATION != Empty values

###### What to do next

- To edit or rerun the query, click **Back to edit** to review the
  template, or **Continue in XQL** to review the XQL.

- Practice running queries with [Query Builder template
  examples](#UUID916e794a9c9e407bd4864e77f4402a76).

##### Run a free text query

You can use the **Free text** template to query your datasets for
free-text strings without building a Cortex Query Language (XQL) query.
The template queries all of the datasets that are stored in your tenant
and returns up to 1,000 results.

> **Note**
>
> Free-text search is also available in XQL queries. You can use the
> `search` stage to query free-text strings in specific datasets, or all
> of the datasets in your tenant.

**How to run a free text query**

1.  Select Investigation & Response \> Search \> Query Builder.

2.  Under **General Search**, select **Free text**.

3.  In the **Text Contains** field, type one or more strings. Separate
    multiple strings with pipes, which applies the OR operator.

4.  Click **TIME** and select a time frame for the query.

- > **Note**

  > Free text search is limited to the last 90 days of data. Specifying
  > a time frame outside of this limitation will cause the query to
  > fail.

5.  Click **Run** to start the query, or click **Schedule** to run the
    query at a specific time.

- Free text search searches the relevant columns in each dataset.
  Relevant columns are subject to a change and can vary between
  datasets.

  You can also click **Continue in XQL** to translate the query with the
  fields that you specified into XQL. In XQL you have the flexibility to
  add additional stages and functions that are not available in the
  Query Builder templates.

6.  Review the results.

- The searched string is highlighted in the results.

  In the **Fields** column, you can see all of the fields in which the
  string was discovered. Fields are listed in the following order: (1)
  `_time`, (2) `_dataset`, and (3) the fields in which the string was
  discovered, ordered by highest to lowest number of hits.

  In the `RAW_DATA` column, click **Show more** to see the specific row
  in the dataset in which the string was discovered.

###### What to do next

- To edit or rerun the query, click **Back to edit** to review the
  template in the Query Builder, or **Continue in XQL** to review the
  XQL.

- Practice running queries with [Query Builder template
  examples](#UUID916e794a9c9e407bd4864e77f4402a76).

##### Query Builder template examples

The following examples can help familiarize you with running queries.

###### Use the Identity template to search for information about a specific user

**Goal**: Search for information about users working on the system.

This example uses the **Identity** template, but you can apply it to any
of the templates. In the example, we run multiple queries that narrow
down our search results and find the required information we require.

####### Query 1: Search for information about all users

1.  Select Investigation & Response \> Search \> Query Builder.

2.  Select the **Identity** template.

3.  Specify **USER = \*** and do not select **Empty values**.

- This searches for all users, and excludes empty values or strings from
  the results. The `USER` field is an alias so all associated fields are
  also searched.

4.  Specify TIME \> Last 7D.

5.  Click **Run**.

In the **Results** page, scroll through the table to find a value or
string that you want to investigate further. If you are not receiving
results, you can broaden the **TIME** to **Last 30D**.

In this example, the results returned information about **USER66** in
the **XDM.SOURCE.USER.USERNAME** column. To refine the search for
information about this user, run another query.

####### Query 2: Search for information about a specific user

1.  Copy the term that you want to search, in this case **USER66**.

2.  Click **Back to edit**.

- The Identity template opens with the original search options.

3.  Click **Add field** and select **SOURCE.USER.USERNAME**.

4.  Specify **SOURCE.USER.USERNAME = USER66** and do not select
    **Empty values**.

5.  Click **Run**.

The **Results** page provides more information about **USER66**.

Look through the results for anything you would like to investigate
further. In this example, there is information about the operations
performed by this user in the **XDM.EVENT.OPERATION** column. We can
refine the search to see all **FILE_REMOVE** operations for **USER66**.

####### Query 3: Search for FILE_REMOVE operations for a specific user

1.  Click **Back to edit**.

2.  Click **Add field** and select **EVENT.OPERATION**.

3.  Specify **EVENT.OPERATION =** and select
    **XDM_CONST.OPERATION_TYPE_FILE_REMOVE** from the list.

4.  Click **Run**.

Review the **Results** page and continue to refine your search by using
this method.

###### Use the Network template to search for hosts triggering threat events in the United States

**Goal**: Search for information about source hosts in the United States
that caused threat events over the last 7 days.

####### Query 1: Search for network information in the United States

1.  Select Investigation & Response \> Search \> Query Builder.

2.  Select the **Network** template.

3.  Specify **COUNTRY = United States** and do not select
    **Empty values**.

- This searches for network activity in the United States, and excludes
  empty values or strings from the results.

4.  Specify TIME \> Last 7D.

5.  Click **Run**.

In the **Results** page, scroll through the table to find a value or
string for which you would like to find more information.

In this example, the results returned information about
**XDM.EVENT.TYPE = threat** for host **DC3ENX4FGC07** in the
**XDM.SOURCE.HOST.HOSTNAME** column. To refine the search, run another
query.

####### Query 2: Search for information about a specific host and event type

1.  Copy the term that you want to search, in this case
    **DC3ENX4FGC07**.

2.  Click **Back to edit**.

- The Network template opens with the original search options.

3.  Click **Add field** and select **EVENT.TYPE**.

4.  Specify **EVENT.TYPE = threat** and do not select **Empty values**.

5.  Click **Add field** and select **SOURCE.HOST.HOSTNAME**.

6.  Specify **SOURCE.HOST.HOSTNAME = DC3ENX4FGC07** and do not select
    **Empty values**.

7.  Click **Run**.

The **Results** page provides more information about
**EVENT.TYPE = threat** actions from host **DC3ENX4FGC07**.

To investigate further we could run another query, or in this case,
investigate the causality chain of the event. In the search results,
right-click and **Investigate Causality Chain**.

###### Use the Free text template to search for an IP address

**Goal**: Search for information about IP address 175.18.7.29 in the
last 24 hours.

1.  Select Investigation & Response \> Search \> Query Builder.

2.  Select the **Free text** template.

3.  Specify **Text Contains = 175.18.7.29**.

4.  Specify TIME \> Last 24H.

5.  Click **Run**.

In the **Results** page the searched string is highlighted. In
the **Fields** column, you can see all of the fields in which the string
was discovered. In the **RAW_DATA** column, click **Show more** to see
the specific row in the dataset in which the string was discovered.

If you want to deepen your search you can **Continue in XQL**, which
opens an XQL search with the fields you defined in the template. You can
add stages and functions to the XQL that narrow down your search.

#### Edit and run queries in Query Center

The **Query Center** displays information about all queries that were
run in the **Query Builder**. From the **Query Center** you can manage
your Cortex Query Language (XQL) and Graph Search queries by viewing
query results, running queries, adjusting queries, and scheduling when a
query runs. Right-click a query to see the available options, where some
of the options differ depending on the type of query you\'ve selected.
The pivot (right-click) options described below are some of the ones
that may require further explanation.

##### View the results of a query

You can view the original results of an XQL query when it was originally
run in the Query Builder and added to the Query Center.

1.  Select Investigation & Response \> Search \> Query Center.

2.  Identify the XQL query by looking in the **Query Name** and
    **Query Description** columns.

- The **Query Description** column displays the parameters that were
  defined for a query. If necessary, use the filter on the column to
  reduce the number of queries displayed.

  Queries that were created from a Query Builder template are prefixed
  with the template name.

3.  Right-click anywhere in the XQL query row and select
    **Show results**.

- You have the option to **Show results in new tab** or
  **Show results in same tab**.

4.  (*Optional*) **Export to file** to export the results to a
    tab-separated values (TSV) file.

5.  (*Optional*) Perform additional investigation on the issues.

- Right-click a value in the results table to see the options for
  further investigation.

##### Run a query

You can run a query for a Graph Search query.

1.  Select Investigation & Response \> Search \> Query Center.

2.  Identify the Graph Search query by looking in the **Query Name** and
    **Query Description** columns.

- The **Query Description** column displays the parameters that were
  defined for a query. If necessary, use the filter on the column to
  reduce the number of queries displayed.

3.  Right-click anywhere in the Graph Search query row and select
    **Run query**.

- You have the option to **Run in same tab** or **Show in new tab**.

4.  (*Optional*) The Graph Search results are displayed in a graph
    format by default. You can toggle to **Table** to view the results
    in a table format. In addition, you can always export the graph
    results using the icon at the top of the page to a PNG, SVG, or TSV
    file. Table results can only be exported to a TSV file.

5.  (*Optional*) Perform additional investigation on the graph or table
    results.

- On the graph results, you can either hover or select different nodes
  for further investigation. While in the table results, you can select
  any cell in the table for further investigation.

##### Modify a query

After you view the query results of an XQL query or run a Graph Search
query as explained in the tasks above, you can change your search
parameters to refine the search results or correct a search parameter.

- For queries created in XQL, type your changes in the XQL query field
  where the original query is listed and the results are displayed in
  the **Query Results** tab. After modifying the query, you can run,
  schedule, or save the query.

- For queries created with a Query Builder template, the defined
  parameters are shown at the top of the **Results** page. Select
  **Back to edit** to modify the query with the template format or
  **Continue in XQL** to open the query in XQL.

- For Graph Search queries, the graph results are displayed. Click
  anywhere in the Graph Search query interface, where your existing
  query is defined, to display the complete query, update your query,
  and rerun the search.

##### Schedule a query to run

You can schedule an XQL query to run on or before a specific date.
Cortex XSIAM creates a new query in the **Query Center**, and when the
query completes, it displays a notification in the notification bar.

**How to schedule a query**

1.  In the **Query Center**, right-click anywhere in the query and then
    select **Schedule**.

2.  Choose a schedule option and the date and time that the query should
    run:

    - **Run one time query on a specific date**

    - **Run query by date and time**: Schedule a recurring query.

3.  Click **OK** to schedule the query.

- Cortex XSIAM creates a new query and schedules it to run on or by the
  selected date and time.

4.  View the status of the scheduled query on the **Scheduled Queries**
    page.

- You can also make changes to the query, edit the frequency, view when
  the query will next run, or disable the query. For more information,
  see [Manage scheduled queries](#UUIDa6a1c386be83dee6adae90853bd56f0a).

##### Query Center reference information

The table below lists the common fields in the Query Center, where the
options differ for an XQL query versus a Graph Search query.

> **Note**
>
> Certain fields are exposed and hidden by default. An asterisk (\*) is
> beside every field that is exposed by default.

Query Center table

+-----------------------------------+-----------------------------------------------------+
| Field                             | Description                                         |
+===================================+=====================================================+
| **BQL**                           | Indicates whether the Cortex Query Language (XQL)   |
|                                   | query was created by the native search.             |
|                                   |                                                     |
|                                   | Native search has been deprecated; this field       |
|                                   | allows you to view data for XQL queries performed   |
|                                   | before deprecation.                                 |
+-----------------------------------+-----------------------------------------------------+
| **COMPUTE UNIT USAGE**            | For XQL queries, indicates the number of query      |
|                                   | units that were used to execute the API query and   |
|                                   | Cold Storage query.                                 |
+-----------------------------------+-----------------------------------------------------+
| **CREATED BY** \*                 | For XQL queries, indicates the user who created or  |
|                                   | scheduled the query. For Graph Search queries,      |
|                                   | indicates the user who created the query.           |
+-----------------------------------+-----------------------------------------------------+
| **DURATION (SEC)**                | Number of seconds it took to execute the XQL query. |
+-----------------------------------+-----------------------------------------------------+
| **EXECUTION ID**                  | Unique identifier of XQL and Graph Search queries   |
|                                   | in the tenant. The identifier ID generated for      |
|                                   | queries executed in Cortex XSIAM and XQL query API. |
+-----------------------------------+-----------------------------------------------------+
| **NUM OF RESULTS**\*              | Number of results returned by the query.            |
+-----------------------------------+-----------------------------------------------------+
| **PUBLIC API**                    | Whether the source executing the XQL query was an   |
|                                   | XQL query API.                                      |
+-----------------------------------+-----------------------------------------------------+
| **QUERY DESCRIPTION**\*           | Query parameters used to run the query.             |
+-----------------------------------+-----------------------------------------------------+
| **QUERY ID**                      | Unique identifier of the query.                     |
+-----------------------------------+-----------------------------------------------------+
| **QUERY NAME**\*                  | - For saved queries, the **Query Name** identifies  |
|                                   |   the query specified according to a randomly       |
|                                   |   generated number.                                 |
|                                   |                                                     |
|                                   |   - XQL queries use the format                      |
|                                   |     **XQL-QUERY-\<number\>**, such as               |
|                                   |     **XQL-QUERY-12**.                               |
|                                   |                                                     |
|                                   |   - Graph Search queries use the format             |
|                                   |     **Graph-Query-\<number\>**, such as             |
|                                   |     **Graph-Query-1247**.                           |
|                                   |                                                     |
|                                   | - For scheduled queries, the **Query Name**         |
|                                   |   identifies the auto-generated name of the parent  |
|                                   |   XQL query. Scheduled queries also display an icon |
|                                   |   to the left of the name to indicate that the XQL  |
|                                   |   query is recurring.                               |
|                                   |                                                     |
|                                   | ![](media/rId2874.png){width="2.7777777777777777in" |
|                                   | height="0.8194444444444444in"}                      |
+-----------------------------------+-----------------------------------------------------+
| **QUERY STATUS**\*                | Status of the query, where the options differ based |
|                                   | on the query type:                                  |
|                                   |                                                     |
|                                   | - XQL queries:                                      |
|                                   |                                                     |
|                                   |   - **Queued**: The query is queued and will run    |
|                                   |     when there is an available slot.                |
|                                   |                                                     |
|                                   |   - **Running**                                     |
|                                   |                                                     |
|                                   |   - **Failed**                                      |
|                                   |                                                     |
|                                   |   - **Partially completed**: The query was stopped  |
|                                   |     after exceeding the maximum number of permitted |
|                                   |     results. The default results for a Cortex Data  |
|                                   |     Model (XDM) query or an XQL dataset query is    |
|                                   |     limited to 1000, when  no limit is explicitly   |
|                                   |     stated in the query. This applies to basic      |
|                                   |     queries with no stages except the `fields`      |
|                                   |     stage. This default limit does not apply to     |
|                                   |     widgets, Correlation Rules, public APIs, saved  |
|                                   |     queries, or scheduled queries, where the limit  |
|                                   |     is a maximum of 1,000,000 results. Queries      |
|                                   |     based on legacy templates are limited to 10,000 |
|                                   |     results. To reduce the number of results        |
|                                   |     returned, you can adjust the query settings and |
|                                   |     rerun.                                          |
|                                   |                                                     |
|                                   |   - **Stopped**: The query was stopped by an        |
|                                   |     administrator.                                  |
|                                   |                                                     |
|                                   |   - **Completed**                                   |
|                                   |                                                     |
|                                   |   - **Deleted**: The query was pruned.              |
|                                   |                                                     |
|                                   | - Graph Search queries:                             |
|                                   |                                                     |
|                                   |   - **Failed**                                      |
|                                   |                                                     |
|                                   |   - **Completed**                                   |
+-----------------------------------+-----------------------------------------------------+
| **RESULTS SAVED**\*               | For XQL queries, you can choose whether to save the |
|                                   | query results, so the output of the field is either |
|                                   | **Yes** or **No**. Yet, for Graph Search queries,   |
|                                   | the results can\'t be saved and must be run each    |
|                                   | time again, so the field is always **No**.          |
+-----------------------------------+-----------------------------------------------------+
| **SIMULATED COMPUTE UNITS**       | Number of XQL query units that were used to execute |
|                                   | the Hot Storage query.                              |
+-----------------------------------+-----------------------------------------------------+
| **Source**                        | Source from which the query was run, for example    |
|                                   | Playbook, Report, or Investigation.                 |
+-----------------------------------+-----------------------------------------------------+
| **Source ID**                     | ID of the source from where the query was run.      |
+-----------------------------------+-----------------------------------------------------+
| **Source Name**                   | Name of the source from where the query was run.    |
+-----------------------------------+-----------------------------------------------------+
| **TIMESTAMP**\*                   | Date and time the query was created.                |
+-----------------------------------+-----------------------------------------------------+
| **XQL**                           | Indicates whether the XQL query was created by an   |
|                                   | XQL search.                                         |
+-----------------------------------+-----------------------------------------------------+

#### Manage scheduled queries

The **Scheduled Queries** page displays information about your scheduled
and recurring queries. From this page, you can edit scheduled query
parameters, view previous executions, disable, and remove scheduled
queries. Right-click a query to see the available options.

##### View executed queries

1.  Select Investigation & Response \> Search \> Scheduled Queries.

2.  Locate the scheduled query for which you want to view previous
    executions.

- If necessary, use the **Filter** to reduce the number of queries
  returned.

3.  Right-click anywhere in the query row, and select
    **Show executed queries**.

- Cortex XSIAM filters the queries on the **Query Center**.

##### Edit the query frequency

1.  Select Investigation & Response \> Search \> Scheduled Queries.

2.  Locate the scheduled query that you want to edit.

- If necessary, use the **Filter** to reduce the number of queries
  returned.

3.  Right-click anywhere in the query row and then select **Edit**.

4.  Adjust the schedule settings, and then click **OK**.

##### Scheduled Queries reference information

The table below ists the common fields in the **Scheduled Queries**
page.

> **Note**
>
> Certain fields are exposed and hidden by default. An asterisk (\*) is
> beside every field that is exposed by default.

Scheduled Queries table

+-----------------------------------+-----------------------------------------------------+
| Field                             | Description                                         |
+===================================+=====================================================+
| **BQL**                           | Whether the query was created by the native search. |
|                                   |                                                     |
|                                   | Native search has been deprecated, this field       |
|                                   | allows you to view data for queries performed       |
|                                   | before deprecation.                                 |
+-----------------------------------+-----------------------------------------------------+
| **CREATED BY**                    | User who created or scheduled the query.            |
+-----------------------------------+-----------------------------------------------------+
| **MITRE ATT&CK TACTIC**           | MITRE ATT&CK tactics tagged in the scheduled query. |
+-----------------------------------+-----------------------------------------------------+
| **MITRE ATT&CK TECHNIQUE**        | MITRE ATT&CK techniques tagged in the scheduled     |
|                                   | query.                                              |
+-----------------------------------+-----------------------------------------------------+
| **NEXT EXECUTION**                | - For queries that are scheduled to run at a        |
|                                   |   specific frequency, this displays the next        |
|                                   |   execution time.                                   |
|                                   |                                                     |
|                                   | <!-- -->                                            |
|                                   |                                                     |
|                                   | - For queries that were scheduled to run at a       |
|                                   |   specific time and date, this field will show      |
|                                   |   `None`.                                           |
+-----------------------------------+-----------------------------------------------------+
| **PUBLIC API**                    | Whether the source executing the query was an XQL   |
|                                   | query API.                                          |
+-----------------------------------+-----------------------------------------------------+
| **QUERY DESCRIPTION**             | Query parameters used to run the query.             |
+-----------------------------------+-----------------------------------------------------+
| **QUERY ID**                      | Unique identifier of the query.                     |
+-----------------------------------+-----------------------------------------------------+
| **QUERY NAME**                    | - For saved queries, the **Query Name** identifies  |
|                                   |   the query specified by the administrator.         |
|                                   |                                                     |
|                                   | - For scheduled queries, the **Query Name**         |
|                                   |   identifies the auto-generated name of the parent  |
|                                   |   query. Scheduled queries also display an icon to  |
|                                   |   the left of the name to indicate that the query   |
|                                   |   is recurring.                                     |
|                                   |                                                     |
|                                   | ![](media/rId2874.png){width="2.7777777777777777in" |
|                                   | height="0.8194444444444444in"}                      |
+-----------------------------------+-----------------------------------------------------+
| **SCHEDULE TIME**                 | Frequency or time at which the query was scheduled  |
|                                   | to run.                                             |
+-----------------------------------+-----------------------------------------------------+
| **XQL**                           | Whether the query was created by XQL search.        |
+-----------------------------------+-----------------------------------------------------+

#### Manage your personal query library

Cortex XSIAM provides as part of the Query Library a personal query
library for saving and managing your own queries. When creating a query
in XQL Search or managing your queries from the Query Center, you can
save queries to your personal library. You can also decide whether the
query is shared with others (on the same tenant) in their Query Library
or unshare it, so it is only visible to you. You can also view the
queries that are shared by others (on the same tenant) in your Query
Library.

The queries listed in your Query Library have different icons to help
you identify the different states of the queries:

- ![](media/rId2887.png){width="0.20833333333333334in"
  height="0.20833333333333334in"}Created by me and unshared.

- ![](media/rId2890.png){width="0.1762817147856518in"
  height="0.20833333333333334in"}Create by me and shared.

- ![](media/rId2893.png){width="0.18333333333333332in"
  height="0.20833333333333334in"}Created by someone else and shared.

The Query Library contains a powerful search mechanism that enables you
to search in any field related to the query, such as the query name,
description, creator, query text, and labels. In addition, adding a
label to your query enables you to search for these queries using these
labels in the Query Library.

**How to add a query to your personal query library**

1.  Save a query to your personal query library.

- You can do this in two ways:

  - **From the Query Builder**

    1.  Select Investigation & Response \> Search \> Query Builder \>
        XQL.

    2.  In the XQL query field, define the parameters of your query.

    3.  Select Save as \> Query to Library.

  - **From the Query Center**

    1.  Select Investigation & Response \> Search \> Query Center.

    2.  Locate the query that you want to save to your personal query
        library.

    3.  Right-click anywhere in the query row, and select
        **Save query to library**.

2.  Set these parameters.

    - **Query Name**: Specify a unique name for the query. Query names
      must be unique in both private and shared lists, which includes
      other people's queries.

    - **Query Description** (*Optional*): Specify a descriptive name for
      your query.

    - **Labels** (*Optional*): Specify a label that is associated with
      your query. You can select a label from the list of predefined
      labels or add your label and then select **Create Label**. Adding
      a label to your query enables you to search for queries using this
      label in the Query Library.

    - **Share with others**: You can either set the query to be private
      and only accessible by you (default) or move the toggle to
      **Share with others** the query, so that other users using the
      same tenant can access the query in their Query Library.

3.  Click **Save**.

- A notification appears confirming that the query was saved
  successfully to the library, and closes on its own after a few
  seconds.

  The query that you added is now listed as the first entry in the
  **Query Library**. The query editor is opened to the right of the
  query.

4.  Other available options.

- As needed, you can return to your queries in the **Query Library** to
  manage your queries. Here are the actions available to you.

  - Edit the name, description, labels, and parameters of your query by
    selecting the query from the **Query Library**, hovering over the
    line in the query editor that you want to edit, and selecting the
    edit icon to edit the text.

  - **Search query data and metadata**: Use the Query Library's powerful
    search mechanism that enables you to search in any field related to
    the query, such as the query name, description, creator, query text,
    and label. The **Search query data and metadata** field is available
    at the top of your list of queries in the **Query Library**.

  - **Show**: Filter the list of queries from the **Show** menu. You can
    filter by the **Palo Alto Networks** queries provided with Cortex
    XSIAM , filter by the queries **Created by Me**, or filter by the
    queries **Created by Others**. To view the entire list,
    **Select all** (default).

  - **Save as new**: Duplicate the query and save it as a new query.
    This action is available from the query menu by selecting the 3
    vertical dots.

  - **Share with others**: If your query is currently unshared, you can
    share with other users on the same tenant your query, which will be
    available in their Query Library. This action is only available from
    the query menu by selecting the 3 vertical dots when your query is
    unshared.

  - **Unshare**: If your query is currently shared with other users, you
    can **Unshare** the query and remove it from their Query Library.
    This action is only available from the query menu by selecting the 3
    vertical dots when your query is shared with others. You can only
    **Unshare** a query that you created. If another user created the
    query, this option is disabled in the query menu.

  - **Delete** the query. You can only delete queries that you created.
    If another user created the query, this option is disabled in the
    query menu when selecting the 3 vertical dots.

#### Legacy Query Builder

> **Note**
>
> We recommend using the Query Builder in **New mode** to take advantage
> of the Query Builder templates and the ability to search the full
> Cortex Data Model (XDM).
>
> In **Legacy mode**, the Query Builder searches predefined datasets
> only. To search the full XDM, switch to New mode or select XQL Search.

The **Legacy Query Builder** provides queries for the following types of
entities:

- **Process**: Search on process execution and injection by process
  name, hash, path, command line arguments, and more. See [Create
  process query](#UUID8f12835a780c89b8549e7e3760901f1c).

- **File**: Search on file creation and modification activity by file
  name and path. See [Create file
  query](#UUIDd6b444714083281aef441049d18a3b4a).

- **Network**: Search network activity by IP address, port, host name,
  protocol, and more. See [Create network
  query](#UUIDe226ac9a89a002def25ecf8696798a67).

- **Image Load**: Search on module load into process events by module
  IDs and more. See [Create image load
  query](#UUIDede3423c719908f416d95ccfcacd1ce9).

- **Registry**: Search on registry creation and modification activity by
  key, key value, path, and data. See [Create registry
  query](#UUID5e4463ac13f0cc615f8358540f70811c).

- **Event Log**: Search Windows event logs and Linux system
  authentication logs by username, log event ID (Windows only), log
  level, and message. See [Create event log
  query](#UUIDead70f11e1d66a6842584f732ccd000c).

- **Network Connections**: Search security event logs by firewall logs,
  endpoint raw data over your network. See [Create network connections
  query](#UUID220f668affbca82acce73f83317eb797).

- **Authentications**: Search on authentication events by identity,
  target outcome, and more. See [Create authentication
  query](#UUID762652ea2555b6ad9dd86c53ae56a015).

- **All Actions**: Search across all network, registry, file, and
  process activity by endpoint or process. See [Query across all
  entities](#UUIDaadbc5bf8d97ab878c30eb0a64e5a873).

The **Query Builder** also provides flexibility for both on-demand query
generation and scheduled queries.

##### Create authentication query

From the Query Builder, you can investigate authentication activity
across all ingested authentication logs and data.

Some examples of authentication queries you can run include:

- Authentication logs by severity

- Authentication logs by the event message

- Authentication logs for a specific source IP address

**How to build an authentication query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **AUTHENTICATION**.

3.  Enter the search criteria for the authentication query.

- By default, Cortex XSIAM will return the activity that matches all the
  criteria you specify. To exclude a value, toggle the `=` option to
  `=!`.

4.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or Run to run the query immediately and view the results
  in the Query Center.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

5.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create event log query

From the **Query Builder** you can search Windows and Linux event log
attributes and investigate event logs across endpoints with a Cortex XDR
agent installed.

Some examples of event log queries you can run include:

- Critical level messages on specific endpoints.

- Message descriptions with specific keywords on specific endpoints.

**How to build an event log query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **EVENT LOG**.

3.  Enter the search criteria for your Windows or Linux event log query.

- Define any event attributes for which you want to search. By default,
  Cortex XDR will return the events that match the attribute you
  specify. To exclude an attribute value, toggle the `=` option to `=!`.
  Attributes are:

  - **PROVIDER NAME**: The provider of the event log.

  - **USERNAME**: The username associated with the event.

  - **EVENT ID**: The unique ID of the event.

  - **LEVEL**: The event severity level.

  - **MESSAGE**: The description of the event.

  To specify an additional exception (match this value except), click
  the **+** to the right of the value and specify the exception value.

4.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Specify one or more of the following attributes: Use a pipe (**\|**)
  to separate multiple values.

  Use an asterisk (**\***) to match any string of characters.

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector.

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

5.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

6.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the
  page, and a notification is sent when the query completes. You can
  also **Cancel** the query or run a new query, where you have the
  option to **Run only new query (cancel previous)** or
  **Run both queries**.

7.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create file query

From the **Query Builder** you can investigate connections between file
activity and endpoints. The Query Builder searches your logs and
endpoint data for the file activity that you specify. To search for
files on endpoints instead of file-related activity, build an XQL query.
For more information, see [How to build XQL
queries](#UUID125805d7e53750e71a87cb4c4140fa73).

Some examples of file queries you can run include:

- Files modified on specific endpoints.

- Files related to process activity that exist on specific endpoints.

**How to build a file query**

1.  From Cortex XSIAM, select Investigation & Response \> Search \>
    Query Builder.

2.  Select **FILE**.

3.  Enter the search criteria for the file events query.

    - File activity: Select the type or types of file activity you want
      to search: **All**, **Create**, **Read**, **Rename**, **Delete**,
      or **Write**.

    - File attributes: Define any additional process attributes for
      which you want to search. Use a pipe (`|`) to separate multiple
      values (for example `notepad.exe|chrome.exe`). By default, Cortex
      XSIAM will return the events that match the attribute you specify.
      To exclude an attribute value, toggle the `=` option to `=!`.
      Attributes are:

      - **NAME**: File name.

      - **PATH**: Path of the file.

      - **PREVIOUS NAME**: Previous name of a file.

      - **PREVIOUS PATH**: Previous path of the file.

      - **MD5**: MD5 hash value of the file.

      - **SHA256**: SHA256 hash value of the file.

      - **ACTION_DISK_DRIVER_NAME**: The driver where the file was
        created.

      - **FILE_SYSTEM_TYPE**: Operating system type where the file was
        run.

      - **ACTION_IS_VFS**: Denotes if the file is on a virtual file
        system on the disk. This is relevant only for files that are
        written to disk.

      - **DEVICE TYPE**: Type of device used to run the file: Unknown,
        Fixed, Removable Media, CD-ROM.

      - **DEVICE SERIAL NUMBER**: Serial number of the device type used
        to run the file.

    <!-- -->

    - To specify an additional exception (match this value except),
      click the **+** to the right of the value and specify the
      exception value.

4.  (*Optional*) Limit the scope to a specific acting process:

- Select **+PROCESS** and specify one or more of the following
  attributes for the acting (parent) process.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  - **NAME**: Name of the parent process.

  - **PATH**: Path to the parent process.

  - **CMD**: Command-line used to initiate the process, including any
    arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the process.

  - **SHA256**: SHA256 hash value of the process.

  - **USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signature
    Unavailable, Signed, Invalid Signature, Unsigned, Revoked, Signature
    Fail.

  - **SIGNER**: Entity that signed the certificate of the parent
    process.

  - **PID**: Process ID of the parent process.

  - **Run search for process, Causality, and OS actors**---The causality
    actor---also referred to as the causality group owner (CGO)---is the
    parent process in the execution chain that the Cortex XDR agent
    identified as being responsible for initiating the process tree. The
    OS actor is the parent process that creates an OS process on behalf
    of a different indicator. By default, this option is enabled to
    apply the same search criteria to initiating processes. To configure
    different attributes for the parent or initiate the process, clear
    this option.

5.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Select **+Host** and specify one or more of the following attributes:

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  <!-- -->

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector.

  <!-- -->

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create image load query

From the Query Builder, you can investigate connections between image
load activity, acting processes, and endpoints.

Some examples of image load queries you can run include:

- Module load into process events by module path or hash.

**How to build an image load query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **IMAGE LOAD**.

3.  Enter the search criteria for the image load activity query.

    - Type of image activity: **All**, **Image Load**, or
      **Change Page Protection**.

    - Identifying information about the image module: Full
      **Module Path**, **Module MD5**, or **Module SHA256**.

- By default, Cortex XSIAM will return the activity that matches all the
  criteria you specify. To exclude a value, toggle the `=` option to
  `=!`.

4.  (*Optional*) To limit the scope to a specific source, click the
    **+** to the right of the value and specify the exception value.

- Specify one or more attributes for the source.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  - **NAME**: Name of the parent process.

  - **PATH**: Path to the parent process.

  - **CMD**: Command-line used to initiate the process, including any
    arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the process.

  - **SHA256**: SHA256 hash value of the process.

  - **USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signature
    Unavailable, Signed, Invalid Signature, Unsigned, Revoked, Signature
    Fail.

  - **SIGNER**: Entity that signed the certificate of the parent
    process.

  - **PID**: Process ID of the parent process.

  **Run search for both the process and the Causality actor**: The
  causality actor---also referred to as the causality group owner
  (CGO)---is the parent process in the execution chain that the app
  identified as being responsible for initiating the process tree.
  Select this option if you want to apply the same search criteria to
  the causality actor. If you clear this option, you can then configure
  different attributes for the causality actor.

5.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Specify one or more of the following attributes: Use a pipe (**\|**)
  to separate multiple values.

  Use an asterisk (**\***) to match any string of characters.

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  <!-- -->

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector.

  <!-- -->

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create network connections query

From the Query Builder, you can investigate network events stitched
across endpoints and the Palo Alto Networks Next-Generation Firewall
logs.

Some examples of a network query you can run include:

- Source and destination of a process.

- Network connections that included a specific App ID

- Processes that created network connections.

- Network connections between specific endpoints.

**How to build a network connection query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **NETWORK CONNECTIONS**.

3.  Enter the search criteria for the network events query.

    - Network attributes: Define any additional process attributes for
      which you want to search. Use a pipe (`|`) to separate multiple
      values (for example `80|8080`). By default, Cortex XSIAM will
      return the events that match the attribute you specify. To exclude
      an attribute value, toggle the `=` option to `=!`. Options are:

      - **APP ID**: App ID of the network.

      - **PROTOCOL**: Network transport protocol over which the traffic
        was sent.

      - **SESSION STATUS**

      - **FW DEVICE NAME**: Firewall device name.

      - **FW RULE**: Firewall rule.

      - **FW SERIAL ID**: Firewall serial ID.

      - **PRODUCT**

      - **VENDOR**

    <!-- -->

    - To specify an additional exception (match this value except),
      click the **+** to the right of the value and specify the
      exception value.

4.  (*Optional*) To limit the scope to a specific source, click the
    **+** to the right of the value and specify the exception value.

- Specify one or more attributes for the source.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  - **HOST NAME**: Name of the source.

  - **HOST IP**: IP address of the source.

  - **HOST OS**: Operating system of the source.

  - **PROCESS NAME**: Name of the process.

  - **PROCESS PATH**: Path to the process.

  - **CMD**: Command-line used to initiate the process, including any
    arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the process.

  - **SHA256**: SHA256 hash value of the process.

  - **PROCESS USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signature
    Unavailable, Signed, Invalid Signature, Unsigned, Revoked, Signature
    Fail.

  - **PID**: Process ID of the parent process.

  - **IP**: IP address of the process.

  - **PORT**: Port number of the process.

  - **USER ID**: ID of the user who executed the process.

  - **Run search for both the process and the Causality actor**: The
    causality actor---also referred to as the causality group owner
    (CGO)---is the parent process in the execution chain that the app
    identified as being responsible for initiating the process tree.
    Select this option if you want to apply the same search criteria to
    the causality actor. If you clear this option, you can then
    configure different attributes for the causality actor.

5.  (*Optional*) Limit the scope to a destination.

- Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  Specify one or more of the following attributes:

  - **REMOTE IP**: IP address of the destination.

  - **COUNTRY**: Country of the destination.

  - Destination **TARGET HOST**,**NAME**, **PORT**, **HOST NAME**,
    **PROCESS USER NAME**, **HOST IP**, **CMD**, **HOST OS**, **MD5**,
    **PROCESS PATH**, **USER ID**, **SHA256**, **SIGNATURE**, or **PID**

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create network query

From the Query Builder, you can investigate connections between network
activity, acting processes, and endpoints.

Some examples of a network query you can run include:

- Network connections to or from a specific IP address and port number.

- Processes that created network connections.

- Network connections between specific endpoints.

**How to build a network query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **NETWORK**.

3.  Enter the search criteria for the network events query.

    - Network traffic type: Select the type or types of network traffic
      issues you want to search: **Incoming**, **Outgoing**, or
      **Failed**.

    - Network attributes: Define any additional process attributes for
      which you want to search. Use a pipe (`|`) to separate multiple
      values (for example `80|8080`). By default, Cortex XSIAM will
      return the events that match the attribute you specify. To exclude
      an attribute value, toggle the `=` option to `=!`. Options are:

      - **REMOTE COUNTRY**: Country from which the remote IP address
        originated.

      - **REMOTE IP**: Remote IP address related to the communication.

      <!-- -->

      - > **Note**

        > When you run the query, depending on the outcome of the
        > results, the value specified in this field might be displayed
        > in the `dst_ip` field in the query results. This occurs if an
        > RDP event is recorded whereby a user connected from the source
        > IP to the destination IP.

      <!-- -->

      - **REMOTE PORT**: Remote port used to make the connection.

      - **LOCAL IP**: Local IP address related to the communication.
        Matches can return additional data if a machine has more than
        one NIC.

      - **LOCAL PORT**: Local port used to make the connection.

      - **PROTOCOL**: Network transport protocol over which the traffic
        was sent.

    <!-- -->

    - To specify an additional exception (match this value except),
      click the **+** to the right of the value and specify the
      exception value.

4.  (*Optional*) To limit the scope to a specific source, click the
    **+** to the right of the value and specify the exception value.

- Specify one or more attributes for the source.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  - **NAME**: Name of the parent process.

  - **PATH**: Path to the parent process.

  - **CMD**: Command-line used to initiate the process, including any
    arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the process.

  - **SHA256**: SHA256 hash value of the process.

  - **USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signature
    Unavailable, Signed, Invalid Signature, Unsigned, Revoked, Signature
    Fail.

  - **SIGNER**: Entity that signed the certificate of the parent
    process.

  - **PID**: Process ID of the parent process.

  - **Run search for process, Causality, and OS actors**: The causality
    actor---also referred to as the causality group owner (CGO)---is the
    parent process in the execution chain that the Cortex XDR agent
    identified as being responsible for initiating the process tree. The
    OS actor is the parent process that creates an OS process on behalf
    of a different indicator. By default, this option is enabled to
    apply the same search criteria to initiating processes. To configure
    different attributes for the parent or initiate the process, clear
    this option.

5.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Specify one or more of the following attributes: Use a pipe (**\|**)
  to separate multiple values.

  Use an asterisk (**\***) to match any string of characters.

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector.

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create process query

From the **Query Builder** you can investigate connections between
processes, child processes, and endpoints.

For example, you can create a process query to search for processes
executed on a specific endpoint.

**How to build a process query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **PROCESS**.

3.  Enter the search criteria for the process query.

    - Process action: Select the type of process action you want to
      search: On process **Execution** or **Injection** into another
      process.

    - Process attributes---Define any additional process attributes for
      which you want to search.

    <!-- -->

    - Use a pipe (`|`) to separate multiple values. Use an asterisk
      (`*`) to match any string of characters.

      By default, Cortex XSIAM will return results that match the
      attribute you specify. To exclude an attribute value, toggle the
      operator from `=` to `!=`. Attributes are:

      - **NAME**: Name of the process. For example, `notepad.exe`.

      - **PATH**: Path to the process. For example,
        `C:\windows\system32\notepad.exe`.

      - **CMD**: Command-line used to initiate the process including any
        arguments, up to 128 characters.

      - **MD5**: MD5 hash value of the process.

      - **SHA256**: SHA256 hash value of the process.

      - **USER NAME**: User who executed the process.

      - **SIGNATURE**: Signing status of the process: Signature
        Unavailable, Signed, Invalid Signature, Unsigned, Revoked,
        Signature Fail.

      - **SIGNER**: Signer of the process.

      - **PID**: Process ID.

      - **PROCESS_FILE_INFO**: Metadata of the process file, including
        file property details, file entropy, company name, encryption
        status, and version number.

      - **PROCESS_SCHEDULED_TASK_NAME**: Name of the task scheduled by
        the process to run in the Task Scheduler.

      - **PROCESS_TOKEN_INFORMATION**: Bitwise token of the process
        privileges.

      - **DEVICE TYPE**: Type of device used to run the process:
        Unknown, Fixed, Removable Media, CD-ROM.

      - **DEVICE SERIAL NUMBER**: Serial number of the device type used
        to run the process.

      To specify an additional exception (match this value except),
      click the **+** to the right of the value and specify the
      exception value.

4.  (*Optional*) Limit the scope to a specific acting process:

- Select **+PROCESS** and specify one or more of the following
  attributes for the acting (parent) process.

  - **NAME**: Name of the parent process.

  - **PATH**: Path to the parent process.

  - **CMD**: Command-line used to initiate the parent process including
    any arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the parent process.

  - **SHA256**: SHA256 hash value of the process.

  - **USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signed,
    Unsigned, N/A, Invalid Signature, Weak Hash

  - **SIGNER**: Entity that signed the certificate of the parent
    process.

  - **PID**: Process ID of the parent process.

  - **Run search on process, Causality and OS actors**: The causality
    actor---also referred to as the causality group owner (CGO)---is the
    parent process in the execution chain that the Cortex XDR agent
    identified as being responsible for initiating the process tree. The
    OS actor is the parent process that creates an OS process on behalf
    of a different initiator. By default, this option is enabled to
    apply the same search criteria to initiating processes. To configure
    different attributes for the parent or initiate a process,

5.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Select **+HOST** and specify one or more of the following attributes:

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  <!-- -->

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector. For more information about the data collector applet,
    [Activate Pathfinder](#UUIDedfbabf66d30717d0d0ef54801b8cf35).

  <!-- -->

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Create registry query

From the Query Builder you can investigate connections between registry
activity, processes, and endpoints.

Some examples of a registry query you can run include:

- Modified registry keys on specific endpoints.

- Registry keys related to process activity that exist on specific
  endpoints.

**How to build a registry query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **REGISTRY**.

3.  Enter the search criteria for the registry events query.

    - Registry action: Select the type or types of registry actions you
      want to search: **Key Create**, **Key Delete**, **Key Rename**,
      **Value Set**, or **Value Delete**.

    - Registry attributes: Define any additional registry attributes for
      which you want to search. By default, Cortex XSIAM will return the
      events that match the attribute you specify. To exclude an
      attribute value, toggle the `=` option to `=!`. Attributes are:

      - **KEY NAME**: Registry key name.

      <!-- -->

      - > **Important**

        > Ensure the **KEY NAME** is entered as a real registry key
        > name, and not as a symbolic link. Otherwise, the query will
        > not retrieve results.

        > Instead of `HKEY_LOCAL_MACHINE\System\CurrentControlSet`,
        > which is a symbolic link, use
        > `KEY_LOCAL_MACHINE\System\ControlSet001`.

        > Instead of `HKEY_CURRENT_USER`, use `HKEY_USERS\<SID>`, where
        > SID is either a SID of the current user or an asterisk (`*`)
        > to represent any SID.

      <!-- -->

      - **DATA**: Registry key data value.

      - **KEY PREVIOUS NAME**: Name of the registry key before
        modification.

      - **VALUE NAME**: Registry value name.

    <!-- -->

    - To specify an additional exception (match this value except),
      click the **+** to the right of the value and specify the
      exception value.

4.  (*Optional*) To limit the scope to a specific source, click the
    **+** to the right of the value and specify the exception value.

- Specify one or more attributes for the source.

  Use a pipe (**\|**) to separate multiple values. Use an asterisk
  (**\***) to match any string of characters.

  - **NAME**: Name of the parent process.

  - **PATH**: Path to the parent process.

  - **CMD**: Command-line used to initiate the process including any
    arguments, up to 128 characters.

  - **MD5**: MD5 hash value of the process.

  - **SHA256**: SHA256 hash value of the process.

  - **USER NAME**: User who executed the process.

  - **SIGNATURE**: Signing status of the parent process: Signature
    Unavailable, Signed, Invalid Signature, Unsigned, Revoked, Signature
    Fail.

  - **SIGNER**: Entity that signed the certificate of the parent
    process.

  - **PID**: Process ID of the parent process.

  - **Run search for process, Causality, and OS actors**: The causality
    actor---also referred to as the causality group owner (CGO)---is the
    parent process in the execution chain that the Cortex XDR agent
    identified as being responsible for initiating the process tree. The
    OS actor is the parent process that creates an OS process on behalf
    of a different indicator. By default, this option is enabled to
    apply the same search criteria to initiating processes. To configure
    different attributes for the parent or initiate the process, clear
    this option.

5.  (*Optional*) Limit the scope to an endpoint or endpoint attributes:

- Specify one or more of the following attributes: Use a pipe (**\|**)
  to separate multiple values.

  Use an asterisk (**\***) to match any string of characters.

  - **HOST**: **HOST NAME**, **HOST IP** address, **HOST OS**,
    **HOST MAC ADDRESS**, or **INSTALLATION TYPE**.

  - **INSTALLATION TYPE** can be either Cortex XDR agent or Data
    Collector.

  - **PROCESS**: **NAME**, **PATH**, **CMD**, **MD5**, **SHA256**,
    **USER NAME**, **SIGNATURE**, or **PID**.

6.  Specify the time period for which you want to search for events.

- Options are **Last 24H** (hours), **Last 7D** (days), **Last 1M**
  (month), or select a **Custom** time period.

7.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or **Run** to run the query immediately and view the
  results in the **Query Center**.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

8.  When you are ready, view the results of the query. For more
    information, see [Review XQL query
    results](#UUID5d102247d2868bf6813913bc96b33623).

##### Query across all entities

From the **Query Builder** you can perform a simple search for hosts and
processes across all file events, network events, registry events,
process events, event logs for Windows, and system authentication logs
for Linux.

Some examples of queries you can run across all entities include:

- All activities on a host

- All activities initiated by a process on a host

**How to build a query**

1.  From Cortex XSIAM , select Investigation & Response \> Search \>
    Query Builder.

2.  Select **ALL ACTIONS**.

3.  (Optional) Limit the scope to a specific acting process:

- Select Add Process to your search, and specify one or more of the
  following attributes for the acting (parent) process. Use a pipe (\|)
  to separate multiple values. Use an asterisk (\*) to match any string
  of characters.

  -----------------------------------------------------------------------
  Field                               Description
  ----------------------------------- -----------------------------------
  NAME                                Name of the parent process.

  PATH                                Path to the parent process.

  CMD                                 Command line used to initiate the
                                      parent process including any
                                      arguments, up to 128 characters.

  MD5                                 MD5 hash value of the parent
                                      process.

  SHA256                              SHA256 hash value of the process.

  USER NAME                           User who executed the process.

  SIGNATURE                           Signing status of the parent
                                      process: Signed, Unsigned, N/A,
                                      Invalid Signature, Weak Hash.

  SIGNER                              Entity that signed the certificate
                                      of the parent process.

  PID                                 Process ID of the parent process.

  Run search on process, Causality    The causality actor, also referred
  and OS actors                       to as the causality group owner
                                      (CGO), is the parent process in the
                                      execution chain that the agent
                                      identified as being responsible for
                                      initiating the process tree. The OS
                                      actor is the parent process that
                                      creates an OS process on behalf of
                                      a different initiator. By default,
                                      this option is enabled to apply the
                                      same search criteria to initiating
                                      processes. To configure different
                                      attributes for the parent or
                                      initiating process, clear this
                                      option.
  -----------------------------------------------------------------------

4.  (Optional) Limit the scope to an endpoint or endpoint attributes:

- Select Add Host to your search and specify one or more of the
  following attributes:

  - HOST: HOST NAME, HOST IP address, HOST OS, HOST ADDRESS, or
    INSTALLATION TYPE.

  - INSTALLATION TYPE can be either an agent, or data collector.

  - PROCESS: NAME , PATH , CMD , MD5 , SHA256 , USER NAME , SIGNATURE,
    or PID.

  <!-- -->

  - Use a pipe (\|) to separate multiple values. Use an asterisk (\*) to
    match any string of characters.

5.  Specify the time period for which you want to search for events.

- Options are Last 24H (hours), Last7D (days), Last1M (month), or select
  a Custom time period.

6.  Choose when to run the query.

- Select the calendar icon to schedule a query to run on or before a
  specific date or Run the query immediately and view the results in the
  Query Center.

  While the query is running, you can always navigate away from the page
  and a notification is sent when the query completes. You can also
  **Cancel** the query or run a new query, where you have the option to
  **Run only new query (cancel previous)** or **Run both queries**.

7.  When ready, view the results in a query.

### Research a known threat

This topic describes the steps you can take to investigate a lead. A
lead can be:

- An issue from a non-Palo Alto Networks system with information
  relevant to endpoints or firewalls.

- Users or hosts that have been reported as acting abnormally.

- Information from online articles or other external threat intelligence
  that provides well-defined characteristics of the threat.

**To research a known threat**

1.  Use threat intelligence to build a Cortex Query Language (XQL) query
    using the Query Builder.

- For example, if external threat intelligence indicates a confirmed
  threat involving specific files or behaviors, search for those
  characteristics.

2.  Review and refine the query results by using filters and running
    follow-up queries to find the information you are looking for.

3.  Select an event of interest, and open the **Causality view**.

- Review the chain of execution and data, navigate through the processes
  on the tree, and analyze the information.

4.  Open the **Timeline** to view the sequence of events over time. If
    deemed malicious, take action using one or more of the response
    actions.

5.  Inspect the information again, and identify any characteristics you
    can use to create a BIOC or correlation rule.

- If you can create a BIOC or correlation rule, test and tune it as
  needed. For more information, see
  [/document/preview/1045838#UUID-771cc82c-35a2-bdf2-1d98-5045b3dd0606](/document/preview/1045838#UUID-771cc82c-35a2-bdf2-1d98-5045b3dd0606)
  and [Create a BIOC rule](#UUID6eb23f2cdfe9d7861a5637e0c7c89f0b).

